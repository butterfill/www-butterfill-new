---
title: Joint Action Goals Reduce Visuomotor Interference Effects from a
  Partner’s Incongruent Actions
authors: Sam Clarke, Luke McEllin, Anna Francová, Marcell Székely, Stephen A.
  Butterfill and John Michael
type: Publication
collection: writing
slug: writing/clarke2019_joint
url: /writing/clarke2019_joint/
summary: Joint actions often require agents to track others’ actions while
  planning and executing physically incongruent actions of their own. Previous
  research has indicated that this can lead to visuomotor interference effects
  when it occurs outside of joint action. How is this avoided or overcome in
  joint actions?
year: 2019
source: src/content/writing/clarke2019_joint.md
---

# Abstract

Joint actions often require agents to track others’ actions while planning and executing physically incongruent actions of their own. Previous research has indicated that this can lead to visuomotor interference effects when it occurs outside of joint action. How is this avoided or overcome in joint actions? We hypothesized that when joint action partners represent their actions as interrelated components of a plan to bring about a joint action goal, each partner’s movements need not be represented in relation to distinct, incongruent proximal goals. Instead they can be represented in relation to a single proximal goal – especially if the movements are, or appear to be, mechanically linked to a more distal joint action goal. To test this, we implemented a paradigm in which participants produced finger movements that were either congruent or incongruent with those of a virtual partner, and either with or without a joint action goal (the joint flipping of a switch, which turned on two light bulbs). Our findings provide partial support for the hypothesis that visuomotor interference effects can be reduced when two physically incongruent actions are represented as mechanically interdependent contributions to a joint action goal.
  

# Joint action goals reduce visuomotor interference effects from a partner’s incongruent actions  

Joint actions often require agents to track others’ actions while planning and executing physically incongruent actions of their own. Previous research has indicated that this can lead to visuomotor interference effects when it occurs outside of joint action. How is this avoided or overcome in joint actions? We hypothesized that when joint action partners represent their actions as interrelated components of a plan to bring about a joint action goal, each partner’s movements need not be represented in relation to distinct, incongruent proximal goals. Instead they can be represented in relation to a single proximal goal – especially if the movements are, or appear to be, mechanically linked to a more distal joint action goal. To test this, we implemented a paradigm in which participants produced finger movements that were either congruent or incongruent with those of a virtual partner, and either with or without a joint action goal (the joint flipping of a switch, which turned on two light bulbs). Our findings provide partial support for the hypothesis that visuomotor interference effects can be reduced when two physically incongruent actions are represented as mechanically interdependent contributions to a joint action goal.  

From handshakes to music-making, dance and team sports, social interactions often require an efficient means of tracking others’ actions while simultaneously planning and executing actions of one’s own1. A basketball player, for example, must monitor and anticipate her teammate’s movements in order to successfully contribute to a pick and roll play.  

Given the broad range of social interactions in which it is important to anticipate, monitor and respond to others’ actions, it is no surprise that a considerable amount of research has been devoted to investigating how we achieve this2–5. An influential idea that has emerged is that the representation of others’ actions is often supported by one’s own motor system, implying that representations of others’ actions are often functionally equivalent to the representations involved in action production $^{2-4,6,7}$ . As a result, the observation of others’ actions can result in action representations that do not clearly distinguish self from other8–10.  

An upshot is that the observation of others’ actions can give rise to representations that interfere with one’s own task performance. In a striking illustration of this, Brass et al.2 found that participants who were instructed to produce finger movements in response to symbolic cues responded more quickly when simultaneously observing irrelevant finger movements that were physically congruent to the ones they were instructed to produce, and more slowly when simultaneously observing irrelevant finger movements that were physically incongruent to these. These findings – and others that build on them11–13 – are taken to indicate that, when observing others’ actions, we automatically represent those actions using motor representations of the same type as those subserving action production.  

This neatly explains why the observation of congruent actions facilitates task performance, while the observation of incongruent actions leads to visuomotor interference effects. However, it also raises a challenge. This is because many joint actions require individuals to produce physically incongruent yet complementary actions14.  

![](public/img/articles/clarke2019_joint/b167ef5857e70a74d3ea3d887fa9189cc71e08eca40b84f06a76ad4a211da543.jpg)  
Figure 1.  Two physically incongruent actions become part of a larger Joint Action plan. If there is no need to represent the other partner’s incongruent action (i.e. if the agent can produce their contribution to the joint action without taking their partner’s behaviour into account), then this may allow agents to bypass the representation of a partner’s actions altogether, allowing interference effects to be reduced or avoided. However, when one agent has to select an action based on which action their partner performs, their individual action cannot be represented only in terms of the more distal joint action or its goal.  

A proficient basketball player, for example, may need to coordinate her movement towards the basket with her teammate’s passing of the ball. But if tracking her teammate’s action elicits motor representations that compete with those underpinning the action she herself must perform, then they may interfere with her own action preparation. In more general terms: where the tracking of others’ actions involves motor representations that are functionally equivalent to the representations underpinning action production, this could give rise to interference effects and prove counter-productive in many cases of joint action.  

This problem can, however, be overcome. In a recent paper by Sacheli, Arcangeli, & Paulesu15 participants played learned melodies with, or merely alongside, a virtual partner. In both cases, this required them to sequentially produce actions that were either physically congruent (e.g. point-point) or physically incongruent to those that had just been produced by the partner (e.g. point-grasp). When participants and their partners performed these actions alongside one another (i.e. in a Non-Interactive Condition) performance was affected by the physical (in)congruence of the movements, as expected. But, when these actions were directed towards a joint action goal (i.e. the joint production of a single melody in a Joint Action Condition), physical congruence became irrelevant: task performance was affected by a reversal in movement-note associations, but not by the congruence or incongruence of the two agents’ movements. This raises the question: why would doing something in the context of a joint action eliminate interference from the perception of incongruent movements but create interference from the perception of anomalous sounds?  

Sacheli et al's proposed answer is that the representation of a joint action goal enables joint action partners to integrate representations of their own and their partner’s actions within a single dyadic (multi-person) motor plan15. As they put it, this dyadic motor plan enables agent’s to select appropriate responses to their partner’s actions on the basis of their predicted outcomes (e.g. the production of a musical note). This explains why anomalous movement-note associations would have generated interference in their study. However, it does not appear to explain why the joint action frame would have reduced interference from physically incongruent movements. In principle, integrating representations of incongruent movements within a larger motor plan could have increased interference effects instead16.  

One possibility, left open by the aforementioned study, is that a joint action frame may lead participants to represent their partner’s actions in relation to a more distal joint action goal (i.e. a string of musical notes) instead of the more proximal goals that bring this about (i.e. grasping or pointing). In cases where the physical incongruence of the actions only obtains at the level of these more proximal goals, this might allow agents to bypass the representation of their partners’ physically incongruent movements altogether, reducing or eliminating visuomotor interference effects (See Fig. 1). The trouble is: there seem to be cases of joint action where it is not sufficient to bypass the representation of a partner’s proximal goal altogether and to merely consider the more distal outcome of the joint action goal. Rather, as illustrated by the basketball players mentioned above, it is often necessary to represent the more proximal goals of a partner’s action in order to select actions that would complement these with respect to the more distal joint action goal. Indeed, this can be true of even the most basic motor movements involved. Thus, basic questions remain. Specifically: can the introduction of a distal joint action goal reduce visuomotor interference effects in cases where incongruent proximal goals are contingently related to one another, and attention to these is required for the selection of appropriate motor movements? And, if so, how might this be achieved?  

![](public/img/articles/clarke2019_joint/2ce08eda33eca62224a293e71a0c157330240c67bd5c7e88f6cd27a6749bb08a.jpg)  
Figure 2.  Where one agent has to select an action based on which action the other performs, interference effects may be reduced if the agent can represent both actions as interrelated components of a single goal and not only in terms of the more distal goal (e.g. passing the ball, in a pick and roll play).  

In addressing the latter question, a natural starting point is the observation that action production typically involves the simultaneous representation of multiple, instrumentally related actions at multiple, instrumentally related levels of abstraction17–20. For example, we represent the action of turning the steering wheel not only at the level of the comparably distal goal (turned steering wheel) but also at the level of comparatively proximal goals, designed to bring this about (e.g. raised left arm; lowered right arm). Importantly, this hierarchical structure must capture instrumental relations between these different goals. Plainly, proximal goals must function to bring about comparatively distal goals. But, in addition to this, the comparatively proximal goals must (themselves) be sensitive to each other such that a modification to one will lead others to change appropriately. For instance, one need not bother moving one’s arms if one is no longer grasping the wheel; and even when one is grasping the wheel, it may be no use raising one’s left arm if one does not simultaneously lower one’s right arm.  

Here, the individual agent must simultaneously produce physically incongruent movements (arm lifting and arm lowering). But, in this case, it is not possible to avoid motoric interference by simply considering each arm’s movement independently of the other, or by simply considering the more distal goal outcome to which these are both directed (a turned wheel). This is because all of these goals are interrelated. Thus, the introduction of the more distal goal must change the way in which the more proximal goals are represented. Specifically, it must lead to their representation as interrelated, and not simply independent contributions to a larger action.  

This raises the possibility that the actions of our joint action partners can be represented in relation to the same action hierarchy (See Fig. 2). Here, the introduction of a comparably distal joint action goal might enable the physically incongruent movements of self and other to be represented as interrelated components of a plan to bring about the joint action goal. If this is possible, then it might reduce or even eliminate interference from the observation of a partner’s physically incongruent movements, even when success in joint action requires one’s selective response to these. Thus, we hypothesise that where agents represent their actions as interrelated components of a plan to bring about a joint action goal, each partner’s movements need not always be represented in relation to distinct, incongruent proximal goals. Instead, they might be represented as interrelated contributions to a single goal. If true, the joint action frame could potentially reduce or even eliminate visuomotor interference effects arising from the observation of what an outsider might take to be a physically incongruent action.  

To test this, we adapted Brass and colleagues’12 paradigm to incorporate a joint action goal, namely turning on two light bulbs by jointly flicking a switch. Here, participants were required to perform one of two finger-lifting movements depending on which numerical cue was presented on a screen, in between a virtual partner’s index and middle fingers (See Fig. 3). These movements could be physically congruent or physically incongruent with a movement performed by the virtual partner. In a Joint Action Goal Condition, lightbulbs were turned on when the participant and the partner simultaneously performed physically incongruent actions, but not when they performed physically congruent actions (something about which our hypothesis makes no predictions). In the Individual Goal Condition, the lights were never turned on (i.e. there was no joint action goal). We reasoned that if participants are able to utilize the joint action goal (turning on the lightbulbs) to represent a planning structure in which their partner’s movement forms a complementary and mutually interrelated contribution, then the physical incongruence of their own and the partner’s movement should be less relevant. This generates the prediction that we should observe reduced visuomotor interference effects in the Joint Action Goal Condition compared to the Individual Goal Condition. In other words, the difference in response times between Congruent trials (wherein the participant and the partner lift the same fingers) and Incongruent trials (wherein the participant and the partner lift different fingers) should be smaller in the Joint Action Goal Conditions than in the Individual Goal Condition.  

![](public/img/articles/clarke2019_joint/d75395a848b5add6a8f3181ec24e0a3e20bb0d29a2c7d5258c059f67da47a62f.jpg)  
Figure 3.  Illustration of the task. Participants were instructed to lift the same finger as the hand in the video when a ‘1’ is displayed (Congruent Condition) and to lift the other finger when a $\cdot_{2},$ is displayed (Incongruent Condition). The left side illustrates the Individual Goal Condition, in which the lights never turn on. The right side illustrates the Joint Action Goal Condition, in which the lights are turned on when two conditions are fulfilled: the number cue $(^{\leftarrow}2^{>})$ indicates that the participant should perform the ‘incongruent’ action, and the participant correctly does so.  

The predictions, sample size, methods, and planned analyses were all pre-registered before data collection and can be accessed at: http://aspredicted.org/blind.php? $\mathbf{X}{=}$ cr4cg2. Unless otherwise noted, we implemented all steps as pre-registered.  

# Results  

To control for speed-accuracy tradeoffs, reaction time (RT) for correct responses and hit rates (HR) were merged into inverse efficiency scores (IES), a combined measure which homogenizes different patterns of speed-accuracy trade-offs $(\mathrm{IES})^{21}$ , by dividing RTs by accuracy for each condition in each group (lower scores mean more efficient responses). We also analyzed the participants’ RT’s.  

For the IES, we conducted a $2\times2\times2$ mixed ANOVA with Jointness (Joint vs Individual Action Goal) and Congruence (Congruent vs Incongruent) as within participants factors, and Group (Joint First, Joint Last) as a between participants factor. The ANOVA revealed a significant main effect of Congruence $F(1,70)=44.41$ , $p90\%)$ , meaning that it is likely that they did not understand the instructions and that their data cannot be relied on. Secondly, we excluded any participants with an overall accuracy more than $2.5\mathrm{SD}$ below the group mean (either Joint First group or Joint Last group) from all our analyses, as their data is likely unreliable. This resulted in the exclusion of 480 trials $(7.6\%)$ or 3 participants from the Joint First group, and 480 trials $(7.6\%)$ or 3 participants from the Joint Last group. Secondly, we excluded 72 $(1.1\%)$ premature responses (responses before the stimulus onset) from the Joint First group, and 58 $\left(0.9\%\right)$ premature responses from the Joint Last group, from all of our analysis. Thirdly, 147 $(2.3\%)$ trials with RTs more than 2.5 standard deviations (SDs) removed from the mean (calculated for each participant for each condition) were excluded from the Joint First group, and 128 trials $(2.1\%)$ were excluded from the Joint Last group. Finally, 240 trials $\left(3.9\%\right)$ incorrect responses for the Joint First group, and 297 trials $\left(4.7\%\right)$ from the Joint Last group were excluded from the RTs. Although these criteria were not pre-registered, we determined to apply them prior to analysing any data. Our rationale was that the hypothesis being tested pertained to the processes engaged when people perform actions while perceiving a physically incongruent action from a joint action partner; on trials on which participants committed errors, we could not be confident that these processes were actually engaged.  

For each participant, we calculated the mean RT’s and accuracy (proportion correct), for congruent and incongruent trials for each condition (see Supplementary File for means per condition). We divided the RTs by the accuracy in order to compute Inverse Efficiency Scores $(\mathrm{IES})^{21}$ as an index of efficiency, appropriately weighting speed and accuracy.  

# References  

1.	 Hassin, R. R., Aarts, H. & Ferguson, M. Automatic goal inferences. Journal of Experimental Social Psychology. 41(2), 129–40 (2005).   
2.	 Brass, M., Bekkering, H., Wohlschläger, A. & Prinz, W. Compatibility between Observed and Executed Finger Movements: Comparing Symbolic, Spatial, and Imitative Cues. Brain and Cognition. 44, 124–143 (2000).   
3.	 Kilner, J. M., Paulignan, Y. & Blakemore, S. J. An interference effect of observed biological movement on action. Current Biology. 13(6), 522–5 (2003).   
4.	 Sebanz, N., Knoblich, G. & Prinz, W. Representing others’ actions: just like one’s own? Cognition. 88, B11–B21 (2003).   
5.	 Ramsey, R. What are reaction time indices of automatic imitation measuring? Consciousness & Cognition. 65, 240–54 (2018).   
6.	 Craighero, L., Fadiga, L., Umiltà, C. A. & Rizzolatti, G. Evidence for visuomotor priming effect. Neuroreport. 8, 347–349 (1996).   
7.	 Craighero, L., Fadiga, L., Rizzolatti, G. & Umiltà, C. A. Visuomotor priming. Visual Cognition. 5, 347–349 (1998).   
8.	 Jeannerod, M. & Pacherie, E. Agency, Simulation and Self-identification. Mind & Language. 19(2), 113–46 (2004).   
9.	 Prinz, W. Perception and Action Planning. European Journal of Cognitive Psychology. 9, 129–54 (1997).   
10. Rizzolatti, G. & Sinigaglia, C. The functional role of the parieto-frontal mirror circuit: interpretations and misinterpretations. Nature Reviews Neuroscience. 11(4), 264–74 (2010).   
11. Stirmer, B., Aschersleben, G. & Prinz, W. Corresponce effects with manual gestures and postures: A study of imitation. Journal of Experimental Psychology: Human Perception and Performance. 26(6), 1746–59 (2000).   
12. Brass, M., Bekkering, H. & Prinz, W. Movement observation affects movement execution in a simple response task. Acta Psychologica. 106(1–2), 3–22 (2001).   
13. Wang, Y., Ramsey, R. & Hamilton,A. F. The control of mimicry by eye contact is mediated by medial prefrontal cortex. Journal of Neuroscience. 31(33), 12001–10 (2011).   
14. Sartori, L. & Betti, S. Complementary actions. Frontiers in Psychology. 6(557) (2015).   
15. Sacheli, L.M,Arcangeli,E.&Palesu, E. Evidence for a dyadic motr plan in joint action. Scientifc Reports. 8, 5027, https:/di. org/10.1038/s41598-018-23275-9 (2018).   
16. della Gatta, F et al. Drawn together: When motor representations ground joint actions. Cognition. 165, 53-60 (2017).   
17. Candidi, M., Sacheli, L. M.&Aglioti, S. M.From muscles synergies and individual goals to interpersonal synergies and shared goals: mirror neurons and interpersonal action hierarchies: comment on “Grasping synergies: a motor-control approach to the mirror neuron mechanism” by D’Ausilio et al. Phys. Life Rev 12, 126–128 (2015).   
18. Chersi, F Neural mechanisms and models underlying joint action. Experimental brain research 211(3-4), 643-653 (2011).   
19. Kilner,J. M. More than one pathway to action understanding. Trends in Cognitive Sciences 15(8), 352-7 (2011).   
20. Grafton, S. T. & Hamilton, A. F. C. Evidence for a distributed hierarchy of action representation in the brain. Human Movement Science 26(4), 590–616 (2007).   
21. Bruyer, R. & Brysbaert, M. Combining speed and accuracy in cognitive psychology: Is the inverse efficiency score (IES) a better dependent variable than the mean reaction time (RT) and the percentage of errors (PE)? Psychologica Belgica 51(1), 5–13 (2011).   
22. Sacheli, L. M., Tieri, G., Aglioti, S. M. & Candidi, M. Transitory Inhibition of the Left Anterior Intraparietal Sulcus Impairs Joint Actions: A Continuous Theta-Burst Stimulation Study. Journal of Cognitive Neuroscience. 30(5), 737–51 (2018).   
23. Kovacs, A. J., Buchanan, J J & Shea, C. H. Bimanual 1: 1 with $90^{\circ}$ continuous relative phase: difficult or easy! Experimental Brain Research. 193(1), 129–136 (2009).   
24. Kennedy, D. M., Boyle,J B. &Shea, C. H. The role of auditory and visual models in the production of bimanual taping pattens. Experimental brain research. 224(4), 507–518 (2013).   
25. Kovacs, A. J,Buchanan,JJ &Shea,C. H. Impossible is nothing: 5: 3 and 4: 3 multi-frequency bimanual cordination Experimental brain research. 201(2), 249–259 (2010).   
26. Kovacs, A. J. & Shea, C. H. The learning of 90 continuous relative phase with and without Lisajous feedback: external and internally generated bimanual coordination. Acta psychologica. 136(3), 311–320 (2011).   
27. Faul F, Erdfelder, E,uchner, A.&Lang, A.G.Statistical power analyses sin $\mathrm{G}^{*}$ Power 3:1 tests for correlation and regression analyses. Behavioral Research Methods. 41(4), 1149–60 (2009).   
28. Mathot,S., Schreij, D. & Theeuwes, J. OpenSesame: An open-source, graphical experiment builder for the social sciences. Behavioral Research Methods. 44(2), 314–24 (2012).   
29. Cousineau, D. Confidence intervals in within-subject designs: A simpler solution to Loftus and Masson's method. Tutorials in Quantitative Methods for Psychology. 1(1), 42–45 (2005).   
30. Loftus, G. & Masson, M. Using confidence intervals in within-subject designs. Psychonomic Bulletin é Review. 1(4), 476-490 (1994).
