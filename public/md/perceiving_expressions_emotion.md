# Perceiving expressions of emotion: What evidence could bear on questions about perceptual experience of mental states?  


# abstract  

Keywords:   
Perceptual experience   
Social cognition   
Categorical perception   
Phenomenal expectations  

What evidence could bear on questions about whether humans ever perceptually experience any of another’s mental states, and how might those questions be made precise enough to test experimentally? This paper focusses on emotions and their expression. It is proposed that research on perceptual experiences of physical properties provides one model for thinking about what evidence concerning expressions of emotion might reveal about perceptual experiences of others’ mental states. This proposal motivates consideration of the hypothesis that categorical perception of expressions of emotion occurs, can be facilitated by information about agents’ emotions, and gives rise to phenomenal expectations. It is argued that the truth of this hypothesis would support a modest version of the claim that humans sometimes perceptually experience some of another’s mental states. Much available evidence is consistent with, but insufficient to establish, the truth of the hypothesis. We are probably not yet in a position to know whether humans ever perceptually experience others’ mental states.  


# 1. Introduction  

The trainer’s mind had wandered so far from the match that he had no idea who was winning until Blanche’s howl of victory rang through the stadium, seizing his attention. Her howl and accompanying aerial contortions revealed much about the category and intensity of her emotions. Afterwards he said he could see she’d won, could see her ecstasy in winning. How could we find out whether this is all merely a way of speaking or in part a literal description of a perceptual experience? More generally, what evidence might bear on questions about whether humans ever perceptually experience any of another’s mental states?  

In asking what evidence might bear on such questions I am presupposing, of course, that they have not yet been answered decisively. This is reasonable given recent interest in arguments whose modest aim is to show only that the view that humans can perceptually experience some mental states of subjects other than themselves is not obviously false (Smith, 2010; McNeill, 2012a, 2012b).  

In asking what evidence might bear on questions about perceptual experience of mental states, I am also presupposing that answering such questions will involve some people doing experiments. This may initially seem controversial given what may appear to be narrowly philosophical arguments for the view that humans can perceptually experience some mental states. However, those arguments quite often rest on unargued conjectures about the existence of certain perceptual states, looks, visual similarities or the like. To illustrate, Smith offers an argument which hinges on the conjecture that there are ‘visual states . . .[which] possess content that matches the causal profile’ of states such as a person’s happiness (2015; on what this amounts to, see Smith, 2010, Section 4). His argument and some other careful narrowly philosophical discussions might be charitably interpreted as providing frameworks for understanding claims about perceptual experience and mental states rather than as offering grounds for accepting or rejecting them.1 There may much that can be discovered without seeking experimental evidence. But to know whether the claims that matter most are true or false we will probably have to find experimental evidence that bears on questions about whether any humans ever perceptually experience others’ mental states.  

Note that the claims under consideration here are about perceptual experience; they are not claims about psychological mechanisms, nor about epistemology. (These distinctions are explained in the Introduction to this Special Issue, Michael & De Bruin, 2015.) These topics are probably related, however. One lesson from research on physical properties is that discoveries about psychological mechanisms can inform views about what can be perceptually experienced (see Section 4). And it is possible that answering questions about perceptual experience will somehow inform investigation of epistemological questions about whether perceiving is sometimes a way of knowing facts about another’s mental states. Nevertheless, my focus in this paper is perceptual experience.  

The aim of this paper is to identify evidence linked to expressions of emotion that bears on claims about perceptually experiencing others’ mental states, and, in so doing, to formulate a modest interpretation of the view that humans can sometimes perceptually experience others’ mental states. I start by describing the problem which motivates this work (in Section 2) and then outline some research on perceptual experiences of physical properties (in Section 4) which will serve as a model for thinking about what evidence concerning expressions of emotion might reveal about perceptual experiences of others’ mental states (in Section 6 onwards).  

# 2. The problem  

Some researchers appear to hold that mere verbal reports and explicit ratings are sufficient to show that humans can perceptually experience some mental properties of subjects other than themselves (see, for example, Schlottmann, Ray, Mitchell, & Demetriou, 2006, p. 135; Scholl & Tremoulet, 2000, p. 299). This would make it easy to confirm the hypothesis about the perception of mental states. After all, Heider and Simmel (1944, p. 257) famously demonstrated that people will, in describing what they see, spontaneously attribute motives and needs to animated polygons. As this suggests, many people are disposed to say things which, if literally true, would imply that they sometimes perceptually experience others’ mental states. Indeed, people will spontaneously say such things even when presented with stimuli which manifestly do not involve subjects of mental states.  

But can we really support claims about perceptual experience merely by measuring verbal reports? In the right situations people will also talk about seeing properties related to the market values or historical origins of physical objects. To infer from this that what humans can perceptually experience extends beyond the narrowly physical to include features related to an object’s scarcity, or that it extends beyond the present to include the past, would make sense only given an extremely broad notion of perceptual experience. Heider and Simmel were clearly operating with such a broad notion, for they stipulated that they use the word ‘perception’ ‘in the sense of cognitive response, i.e. as covering all cognitive processes which follow the exposure of a set of receptors to stimulation’ (Heider & Simmel, 1944, p. 243, Footnote 1). This is a way of saying that they are not concerned with perception at all.  

Compare the question, can humans perceptually experience categorical colours of physical objects in addition to particular shades? Can humans, for example, perceive the greenness of an unripe tomato where greenness is a property the tomato shares with a blade of grass and a leaf? Answering this question depends in part on complex issues about when and why verbal interference affects discrimination between categorical colour properties (Roberson & Davidoff, 2000; Wiggett & Davies, 2008). Clearly what people say about their experiences is not decisive here. But if such verbal reports alone are not sufficient to decide questions about perceptual experience of colour, they surely cannot decide questions about perceptual experience of mental states either.  

This leaves us with a problem. Given that mere verbal reports and explicit ratings alone are not sufficient to establish claims about perceptual experience, how else could the hypothesis that humans sometimes perceptually experience others’ mental states be tested?  

# 3. Phenomenal expectations (a preliminary step)  

In working out what kind of evidence might be relevant to answering questions about whether humans ever perceptually experience others’ mental states, it is useful to consider physical properties. In tracking objects’ movements, which physical properties of them can humans perceptually experience? In particular, can they perceptually experience properties such as solidity, velocity or momentum?  

As a preliminary to investigating both this question and its counterpart about mental states, it is useful to distinguish two ways in which things can feature in perceptual experience. Suppose you saw the scene depicted in the right panel of Fig. 1 on the next page. Do you perceptually experience the parts of the shape behind the thumb? In one sense you do not: after all, the thumb is blocking your view of them. So accurately characterising your perceptual experience requires distinguishing some parts of the shape from others. But we cannot simply say that you do not perceptually experience the occluded parts of the shape because your perceptual experience is not neutral on these parts of the shape. If the thumb were removed to reveal the scene depicted in the left panel of Fig. 1, an expectation would be violated. Such expectations are plausibly perceptual rather than being a matter of believing or knowing in part because of the laws that govern them and in part because they are judgement-independent. As Kellman and Spelke (1983) report, Michotte, Thines and Crabbe observed that people typically continue to report seeing a single large triangle behind the thumb even when they know that there is not one there. You can cover and reveal the shape repeatedly without losing the incorrect expectation that there is a triangle behind the thumb. As this illustrates, things can be unperceived in one sense—because they are, for example, occluded—while being perceived in another sense. To describe cases like this—cases where perceptual experience is not neutral concerning things which are in some sense unperceived—I will use the term phenomenal expectation.2 When encountering the scene depicted in the right panel of Fig. 1, people typically have phenomenal expectations concerning the occluded parts of the shape.  

![](images/72cb3b85f21449f0adaa1cea5b92408c0321b7af3ccb84e2d89b70ad925766d5.jpg)  
Fig. 1. Phenomenal expectations. Source: Michotte, Thines, and Crabbe (1991) via Kellman and Spelke (1983, Fig. 2).  

Phenomenal expectations are not limited to static features of objects. To illustrate, imagine being shown a video consisting of two static frames, first the frame on the left in Fig. 2 on the next page and then the frame on the right. You would typically see two objects moving horizontally. This is apparent motion: objects which appear successively at two locations sometimes result in a perceptual experience as of an object moving between those locations (Burt & Sperling, 1981). In some but not all cases, the perceptual experiences associated with apparent motion are readily distinguishable from the perceptual experiences associated with encountering actually moving objects. You do have a sense of the things moving, and the sense is perceptual, but your experience is quite different from what it would be if the things were actually moving. In these cases there are phenomenal expectations concerning the objects’ movements. It is your phenomenal expectations which specify that a particular object is located midway between the two endpoints of its movement at a certain time. As this illustrates, some phenomenal expectations concern objects’ movements.  

Note that the existence of a phenomenal expectation requires more than anticipation in a perceptual process. A variety of mechanisms, extending to statistical learning and motor processes, modulate perceptual processes in such a way as to enable a range of features of objects to be perceptually represented in advance of the objects actually having those features (e.g. Kandel, Orliaguet, & Viviani, 2000; Turk-Browne et al., 2010; Wilson & Knoblich, 2005).3 Anticipation in perceptual processes is surely necessary for there to be phenomenal expectations. But not all anticipation in perceptual processes need result in phenomenal expectations.  

How are phenomenal expectations relevant to our questions about the possibility of perceptually experiencing physical properties and mental states? As we will see, much of the evidence on whether humans can perceptually experience physical properties of objects such as solidity and momentum is evidence that such properties influence phenomenal expectations. I shall also suggest, later (in Section 8), that in asking whether humans ever perceptually experience others’ mental states it is useful to focus on how, if at all, others’ mental states can influence phenomenal expectations.  

# 4. Physical properties influence phenomenal expectations  

Which physical properties of objects feature in, or influence, phenomenal expectations? When an object moves, for instance, do humans ever have phenomenal expectations concerning its spatio-temporal trajectory? If they do, can an object’s solidity or momentum somehow influence their phenomenal expectations concerning its movements?  

I shall take a perverse approach to answering these questions. It is arguably impossible to adequately answer them without considering research on the perception of force (see Jones, 1986; Wolff & Shepard, 2013 for reviews), and related illusions (e.g. Diedrichsen, Verstynen, Hon, Zhang, & Ivry, 2007). But I shall ignore all such research in what follows, with the result that I am addressing the question almost as if it were not about actual humans but about imaginary incorporeal humans who are incapable of movement and never intervene on objects. The result is an artificially narrow view of the evidence concerning whether humans can perceptually experience properties such as solidity or momentum. But there is a reason for adopting this perverse restriction rather than considering a wider body of evidence. Adhering to the perverse restriction on evidence for claims about perceptually experiencing solidity or momentum will yield a useful model for parallel questions about perceptually experiencing mental states.4  

![](images/ec25dd63d46df9848d089fba3ed2a8874b12926213e1fc8bb3c9af1e3f5c2cff.jpg)  
Fig. 2. Apparent motion. Source: Odic et al. (2012, part of Fig. 2 on p. 1060).  

The first thing we need is to know something about how perceptual systems track objects. In principle we could imagine a perceptual system that is concerned exclusively with answering questions about the locations of features at particular times. Such a system would be concerned with whether there is a red square over there now, but not with whether this red square is the same as the thing that was over there a moment ago. It is plausible, though, that many perceptual systems, including those found in primates, are concerned not just with the locations of features but also with objects and their movements.  

Consider the claim that perception involves a system (at least one) of indexes which attach to objects; this claim is common to a range of theories about aspects of object perception including those offered by Kahneman, Treisman, and Gibbs (1992), Pylyshyn et al. (1994) and Alvarez and Franconeri (2007). These object indexes can be thought of, roughly, as mental analogues of the pins that an old fashioned logistician sticks into a map in keeping track of supply trucks. When things go well, the movements of trucks on the ground are mirrored by the movements of pins on the map. The key characteristic of the pins is just this: ignoring re-use, if you have the same pin at two times, then the trucks it points to at those times are one and the same truck.  

Two famous discoveries provided early evidence that perception involves a system (at least one, perhaps more) of indexes for objects analogous to these pins and introduced the paradigms used to investigate how object indexes function. Pylyshyn and Storm (1988) showed that humans are able to track multiple moving objects simultaneously; and it seems they do this by means of parallel processes (Howe, Cohen, Pinto, & Horowitz, 2010).5 And Kahneman et al. (1992) showed that in a display with moving objects, people are faster to re-identify features when they are positioned on the same object: that is, there is an object-specific preview benefit.6 While much remains to be learnt about the mechanisms involved (see, for example, Xu & Chun, 2009), these and other findings indicate that perception involves a system of object indexes (see Scholl & Flombaum, 2010 for a brief overview).  

How are object indexes relevant to our question about which if any physical properties of objects influence phenomenal expectations? Consider two claims. First, there is a system of object indexes for tracking objects’ movements whose operations can be facilitated by information about solidity or momentum in accordance with certain principles such as impetus. (Let me abbreviate this first claim by saying that the operations of object indexes reflect solidity or momentum.) Second, this system of object indexes sometimes gives rise to phenomenal expectations concerning the movements of objects.7 These claims jointly provide one way—not the only way—of making precise the rough idea that one or both of these physical properties, solidity and momentum, can be perceptually experienced. Evidence for these claims would be evidence that humans sometimes perceptually experience physical properties like solidity or momentum. But is there any such evidence?  

Consider how object indexes are maintained over time in cases where the indexed objects are not continuously perceptible (in terms of the analogy, the question is how the logistician moves pins when she has partial information about the supply trucks). What determines whether this object at time-1 and that object at time-2 have the same object index pinned to them? One factor may be the similarity of their features (Hollingworth & Franconeri, 2009). Another factor is the objects’ spatio-temporal trajectories: objects’ whose movements are consistent with the movement of a single object tend to have a single object index pinned to them (Flombaum & Scholl, 2006; Mitroff & Alvarez, 2007). In fact, spatio-temporal constraints sometimes mean that even two objects with completely different shapes and colours and no common features are assigned the same object index (Odic et al., 2012).8 There is no comparably substantial, direct evidence that physical properties like solidity or momentum also influence how object indexes are maintained.9 However there are indirect routes to the conclusion that they do.  

A conjecture about development provides one route to the conclusion that the operations of some object indexes reflect solidity. From around three months of age, infants manifest abilities to track occluded objects, and do so in ways that reflect some understanding of physical properties like solidity (e.g. Baillargeon, 1987; Durand & Lécuyer, 2002; Saxe, Tzelnic, & Carey, 2006; Spelke, Breinlinger, Macomber, & Jacobson, 1992). Several researchers have conjectured that infants’ abilities are based not on knowledge or thought about objects but rather on the very system of object indexes that underpins object-specific preview benefits in adults (Carey & Xu, 2001; Leslie, Xu, Tremoulet, & Scholl, 1998; Scholl, 2007; Scholl & Leslie, 1999). Of course, this conjecture alone is unlikely to explain the full range of abilities to track physical objects that infants manifest throughout their first year of life (Cacchione, 2013). But several considerations count in favour of the conjecture. First, it is plausible that object indexes are involved when six month olds encounter an object undergoing occlusion (Kaufman, Csibra, & Johnson, 2005). Second, infants’ abilities to track objects seem to prioritise spatio-temporal cues over featural information in much the way observed when measuring object-specific preview benefits (Xu, Carey, & Quint, 2004). And, third, the conjecture suggests an elegant way of making sense of some otherwise puzzling discrepancies between tests of infants’ abilities to represent unperceived objects using different measures (e.g. Hood, Carey, & Prasada, 2000; Hood, Cole-Davies, & Dias, 2003; Moore & Meltzoff, 2010; Shinskey & Munakata, 2001).10  

How is the conjecture that infants’ abilities to track occluded objects rely on object indexes relevant to our question about perceptual experience? Infants’ abilities to track the locations of temporarily occluded objects show sensitivity to physical properties like solidity from around four months of age or earlier (Baillargeon, 1987; Durand & Lécuyer, 2002; Spelke et al., 1992). The conjecture that these abilities depend on the very object indexes which underpin object-specific preview benefits therefore supports the two claims that are jointly sufficient for us to conclude that solidity or momentum is perceptually experienced. There is a system of object indexes whose operations reflect solidity or momentum and which gives rise to phenomenal expectations concerning objects’ movements.  

An independent route to the same conclusion involves psychophysics rather than development. Sometimes when adult humans observe a moving object that disappears, they will misremember the location of its disappearance in way that reflects its momentum; this effect is called representational momentum (Freyd & Finke, 1984; Hubbard, 2010). The trajectories implied by representational momentum reveal that the effect reflects impetus mechanics rather than Newtonian principles (Freyd & Jones, 1994; Hubbard, 2013; Hubbard, Blessum, & Ruppel, 2001; Kozhevnikov & Hegarty, 2001). And these trajectories are independent of subjects’ scientific knowledge (Freyd & Jones, 1994; Kozhevnikov & Hegarty, 2001). Representational momentum therefore reflects judgement-independent expectations about objects’ movements which track momentum in accordance with a principle of impetus.11 But are these expectations phenomenal expectations? We should be cautious here because the relation between representational momentum and object perception is not straightforward (compare Freyd, 1987, p. 433), and because there are currently several competing models of representational momentum and related phenomena involving misremembered location (Hubbard, 2010). However it is perhaps tempting to conjecture that the expectations manifested in representational momentum are a consequence of some perceptual system of object indexes.12 This conjecture implies that there is a system of object indexes whose operations reflect momentum as characterised by impetus mechanics, and which gives rise to phenomenal expectations concerning objects’ movements. That is, it implies that, in a sense, humans can perceptually experience not only a physical object’s movements but also its momentum or solidity.  

The evidence I have reviewed for this claim is indirect and leaves many questions open. As emphasised at the start of this section, I have imposed an artificial restriction on the range of evidence considered by imagining incorporeal human perceivers who neither intervene on objects nor move. Even under this restriction, evidence other than that reviewed here may be relevant; for instance, studies of the launching effect and related sensitivities to causal interactions among perceived objects might (Butterfill, 2009) or might not (Rips, 2011) yield evidence. But my aim here was not to establish the claim: it was to identify an approach that can serve as a model for investigating a parallel claim about perceptual experience of mental states.  

Reflection on how the claim that humans sometimes perceptually experience physical properties like solidity or momentum might be tested supports three conclusions which can guide our thinking about perceptual experience and mental states. First, even if scientists rarely explicitly mention claims about perceptual experience, such claims can be supported by, or inconsistent with, experimental evidence; and there are rich bodies of evidence that do bear on them. Second, working out how to evaluate such claims involves making connections between perceptual processes and phenomenology. These connections can inform views about the nature of experience and generate new predictions. Third, it is not necessary to start with general stipulations about, or criteria governing, where perceptual experience ends and other forms of cognition begin. We can often be more confident in detailed claims about particular cases than we can in ambitious generalisations (compare Smortchkova, 2014, pp. 11–44).  

Before going further, consider an objection to the way I have been interpreting the view that humans sometimes perceptually experience properties like solidity or momentum. (Or skip over the objection if you like.)  

# 5. An objection  

In the previous section I identified a modest interpretation of the view that humans can perceptually experience physical properties like solidity or momentum. This view does not imply that such properties ever feature in perceptual experience in the same way that shapes, tones, colours or odours can. Nor is there even commitment to the claim that phenomenal expectations are expectations about solidity or momentum. The view is merely that these properties, solidity and momentum, may make a difference to the overall phenomenal character of perceptual experiences because of the guiding role of information about them in processes involving object indexes that give rise to phenomenal expectations. As far as the view I have defended goes, such expectations may concern only the movements of objects.  

You may object that this way of interpreting the view about perceptual experience of properties like solidity or momentum is too modest. I suppose that any adequate view must permit a distinction between what is represented in perceptual processes and what is perceptually experienced. But, you might object, isn’t this distinction obliterated by my modest interpretation of the claim about perceptual experience of solidity or momentum? Doesn’t accepting such a modest interpretation amount to accepting that anything which influences phenomenal expectations in any way at all is perceptually experienced?  

It does not. Consider one indicator that the relation between solidity or momentum and phenomenal expectations about the movements of objects is special. In a world lacking solidity and momentum, there could still be moving things; whereas in a world lacking movement there could not be momentum, and solidity would have no functional role. Relatedly, phenomenal expectations could not be influenced by information about solidity or momentum unless they concerned objects’ movements; and the converse is false. Let me abbreviate this by saying that information about momentum counterfactually enhances phenomenal expectations concerning movement. Not everything that influences an aspect of perceptual experience also counterfactually enhances it. Information about contrasts in luminance may influence perceptual experiences concerning edges, but luminance contrasts are not thereby perceptually experienced. Or, to take another case, information about junctions may influence perceptual experiences concerning three-dimensional shapes, but junctions are not thereby perceptually experienced. What indicates that these influences differ in their significance for phenomenology from those involving information about solidity or momentum? Information about luminance contrasts does not counterfactually enhance perceptual experiences of edges, and information about junctions does not counterfactually enhance perceptual experiences about three-dimensional shape. (After all, there could be luminance contrasts in a world without edges, and there could be junctions in a two-dimensional world.) So accepting the modest interpretation of the view that humans can perceptually experience physical properties like solidity or momentum is consistent with holding that there is a distinction between what is represented in perceptual processes and what is perceptually experienced.  

Counterfactual enhancement is only one indicator that the relation between solidity or momentum and phenomenal expectations about objects’ movements is special.13 I am not suggesting that counterfactual enhancement explains why it is possible to interpret the view that solidity or momentum are perceptually experienced in the modest way I have proposed whereas similar ways of interpreting corresponding views about other properties would be unacceptable. My suggestion is just that accepting the modest interpretation of the view about perceptual experience of some physical properties does not commit you to accepting the same for arbitrary physical properties.  

In what follows I evaluate a similarly modest interpretation of the view that humans can perceptually experience some mental properties of subjects other than themselves. What evidence is there, and what evidence could there be, for this view?  

# 6. Categorical perception and emotion  

We have been asking what kinds of evidence could bear on questions about the perceptual experience of physical properties. How can this guide us in working out what kinds of evidence might bear on questions about the perceptual experience of others’ mental states?  

When asking about physical properties like momentum or solidity, it is useful—and perhaps even essential—to start from what we know about how perceptual processes track objects (as we saw in Section 4). Similarly, when asking about mental states it makes sense to start by thinking about how perceptual processes track the subjects of mental states. The subjects of mental states pursue goals and they express emotions. This suggests two lines of enquiry. One line focusses on animacy and object- or goal-directed behaviours, another on expressions of emotion. Here I shall consider the second line only.14  

Do any perceptual processes in humans discriminate stimuli according to the expressions of emotion they involve? That is, do humans have categorical perception of expressions of emotion?15 To answer this question we first need to consider findings about the discrimination of expressions, leaving open for now whether discrimination involves perceptual processes. Assume that we as theorists have a system which allows us to categorise static pictures of faces and other stimuli according to which emotion we think they are expressing: some faces are happy, others fearful, and so on. From five months of age, or possibly much earlier (Field, Woodson, Greenberg, & Cohen, 1982), through to adulthood, humans are better at distinguishing faces when they differ with respect to these categories than when they do not (Bornstein & Arterberry, 2003; Cheal & Rutherford, 2011; Etcoff & Magee, 1992; Gelder, Teunisse, & Benson, 1997; Hoonhorst et al., 2011; Kotsoni et al., 2001). To illustrate, consider Fig. 3. The idea is this. With respect to all features apart from the expression of emotion, each face picture differs from its neighbours no more than any other picture differs from its neighbours. Most neighbouring pairs of face pictures would be relatively hard to distinguish, especially if they were not presented side-by-side. But most people find one pair of neighbouring face pictures relatively easy to distinguish—you may notice this yourself.  

What underlies these patterns of discrimination? Several possibilities that would render them uninteresting for our purposes can be ruled out. The patterns of discrimination do not appear to be an artefact of linguistic labels (Sauter, LeGuen, & M, 2011; see also Laukka, 2005, p. 291),16 nor of the particular choices subjects in these experiments are presented with (Bimler & Kirkland, 2001; Fujimura, Matsuda, Katahira, Okada, & Okanoya, 2011). Nor are the patterns of discrimination due to narrowly visual features of the stimuli used (Sato & Yoshikawa, 2009). We can be confident, then, that the patterns of discrimination probably reflect one or more processes which categorises stimuli by expression of emotion.  

What kinds of process are these? Although linguistic information can have a top-down effect on categorical perception (Cheal & Rutherford, 2013), the processes of categorisation underpinning the patterns of discrimination just observed are unlikely to rely entirely on conceptual thought about the stimuli. At least some of them are rapid (occurring within roughly $200\mathrm{ms~c}$ f a stimulus’ appearance), pre-attentive (Vuilleumier & Schwartz, 2001) and automatic in the sense that whether they occur is to a significant degree independent of subjects’ tasks and motivations (Batty & Taylor, 2003).  

But are any of the processes that categorise stimuli by expression of emotion perceptual? Answering this question is complicated by the fact that many parts of the brain are involved (Adolphs, 2002; Vuilleumier & Pourtois, 2007). There is evidence that both the amygdala (Harris, Young, & Andrews, 2012, 2014) and also some cortical structures (Batty & Taylor, 2003) respond categorically to expressions of emotion; and that intervening in the operations of the somatosensory cortex can impair categorisation (Pitcher, Garrido, Walsh, & Duchaine, 2008; see also Banissy et al., 2011). To my knowledge, so far it is only for happy and fearful stimuli that we have direct evidence from both neurophysiological (Campanella, Quinet, Bruyer, Crommelinck, & Guerit, 2002) and behavioural measures (Williams, Moss, Bradshaw, & Mattingley, 2005) of categorisation occurring in perceptual processing. So while the evidence is not conclusive, there is converging evidence that some perceptual processes categorise stimuli including faces by expression of emotion. Humans may have categorical perception not only for speech, colour, orientation and other properties but also for expressions of emotion.  

How is any of this relevant to our question about whether any mental states can be perceptually experienced? The evidence for categorical perception is evidence that there are perceptual processes which track expressions of emotion and which give rise to phenomenal expectations. Having identified evidence for the existence of such processes, we need to ask whether the mental states of the thing perceived influence how expressions of emotion are tracked. (This is analogous to asking whether properties like solidity or momentum affect how perceptual processes track physical objects’ movements.) Before doing this we must face up to a complication, however.  

![](images/d3f416ffabd641ed5e5346fac11617867fee9622618c45ddca2fa76d31d3cc55.jpg)  
Fig. 3. The faces at either end have been morphed with each other in differing degrees in order to produce a sequence of faces where each differs physically from its neighbours by a fixed amount. Source: Kotsoni et al. (2001, Fig. 1).  

# 7. What are the perceptual processes supposed to categorise?  

We have just seen evidence that humans have categorical perception for expressions of emotion. To work out how this might bear on hypotheses about perceptual experience of mental states, we need to ask: What are these processes supposed to categorise? One answer is obvious, of course: expressions of emotion are what they are supposed to characterise. But what are these?  

It is perhaps tempting to assume that categories of emotion like happiness, sadness, fear and surprise are each associated with a category of facial configurations, and that the relation between the emotions and the categories of configurations is merely contingent. (So that the expression associated with happiness might just have well been associated with surprise.) This might make it plausible to assume, further, that the things perceptual processes are supposed to categorise—the ‘expressions of emotion’—are facial configurations. If this were right, the evidence we have been reviewing on perception and emotion would support the view that humans have phenomenal expectations concerning certain characteristic bodily effects of some mental states. It would not support the view that humans can perceptually experience mental states in the sense in which, arguably, they can perceptually experience physical properties like solidity and momentum.  

But are the things categorised by perceptual processes facial configurations? This view faces a problem. There is evidence that the same facial configuration can express intense joy or intense anguish depending on the posture of the body it is attached to, and, relatedly, that humans cannot accurately determine emotions from spontaneously occurring facial configurations (Aviezer et al., 2008; Aviezer, Trope, & Todorov, 2012; Motley & Camden, 1988). These and other findings, while not decisive, cast doubt on the view that categories of emotion are associated with categories of facial configurations (Hassin, Aviezer, & Bentin, 2013). This evidence makes the findings we have reviewed on categorical perception puzzling. Given that the facial configurations are not diagnostic of emotion, why are they categorised by perceptual processes?17 This question appears unanswerable as long as we retain the assumption—for which, after all, no argument was given—that the things categorical perception is supposed to categorise are facial configurations. But if we reject this assumption, what is the alternative?  

Compare expressing an emotion by, say, smiling or frowning, with articulating a phoneme. Both have a communicative function (on expressions of emotion, see for example Blair, 2003; Sato & Yoshikawa, 2007) and both are categorically perceived, but the phonetic case has been more extensively investigated. Variations due to coarticulation, rate of speech, dialect and many other factors mean that isolated acoustic signals are not generally diagnostic of phonemes: in different contexts, the same acoustic signal might be a consequence of the articulation of any of several phonemes. So here there is a parallel between speech and emotion. Much as isolated facial expressions are not diagnostic of emotions (as we saw a moment ago), isolated acoustic signals are plausibly not diagnostic of phonetic articulations. Why then are isolated acoustic signals—which rarely even occur outside the lab—categorised by perceptual or motor processes at all? To answer this question we first need a rough idea of what it is to articulate a phoneme. Articulating a phoneme involves making coordinated movements of the lips, tongue, velum and larynx. How these should move depends in complex ways on numerous factors including phonetic context (Browman & Goldstein, 1992; Goldstein, Fowler, Schiller, & Meyer, 2003). In preparing for such movements, it is plausible that the articulation of a particular phoneme is an outcome represented motorically, where this motor representation coordinates the movements and normally does so in such a way as to increase the probability that the outcome represented will occur. This implies that the articulation of a particular phoneme, although probably not an intentional action, is a goal-directed action whose goal is the articulation of that phoneme. (On the link between motor representation and goaldirected action, see Butterfill & Sinigaglia, 2014.) Now some hold that the things categorised in categorical perception of speech are not sounds or movements (say) but rather these outcomes—the very outcomes in terms of which speech actions are represented motorically (Liberman & Whalen, 2000; see also Browman & Goldstein, 1992).18 On this view, categorical perception of speech is a process which takes as input the bodily and acoustic effects of speech actions and attempts to identify which outcomes the actions are directed to bringing about, that is, which phonemes the speaker is attempting to articulate. That isolated acoustic signals can engage this process and thereby trigger categorical perception is merely a side-effect, albeit one with useful methodological consequences.  

How is this relevant to understanding categorical perception of expressions of emotion? A problem arose from the perhaps natural assumption that the things categorical perception is supposed to categorise are facial configurations. The problem, as we saw, is that this assumption conflicts with evidence that facial configurations are not diagnostic of emotions. We can resolve the conflict by rejecting the assumption in favour of an alternative inspired by the view that the things categorised in categorical perception of speech are not acoustic signals but actions of a certain type, phonetic articulations, where the actions are categorised by the outcomes to which they are directed. Whether or not the things categorised in categorical perception of speech are actions, maybe this is true of categorical perception of expressions of emotions.  

This wild conjecture requires that some expressions of emotion—such as smiling or frowning—be goal directed actions in roughly the sense that the articulation of a phoneme is a goal-directed action. This may initially strike you as implausible given that such expressions of emotion can be spontaneous, unintentional and involuntary. But note that expressing an emotion by, say, smiling or frowning, whether intentionally or not, involves making coordinated movements of multiple muscles where exactly what should move and how can depend in complex ways on contextual factors. That such an expression of emotion is a goal-directed action follows just from its involving motor expertise and being coordinated around an outcome (the goal) in virtue of that outcome being represented motorically.19 Recognising that some expressions of emotion are goaldirected actions in this sense makes it possible to explain what distinguishes a genuine expression of emotion of this sort, a smile say, from something unexpressive like the exhalation of wind which might in principle resemble the smile kinematically. Like any goal-directed actions, genuine expressions of emotion of this sort are distinguished from their kinematically similar doppelgänger in being directed to outcomes by virtue of the coordinating role of motor representations and processes.  

Recall that the wild conjecture under consideration is that the things categorical perception is supposed to categorise, the ‘expressions of emotion’, are actions of a certain type, and these are categorised by which outcomes they are directed to. Let me explain the increasingly bold commitments involved in accepting this conjecture. First, the things categorised in categorical perception of expressions of emotion are events rather than configurations or anything static. (Note that this is consistent the fact that static stimuli can trigger categorical perception; after all, static stimuli can also trigger motor representations of things like grasping (Borghi et al., 2007).) Second, these events are not mere physiological reactions (as we might intuitively take blushing to be) but things like frowning and smiling, whose performance involves motor expertise. Third, these events are perceptually categorised by the outcomes to which they are directed. That is, outcomes represented motorically in performing these actions are things by which these events are categorised in categorical perception.  

Should we accept the wild conjecture? It goes well beyond the available evidence and currently lacks any reputable endorsement. In fact, we lack direct evidence for even the first of the increasingly bold commitments just mentioned (namely, the claim that the things categorically perceived are events). A further problem is that we know relatively little about the actions which, according to the wild conjecture, are the things categorical perception is supposed to categorise (Scherer, Mortillaro, & Mehu, 2013, p. 47; see also Scherer & Ellgring, 2007 & Fernández-Dols, 2013). However, the wild conjecture is less wild than the only published responses to the problems that motivate it.20 And, as I shall now explain, several considerations make the wild conjecture seem at least worth testing.  

Consider again the procedure used in testing for categorical perception. Each experiment begins with a system for categorising the stimuli (expressions). This initial system is either specified by the experimenters or, in some cases, by having the participants first divide stimuli into categories using verbal labels or occasionally using non-verbal decisions. The experiment then seeks to measure whether this initial system of categories predicts patterns in discrimination. But what determines which category each stimulus is assigned to in the initial system of categories? You might guess that it is a matter of how likely people think it is that each stimulus—a particular facial configuration, say—would be associated with a particular emotion. In fact this is wrong. Instead, each stimulus is categorised in the initial system according to how suitable people think such an expression would be to express a given emotion: this is true whether the stimuli are facial (Horstmann, 2002) or vocal (Laukka, Audibert, & Aubergé, 2011) expressions of emotion (see also Parkinson, 2013, pp. 98–9). To repeat, in explicitly assigning an expression to a category of emotion, people are not making a judgement about the probability of someone with that expression having that emotion: they are making a judgement about which category of emotion the expression is most suited to expressing. Why is this relevant to understanding what perceptual processes categorise? The most straightforward way of interpreting the experiments on categorical perception is to suppose that they are testing whether perceptual processes categorise stimuli in the same ways as the initial system of categories does. But we have just seen that the initial system categorises stimuli according to the emotions they would be best suited to expressing. So on the most straightforward interpretation, the experiments on categorical perception of expressions of emotion are testing whether there are perceptual processes whose function is to categorise actions of a certain type by the outcomes to which they are directed. So the wild conjecture is needed for the most straightforward interpretation of these experiments. This does not make it true but it does make it worth testing.  

So far I have focussed on evidence for categorical perception from experiments using faces as stimuli. However, there is also evidence that perceptual processes categorise vocal and facial expressions alike (Grandjean et al., 2005; Laukka, 2005; see also Jaywant & Pell, 2012). We also know that various contextual factors can affect how even rapidly occurring perceptual processes discriminate expressions of emotion (Righart & Gelder, 2008). There is even indirect evidence that categorical perception may concern whole bodies rather than just faces or voices (Aviezer, Bentin, Dudarev, & Hassin, 2011; Aviezer et al., 2008). In short, categorical perception of expressions of emotion plausibly resembles categorical perception of speech in being a multimodal phenomenon which concerns the whole body and is affected by several types of contextual feature. This is consistent with the wild conjecture we are considering. The conjecture generates the further prediction that the effects of context on categorical perception of expressions of emotion will resemble the myriad effects of context on categorical perception of speech so that ‘every potential cue . . .is an actual cue’ (Liberman & Mattingly, 1985, p. 11; for evidence of context effects see in categorical perception of speech, for example, Jusczyk, 1997, p. 44; Nygaard & Pisoni, 1995, pp. 72–5; Repp & Liberman, 1987).  

How would the conjecture under consideration, if true, bear on our question about perceptual experience of mental states? Recall that the conjecture is this: the expressions of emotion categorical perception is supposed to categorise are actions of a certain type, and these are categorised by the outcomes to which they are directed. Since outcomes are not mental states (of course), the view might initially appear to imply that evidence from categorical perception cannot bear on whether humans can perceptually experience mental states. This is also what the comparison with categorical perception of speech might be taken to indicate: in both cases, perceptual processes involve information about outcomes to which actions are directed rather than information about mental states. This suggests that the phenomenal expectations these processes give rise to concern action outcomes and not mental states. However things are not quite so straightforward.  

# 8. Do humans ever perceptually experience emotions in categorically perceiving their expressions?  

According to the wild conjecture under consideration, categorical perception of expressions of emotion is supposed to categorise actions of a certain type by the outcomes to which they are directed. What evidence could take us from this conjecture to a conclusion about perceptual experience of emotions?  

In outline we seek a view parallel to the one about physical properties considered earlier (in Section 4). There the idea was this. A perceptual mechanism for tracking objects’ movements exists; its operations can be facilitated by information about solidity or momentum in accordance with certain principles such as impetus; and it can give rise to phenomenal expectations about objects’ movements. Here is a parallel view: (a) a perceptual mechanism for tracking actions of a certain type exists; (b) its operations can be facilitated by information about agents’ emotions in accordance with principles describing aspects of their functional or normative roles; and (c) it gives rise to phenomenal expectations about the outcomes to which agents’ actions are directed, or about agents’ bodily configurations or movements.21 So far I have been examining the case for the claim that categorical perception of expressions of emotions is a perceptual mechanism with the features specified in (a) and (c). Is there any evidence that it also has the feature specified in (b)? That is, can categorical perception of facial expressions of emotion be facilitated by information about others’ emotions?  

First consider a theoretical objection. Assume that categorical perception of facial expressions of emotion exists in part because it enables information about others’ emotions to be discovered. (I relied on this assumption in Section 7 when arguing that the things categorical perception is supposed to categorise are not facial configurations.) If discovering information about others’ emotions is supposed to be an upshot of categorical perception, how could such information also facilitate it? The objection is that it cannot: the information about others’ emotions that might facilitate categorical perception is the very information that it could enable you to discover.  

In reply to the objection consider a simplistic model of how categorical perception of facial expressions of emotion works. Observed configurations and movements are identified as a possible expression of emotion. Two or more competing hypotheses about which emotion is being expressed are formulated. Each hypothesis generates different predictions about the outcomes to which the candidate expression of emotion is directed, and these in turn generate different predictions about how the action will unfold and about its sensory consequences. These predictions are tested against perceptual information, and hypotheses are scored according to how well their predictions stand up. If one hypothesis pulls far enough ahead in this contest, the observed configurations and movements are categorised as an action directed to the predicted outcomes, and thereby as a particular expression of emotion. This model, although obviously simplistic, illustrates how accepting that categorical perception enables information about others’ emotions to be discovered is in principle compatible with supposing that such information also facilitates the process of categorisation. Acquiring information about another’s emotions and categorically perceiving her expressions of emotion may be aspects of a single process.  

It is just conceivable that the simplistic model is not entirely misguided. A range of evidence suggests that some of the processes that would be involved in your experiencing certain emotions can also occur when you merely observe expressions of those emotions (Bastiaansen, Thioux, & Keysers, 2009; Gallese, Keysers, & Rizzolatti, 2004; Rizzolatti & Sinigaglia, 2008, Chapter 7; van der Gaag, Minderaa, & Keysers, 2007; Wicker et al., 2003), and that the occurrence of these processes can facilitate perceptual discrimination of expressions of emotion (Adolphs, Damasio, Tranel, Cooper, & Damasio, 2000; Pitcher et al., 2008). There is also evidence indicating that such processes might influence sensorimotor processes responsible for preparing or monitoring actions (Hill et al., 2013), and that sensorimotor processes can in turn facilitate perceptual discrimination of expressions of emotion (Banissy et al., 2011; Enticott, Johnston, Herring, Hoy, & Fitzgerald, 2008; Oberman, Winkielman, & Ramachandran, 2007).22  

These findings inspire a revision to the simplistic model just considered. When observed configurations and movements are identified as a possible expression of emotion, a ‘hypothesis’ about which emotion is being expressed is actually the occurrence of processes in the observer which would normally occur were she to have that emotion. This results in various outcomes being represented motorically. And these representations in turn generate predictions about the action and its sensory consequences. The predictions’ successes or failures influence which outcomes continue to be represented motorically and selectively modulate the occurrence of the emotion-related processes in the observer. These representations and processes influence whether and how the expression of emotion is perceptually categorised. This is one way in which information about others’ emotions might facilitate categorical perception.  

That something like this model might describe part of what is involved in detecting expressions of emotion is not a new idea. A key presupposition of the model is that familiar ideas about the role of motor representations and processes in identifying others’ actions (e.g. Rizzolatti & Sinigaglia, 2010; Wolpert, Doya, & Kawato, 2003) can be extended to the special case where the actions are expressions of emotion. Several researchers have already defended detailed views along roughly these lines (including Adolphs, 2001 as well as those already cited). What is novel is just the claim that visceromotor processes involved in observing others’ actions might influence phenomenal expectations by virtue of facilitating the categorical perception of expressions of emotion.  

The model provides an answer to the question I started with. One way to find evidence for or against claims about humans’ abilities to perceptually experience others’ mental states is to test the commitments and predictions of this model. These commitments and predictions are not so strongly supported by the available evidence that everyone will find the model compelling. However, the model does have two virtues. It makes a claim about perceptual experience of mental states precise enough to refute, and links it the claim to a growing body of research.  

# 9. Conclusion  

What evidence might bear on questions about whether humans ever perceptually experience any of another’s mental states, and how could these questions be made precise enough to test experimentally? In this paper I have defended a partial answer based on the discovery that humans have categorical perception of expressions of emotion (see Section 6) and the further conjecture that the expressions of emotion categorical perception is supposed to categorise are actions of a certain type, where these are categorised by the outcomes to which they are directed (see Section 7). Categorical perception of expressions of emotion clearly has effects on the overall phenomenological character of experiences, for it facilitates explicit perceptual judgements of sameness and difference (as we saw in Section 6). It does not follow that expressions of emotion are perceptually experienced in the same sense in which the shapes of physical objects are. More plausibly, categorical perception gives rise to phenomenal expectations about action outcomes or about the bodily configurations, articulations and movements which are involved in some expressions of emotion. On the face of it, this might suggest that evidence about categorical perception could not support a claim about the perceptual experience of mental states. However, reflection on a parallel claim about physical properties suggests otherwise. In the physical case, there is some evidence that properties like solidity and momentum are sometimes perceptually experienced in the sense that information about them has predictable and beneficial effects on phenomenal expectations concerning the movements of objects (see Section 4). Analogously we might conjecture that information about others’ emotions sometimes facilitates categorical perception of expressions of emotion and thereby influences phenomenal expectations. This conjecture is partially supported by evidence that some processes involved in having certain emotions also occur in observing them, and that such processes facilitate perceptual discrimination of expressions of emotion either directly or by way of influencing motor processes (see Section 8).  

If all of this is right there is at least one sense in which humans can sometimes perceptually experience certain of another’s mental states: information about others’ emotions can facilitate categorical perception of their expressions of emotion which in turn gives rise to phenomenal expectations concerning outcomes to which their actions are directed or concerning their bodily configurations, articulations and movements. This is not to say that humans can perpetually experience another’s mental states in the sense that they can perceptually experience a physical object’s shape (Section 3). But others’ mental states can have predictable and beneficial effects on the overall phenomenal characters of perceptual experiences.  

It is worth emphasising that there are gaps in the evidence. The view we have been discussing is worth considering because it is consistent with the available evidence and refutable by new findings, not because there is decisive evidence for it. In fact, at present it appears that there is less evidence for the claim that humans can sometimes perceptually experience any of another’s emotions than for the claim that an imaginary incorporeal human could perceptually experience physical properties of objects like solidity or momentum. But emotions are among the mental states most likely to be perceptually experienced, and research on how perceptual processes track expressions of emotion is most likely to provide evidence relevant to evaluating claims about perceptual experience and emotions. The gaps in the evidence therefore reveal something important. We are probably not yet in a position to know whether humans ever perceptually experience others’ mental states.  

# References  

Adolphs, R. (2001). The neurobiology of social cognition. Current Opinion in Neurobiology, 11, 231–239.   
Adolphs, R. (2002). Recognizing emotion from facial expressions: Psychological and neurological mechanisms. Behavioral and Cognitive Neuroscience Reviews, 1, 21–62. PMID: 17715585.   
Adolphs, R., Damasio, H., Tranel, D., Cooper, G., & Damasio, A. R. (2000). A role for somatosensory cortices in the visual recognition of emotion as revealed by three-dimensional lesion mapping. The Journal of Neuroscience, 20, 2683–2690. PMID: 10729349.   
Alvarez, G. A., & Franconeri, S. L. (2007). How many objects can you track? Evidence for a resource-limited attentive tracking mechanism. Journal of Vision, 7, 14. PMID: 17997642.   
Aviezer, H., Bentin, S., Dudarev, V., & Hassin, R. R. (2011). The automaticity of emotional face-context integration. Emotion, 11, 1406–1414.   
Aviezer, H., Hassin, R. R., Ryan, J., Grady, C., Susskind, J., Anderson, A., et al (2008). Angry, disgusted, or afraid? Studies on the malleability of emotion perception. Psychological Science, 19, 724–732. PMID: 18727789.   
Aviezer, H., Trope, Y., & Todorov, A. (2012). Body cues, not facial expressions, discriminate between intense positive and negative emotions. Science, 338, 1225–1229. PMID: 23197536.   
Baillargeon, R. (1987). Object permanence in 3.5-and 4.5-month-old infants. Developmental Psychology, 23, 655–664.   
Baillargeon, R. (2002). The acquisition of physical knowledge in infancy: A summary in eight lessons. In U. Goswami (Ed.), Blackwell handbook of childhood cognitive development (pp. 47–83). Oxford: Blackwell.   
Banissy, M. J., Garrido, L., Kusnir, F., Duchaine, B., Walsh, V., & Ward, J. (2011). Superior facial expression, but not identity recognition, in mirror-touch synesthesia. The Journal of Neuroscience, 31, 1820–1824. PMID: 21289192.   
Barrett, L. F., Mesquita, B., & Gendron, M. (2011). Context in emotion perception. Current Directions in Psychological Science, 20, 286–290.   
Bastiaansen, J. a. C. J., Thioux, M., & Keysers, C. (2009). Evidence for mirror systems in emotions. Philosophical Transactions of the Royal Society B: Biological Sciences, 364, 2391–2404. PMID: 19620110.   
Batty, M., & Taylor, M. J. (2003). Early processing of the six basic facial emotional expressions. Cognitive Brain Research, 17, 613–620.   
Bimler, D., & Kirkland, J. (2001). Categorical perception of facial expressions of emotion: Evidence from multidimensional scaling. Cognition $\mathcal{E}E$ motion, 15, 633–658.   
Blair, R. J. R. (2003). Facial expressions, their communicatory functions and neuro-cognitive substrates. Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences, 358, 561–572. PMID: 12689381.   
Borghi, A. M., Bonfiglioli, C., Lugli, L., Ricciardelli, P., Rubichi, S., & Nicoletti, R. (2007). Are visual stimuli sufficient to evoke motor information? Studies with hand primes. Neuroscience Letters, 411, 17–21.   
Bornstein, M. (1987). Perceptual categories in vision and audition. In S. Harnad (Ed.), Categorical perception: The groundwork of cognition. Cambridge: Cambridge University Press.   
Bornstein, M., & Arterberry, M. E. (2003). Recognition, discrimination and categorization of smiling by 5-month-old infants. Developmental Science, 6, 585–599.   
Browman, C. P., & Goldstein, L. (1992). Articulatory phonology: An overview. Phonetica, 49, 155–180.   
Burt, P., & Sperling, G. (1981). Time, distance, and feature trade-offs in visual apparent motion. Psychological Review, 88, 171–195.   
Butterfill, S. (2009). Seeing causes and hearing gestures. Philosophical Quarterly, 59, 405–428.   
Butterfill, S. A., & Sinigaglia, C. (2014). Intention and motor representation in purposive action. Philosophy and Phenomenological Research, 88, 119–145.   
Cacchione, T. (2013). The foundations of object permanence: Does perceived cohesion determine infants’ appreciation of the continuous existence of material objects? Cognition, 128, 397–406.   
Campanella, S., Quinet, P., Bruyer, R., Crommelinck, M., & Guerit, J. M. (2002). Categorical perception of happiness and fear facial expressions: An ERP study. The Journal of Cognitive Neuroscience, 14, 210–227.   
Carey, S., & Xu, F. (2001). Infants’ knowledge of objects: Beyond object files and object tracking. Cognition, 80, 179–213.   
Cheal, J. L., & Rutherford, M. D. (2011). Categorical perception of emotional facial expressions in preschoolers. Journal of Experimental Child Psychology, 110, 434–443.   
Cheal, J. L., & Rutherford, M. D. (2013). Context-dependent categorical perception of surprise. Perception, 42, 294–301.   
Diedrichsen, J., Verstynen, T., Hon, A., Zhang, Y., & Ivry, R. B. (2007). Illusions of force perception: The role of sensori-motor predictions, visual information, and motor errors. Journal of Neurophysiology, 97, 3305–3313.   
Durand, K., & Lécuyer, R. (2002). Object permanence observed in 4-month-old infants with a 2D display. Infant Behavior and Development, 25, 269–278.   
Enticott, P. G., Johnston, P. J., Herring, S. E., Hoy, K. E., & Fitzgerald, P. B. (2008). Mirror neuron activation is associated with facial emotion processing. Neuropsychologia, 46, 2851–2854.   
Etcoff, N. L., & Magee, J. J. (1992). Categorical perception of facial expressions. Cognition, 44, 227–240.   
Fernández-Dols, J.-M. (2013). Advances in the study of facial expression: An introduction to the special section. Emotion Review, 5, 3–7.   
Field, T. M., Woodson, R., Greenberg, R., & Cohen, D. (1982). Discrimination and imitation of facial expression by neonates. Science, 218, 179–181. PMID: 7123230.   
Flombaum, J. I., & Scholl, B. J. (2006). A temporal same-object advantage in the tunnel effect: Facilitated change detection for persisting objects. Journal of Experimental Psychology. Human Perception and Performance, 32, 840–853. PMID: 16846283.   
Franconeri, S. L., Jonathan, S. V., & Scimeca, J. M. (2010). Tracking multiple objects is limited only by object spacing, not by speed, time, or capacity. Psychological Science, 21, 920–925. PMID: 20534781.   
Franconeri, S. L., Pylyshyn, Z. W., & Scholl, B. J. (2012). A simple proximity heuristic allows tracking of multiple objects through occlusion. Attention, Perception, & Psychophysics, 74, 691–702.   
Freyd, J. J. (1987). Dynamic mental representations. Psychological Review, 94, 427–438.   
Freyd, J. J., & Finke, R. A. (1984). Representational momentum. Journal of Experimental Psychology: Learning, Memory, and Cognition, 10, 126–132.   
Freyd, J. J., & Jones, K. T. (1994). Representational momentum for a spiral path. Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 968–976.   
Fugate, J. M. B., Gouzoules, H., & Barrett, L. F. (2010). Reading chimpanzee faces: Evidence for the role of verbal labels in categorical perception of emotion. Emotion, 10, 544–554.   
Fujimura, T., Matsuda, Y.-T., Katahira, K., Okada, M., & Okanoya, K. (2011). Categorical and dimensional perceptions in decoding emotional facial expressions. Cognition & Emotion, 26, 587–601. PMID: 21824015.   
Gallese, V., Keysers, C., & Rizzolatti, G. (2004). A unifying view of the basis of social cognition. Trends in Cognitive Sciences, 8, 396–403.   
Gelder, B. D., Teunisse, J. P., & Benson, P. J. (1997). Categorical perception of facial expressions: Categories and their internal structure. Cognition and Emotion, 11, 1–23.   
Gendron, M., Lindquist, K. A., Barsalou, L., & Barrett, L. F. (2012). Emotion words shape emotion percepts. Emotion, 12, 314–325.   
Goldstein, L., Fowler, C. A., Schiller, N. O., & Meyer, A. S. (2003). Articulatory phonology: A phonology for public language use. In Phonetics and phonology in language comprehension and production (pp. 159–207). Mouton de Gruyter.   
Grandjean, D., Sander, D., Pourtois, G., Schwartz, S., Seghier, M. L., Scherer, K. R., et al (2005). The voices of wrath: Brain responses to angry prosody in meaningless speech. Nature Neuroscience, 8, 145–146.   
Harris, R. J., Young, A. W., & Andrews, T. J. (2012). Morphing between expressions dissociates continuous from categorical representations of facial expression in the human brain. Proceedings of the National Academy of Sciences, 109, 21164–21169. PMID: 23213218.   
Harris, R. J., Young, A. W., & Andrews, T. J. (2014). Dynamic stimuli demonstrate a categorical representation of facial expression in the amygdala. Neuropsychologia, 56, 47–52.   
Hassin, R. R., Aviezer, H., & Bentin, S. (2013). Inherently ambiguous: Facial expressions of emotions, in context. Emotion Review, 5, 60–65.   
Heider, F., & Simmel, M. (1944). An experimental study of apparent behaviour. American Journal of Psychology, 57, 243–259.   
Hill, A. T., Fitzgibbon, B. M., Arnold, S. L., Rinehart, N. J., Fitzgerald, P. B., & Enticott, P. G. (2013). Modulation of putative mirror neuron activity by both positively and negatively valenced affective stimuli: A TMS study. Behavioural Brain Research, 249, 116–123.   
Hollingworth, A., & Franconeri, S. L. (2009). Object correspondence across brief occlusion is established on the basis of both spatiotemporal and surface feature cues. Cognition, 113, 150–166.   
Hood, B., Carey, S., & Prasada, S. (2000). Predicting the outcomes of physical events: Two-year-olds fail to reveal knowledge of solidity and support. Child Development, 71, 1540–1554.   
Hood, B., Cole-Davies, V., & Dias, M. (2003). Looking and search measures of object knowledge in preschool children. Developmental Science, 29, 61–70.   
Hoonhorst, I., Medina, V., Colin, C., Markessis, E., Radeau, M., Deltenre, P., et al (2011). Categorical perception of voicing, colors and facial expressions: A developmental study. Speech Communication, 53, 417–430.   
Horowitz, T. S., Birnkrant, R. S., Fencsik, D. E., Tran, L., & Wolfe, J. M. (2006). How do we track invisible objects? Psychonomic Bulletin & Review, 13, 516–523.   
Horowitz, T. S., & Cohen, M. A. (2010). Direction information in multiple object tracking is limited by a graded resource. Attention, Perception, & Psychophysics, 72, 1765–1775.   
Horstmann, G. (2002). Facial expressions of emotion: Does the prototype represent central tendency, frequency of instantiation, or an ideal? Emotion, 2, 297–305.   
Howe, P. D. L., Cohen, M. A., Pinto, Y., & Horowitz, T. S. (2010). Distinguishing between parallel and serial accounts of multiple object tracking. Journal of Vision, 10, 11. PMID: 20884586.   
Howe, P. D. L., & Holcombe, A. O. (2012). Motion information is sometimes used as an aid to the visual tracking of objects. Journal of Vision, 12, 10. PMID: 23232339.   
Hubbard, T. L. (2005). Representational momentum and related displacements in spatial memory: A review of the findings. Psychonomic Bulletin & Review, 12, 822–851.   
Hubbard, T. L. (2010). Approaches to representational momentum: Theories and models. In R. Nijhawan & B. Khurana (Eds.), Space and time in perception and action. Cambridge: Cambridge University Press.   
Hubbard, T. L. (2013). Launching, entraining, and representational momentum: Evidence consistent with an impetus heuristic in perception of causality. Axiomathes, 23, 633–643.   
Hubbard, T. L., Blessum, J. A., & Ruppel, S. E. (2001). Representational momentum and Michotte’s launching effect paradigm (1946/1963). Journal of Experimental Psychology: Learning, Memory, and Cognition, 27, 294–301.   
Jaywant, A., & Pell, M. D. (2012). Categorical processing of negative emotions from speech prosody. Speech Communication, 54, 1–10.   
Jones, L. A. (1986). Perception of force and weight: Theory and research. Psychological Bulletin, 100, 29–42.   
Jordan, K. E., Clark, K., & Mitroff, S. R. (2010). See an object, hear an object file: Object correspondence transcends sensory modality. Visual Cognition, 18, 492–503.   
Jusczyk, P. (1997). The discovery of spoken language. Cambridge, Mass.: MIT.   
Kahneman, D., Treisman, A., & Gibbs, B. J. (1992). The reviewing of object files: Object-specific integration of information. Cognitive Psychology, 24, 175–219.   
Kandel, S., Orliaguet, J.-P., & Viviani, P. (2000). Perceptual anticipation in handwriting: The role of implicit motor competence. Perception & Psychophysics, 62, 706–716.   
Kaufman, J., Csibra, G., & Johnson, M. H. (2005). Oscillatory activity in the infant brain reflects object maintenance. Proceedings of the National Academy of Sciences of the United States of America, 102, 15271–15274.   
Keane, B. P., & Pylyshyn, Z. W. (2006). Is motion extrapolation employed in multiple object tracking? Tracking as a low-level, non-predictive function. Cognitive Psychology, 52, 346–368.   
Kellman, P. J., & Spelke, E. S. (1983). Perception of partly occluded objects in infancy. Cognitive Psychology, 15, 483–524.   
Kotsoni, E., Haan, M. d., & Johnson, M. H. (2001). Categorical perception of facial expressions by 7-month-old infants. Perception, 30, 1115–1125.   
Kozhevnikov, M., & Hegarty, M. (2001). Impetus beliefs as default heuristics: Dissociation between explicit and implicit knowledge about motion. Psychonomic Bulletin $\mathcal{E}R$ eview, 8, 439–453.   
Krushke, J. K., & Fragassi, M. M. (1996). The perception of causality: Feature binding in interacting objects. In Proceedings of the eighteenth annual conference of the cognitive science society (pp. 441–446). Hillsdale, NJ: Erlbaum.   
Laukka, P. (2005). Categorical perception of vocal emotion expressions. Emotion, 5, 277–295.   
Laukka, P., Audibert, N., & Aubergé, V. (2011). Exploring the determinants of the graded structure of vocal emotion expressions. Cognition & Emotion, 26, 710–719. PMID: 21851327.   
Leslie, A., Xu, F., Tremoulet, P. D., & Scholl, B. J. (1998). Indexing and the object concept: Developing ‘what’ and ‘where’ systems. Trends in Cognitive Sciences, 2.   
Liberman, A. M., & Mattingly, I. G. (1985). The motor theory of speech perception revised. Cognition, 21, 1–36.   
Liberman, A. M., & Whalen, D. H. (2000). On the relation of speech to language. Trends in Cognitive Sciences, 4, 187–196.   
Matthen, M. (2005). Seeing, doing and knowing. Oxford: Clarendon.   
McNeill, W. E. S. (2012a). Embodiment and the perceptual hypothesis. The Philosophical Quarterly, 62, 569–591.   
McNeill, W. E. S. (2012b). On seeing that someone is angry. European Journal of Philosophy, 20, 575–597.   
Michael, J., & De Bruin, L. (2015). How direct is social perception?. Consciousness and Cognition, 36, 373–375.   
Michotte, A., Thines, G., & Crabbe, G. (1991). Amodal completions of perceptual structures (A. Michotte, G. Thines, & G. Crabbe, Trans.). In: G. Thinès, A. Costall, & G. Butterworth (Eds.), Michotte’s experimental phenomenology of perception (pp. 140–167). Hillsdale, NJ: Erlbaum (Original work published 1964).   
Mitroff, S. R., Scholl, B. J., & Wynn, K. (2005). The relationship between object files and conscious perception. Cognition, 96, 67–92.   
Moore, M. K., & Meltzoff, A. N. (2010). Numerical identity and the development of object permanence. In S. P. Johnson (Ed.), Neoconstructivism: The new science of cognitive development (pp. 61–83). Oxford: Oxford University Press.   
Motley, M. T., & Camden, C. T. (1988). Facial expression of emotion: A comparison of posed expressions versus spontaneous expressions in an interpersonal communication setting. Western Journal of Speech Communication, 52, 1–22.   
Noles, N. S., Scholl, B. J., & Mitroff, S. R. (2005). The persistence of object file representations. Perception & Psychophysics, 67, 324–334.   
Nygaard, L. C., & Pisoni, D. B. (1995). Speech perception: New directions in research and theory. In L. Miller, Joanne, & P. D. Eimas (Eds.), Speech, language and communication (pp. 63–96). London: Academic Press.   
Oberman, L. M., Winkielman, P., & Ramachandran, V. S. (2007). Face to face: Blocking facial mimicry can selectively impair recognition of emotional expressions. Social Neuroscience, 2, 167–178. PMID: 18633815.   
Odic, D., Roth, O., & Flombaum, J. I. (2012). The relationship between apparent motion and object files. Visual Cognition, 20, 1052–1081.   
Parkinson, B. (2013). Contextualizing facial activity. Emotion Review, 5, 97–103.   
Pitcher, D., Garrido, L., Walsh, V., & Duchaine, B. C. (2008). Transcranial magnetic stimulation disrupts the perception and embodiment of facial expressions. The Journal of Neuroscience, 28, 8929–8933. PMID: 18768686.   
Pylyshyn, Z., Burkell, J., Fisher, B., Sears, C., Schmidt, W., & Trick, L. (1994). Multiple parallel access in visual attention. Canadian Journal of Experimental Psychology/Revue canadienne de psychologie expérimentale, 48, 260–283.   
Pylyshyn, Z. W., & Storm, R. W. (1988). Tracking multiple independent targets: Evidence for a parallel tracking mechanism. Spatial Vision, 179–197.   
Repp, B. H. (1984). Categorical perception: Issues, methods, findings. Speech and Language: Advances in Basic Research and Practice, 10, 243–335.   
Repp, B. H., & Liberman, A. M. (1987). Phonetic category boundaries are flexible. In S. Harnad (Ed.), Categorical perception: The groundwork of cognition (pp. 89–112). Cambridge: Cambridge University Press.   
Righart, R., & Gelder, B. d. (2008). Rapid influence of emotional scenes on encoding of facial expressions: An ERP study. Social Cognitive and Affective Neuroscience, 3, 270–278. PMID: 19015119.   
Rips, L. J. (2011). Causation from perception. Perspectives on Psychological Science, 6, 77–97.   
Rizzolatti, G., & Sinigaglia, C. (2008). Mirrors in the brain: How our minds share actions, emotions. Oxford University Press.   
Rizzolatti, G., & Sinigaglia, C. (2010). The functional role of the parieto-frontal mirror circuit: Interpretations and misinterpretations. Nature Reviews: Neuroscience, 11, 264–274.   
Roberson, D., & Davidoff, J. (2000). The categorical perception of colors and facial expressions: The effect of verbal interference. Memory, 28, 977–986.   
Roget, P. M. (1825). Explanation of an optical deception in the appearance of the spokes of a wheel seen through vertical apertures. Philosophical Transactions of the Royal Society of London, 115, 131–140.   
Sato, W., & Yoshikawa, S. (2007). Spontaneous facial mimicry in response to dynamic facial expressions. Cognition, 104, 1–18.   
Sato, W., & Yoshikawa, S. (2009). Detection of emotional facial expressions and anti-expressions. Visual Cognition, 18, 369–388.   
Sauter, D. A., LeGuen, O., & M, B. (2011). Categorical perception of emotional facial expressions does not require lexical categories. Emotion, 11, 1479–1483.   
Saxe, R., Tzelnic, T., & Carey, S. (2006). Five-month-old infants know humans are solid, like inanimate objects. Cognition, 101, B1–B8.   
Scherer, K. R., & Ellgring, H. (2007). Are facial expressions of emotion produced by categorical affect programs or dynamically driven by appraisal? Emotion, 7, 113–130.   
Scherer, K. R., Mortillaro, M., & Mehu, M. (2013). Understanding the mechanisms underlying the production of facial expression of emotion: A componential perspective. Emotion Review, 5, 47–53.   
Schlottmann, A., Ray, E. D., Mitchell, A., & Demetriou, N. (2006). Perceived physical and social causality in animated motions: Spontaneous reports and ratings. Acta Psychologica, 123, 112–143.   
Scholl, B. J. (2007). Object persistence in philosophy and psychology. Mind $\delta\stackrel{,}{\sigma}L$ anguage, 22, 563–591.   
Scholl, B. J., & Flombaum, J. I. (2010). Object persistence. In B. Goldstein (Ed.). Encyclopedia of perception (Vol. 2, pp. 653–657). Thousand Oaks, CA: Sage.   
Scholl, B. J., & Leslie, A. (1999). Explaining the infant’s object concept: Beyond the perception/cognition dichotomy. In E. LePore & Z. Pylyshyn (Eds.), What is cognitive science? (pp 26–73). Oxford: Blackwell.   
Scholl, B. J., & Pylyshyn, Z. W. (1999). Tracking multiple items through occlusion: Clues to visual objecthood. Cognitive Psychology, 38, 259–290.   
Scholl, B. J., & Tremoulet, P. D. (2000). Perceptual causality and animacy. Trends in Cognitive Sciences, 4, 299–309.   
Shinskey, J., & Munakata, Y. (2001). Detecting transparent barriers: Clear evidence against the means-end deficit account of search failures. Infancy, 2, 395–404.   
Smith, J. (2010). Seeing other people. Philosophy and Phenomenological Research, 81, 731–748.   
Smith, J. (2015). The phenomenology of face-to-face mindreading. Philosophy and Phenomenological Research, 90, 274–293.   
Smortchkova, J. (2014). The social content of visual experience. Ph.D. thesis, Institut Jean Nicod, École Normale Supérieure, Paris.   
Spelke, E. S., Breinlinger, K., Macomber, J., & Jacobson, K. (1992). Origins of knowledge. Psychological Review, 99, 605–632.   
St Clair, R. (2012). Through space and time: An examination of motion in multiple object tracking. Ph.D. thesis, Vanderbilt University.   
Turk-Browne, N. B., Scholl, B. J., Johnson, M. K., & Chun, M. M. (2010). Implicit perceptual anticipation triggered by statistical learning. The Journal of Neuroscience, 30, 11177–11187. PMID: 20720125.   
van der Gaag, C., Minderaa, R. B., & Keysers, C. (2007). Facial expressions: What the mirror neuron system can and cannot tell us. Social Neuroscience, 2, 179–222. PMID: 18633816.   
Vuilleumier, P., & Pourtois, G. (2007). Distributed and interactive brain mechanisms during emotion face perception: Evidence from functional neuroimaging. Neuropsychologia, 45, 174–194.   
Vuilleumier, P., & Schwartz, S. (2001). Emotional facial expressions capture attention. Neurology, 56, 153–158. PMID: 11160948.   
Wicker, B., Keysers, C., Plailly, J., Royet, J.-P., Gallese, V., & Rizzolatti, G. (2003). Both of us disgusted in my insula: The common neural basis of seeing and feeling disgust. Neuron, 40, 655–664.   
Wiggett, J. A., & Davies, I. R. L. (2008). The effect of Stroop interference on the categorical perception of color. Memory & Cognition, 36, 231–239.   
Williams, M., Moss, S., Bradshaw, J., & Mattingley, J. (2005). Look at me, I’m smiling: Visual search for threatening and nonthreatening facial expressions. Visual Cognition, 12, 29–50.   
Wilson, M., & Knoblich, G. (2005). The case for motor involvement in perceiving conspecifics. Psychological Bulletin, 131, 460–473.   
Wolff, P., & Shepard, J. (2013). Causation, touch, and the perception of force. Psychology of Learning and Motivation, 58, 167–202.   
Wolpert, D. M., Doya, K., & Kawato, M. (2003). A unifying computational framework for motor control and social interaction. Philosophical Transactions: Biological Sciences, 358, 593–602.   
Xu, F., Carey, S., & Quint, N. (2004). The emergence of kind-based object individuation in infancy. Cognitive Psychology, 49, 155–190.   
Xu, Y., & Chun, M. M. (2009). Selecting and perceiving multiple visual objects. Trends in Cognitive Sciences, 13, 167–174.  