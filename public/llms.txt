Site: Stephen Butterfill's Personal Academic Website
Author: Stephen Butterfill

---

Title: Mindreading is an Asynchronous Joint Activity: The M-a-J-a Account of Theory of Mind Performance, and Individual Differences
Authors: Apperly, Ian and Devine, Rory T. and Butterfill, Stephen A.
Year: 2025
Type: Publication

<div class="fulltext">
<p><strong>Mindreading is an Asynchronous Joint Activity: The M-A-J-A
Account of Theory of Mind performance, and individual
differences.</strong></p>
<p><strong>Abstract</strong></p>
<p>Research on mindreading has been dominated by questions about the
presence, absence or nature of mindreading concepts or structures, and
by paradigms designed to create the most favourable circumstances for
demonstrating such abilities. This focus on competence has led to a
neglect of questions about performance. Yet without a theory of
performance, mindreading concepts and structures are incapable of
explaining how we ascribe particular thoughts and feelings to other
people, and it is impossible to explain individual differences in
mindreading that are persistent, robust, specific, and consequential for
social abilities. We reconsider the theoretical foundations of
mindreading to develop an account on which competent mindreading
requires generating and selecting mental states that can be recognised
as plausible and appropriate by other people, and so is essentially a
joint social activity. It is an asynchronous joint activity because,
once learned, it can be performed alone. The M-A-J-A (Mindreading as
Asynchronous Joint Activity) account explains how mindreading serves as
a mediator in human social lives, is shaped by social experience, varies
according to that experience, and enables social abilities that would
not be the same without its mediating role. The M-A-J-A account can
explain a swath of existing findings about individual differences in
mindreading that are otherwise puzzling. It provides a framework for
understanding how and why mindreading abilities might vary across the
lifespan, and for developing interpretable and psychometrically robust
measures to study this variation.</p>
<p>Keywords: mentalizing; theory of mind; joint action; individual
differences; psychometric</p>
<p>Forty years after the first empirical paper testing children’s false
belief reasoning, research on mindreading is still viewed predominantly
through the lens of early development. This focus on <em>when</em> such
abilities first occur has consequences for both theoretical and
empirical enquiry. Developmental theories tend to emphasise basic
structural necessities – such as concepts of belief, desire, intention
and the like (e.g., Carpendale &amp; Lewis, 2004 ; Doherty &amp; Perner,
2020; Tomasello, 2018, Wellman, 2014). Empirical studies prioritise
paradigms that are sensitive to the detection of such concepts (e.g.,
Scott &amp; Baillargeon, 2017). Of course, researchers have also
examined <em>how</em> mindreading develops in ontogeny (e.g. Devine
&amp; Lecce, 2021; Gopnik &amp; Meltzoff, 1997; Hughes, 2011; Tomasello,
2010), phylogeny (e.g., Krupenye &amp; Call, 2017; Martin &amp; Santos,
2016), and human history (e.g., Heyes, 2019; Moore, 2021), how it varies
between individuals and groups (e.g., Hughes &amp; Devine, 2015;
Osterhaus &amp; Bosacki, 2022; Yeung et al., 2024; Lillard, 1998), and
its cognitive (e.g., Apperly, 2010; Ferguson &amp; Bradford, 2021) and
neural basis (e.g., Gilead &amp; Oschner, 2021). However, the lens of
early development means that even this research is dominated by
questions about the presence, absence or nature of mindreading concepts
or structures, and by paradigms designed to create the most favourable
of circumstances for demonstrating such abilities. This is critically
limiting for both theoretical and empirical work. Theoretically,
concepts may be necessary for mindreading, but they are insufficient
because it remains unclear how someone with the necessary concepts is
ever in a position to use them effectively. Empirically, as we shall
review below, there is increasing evidence of individual differences in
mindreading that are persistent, robust, specific, and consequential,
yet we lack theories or tasks that cast light on the reasons for this
variation. After 40 years we still do not know how people ascribe any
specific mental state, nor why some people are better at this than
others. Our contention is that these basic questions are related and can
only be addressed by rethinking, from the foundations up, ideas about
what mindreading is and what makes it possible.</p>
<p>In what follows we first introduce our key ideas in outline form.
Next, we develop the theoretical basis for our contention, beginning
from foundations, and explore its consequences for how mindreading is
conceptualised. In the second half of the paper, we show how our
approach can address large gaps in current understanding of longitudinal
stability in mindreading and individual differences across the lifespan.
We end with a framework for the development of new measures. Such
measures would be a major improvement on current approaches because they
would make transparent what it means for a person to be more or less
good at mindreading.</p>
<h1 id="outline">Outline</h1>
<p>What does it mean to “be in a position” to use mindreading concepts
effectively? This is a question that we will tackle in stages, but let
us start by illustrating the essential problem using by far the most
widely-adopted paradigm for mindreading: false belief tasks. In one
classic form of false belief task (Wimmer &amp; Perner, 1983) Maxi
places his chocolate in the blue cupboard. While he is playing outside
his mother moves it to the green cupboard. Maxi returns, wanting his
chocolate. The critical question is where will he look for his
chocolate? Most people over the age of 4 or 5 years agree that he will
look in the blue cupboard, because that is where he falsely believes his
chocolate is located. But <em>why</em> do most people agree? Strictly
speaking, Maxi could reasonably think his chocolate is elsewhere - he
might have prior experience of his mother’s preference for storing food
in the green cupboard, he might have a prior agreement with his mother,
or he might have unusual beliefs about the behaviour of physical
objects. It is only the carefully-crafted pragmatic constraints of the
story (and our sensitivity to those constraints) that mean we are in a
position to conceive of only one possible correct answer. Such false
belief tasks are an essential workhorse of empirical research on
mindreading, but they also obscure the fact that the world is not
subject to the kinds of pragmatic constraints that govern storytelling
and does not typically come neatly curated into correct and incorrect
alternatives for what people think or feel. Outside such tightly
constrained tasks mindreaders must take on much more of the work of
homing in on plausible mental states. Understanding how we do this is an
essential and overlooked puzzle about mindreading.</p>
<p>Why are individual differences in mindreading informative for our
purposes? Again, we will tackle this in stages. But let us first
establish the intuition that there really is variation in mindreading
and explain why this might be puzzling. Imagine, for a moment, your
social network of adult friends, colleagues, and acquaintances. If it is
anything like ours then you might perceive substantial variation in
people’s social skills. You may also work in an environment that is
highly selective for academic ability. If your work environment is
anything like ours, then you might still perceive substantial variation
in social skills. That is to say, although general cognitive ability may
be relevant for social skills, it is clearly not a sufficient
explanation for their variation. As we will later describe, this
conclusion is also borne out by empirical investigations. The puzzle is
that adults, and indeed children from middle childhood onwards, tend to
pass tests for key mindreading concepts (e.g., Wellman, Fang, &amp;
Peterson, 2011). There are tests of “advanced” mindreading that continue
to pose varying degrees of challenge, and children’s earlier performance
on tests of mindreading concepts predict later success with “advanced”
mindreading (e.g., Devine, White, Ensor &amp; Hughes, 2016). However,
there is no theory of “advanced mindreading concepts” to explain what is
challenging about these tasks. Thus, the origin of individual
differences in “advanced” mindreading is a key point of failure for
existing concept-focused theories, and a key challenge for empirical
research is to devise mindreading tasks that do justice to the intuition
that some people appear better at this kind of thing than others.</p>
<h1 id="foundations">Foundations </h1>
<p>Giving someone a chef’s knife does not make them a chef; it may not
even make them good at cutting. Someone looking to employ a chef would
be pleased to see that they have a chef’s knife but would also want to
know that they were able to use it successfully. Research on mindreading
has been dominated by the first half of the job description, that is,
whether the mindreader has the necessary concepts and rules, while
neglecting the second half, that is, whether they can they use them
successfully. We believe that key puzzles in research on mindreading can
be traced to this neglect.</p>
<p>The issue of successfully using mindreading concepts and rules may
seem simple, a minor detail even. Yet comparison with linguistic
communication suggests otherwise. While much can be learned from the
study of words and linguistic rules, multiple additional fields of study
(for example, in phonetics and pragmatics) have proved necessary for
addressing how such elements of language are used for successful
communication. Likewise, understanding mindreading performance may
require fundamentally new ideas. To understand performance, we need an
account of successful mindreading.</p>
<p>It is commonly supposed that when we mindread, success consists in
identifying facts about mental states as accurately as possible. Framed
this way, one starts with an agent whose head is full of beliefs,
desires, and intentions that interact to cause the agent’s behaviour.
These mental states cannot be observed directly, and so the mindreader’s
job is to infer what they might be from the agent’s behaviour. Success
is determined by identifying as accurately as possible which mental
states the agent in fact has. To many readers this will seem so
obviously true that it does not need stating, and although it is seldom
stated this supposition is the foundation for most psychological
research on mindreading. But one does not need to look far for a
contrary view. Dennett’s (1988) “intentional stance” theory is widely
cited in empirical research on mindreading. Yet in Dennett’s framing
mental states are ascribed as an interpretive gloss over a set of
behaviours with no commitment to their neurocognitive basis. If
behaviour is predicted successfully then the mental state ascriptions
are accurate. The sense in which agents “have” mental states is
fundamentally different in this framing because the facts about mental
states are determined by whether mindreading succeeds or fails (and not
the other way around).</p>
<p>While Dennett focussed on successful prediction of behaviour as the
standard of success for mindreading, others have proposed widening the
standard to include success in attributing responsibility, making sense
of behaviours, and modulating behaviours or ‘mindshaping’ (e.g.,
Zawidzki, 2013). In what follows we offer a partial defence of these
insights and build on them to offer a refinement: successful mindreading
requires generating and selecting mental states that can be recognised
as plausible and appropriate by other people.</p>
<p>This view of successful mindreading need not be based on taking for
granted Dennett’s position. One can also support the view by starting
from an opposing theory on which facts about mental states do determine
whether mindreading is successful, namely Davidson’s (1973, 1985, 1990)
extensively developed theory.<a href="#fn1" class="footnote-ref"
id="fnref1" role="doc-noteref"><sup>1</sup></a> Inspired by the success
of decision theory, and specifically by the possibility of treating
decision theory as an elucidation of what preferences are (Jeffrey,
1983),<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a> Davidson pointed to a set of
normative requirements which specify a structure to which, he claimed,
any mindreading target’s mental states must conform (Davidson, 1980, 7,
12).<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a> To illustrate, one requirement is
that the target’s beliefs be logically consistent; another is that the
target and the mindreader agree about which observations provide
evidential support for which conclusion. Davidson demonstrated that this
structure makes it possible, in principle at least, to discover a
person’s mind through observation and communication.<a href="#fn4"
class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>
Davidson’s theory also entails a clear view about what makes for better
or worse mindreading. In the same sense that there are facts about an
object’s weight or temperature, so also there are facts about a person’s
mental states; and better mindreading is more accurately identifying
those mental states.<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p>
<p>But is this view true? Davidson’s theory was never supposed to be an
account of how people actually read others’ minds (Davidson, 1990),<a
href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a> but by articulating the
requirements-in-principle for accurate identification of mental states
it illuminates some challenges of mindreading in practice. As we will
see (in the section on <em>Formal Models</em>), these challenges also
arise for theories which attempt to describe how people actually read
others’ minds (e.g., Baker et al, 2017). Attention to the challenges
will lead us to a different view about what makes for better
mindreading.</p>
<p>The first challenge is the problem of infinite observations.
Davidson’s theory requires observations of ‘a potential infinity’ of
actions to identify any mental states at all (Davidson 1990, 314). In
order to ascribe to Maxi the belief that the chocolate is in the blue
cupboard the mindreader would need to observe all of the possible
consequences of that belief. Without doing so it is impossible to
exclude the potential infinity of variously similar but non-identical
beliefs (e.g., that he thinks the chocolate is in the blue cupboard
every day except Thursdays). By contrast, practical mindreading involves
not merely finite<del>,</del> but often very few observations, as
illustrated by even the simplified case of Maxi discussed above. How can
mindreaders coherently attribute any mental states based on few
observations? However they do this, it will amount to selecting one or
another set of background assumptions to fill in the missing
observations imaginatively. Which background assumptions should be
adopted? There are indefinitely many possible background assumptions
which could be used to fill in missing observations. We have already
illustrated this in the case of Maxi: when asked about his actions or
beliefs, many people assume, usually implicitly, that Maxi shares their
beliefs about the ways physical objects behave, that he has no
expectations about his chocolate moving while absent, and so on. These
implicit assumptions fill in for missing observations. But there are, of
course, other assumptions people could make which would lead them to
predict different actions and to attribute different mental states to
Maxi. And these alternative assumptions would not necessarily be wrong.
A group of people might be found to rely on different implicit
assumptions, and there would be no logical or rational grounds to
criticise them. The most we can say is that there is likely to be an
advantage in making roughly the same background assumptions as other
people with whom you might seek agreement, including Maxi.</p>
<p>This matters for understanding what skilled mindreading performance
is. Having the right concepts and rules is not sufficient. Practical
considerations will be needed in selecting background assumptions to
fill in missing observations. Whether particular background assumptions
are good may depend on a mindreader’s aims: what works well for
prediction may work less well when the aim is to assign blame or to
challenge another person’s self-understanding. Given the value of
agreement with others on which mental states a person has, whether
particular background assumptions are good may also depend on which
assumptions other mindreaders will make. One consequence is that better
mindreading is not a matter of more accurately identifying mental
states, because objective criteria for accuracy are not in play. Another
consequence is that better mindreaders may be more flexible in shifting
background assumptions between contexts, more willing to consider a
wider range of possible mental states when confidence in background
assumptions is lower, and better at aligning background assumptions with
others. In short, they will be good at generating plausible background
assumptions and at selecting the most appropriate from among them.</p>
<p>One might attempt to respond to this challenge by suggesting that
mindreading need not involve infinite observations at all because it can
be anchored in platitudes (Lewis, 1972). To illustrate, one platitude is
that being told something entails knowing it. If Maxi is told that his
chocolate is in the green cupboard, then we might infer that Maxi knows
his chocolate is in the green cupboard. Such platitudes are surely
useful in mindreading (Heider, 1958), but we will overestimate their
usefulness if we ignore context. Perhaps the speaker has deceptive
motives, or is joking, or simply being sarcastic. Perhaps Maxi does not
hear or correctly process the message. An indefinite range of contextual
factors can render the platitude incorrect. Appeal to platitudes appears
to solve the problem of infinite observations only if we ignore the role
of context in mindreading.</p>
<p>The problem of irrationality is the second challenge we face in
applying Davidson’s theory in practical mindreading. Similarly to
decision theory, Davidson’s theory applies only on condition that people
are ideally rational (and, perhaps even less plausibly, mostly
truthful). This condition requires not just flawless inferences: Maxi’s
every belief, desire and intention must at all times bear in exactly the
right way on his actions.<a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> Failure of this condition would lead
to the conclusion that no humans, nor any other finite animals, have any
mental states at all—and our bounded rationality implies, of course,
that this condition does fail.<a href="#fn8" class="footnote-ref"
id="fnref8" role="doc-noteref"><sup>8</sup></a> A model of how people
attribute mental states must allow that people are rational only within
limits. Davidson suggested that his theory can be saved only by adopting
the formal device that it should apply to parts of people’s minds within
which the rationality assumption could hold.<a href="#fn9"
class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>
While other strategies are conceivable (for example, practical
mindreaders will simply ignore some of the things people do), any
strategy involves deciding where exactly to hold on to a rationality
assumption. To illustrate, if Maxi’s preferences fail to exhibit
transitivity we might select between different possibilities about which
are his ‘true’ preferences and which decision reflects a ‘mistake’. This
selection cannot, of course, be made on the basis of what is rational.
What makes for better or worse selections will depend on practical
considerations like the mindreader’s culture, as there are likely to be
advantages in agreeing with others around us on which mental states
someone has. This is a second reason why we cannot think of better
mindreading as simply being more accurate in identifying mental states.
Because there are many ways you could compensate for irrationality,
there are many ascriptions of mental states which will all count as
equally accurate. But in practice, people around you are unlikely to
recognize you as a competent mindreader unless you agree with them about
what Maxi’s mental states are, and the ability to agree with them is
what underwrites mindreading’s utility, even when mindreading alone.</p>
<p>To conclude this section, the problems of infinite observations and
irrationality complement each other as one concerns a limit on
mindreaders (they are finite) and the other a limit on the mindreader’s
targets (they are imperfectly rational). Both problems motivate
rejecting the otherwise attractively simple idea that better mindreading
is merely a matter of more accurately identifying mental states.<a
href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a> Instead, we must recognize that
using mindreading concepts effectively involves identifying assumptions
that are plausible and selecting those that are appropriate in a given
context. What makes assumptions plausible and appropriate is not
something internal to mindreading but is a consequence of what seems
plausible and appropriate to people, who of course include both
mindreaders and mindreading targets. In this respect, mindreading is not
entirely unlike public gift-giving. Success requires other people being
disposed to recognise that the gift—or mental state ascription—was
appropriate. Ultimately, then, an individual is successful at
mindreading if they ascribe states, predict behaviours, assign
responsibility, and so on in just the way that would occur if they were
involved in a joint mindreading activity with others around them.</p>
<h1 id="developing-the-theory">Developing the theory </h1>
<p>As described in the <em>Outline</em> section, concepts and rules are
unlikely to be sufficient for mindreading because there may be multiple
plausible responses even in simple cases. For example, even carefully
crafted false belief tasks appear to be a test of whether someone’s
intuitions, and their confidence in them, go well beyond anything
established by mental state concepts, general principles for their
application, and the available evidence in this particular
situation.</p>
<p>To see the extent of this challenge we need a richer example than
classic false belief tasks, and so we start by developing the problem of
mindreading other people’s thoughts and feelings through the example of
gift-giving. Tulip, the head of department, is delighted with the
tickets to the opera that her staff bought for her 50<sup>th</sup>
birthday. When Bruno, Tulip’s secretary, was tasked with organising the
gift a few ideas had sprung to mind, though on reflection some seemed
better than others. Although Tulip isn’t known as an opera buff, it felt
like the kind of thing she would like, and her partner confirmed that
she didn’t already have tickets. Moreover, it’s the kind of thing she
would be happy for everyone to know that she likes. Bruno was confident
Tulip would have liked a wine-tasting class even more, but highlighting
her liking for alcohol felt potentially awkward, especially in an office
where some colleagues do not drink.</p>
<p>This example illustrates that beneath the surface of the everyday
activity of gift-giving lies considerable complexity. Success requires
abductive “best guesses” about potentially appropriate gifts, which take
account of the characteristics of the recipient and their context.
Selection among these possibilities that present themselves involves
consideration of reasonableness, normativity, and reflexive awareness of
others, as well as accommodating particular facts (such as whether the
recipient already has the present). In short, selecting a gift draws
upon a rich web of information, sources of structure, and constraint, it
is essentially relational (involving the giver, the receiver, and
audience), and reaches both forwards and backwards in time to take
account of relevant history and anticipate future consequences. From
everyday experience we might add that it is also something that some
people seem distinctly better at than others.</p>
<p>Our contention is that gift-giving illustrates key challenges
inherent in many instances of mindreading. In common with longstanding
views, mindreading involves the generation and selection of candidate
thoughts or feelings for the target. In contrast with most existing
views, it suggests that the success of mindreading should be judged by
the extent to which it accords with “what people would think” is
plausible and appropriate. It even implies that someone mindreading
alone is nevertheless attempting to reason from the perspective of a
group of people, which is a form of collective reasoning (e.g.,
Bacharach, 2006; Chater et al., 2022; Schelling, 1960). In what follows
we aim to show that these insights motivate a new theory, assimilate a
wide range of disparate empirical evidence, and generate productive
directions for new research on how social understanding varies between
individuals and between groups.</p>
<p><strong>Analogy with modal thinking</strong></p>
<p>The challenge of generating useful answers from a large and
ill-defined problem space is widely recognised outside of the literature
on mindreading. For example, Phillips et al. (2021) addressed the puzzle
of “what comes to mind” during modal thinking about what is possible,
but potentially not actual. They note that previous literature
consistently “…proposes that we generate the ’alternative possibilities’
fundamental to modal cognition by (i) delimiting a task-relevant
partition within the vast space of conceivable possibilities, (ii)
considering a smaller subset of particular possibilities within the
relevant part of that partition, and then (iii)<a href="#fn11"
class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>
ordering or evaluating them in task-relevant ways to inform our final
modal judgments” (p1027). For example, faced with the task of
identifying something for dinner after a disabling trip to the dentist
(e.g., Morris et al., 2021), people might (i) form a task-relevant
partition of “dishes” (ruling out the much larger set of all inedible
things, and things that are edible but not dishes), (ii) generate a
smaller “consideration set” of possibilities based upon heuristics
including decontextualised value and frequency (iii) select from the
consideration set a dish that avoids elements that are hard or crunchy
and therefore unsuitable after a disabling trip to the dentist. We
believe the challenge of generating and selecting possibilities in modal
thinking is a model for the challenge of generating and selecting mental
state ascriptions in mindreading , but also that mindreading requires
distinctive solutions to these challenges that are enlightening about
how mindreading is possible and why it might vary between people.</p>
<h2 id="mapping-the-analogy-to-mindreading.">Mapping the analogy to
mindreading.</h2>
<p>As already noted, it is often assumed that, for someone with the
right concepts and rules, mindreading is a matter of inferring from
observed behaviour what people think, feel and intend, much as you might
infer from texture and rise what is happening inside a loaf. As we noted
in <em>Foundations,</em> making such inferences in mindreading would
require choosing which of indefinitely many possible background
assumptions to make and selecting one among many possible ways of
repairing irrationality. The range of possible background assumptions
and repair strategies therefore generates a puzzle: How are we so
remarkably good at having clear intuitions about what someone else is
thinking, feeling, or intending, with high confidence and in agreement
with others? Any adequate account of mindreading must explain how these
difficulties are overcome.<a href="#fn12" class="footnote-ref"
id="fnref12" role="doc-noteref"><sup>12</sup></a> In an analogous way to
modal thinking we propose that having such intuitions depends on (i)
“partitioning” with rule-based constraints, (ii) generating a
“consideration set” of plausible possibilities by narrowing down the
possible range of thoughts, feelings, or intentions another is having,
and (iii) selecting the most appropriate answer from the consideration
set.</p>
<p><strong>(i) Partitioning</strong><em>.</em> Mindreading affords many
opportunities for using rules to partition the indefinitely large space
of possible mental states. For example, since <em>Anna Karenina</em> was
both written and set in late 19<sup>th</sup> century Russia, Anna could
never have views about such things as global warming or smartphones, or
anything else that was not known at the time. Equally, Steve Jobs’
koumpounophobia provides a rule-based limit on the space of possible
desires that could be ascribed to him. However, while partitioning in
this way clearly reduces the possibilities, as for modal reasoning, the
space of possible answers will often remain large, leaving a major
challenge for steps (ii) and (iii), which cannot be addressed using
rules.</p>
<p><strong>(ii) A consideration set of plausible possibilities.</strong>
Step two in the model of modal reasoning uses heuristics including
decontextualised value and frequency as a basis for generating a
consideration set of plausible possibilities. These heuristics are
unlikely to be helpful for mindreading because they are insensitive to
context and reflect only the person’s individual interests and
experiences. What is needed is some heuristic basis on which “what comes
to mind” could be conditional on context and the collective interests
and experiences of people, not individuals.</p>
<p>To address this, we take inspiration from analysis of related
challenges that arise when people interact for communicating and acting
together. An influential suggestion is that interacting people address
these challenges by aligning their actions, and the mental
representations and neural processes that govern them. For example,
during a discourse, participants make rapid decisions about the
linguistic forms they are hearing and producing, based on perceptual
input that only partially constrains choices. Many accounts suggest that
participants solve this problem through alignment. Over repeated
conversational turns, discourse participants increasingly converge in
their phonology, word selection, syntax, and meaning representations
(e.g., Galotti &amp; Frith, 2013; Pickering &amp; Garrod, 2004). So
although on a given turn a speaker might have used many possible
linguistic forms to express their meaning, they are more likely to
repeat ones that have already featured in the discourse. These
alignments simplify the tasks of communicators, by making the same
(aligned) representations more available than logically possible
alternatives.<a href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a> Importantly, interactive alignment
does not entail mindreading, or other inferential processes, but is
thought instead to depend upon “low-level” priming mechanisms at
multiple levels of processing (e.g., Pickering &amp; Garrod, 2004).</p>
<p>Such alignments have been studied at timescales from milliseconds to
minutes, focussing on temporary alignments between participants in a
discrete interaction that are dispensed with at the end of the
interaction. These are the wrong properties for our purposes. Firstly,
it is unlikely that the alignment that is possible within a single
interaction would be sufficient to bridge the large gap between generic
information from scripts and schemas and the ascription of highly
specific thoughts and feelings. Secondly, temporary interactive
alignment cannot, by definition, support mindreading outside
interactions, yet such mindreading is commonplace. We suggest that these
limitations could be addressed with a relatively modest extension of
theories of interactive alignment. Research on discourse processing
finds that comprehension influences different memory systems over
different timescales, with some effects only operating within the
limited bounds of short-term memory and others drawing upon and
influencing long-term memory (e.g., Rayner, Pollatsek, Ashby &amp;
Clifton, 2012). It is only a small step to suppose that alignment, too,
develops beyond specific interactions, creating longer-term,
asynchronous alignment. Such alignment means that in situations where
collective reasoning is relevant, individuals are primed, in a
context-sensitive manner, to think similar things in similar ways.</p>
<p>In sum, Morris et al. (2021) suggest that responses “come to mind”
for modal reasoning according to their frequency and “cached value”
derived from the reasoner’s experience. We suggest that responses “come
to mind” for mindreading according to their salience derived from the
mindreader’s past interactive alignment. We propose that such
asynchronous alignment is critical for explaining how people are in a
position to generate plausible candidates for what another person might
be thinking or feeling.</p>
<h3
id="iii-selecting-an-appropriate-answer-from-the-consideration-set-of-plausible-mental-states.">(iii)
Selecting an appropriate answer from the consideration set of plausible
mental states.</h3>
<p>Models of modal reasoning commonly propose that plausible candidate
responses are evaluated according to task-specific constraints (such as
needing to avoid hard or crunchy food) to select a response (Phillips et
al., 2021). For mindreading the example of gift-buying illustrates the
considerations that guide the selection of an appropriate thought or
feeling. These include normative rules about what is morally and
socially appropriate, and whether the ascription seems reasonable in
light of other things we know about what the person thinks, wants and
feels, and other aspects of their situation, time, or circumstances.
Considerations are at least sometimes reflexive, such that what I think
someone else will want should depend, in part, on their knowing that I
or others might find out.</p>
<p>Importantly, such consideration of “appropriateness” is essentially
social. What it means to pick the most appropriate possible mental state
may just be to pick the one to which a group of people – including the
mindreader and the target of the mental state ascription - might also
agree, given sufficient time to discuss it. This is why an important
determiner of mindreading success will be shared criteria of
appropriateness, shared norms and therefore shared background and
experience with the targets of mindreading and everyone else
involved.</p>
<h2
id="conclusion-mindreading-is-an-asynchronous-joint-activity-m-a-j-a">Conclusion:
Mindreading is an asynchronous joint activity (M-A-J-A<a href="#fn14"
class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a>)</h2>
<p>We propose that mindreading involves partitioning, generation of
plausible candidate thoughts and feelings for the mindreading target,
and selection of the most appropriate from among this set. Mindreading
is “asynchronous” insofar as the criteria of plausibility and
appropriateness depend upon a background that exists prior to the
current mindreading episode. This is true whether the mindreader is a
participant or a spectator in a current social interaction, or if they
are alone in the dark trying to imagine why their friend has not called,
or whether Tolstoy was consistent in his depiction of Karenin’s
indifference to his wife’s mental life. Mindreading is nevertheless a
“joint activity” because the criteria of plausibility and
appropriateness are essentially joint criteria. These criteria are not
merely socially learned. Rather, they are constituted by the intuitions
and principles with which groups of mindreaders will tend to agree, and
to which individuals hold themselves in order to be considered rational
and reasonable.</p>
<p><img src="/public/img/articles/apperly2025_mindreading/image1.png" style="width:6.27014in;height:6.70486in"
alt="A diagram of a process AI-generated content may be incorrect." /></p>
<p><em>Figure 1. Schematic model of the process of generation and
selection of mindreading inferences. (a) Rule-based constraints form a
partition of possible mental states from the field of all available
mental states. (b) Plausible candidates are generated by integrating
inputs about the target and context with background information that has
been structured through interactive social experience. Variation in
plausibility is represented by the height of the blue bars. (c) The most
appropriate candidate(s) is selected by integrating inputs about the
target and context with considerations of normativity, morality, and
reasonableness derived from prior social experience. The selected mental
state (red bar) may not have been the most plausible at step (b). The
selections may become additional inputs to the generation process (d),
resulting in further cycles of generation and selection. This ultimately
leads to an appropriate candidate being selected as the mindreading
inference (e).</em></p>
<h1 id="comparison-with-other-accounts">Comparison with other accounts
</h1>
<p>The present account builds upon a rich history of over forty years of
theories about the nature of mindreading by philosophers and
psychologists. In this section we aim to cast light on the current
proposals by identifying crucial points of similarity and contrast with
existing accounts. The lens of early development has led many accounts
to focus upon the basic structural necessities for mindreading. This
leads them to neglect or underestimate the importance of questions about
<em>how</em> we ascribe mental states that are plausible and
appropriate, and severely limits their capacity to explain developmental
continuity beyond early childhood or continuing variation in mindreading
in adults.</p>
<h2 id="tomm-sp">ToMM-SP</h2>
<p>A longstanding account proposes that a “Theory of Mind Module”
generates possible belief contents while a “Selection Processor” selects
between them (e.g., Leslie, Friedman &amp; German, 2004). We do not
endorse this modular account, but we gladly acknowledge that our
proposal that mindreading involves processes of generation and selection
takes inspiration from this and other work that distinguishes between
generation and selection during reasoning and decision-making (e.g.,
Kahneman, 2003; Morris et al., 2021). However, Leslie et al.’s account
suffers from two essential problems that relate to the challenges
addressed in the present work. First, the ToMM-SP model provides no
explanation for how the Theory of Mind Module generates possible belief
contents. This should not be surprising since a modular architecture is
thought by many to be incompatible with the abductive reasoning required
for mental state ascription (Fodor, 2001). Second, Leslie et al.’s
account provides no explanation for how the Selection Processor decides
which belief to inhibit and which to select (e.g., Apperly, 2010;
Doherty, 2008). Leslie, Friedman, and German (2004) hint at the
challenge when they suggest that “In reaching its decisions, [the
Selection Processor] accesses a learned database of circumstances
relevant to selecting between candidate beliefs”. However, because their
focus is on the basic structural necessities for mindreading they do not
consider the challenges in understanding how such a database develops or
how it supports such decisions. From the current perspective the ToMM-SP
account addresses much of the challenge of mindreading with a promise
that a solution exists somewhere else.</p>
<h2 id="development-of-structures-and-concepts">Development of
structures and concepts</h2>
<p>Whereas the ToMM-SP account assumes that the fundamental structures
and concepts for mindreading are innate in a domain-specific module,
other influential accounts propose that these are acquired during early
development. For example, Perner and colleagues emphasise the
acquisition of cognitive structures for metarepresentation (Perner,
1991) or, more recently, for the abstract representation of perspective
(Doherty &amp; Perner, 2020). We acknowledge, of course, that a full
account of mindreading requires a theory of the cognitive structures
involved. However, such structures are empty vehicles for mindreading;
necessary for representing mental states but providing no account of how
the mindreader comes to ascribe any particular mental state to anyone.
In a related programme of work, Wellman and Gopnik (e.g., Gopnik &amp;
Wellman, 1992) have led the way in studying children’s acquisition of
fundamental mindreading concepts, of perception, knowledge, belief,
desire, intention and the like (e.g., Gopnik &amp; Meltzoff, 1997;
Wellman, 2014). On one reading these concepts play an analogous role to
the structures emphasised by Perner and colleagues, providing the
necessary vehicles for mindreading but no account of their use. On
another reading, concepts are intended to specify the rules for the use
of mindreading – an approach sometimes referred to as “theory-theory”
(Gopnik &amp; Wellman, 1992, Gopnik &amp; Meltzoff, 1997). However, for
reasons described above they fall far short of achieving that objective
and there are reasons to doubt that they could if they tried. Research
on the development of structures and concepts can complement but cannot
replace the idea that mindreading is an asynchronous joint activity.</p>
<h2 id="mindreading-as-simulation">Mindreading as simulation</h2>
<p>The essential idea behind simulation accounts is that the mindreader
need not have an exhaustively specified set of rules for mindreading and
can instead use their own mind as a model with which to simulate the
functional processes of the target’s mind (e.g., Goldman, 2006; Harris,
1992). For this reason, it has been suggested that simulation might
avoid the problems of intractable processing described above (Heal,
1996). Accounts typically appeal to “relevant similarity” in biology and
experience which ensures that any one brain may serve as the basis for
simulating any other, given appropriately similar starting states.
However, accounts never explain how biology or experience underwrites
the kinds of similarity that are necessary. For this reason, simulation
accounts beg the question which should be at the centre of any account
of mindreading: how is it that anyone is ever in the position to
mindread?<a href="#fn15" class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a></p>
<p><strong>Scripts, Schemas and Intuitive Models</strong></p>
<p>Research in cognitive and social psychology suggests that
representations of events, situations, and people are organised into
scripts, schemas, and stereotypes (e.g., Cantor et al., 1982; Fiske
&amp; Taylor, 1984; Gilbert, 1998; Schank &amp; Abelson, 1977). These
ensure that people in a restaurant (to pick a famous example) will share
certain expectations about seating, ordering, eating etc., enabling
co-ordination between waiters, sommeliers, and diners. Likewise, there
is evidence that people have an intuitive model of the structure of
personality traits (a “mindspace”), the accuracy of which is related to
their success on advanced mindreading tasks (e.g., Conway et al., 2019;
Long et al., 2022). Each of these knowledge structures offers schematic,
generalizable information about a situation, event, or person that
surely helps with forming a consideration set of plausible possibilities
for what someone is thinking. However, this utility is both problematic
and limited. It is problematic because over-reliance on generic
information is likely to be a source of systematic bias in mindreading
(Spaulding, 2018), just as it is in a wide range of other social
judgements (e.g., Fiske, 1993). It is limited because scripts, schemas,
stereotypes, and other intuitive models are insufficient to explain how
we are in a position to go beyond generic information to make flexible,
fine-grained, ad-hoc inferences in a particular instance.</p>
<p><strong>Mindreading Accuracy</strong></p>
<p>The challenge of mindreading has often been framed in terms of the
“unobservability” of mental states that are presumed to exist in the
head of the target of mindreading (e.g., Goldman, 2006; Gopnik &amp;
Wellman, 1992; Johnson, 2000; Leslie., 1987; Whiten, 1996). This has
motivated attempts to access the “ground truth” of what mindreading
targets think and feel by asking them to report on these mental states,
and it motivates the idea that the objective of mindreading is accurate
identification of those unobservable mental states (e.g., Long et al.,
2022; Long, Catmur &amp; Bird, 2024). These views face challenges both
in theory and in practice.</p>
<p>The idea that people have privileged and accurate access to their own
thoughts has a long and contentious history (Locke, 1689; Russell, 1917;
Stich, 1983; Boghossian, 1989; Dretske, 1994; Shoemaker, 1994; McGeer,
1996; Moran, 2001; Bar-On, 2004). It may even be that such self-reports
entail the application of interpretive mindreading to oneself (e.g.,
Carruthers, 2011). Therefore, it is far from obvious that self-reported
mental states are a source of ground-truth against which the accuracy of
mindreading can be evaluated. Suppose, however, that self-reported
mental states were a potential source of ground-truth. Even then,
accounts of mental state ascription suggest that accurate identification
of these states by mindreaders is not possible in practice, and so
cannot be a criterion for mindreading success (see
<em>Foundations</em>).</p>
<p>In practice, a long tradition of research on “empathic accuracy” has
nonetheless assessed mindreaders’ accuracy against targets’
self-reports. With origins in research on therapeutic interactions Ickes
and colleagues (e.g., Ickes et al., 1986; Ickes, 1993; Marangoni et al.,
1995) had targets watch a recording of themselves during a clinical
interview or an informal interaction and report post hoc on the thoughts
and feelings they were experiencing. However, this programme of work
finds only limited evidence for stable individual differences in
empathic accuracy when participants attempt to infer those thoughts and
feelings (Ickes et al., 2000). Accurate judgement of emotional valence
depends upon the target themselves demonstrating high emotional
expressivity (Zaki et al., 2008), and empathic accuracy is often
better-explained via relational factors such as whether (and how well)
the target and perceiver are known to each other, rather than the
mindreading abilities of participants (e.g., Zaki et al., 2009).</p>
<p><strong>Mindshaping</strong></p>
<p>Zawidzki (2013) claims that the success of human communication and
coordination is founded in the interlocking products of social
experience. Social experience shapes people’s minds in ways that make
them mutually interpretable and entitles individuals to reasonable
expectations about others while also making them subject to the same
reasonable expectations themselves. While Zawidzki’s (2013) objectives
are not limited to theorising about mindreading<a href="#fn16"
class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>
there is a clear relationship with the present account. Alignment is a
two-way process, and so our proposal that successful mindreading depends
on asynchronous alignment implies that the criteria for successful
mindreading serve a regulatory as well as a descriptive function,
providing criteria to which the target of mindreading should be holding
themselves. Consistent with Zawidzki (2013), according to the M-A-J-A
account we not only mindread others but also expect everyone (including
ourselves) to be held accountable to mindreading interpretations of
their own thoughts, feelings, and behaviour. This shared expectation
provides further foundation for the effectiveness of socially agreed
interpretive principles.</p>
<h2 id="formal-models-of-mindreading">Formal models of mindreading</h2>
<p>There have been recent advances in modelling mindreading using formal
methods. For example, Bayesian models conceptualise intuitive
understanding of behaviour as a “naive utility calculus” according to
which people act rationally to maximise their expected rewards (e.g.,
Baker et al., 2017; Jara-Ettinger et al., 2016). Within a simple
simulated world, such models can predict action given an agent’s desires
and beliefs and infer the most likely beliefs and desires from
observation of behaviour. They yield results that accord impressively
well with the judgements of children and adults. However, success for
“Bayesian ToM” models has only been demonstrated for simple scenarios
that maintain tractable reasoning by creating a highly constrained toy
world of possible beliefs and desires, and as noted by Stuhlmuller and
Goodman (2014) <em>“At the algorithmic level, it seems likely that exact
inference will not scale to models with realistic state spaces.”</em>
This illustrates that the problems of infinite observations and
rationality raised in <em>Foundations</em> also arise for these newer
formal models. Clearly these and analogous formal models (e.g.,
Veissiere et al., 2019) offer exciting prospects for future advances by
specifying the general reasoning principles over mindreading concepts.
Stuhlmuller and Goodman suggest that there is an outstanding question of
understanding how humans cope with situations that cannot be modelled
with an exact inference algorithm. We believe this is directly aligned
with the M-A-J-A account’s objective of understanding how humans make
mindreading inferences that are plausible and appropriate without
artificial constraints on the state space of possible mental states.</p>
<h2 id="mindreading-is-3rd-person-and-spectatorial">Mindreading is 3rd
person and spectatorial</h2>
<p>An influential critique proposes that social abilities essentially
involve interaction with others (e.g., Redcay &amp; Schilbach, 2019;
Schilbach et al, 2013). This view paints mindreading as non-interactive,
“third-person”, and “spectatorial”, and therefore a mis-characterisation
of our social abilities. We suggest that a less polarised perspective
may be useful. We take it as a given that many social abilities do not
require mindreading. Equally, it is clear that mindreading is something
that people do, that it serves valuable functions, and stands in need of
explanation. Moreover, while mindreading surely occurs during
interactions it just as surely occurs outside of them. Therefore, an
account of mindreading cannot depend upon the involvement of the
mindreader in a current interaction with another person. There is
potential for rapprochement, however, because the account developed here
<em>does</em> suggest that mindreading is essentially a joint activity,
albeit one where the “joint” aspects are often asynchronous because they
are the products of past interactions and anticipate future social
evaluation.</p>
<h2 id="mindreading-is-socially-constructed">Mindreading is socially
constructed</h2>
<p>The M-A-J-A account has clear affinities with a variety of claims
about the social construction of mindreading. It is also informative to
identify points of divergence. A social constructivist perspective is
prominent in developmental research (e.g., Carpendale &amp; Lewis, 2004;
Fernyhough, 2008; Meins, 2013; Nelson, 1998; Tomasello, 2018), inspired
by theoretical ideas from Vygotsky (1931/1997) and Mead (1934), and
drawing upon evidence that early mindreading is influenced by social
experience with parents and siblings (for meta-analysis see Devine &amp;
Hughes, 2018), and linguistic experience, perhaps especially with
communicative and pragmatic aspects of language (e.g., Astingon &amp;
Baird, 2005). Guided by the lens of early development these approaches
have emphasised the social construction of basic mindreading concepts
and set themselves in contrast to nativist accounts (e.g., Leslie et
al., 2004) or constructivist accounts that emphasise individual
discovery and theory-building (e.g., Gopnik &amp; Meltzoff, 1997;
Wellman, 2014). However, our account is agnostic on this question about
early development: mindreading concepts could be innate, individually or
socially constructed, or indeed the emphasis on the acquisition of
mindreading concepts could be misplaced. There still remains the
question of how people put these abilities to practical use, and this is
the focus of our account. This has not typically been a focus of social
constructivist accounts of early development, even if they might
naturally be extended for this purpose.</p>
<p>Beyond the focus on early development, researchers from a range of
disciplines have suggested that mindreading might be influenced or even
constituted by “narrative practice” that is essentially socio-cultural
in nature (e.g., Bruner, 1990; Hutto 2012; Nelson. 1998) and might be
affected by experience with reading character-rich fiction (Zunshine,
2006). Narratives (whether oral or written) are very rich forms,
conveying information about people and situations both directly, and
more indirectly in ways analogous to scripts and schemas. Like
mindreading, storytelling involves turning a potentially infinite space
of possibilities into a finite one. For these general reasons narrative
experience is a plausible contributor to mindreading, and it is
plausible that good storytellers are also good mindreaders. However, a
particularly distinctive idea is that folk psychological narratives
“...make explicit mention of how mental states ….. figure in the lives,
history, and larger projects of their owners” (Hutto, 2009, p11), and
that exposure to such narratives, and experience with generating such
narratives of one’s own, provides the crucial training for understanding
how mental states work together in predictions, explanations, and
justifications of words and deeds. If this idea is understood in terms
of different narrative forms this would suggest that different forms of
folk psychological narrative are relevant inputs for mindreading but are
limited because they deal only in generalities in a similar way to
scripts and schemas. A yet more productive reading of this idea is that
narrative communication may be a critical forum for learning the soft
constraints on how mindreading is used to make sense of oneself and
others, and to test one’s own application of those constraints is
aligned with that of the critical arbiters: other people.</p>
<h2 id="two-systems-accounts">“Two-systems” accounts</h2>
<p>Two of us (Apperly &amp; Butterfill, 2009; Butterfill &amp; Apperly,
2013) have argued that mindreading might be achieved via two types of
process that make complementary trade-offs between flexibility and
efficiency, in common with longstanding proposals in many other areas of
cognition. The account developed here is wholly independent of the
success or otherwise of a two-systems approach to mindreading.</p>
<p>The M-A-J-A accont shares some of the same motivating concerns. Part
of the motivation for a two-systems account is that processing
“belief-like states” that are simpler than beliefs provides a way of
avoiding the potentially intractable processing described earlier, if
only for the limited range of cases where belief-like states will
suffice. However, our two-systems account has not fully addressed the
challenge of explaining how people manage to ascribe full-blown beliefs.
To that extent the present proposals could be viewed as addressing a
significant omission in the two-systems account. Importantly, however,
this is also a significant omission from every alternative theory,
meaning that the present critique and proposals are relevant
irrespective of one’s preference among current theories of
mindreading.</p>
<h1
id="applying-the-theory-to-the-challenge-of-understanding-individual-differences-in-mindreading">Applying
the theory to the challenge of understanding individual differences in
mindreading</h1>
<p>Thus far our account has been motivated by the observation that
existing theories of mindreading fail to explain how mindreading
concepts can be used in practice. We now turn to variability in
mindreading. The motivating intuitions here are that some people are
more socially able than others, that their social abilities may vary
between contexts (e.g., home versus the workplace), and that variation
in mindreading has something to do with this. These intuitions are
validated by impressive advances in measurement of individual
differences in mindreading. The need for new theory is motivated by the
surprising failure of existing theories to explain how such individual
differences are possible. We review core phenomena from recent research
and highlight two important phenomena: longitudinal stability, whereby
individual differences in mindreading in early childhood are stable over
time and predict later social abilities; and the existence of individual
differences in mindreading into adulthood. We then explain why these
phenomena are poorly accounted for by existing theories, before
examining how our new account can help.</p>
<h2 id="core-methods-and-phenomena">Core methods and phenomena</h2>
<p>Measurement of individual differences requires mindreading tasks on
which performance will vary reliably in a given age range. It has been
found that tasks originally devised to test for young children’s
possession of mindreading concepts - such as the false belief task - can
be aggregated into batteries that provide reliable measures of
individual differences in young children. Individual differences in
performance on false-belief task batteries are psychometrically robust:
they are explained by a single latent factor (e.g., Hughes, Devine &amp;
Wang, 2018), show test-retest reliability (e.g., Hughes et al., 2000),
and exhibit rank-order stability over time (e.g., Devine &amp; Hughes,
2019). They are consequential in that they predict later social
adjustment (e.g., Lecce &amp; Devine, 2021). Unsurprisingly, since
standard false belief tasks were specifically devised to be sensitive
tests of young children’s concept possession, these tasks also
demonstrate ceiling effects beyond age 6. However, the presence of
ceiling effects in false belief task performance (as well as measures of
desire understanding or second-order false belief understanding) do not
necessarily preclude persisting individual differences in mindreading
beyond early childhood. To overcome ceiling effects researchers have
devised mindreading tasks that involve more subtle or complicated uses
of beliefs, desires, and intentions. For example, the Strange Stories
task (White et al., 2008; Happé, 1994) presents children with short
stories and the Silent Film task (Devine et al., 2013) presents children
with short film excerpts, and tests their understanding of the depicted
social scenarios that might involve misunderstandings, lies, and
double-bluffs. The correct answer is an interpretation determined by the
researchers’ own judgement, by the majority view of a reference sample
of participants, or some combination of these criteria (Yeung et al.,
2023). Such tasks successfully raise the ceiling for performance and
measure reliable variance into adolescence (Devine, Kovatchev, Grumley
Traynor, Smith &amp; Lee, 2023).</p>
<p>These tasks are not only harder. Numerous studies have demonstrated
clear gains in mindreading performance across middle childhood and
adolescence (e.g., Devine &amp; Hughes, 2013; Dumontheil et al., 2010;
Osterhaus et al., 2016; Meinhardt-Injac et al., 2020). These gains are
difficult to explain in terms of “new mindreading concepts” but
nonetheless appear specifically social because they are not explained by
improved performance in language ability or executive function (e.g.,
Devine &amp; Hughes, 2016; Lecce et al., 2017).</p>
<p>Alongside evidence of continued growth in mindreading performance,
there are marked individual differences in performance even within
narrow age ranges (e.g., Devine et al., 2023). Rank-order stability in
mindreading performance on a given task challenges the idea that
individual differences in performance simply capture temporary
differences in children’s mastery of mental concepts or differences
arising from task performance factors (e.g., Hughes &amp; Devine, 2015).
Instead, measures like the false belief task appear to provide an early
marker of persistent individual differences in mindreading, measured
within a narrow window of sensitivity for a given task (Devine, 2021).
Moreover, individual differences in performance exhibit longitudinal
stability over time (e.g., Banerjee et al., 2011; Lecce et al., 2024).
Longitudinal rank-order stability in performance across different
age-appropriate measures (i.e. heterotypic stability) suggests that
different mindreading tasks might tap into individual differences in the
same underlying trait at different points in development (e.g., Devine
et al., 2016).</p>
<p>Individual differences in mindreading are consequential because they
are linked with meaningful social outcomes. For example, over-and-above
language ability, executive function and social motivation, individual
differences in mindreading in middle childhood and adolescence are
associated with superior social skills (e.g., Ronchi et al., 2020;
Devine &amp; Apperly, 2022; Tamnes et al., 2018). Furthermore, in line
with evidence from early childhood about the influence of social
experience on young children’s mindreading (e.g., Devine &amp; Hughes,
2018), children in classrooms where teachers frequently use mental state
language perform better on tests of mindreading than other children
(Lecce et al., 2022). In summary, individual differences in mindreading
from early childhood to adolescence appear to be persistent, robust,
specific, and consequential.</p>
<p>There is evidence that individual differences in mindreading persist
beyond adolescence into adulthood. In a recent systematic review Yeung
et al. (2024) identified 273 studies that used 75 different measures of
mindreading with adults. Yeung et al. also argue that current evidence
falls short of meeting strong criteria for reliable and valid
measurement, in contrast to what has been observed in children. However,
current literature provides reason to be optimistic that meaningful
individual differences in mindreading persist beyond adolescence, and
therefore have the potential to explain persistent individual
differences in social ability.</p>
<h3 id="explaining-longitudinal-stability">Explaining longitudinal
stability </h3>
<p>No existing account can adequately explain evidence that individual
differences in mindreading are stable over time. Differences in
processing capacity or social motivation have the potential – in
principle – to explain why some children may be faster than others to
pass mindreading tasks, and why differences in mindreading are
persistent over time. However, as noted above, processing capacity turns
out to be insufficient to explain why earlier mindreading predicts later
mindreading and social abilities because variation in mindreading
performance predicts social outcomes over and above performance on
measures of executive function and language ability (e.g., Devine et
al., 2016). Regarding social motivation, recent work suggests this, too,
only partially accounts for individual differences in mindreading and
social ability (Devine &amp; Apperly, 2021).</p>
<p>Accounts that focus on the structures and concepts necessary for
mindreading fail to explain longitudinal stability because mindreading
concepts and structures can only ever serve as enablers of social
ability, whereas what is needed is for mindreading to serve as a
mediator. To illustrate, let us suppose that social experience and
social motivation predict mindreading success because they help children
to acquire conceptual grasp of the difference between beliefs, desires,
and intentions, or between such mental states and other things such as
shadows (e.g., Estes, 1988; Wellman &amp; Estes, 1986), or help the
development of representational structures necessary for thinking about
mental states (e.g., Doherty &amp; Perner, 2020; Perner, 1991). This
would <em>enable</em> new ways of thinking about mental states. However,
concepts and structures are thought to be universally acquired by late
childhood. If all children acquire the same set of concepts and
structures for mindreading then concepts and structures cannot explain
why mindreading ability continues to vary, or why such variance predicts
later social ability.</p>
<p>In contrast the Mindreading as Asynchronous Joint Activity (M-A-J-A)
account shows how the effective use of mindreading can continue to vary.
This means that it can be a <em>mediator</em>, that continues to be
affected by social experience, social motivation, and other influences,
and has unique new influences on social ability. Put simply, the M-A-J-A
account has the right form to explain longitudinal stability in
mindreading, whereas conceptual accounts do not.</p>
<p><strong>New predictions.</strong></p>
<p>Providing a viable explanation of longitudinal stability yields new
and distinctive predictions regarding the measurement of early
mindreading abilities. One common practice is to measure early
mindreading according to a “scale” ranging from early-acquired to
later-acquired concepts. This accords well with conceptual accounts, and
as demonstrated by Wellman and colleagues (e.g., Wellman &amp; Liu,
2004; Wellman, Fang &amp; Peterson, 2011) scales of this kind not only
show an age-related increase in the number of concepts present, but also
a reliable order of emergence, at least within a given culture. A second
common practice measures individual differences on batteries of
different instantiations of the same task - most often false belief
tasks – within a sensitive age range (e.g., Hughes &amp; Devine, 2015).
This accords poorly with conceptual accounts, which have no basis for
interpreting degrees of performance on tasks designed to operationalise
the same concept (Apperly, 2012), yet as reviewed above, performance on
such batteries shows stable and meaningful variability. Whereas these
two measurement approaches are often used interchangeably, we propose
that variation on such measures should instead be conceptualised on two
orthogonal dimensions (see Figure 2). The vertical dimension corresponds
to the number of mental state concepts that a child appears to
understand at a given point in time. The horizontal dimension
corresponds to the number of contexts (operationalised as the number of
tasks) in which a child can demonstrate appropriate use of a given
concept. To the extent that mindreading is a mediator and not merely an
enabler of later abilities a child’s score on the horizontal dimension
should be a better predictor of later mindreading and later social
ability, compared with their score on the vertical dimension.</p>
<p><img src="/public/img/articles/apperly2025_mindreading/image2.svg"
style="width:6.27014in;height:2.63889in" /></p>
<p><em>Figure 2. Visualisation of variation in early mindreading on two
orthogonal dimensions. The vertical dimension corresponds to the number
of concepts currently in a child’s repertoire (cf. Wellman &amp; Liu,
2004). The horizontal dimension corresponds to flexible exercise of a
given concept across different contexts (False belief a-e). For clarity
the latter is illustrated only for the example of false beliefs, but of
course any concept can be tested across multiple contexts, as
illustrated by the range of tasks that target each concept in the
existing literature.</em></p>
<p>The M-A-J-A account also yields distinctive new predictions about the
influence of social experience on mindreading by distinguishing between
generation of plausible mental states versus selection of the most
appropriate from among them. The account suggests that children’s
exposure to rich social and communicative interactions in which they
become aligned with others will influence their ability to generate
plausible possibilities when required to imagine what someone else is
thinking or feeling (c.f. Ensor &amp; Hughes, 2008; Meins et al., 2003).
It also suggests that children’s participation in joint folk
psychological activities - of negotiating how mental states feature in
reason-giving explanations about other people and oneself - will be a
particular influence on their ability to select the most appropriate
mental state from among plausible possibilities.</p>
<p>In summary, the M-A-J-A account has the right form to explain
longitudinal stability, is readily compatible with evidence of social
effects on mindreading over and above cognitive effects and leads to
novel predictions and recommendations for improved methods for future
work.</p>
<h3 id="explaining-lifespan-individual-differences">Explaining Lifespan
individual differences </h3>
<p>Since tests of core mindreading concepts are passed during childhood,
adolescents and adults cannot be expected to vary in their possession of
such core concepts. It has been suggested that adolescents and adults
continue to acquire more subtle or sophisticated mindreading concepts,
which may not reach a ceiling of sophistication in all adults (e.g.,
Wellman, 2014). However, no theory describing advanced mindreading
concepts has yet been articulated (e.g., Osterhaus &amp; Bosacki, 2022),
and it is unclear what new concepts are required for success on existing
“advanced” mindreading tasks.<a href="#fn17" class="footnote-ref"
id="fnref17" role="doc-noteref"><sup>17</sup></a> At most such tasks
typically involve the combination or recursion of core concepts (e.g.,
an intention thwarted by ignorance; beliefs about beliefs), suggesting
that they may require greater processing capacity but not new concepts.
New mindreading concepts do not seem necessary to explain lifespan
individual differences in mindreading, nor are they likely to be
sufficient.</p>
<p>There is evidence from neuropsychology, dual-task interference, and
brain stimulation suggesting that adults’ successful mindreading depends
upon possessing the necessary capacity for working memory and cognitive
control (e.g., Apperly, 2010; Frith &amp; Frith, 2012; Gilead &amp;
Oschner, 2021; Happe et al., 2017). However, correlations between
mindreading performance and tests of working memory and cognitive
control are typically modest and are observed inconsistently (e.g.,
Qureshi et al., 2019; Ryskin et al., 2015), suggesting that these
capacities, while necessary, are not critically limiting for many adults
on many tasks. A potential exception is highly recursive mindreading,
which plausibly makes considerable demands on working memory. However,
recent evidence suggests that previous work has significantly
overestimated adults’ recursive mindreading capacity (Wilson et al.,
2023), suggesting that it is unlikely to be a major source of individual
differences. Overall, this limited role for processing capacity in
explaining individual differences accords with the intuition that
general cognitive ability is relevant but insufficient to explain
variation in social ability.</p>
<p>Finally, it seems very plausible that variation in social motivation
is a source of variation in both social ability in general and
mindreading in particular, and there is a small but growing body of
evidence consistent with this possibility (e.g., Contreras-Huerta et
al., 2020; Pomareda, Devine &amp; Apperly, 2024a). However, without an
account of how mindreading can vary in adults, there is no way of
explaining how it could be affected by variation in social
motivation.</p>
<p>In sum, despite much work, the current literature has made little
progress beyond the unsatisfactory conclusion that adults who score
higher on tests of mindreading are demonstrating greater mindreading
abilities. The M-A-J-A account addresses this challenge by providing
criteria for judging the quality of mindreading.</p>
<h2 id="what-counts-as-a-good-mindreading-answer">What counts as a
“good” mindreading answer?</h2>
<p>According to the M-A-J-A account, good mindreading is about agreement
with others around us, including - but not only - the target of
mindreading. To a first approximation a good interpretation is just what
a group of people would jointly conclude given adequate time to discuss
it. Discussion establishes consensus on relevant information about the
target and their situation, airs potential interpretations, and supports
the selection of the best interpretation in light of moral and normative
rules, context, and considerations of “reasonableness”. By the end all
discussants should acknowledge the quality of the agreed-upon
interpretation, even if it was not the one they would have reached
independently. It follows that a good mindreader is someone who can
simulate the results of such a group process.<a href="#fn18"
class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>
As described earlier, the M-A-J-A account suggests that such simulation
is dependent upon prior experience of interactive alignment that equips
the mindreader with the intuitions to generate a plausible set of
candidate mental states, and the shared norms and principles used to
select an appropriate mental state from that set.</p>
<p>The first approximation assumes that both the group of mindreaders
and the mindreading target are drawn from a similar population, so that
it is possible to establish consensus on what information is relevant,
what interpretations are plausible, and which is most appropriate.
However, it is clearly possible that differences in knowledge,
judgements of relevance, and what is moral, reasonable, or normatively
correct, could result in groups with different compositions coming to
different agreements, or to those agreements being invalid for the
target. It follows that a mindreader who is flexible enough to simulate
the interpretations of a range of groups and targets will be more
successful than one who cannot. With these conclusions it is possible to
address the challenge of measuring individual differences in
mindreading.</p>
<h2
id="measurement-of-individual-differences-across-the-lifespan-mindreading-interpretations">Measurement
of individual differences across the lifespan: mindreading
interpretations</h2>
<p>The M-A-J-A account takes the need for interpretation to be a central
feature of mindreading, rather than an unfortunate bug in existing
attempts to measure it (c.f. Long, Catmur &amp; Bird, 2024). A first
step forward would be for researchers to recognise interpretation as a
potential source of variation. Many existing tests of mindreading in
adults score responses in ways that confound the quality of
participants’ responses (i.e. their plausibility and appropriateness)
with the mere quantity of mental states mentioned in the response. Using
a coding scheme that separated these variables Pomareda et al. (2024b)
found independent variation in quality and quantity of mental state
descriptions in participants’ mindreading explanations, suggesting that
these are separate constructs with potentially distinctive roles in
predicting social ability.</p>
<p>Second, our analysis highlights the social character of criteria for
determining a good interpretation. This should make researchers think
carefully about whose interpretations are relevant and valid, who gets
to decide which interpretations are better, and whether the answers to
these questions are appropriate for a given research question. Suppose,
for illustration, that some mindreading stories were created and scored
by a straight, white, middle-class, middle-aged, British male academic
(the first author acknowledges these characteristics and also owns a
chef’s knife). We contend that these stories and scoring decisions are
unlikely to reflect all the ways in which a broader range of people use
mindreading to understand themselves and others, and that this measure
may turn out to be easier for people who are more like the researcher
than people who are less like him. We suspect that few researchers would
disagree. Yet frustratingly, this remains a contention because there is
remarkably little evidence on variation in mindreading interpretations,
or on the measurement fairness of mindreading tasks across different
populations (e.g., Devine &amp; Hughes, 2013; Hughes, Devine &amp; Wang,
2018). This reflects the limits of current theories, which do not
explain why these considerations might be important, and it reflects
limited use of standard psychometric considerations, (e.g., about the
“fairness” of measurement between different groups) when designing and
analysing studies of mindreading (Yeung et al., 2023).</p>
<p>What solutions are available? In relation to stimuli, it is feasible
to generate mindreading stimuli, questions, and answers systematically
to reflect the ways that mental states are used in reason-giving
explanations by a broad range of people – not just “experts” or
“authorities”. For example, in ongoing work, we have collaborated with
young adults with diverse demographic characteristics to create
personally meaningful narratives involving social situations that entail
mindreading. The creators, not the researchers, were allowed authority
over the correct mindreading interpretation of their narrative. Such
stimuli have higher face validity than narratives created by an
individual or homogenous group of researchers. They also open the way
for testing whether variation in the way that different people use
mindreading in reason-giving explanations is itself a source of
challenge for mindreaders, whether the ease with which mindreaders
address that challenge varies, and whether this depends on the diversity
of their social experience. This would capture the intuition that a
person may be a capable mindreader when “at home” in a familiar
environment, but less capable in less familiar environments. Moreover,
it suggests that a maximally capable mindreader is one who is able to
adapt their mindreading interpretations to the largest range of
different mindreading targets and social contexts.</p>
<p>In relation to evaluating performance, the M-A-J-A account suggests
that the ultimate criterion should be what the (possibly open-ended)
group of people relevant to the mindreader would agree was a good
mindreading interpretation. This means that there may sometimes be more
than one acceptable mindreading interpretation, that acceptability may
vary by context, and that different groups of people may agree on
different interpretations. Investigating these possibilities Yeung
(2024) asked participants to view scenes involving two protagonists (see
Figure 3), and to choose between the interpretations that participants
had given spontaneously in a prior study. Without additional context
participants showed clear preferences for some interpretations over
others, though more than one interpretation was often favoured for a
given scene. However, these preferences were influenced by additional
contextual information, and by participant characteristics (age of
participants in this instance). On the M-A-J-A account the more frequent
responses are all contenders for being “good” mindreading answers.
However, a good mindreader is one who can accommodate the systematic
variation in when any of these potentially good responses is plausible
and appropriate.</p>
<p><img src="/public/img/articles/apperly2025_mindreading/image3.svg"
style="width:6.27014in;height:3.59097in" /></p>
<p><em>Figure 3. Example stimuli and illustrative data from Yeung
(2024), study 5d. Twenty adult participants per condition judged the
response option that best fit the picture. Participants were either
given no further context, or prime sentence intended to bias them
towards response (a) or (b). Data presented here are from a “young”
adult sample aged 18-25. A further study found that these patterns
differed in younger versus older adults (aged 53-60). Whereas younger
adults’ spontaneous interpretations were most often consistent with
option (a), older adults’ interpretations were more often consistent
with option (c). A person who was sensitive to such variation would be a
more capable mindreader.</em></p>
<p>We want to emphasise that there is no single “correct” approach to
these challenges for empirical research. Sometimes it will be
appropriate to crowd-source opinion on the correct answers; sometimes
authorial intention will be valid; sometimes it will be appropriate to
ask a mindreading target what they are thinking or feeling. Design
choices should depend both on theory (i.e., the research question) and
on empirical considerations (i.e., the scoring criteria to capture
individual differences). However, we propose there is potential for
researchers to transform the field by using transparent and
hypothesis-informed decisions to guide selection and interpretation of
existing tasks and creation and scoring of new tasks, and robust
psychometric evaluation of how well the tasks serve their research
objectives.</p>
<h1 id="summary-and-conclusion">Summary and conclusion</h1>
<p>To date research on mindreading has failed to address fundamental
questions about how we ascribe thoughts and feelings to other people,
and why some people seem to be better at this than others. The M-A-J-A
account addresses these failures by rethinking what mindreading is and
what makes it possible.</p>
<p>We began by challenging the widespread assumption that successful
mindreading consists of identifying facts about mental states as
accurately as possible. While a target’s mental state can be identified
accurately in principle (Davidson, 1973; 1990), accurate identification
of mental states is a wildly unachievable objective in practice.
Instead, part of the art of competent mindreading is generating
plausible assumptions and selecting the most appropriate for a given
context. What is most appropriate will depend, among other things, on
which assumptions others around you would select, and what your aims in
mindreading are. A successful mindreader is one who generates and
selects those assumptions as if they were making their decisions as part
of a group of peers.</p>
<p>How are individuals able to simulate the conclusions of the
hypothetical decision-making of a group? In short, because they are
socialised. A history of interactive alignment leads members of a
population to have similar intuitions about what others might plausibly
be thinking or feeling in a particular situation, and to recognise
similar principles of normativity, appropriateness, and reasonableness.
To the extent that this is true, mindreading is not so much socially
constructed as socially constituted as an ongoing but asynchronous joint
activity.</p>
<p>The picture that emerges is one that still features mindreading
concepts and structures as necessary elements that enable mindreading
in-principle. But the practice of mindreading requires the significant
additions that we have described here. Besides giving conceptual
research on mindreading foundations that can bear its weight, we have
shown that our proposals have the capacity to explain extensive
empirical phenomena that are currently puzzling and provide a framework
for new empirical approaches to studying mindreading beyond the early
developmental period that has been the dominant focus for the past 40
years.</p>
<p><strong>References</strong></p>
<p>Abell, F., Happe, F., &amp; Frith, U. (2000). Do triangles play
tricks? Attribution of mental states to animated shapes in normal and
abnormal development. <em>Cognitive Development</em>, <em>15</em>(1),
1-16.</p>
<p><mark>Allais, M. (1979). The So-Called Allais Paradox and Rational
Decisions under Uncertainty. In M. Allais &amp; O. Hagen (Eds.),</mark>
<em>Expected Utility Hypotheses and the Allais Paradox: Contemporary
Discussions of the Decisions under Uncertainty with Allais’
Rejoinder</em> <mark>(pp. 437–681). Dordrecht: Springer.</mark></p>
<p>Apperly, I.A. (2010). <em>Mindreaders: the cognitive basis of “theory
of mind”.</em> Hove: Psychology Press / Taylor &amp; Francis Group.</p>
<p>Apperly, I.A. (2012). What is “theory of mind”? Concepts, cognitive
processes and individual differences. <em>Quarterly Journal of
Experimental Psychology, 65(5),</em> 825-839.</p>
<p>Apperly, I.A. &amp; Butterfill, S.A, (2009). Do humans have two
systems to track beliefs and belief-like states? <em>Psychological
Review, 116(4), 953-970.</em></p>
<p><em>Apperly, I.A. &amp; Wang, J.J. (2021). The Cognitive Basis of
Social Interaction in adulthood. In Ferguson, H.J., Brunsdon, V. &amp;
Bradford, E. (Eds.) The Cognitive Basis of Social Interaction Across the
Lifespan. OUP.</em></p>
<p>Astington, J. W., &amp; Baird, J. A. (Eds.). (2005). <em>Why language
matters for theory of mind</em>. Oxford University Press.</p>
<p>Aviezer, H., Trope, Y., &amp; Todorov, A. (2012). Holistic person
processing: faces with bodies tell the whole story. <em>Journal of
personality and social psychology</em>, <em>103</em>(1), 20.</p>
<p>Bacharach, M. (2006). <em>Beyond individual choice</em>. Princeton:
Princeton University Press.</p>
<p>Bahrami, B., Olsen, K., Latham, P. E., Roepstorff, A., Rees, G.,
&amp; Frith, CD. (2010). Optimally interacting minds. <em>Science,
329,</em> 1081–1085.</p>
<p>Baker, C. L., Jara-Ettinger, J., Saxe, R., &amp; Tenenbaum, J. B.
(2017). Rational quantitative attribution of beliefs, desires and
percepts in human mentalizing. <em>Nature Human Behaviour</em>,
<em>1</em>(4), 0064.</p>
<p>Banerjee, R., Watling, D., &amp; Caputi, M. (2011). Peer relations
and the understanding of faux pas: Longitudinal evidence for
bidirectional associations. <em>Child development</em>, <em>82</em>(6),
1887-1905.</p>
<p>Bar-On, D. (2004). <em>Speaking My Mind: Expression and
Self-Knowledge</em>. Oxford: Oxford University Press.</p>
<p>Barrett, H. C. (2020). Towards a cognitive science of the human:
Cross-cultural approaches and their urgency. <em>Trends in cognitive
sciences</em>, <em>24</em>(8), 620-638.</p>
<p>Boghossian, P. (1989). Content and Self-Knowledge. <em>Philosophical
Topics</em>, 17(1): 5–26.</p>
<p>Bruner, J. (1990). <em>Acts of meaning</em> (Vol. 3). Harvard
university press.</p>
<p>Butterfill, S. &amp; Apperly I.A. (2013). How to construct a minimal
theory of mind. <em>Mind &amp; Language, 28(2)</em>
606-637<em>.</em></p>
<p>Callaghan, T., Rochat, P., Lillard, A., Claux, M. L., Odden, H.,
Itakura, S., ... &amp; Singh, S. (2005). Synchrony in the onset of
mental-state reasoning: Evidence from five cultures. <em>Psychological
Science</em>, <em>16</em>(5), 378-384.</p>
<p>Cantor, N., Mischel, W., &amp; Schwartz, J. C. (1982). A prototype
analysis of psychological situations. Cognitive Psychology, 14,
45-77.</p>
<p>Carpendale, J. I., &amp; Lewis, C. (2004). Constructing an
understanding of mind: The development of children's social
understanding within social interaction. <em>Behavioral and brain
sciences</em>, <em>27</em>(1), 79-96.</p>
<p>Carruthers, P. (2011). <em>The opacity of mind: An integrative theory
of self-knowledge</em>. OUP Oxford.</p>
<p>Chater, N., Zeitoun., H., &amp; Melkonyan, T. (2022). The paradox of
social interaction: shared intentionality, we-reasoning, and virtual
bargaining. <em>Psychological Review, 129(3),</em> 415–437.</p>
<p>Contreras-Huerta, L. S., Pisauro, M. A., &amp; Apps, M. A. (2020).
Effort shapes social cognition and behaviour: A neuro-cognitive
framework. <em>Neuroscience &amp; Biobehavioral Reviews</em>,
<em>118</em>, 426-439.</p>
<p>Conway, J. R., Catmur, C., &amp; Bird, G. (2019). Understanding
individual differences in theory of mind via representation of minds,
not mental states. <em>Psychonomic bulletin &amp; review</em>,
<em>26</em>, 798-812.</p>
<p><mark>Davidson, D. (1973). Radical interpretation. In</mark>
<em>Inquiries into truth and interpretation</em> <mark>(pp. 125–139).
Oxford: Oxford University Press.</mark></p>
<p>Davidson, D. (1974). Belief and the basis of meaning. In
<em>Inquiries into truth and interpretation</em> (pp. 141–154). Oxford:
Oxford University Press.</p>
<p>Davidson, D. (1980). Toward a unified theory of meaning and action.
<em>Grazer Philosophische Studien</em>, <em>11</em>, 1–12.</p>
<p>Davidson, D. (1985). A new basis for decision theory. <em>Theory and
Decision</em>, <em>18</em>, 87–98.</p>
<p>Davidson, D. (1990). The structure and content of truth. <em>The
Journal of Philosophy</em>, <em>87</em>(6), 279–328.</p>
<p>Davidson, D. (1995). Could there be a science of rationality?
<em>International Journal of Philosophical Studies</em>, <em>3</em>(1),
1–16.</p>
<p>Davidson, D. (2004). <em>Problems of rationality</em>. Oxford:
Clarendon Press.</p>
<p><mark>Devine, R.T. (2021). Individual differences in theory of mind
in middle childhood and adolescence. In Devine, R.T. &amp; Lecce, S.
(2021) (Eds). <em>Theory of Mind in Middle Childhood and Adolescence:
Integrating Multiple Perspectives</em> (pp 55-76). Routledge.</mark></p>
<p>Devine, R.T. &amp; Apperly, I.A. (2022) Willing and Able? Theory of
Mind, Social Motivation and Social Competence in Middle Childhood and
Early Adolescence. <em>Developmental Science.</em> <em>25 (1),
e13137.</em></p>
<p>Devine, R. T., &amp; Hughes, C. (2013). Silent films and strange
stories: Theory of mind, gender, and social experiences in middle
childhood. <em>Child development</em>, <em>84</em>(3), 989-1003.</p>
<p><mark>Hughes, C., &amp; Devine, R. T. (2015). Individual differences
in theory of mind from preschool to adolescence: Achievements and
directions.</mark> <em>Child development perspectives</em><mark>,</mark>
<em>9</em><mark>(3), 149-153.</mark></p>
<p>Devine, R. T., &amp; Hughes, C. (2016). Measuring theory of mind
across middle childhood: Reliability and validity of the silent films
and strange stories tasks. <em>Journal of experimental child
psychology</em>, <em>149</em>, 23-40.</p>
<p>Devine, R. T., &amp; Hughes, C. (2018). Family correlates of false
belief understanding in early childhood: A meta‐analysis. <em>Child
development</em>, <em>89</em>(3), 971-987.</p>
<p>Devine, R. T., &amp; Hughes, C. (2019). Let's talk: Parents’ mental
talk (not mind‐mindedness or mindreading capacity) predicts children's
false belief understanding. <em>Child Development</em>, <em>90</em>(4),
1236-1253.</p>
<p>Devine, R. T., Kovatchev, V., Grumley Traynor, I., Smith, P., &amp;
Lee, M. (2023). Machine learning and deep learning systems for automated
measurement of “advanced” theory of mind: Reliability and validity in
children and adolescents. <em>Psychological Assessment</em>,
<em>35</em>(2), 165.</p>
<p>Devine, R. T., &amp; Lecce, S. (Eds.). (2021). <em>Theory of mind in
middle childhood and adolescence: Integrating multiple
perspectives</em>. Routledge.</p>
<p>Devine, R. T., White, N., Ensor, R., &amp; Hughes, C. (2016). Theory
of mind in middle childhood: Longitudinal associations with executive
function and social competence. <em>Developmental psychology</em>,
<em>52</em>(5), 758.</p>
<p>Dennett, D. C. (1988). Précis of the intentional stance.
<em>Behavioral and brain sciences</em>, <em>11</em>(3), 495-505.</p>
<p>Doherty, M. J., &amp; Perner, J. (2020). Mental files: Developmental
integration of dual naming and theory of mind. <em>Developmental
Review</em>, <em>56</em>, 100909.</p>
<p>Dixson, H. G., Komugabe‐Dixson, A. F., Dixson, B. J., &amp; Low, J.
(2018). Scaling theory of mind in a small‐scale society: A case study
from Vanuatu. <em>Child Development</em>, <em>89</em>(6), 2157-2175.</p>
<p>Doherty, M. (2008). <em>Theory of mind: How children understand
others' thoughts and feelings</em>. psychology press.</p>
<p>Dretske, F. (1994). “Introspection”, <em>Proceedings of the
Aristotelian Society</em>. 94(1), 263–278.</p>
<p>Dumontheil, I., Apperly, I. A., &amp; Blakemore, S. J. (2010). Online
usage of theory of mind continues to develop in late adolescence.
<em>Developmental Science</em>, <em>13</em>(2), 331-338.</p>
<p>Dziobek, I., Fleck, S., Kalbe, E., Rogers, K., Hassenstab, J., Brand,
M., ... &amp; Convit, A. (2006). Introducing MASC: a movie for the
assessment of social cognition. <em>Journal of autism and developmental
disorders</em>, <em>36</em>, 623-636.</p>
<p>Estes, D., Wellman, H. M., &amp; Woolley, J. D. (1989). Children's
understanding of mental phenomena. In <em>Advances in Child Development
and Behavior</em> (Vol. 22, pp. 41-87).</p>
<p>Ferguson, H. J., &amp; Bradford, E. E. (Eds.). (2021). <em>The
cognitive basis of social interaction across the lifespan</em>. Oxford
University Press.</p>
<p>Fernyhough, C. (2008). Getting Vygotskian about theory of mind:
Mediation, dialogue, and the development of social understanding.
<em>Developmental Review</em>, <em>28</em>(2), 225-262.</p>
<p>Fiske, S. T., &amp; Taylor, S. E. (1984). Social cognition. New York:
Random House.</p>
<p>Fiske, S. T. (1993). Social cognition and social perception.
<em>Annual review of psychology, 44(1),</em> 155-194.</p>
<p>Fodor, J. A. (2001). <em>The mind doesn't work that way: The scope
and limits of computational psychology</em>. MIT press.</p>
<p>Frith, C. D., &amp; Frith, U. (2012). Mechanisms of social cognition.
<em>Annual review of psychology</em>, <em>63</em>, 287-313.</p>
<p>Gallotti, M., &amp; Frith, C. D. (2013). Social cognition in the
we-mode. <em>Trends in Cognitive Sciences</em>, <em>17</em>(4),
160-165.</p>
<p>Gilbert, D. T. (1998). Ordinary personology. In D. T. Gilbert, S. T.,
Fiske, &amp; G. Lindzey (Eds.), The handbook of social psychology (4th
ed., pp. 8-150). New York: McGraw Hill.</p>
<p>Gilead, M., &amp; Ochsner, K. N. (Eds.). (2021). <em>The neural basis
of mentalizing</em>. New York: Springer International Publishing.</p>
<p>Goldman, A. I. (2006). <em>Simulating minds: The philosophy,
psychology, and neuroscience of mindreading</em>. Oxford University
Press.</p>
<p><mark>Gönültaş, S., Selçuk, B., Slaughter, V., Hunter, J. A., &amp;
Ruffman, T. (2020). The capricious nature of theory of mind: Does mental
state understanding depend on the characteristics of the target?.</mark>
<em>Child Development</em><mark>,</mark> <em>91</em><mark>(2),
e280-e298.</mark></p>
<p>Gopnik, A., &amp; Meltzoff, A. N. (1997). <em>Words, thoughts, and
theories</em>. Mit Press.</p>
<p>Gopnik, A., &amp; Wellman, A. N. (1992). Why the child’s theory of
mind really <em>is</em> a theory. <em>Mind &amp; Language,
7(1&amp;2),</em> 145-171.</p>
<p>Happé, F., Cook, J. L., &amp; Bird, G. (2017). The structure of
social cognition: In (ter) dependence of sociocognitive processes.
<em>Annual review of psychology</em>, <em>68</em>, 243-267.</p>
<p>Harris, P. L. (1992). From simulation to folk psychology: the case
for development. <em>Mind &amp; Language</em>.</p>
<p>Heal, J. (1996). Simulation, theory, and content. In Carruthers, P.,
&amp; Smith, P. K. (Eds.). <em>Theories of theories of mind</em>.
Cambridge university press. 75-89.</p>
<p>Heider, F. (1958). <em>The psychology of interpersonal
relations.</em> Hillsdale, N.J: Lawrence Erlbaum Associates.</p>
<p>Heyes, C. (2019). Précis of cognitive gadgets: The cultural evolution
of thinking. <em>Behavioral and Brain Sciences</em>, <em>42</em>,
e169.</p>
<p>Hughes, C. (2011). <em>Social understanding and social lives: From
toddlerhood through to the transition to school</em>. Psychology
Press.</p>
<p>Hughes, C., Adlam, A., Happé, F., Jackson, J., Taylor, A., &amp;
Caspi, A. (2000). Good test‐retest reliability for standard and advanced
false‐belief tasks across a wide range of abilities. <em>Journal of
Child Psychology and Psychiatry</em>, <em>41</em>(4), 483-490.</p>
<p>Hughes, C., &amp; Devine, R. T. (2015). Individual differences in
theory of mind from preschool to adolescence: Achievements and
directions. <em>Child development perspectives</em>, <em>9</em>(3),
149-153.</p>
<p>Hughes, C., Devine, R. T., &amp; Wang, Z. (2018). Does parental
mind‐mindedness account for cross‐cultural differences in preschoolers’
theory of mind?. <em>Child development</em>, <em>89</em>(4),
1296-1310.</p>
<p><mark>Ensor, R., &amp; Hughes, C. (2008). Content or connectedness?
Mother–child talk and early social understanding.</mark> <em>Child
development</em><mark>,</mark> <em>79</em><mark>(1), 201-216.</mark></p>
<p>Hutto, D. (2009). Folk psychology as narrative practice. <em>Journal
of Consciousness Studies</em>, <em>16</em>(6-7), 9-39.</p>
<p>Hutto, D. D. (2012). <em>Folk psychological narratives: The
sociocultural basis of understanding reasons</em>. Cambridge, Mass.: MIT
Press.</p>
<p><mark>Jeffrey, R. C. (1983).</mark> <em>The logic of decision, second
edition</em><mark>. Chicago: University of Chicago Press.</mark></p>
<p><em>Kahneman, D. (2003). A perspective on judgment and choice:
Mapping bounded rationality. American Psychologist, 58(9),
697–720.</em></p>
<p>Ickes, W. (1993). Empathic accuracy. <em>Journal of personality</em>,
<em>61</em>(4), 587-610.</p>
<p>Ickes, W., Robertson, E., Tooke, W., &amp; Teng, G. (1986).
Naturalistic social cognition: Methodology, assessment, and validation.
<em>Journal of Personality and Social Psychology</em>, <em>51</em>(1),
66.</p>
<p>Ickes, W., Buysse, A. N. N., Pham, H. A. O., Rivers, K., Erickson, J.
R., Hancock, M., ... &amp; Gesn, P. R. (2000). On the difficulty of
distinguishing “good” and “poor” perceivers: A social relations analysis
of empathic accuracy data. <em>Personal Relationships</em>,
<em>7</em>(2), 219-234.</p>
<p>Jara-Ettinger, J., Gweon, H., Schulz, L. E., &amp; Tenenbaum, J. B.
(2016). The naïve utility calculus: Computational principles underlying
commonsense psychology. <em>Trends in cognitive sciences</em>,
<em>20</em>(8), 589-604.</p>
<p>Jeffrey, R. C. (1983). <em>The Logic of Decision, Second
Edition</em>. Chicago: University of Chicago Press.</p>
<p>Johnson, S. (2000). The recognition of mentalistic agents in infancy.
<em>Trends in Cognitive Sciences</em>, <em>4</em>, 22–28.</p>
<p>Krupenye, C., &amp; Call, J. (2019). Theory of mind in animals:
Current and future directions. <em>Wiley Interdisciplinary Reviews:
Cognitive Science</em>, <em>10</em>(6), e1503.</p>
<p>Lecce, S., Bianco, F., Devine, R. T., &amp; Hughes, C. (2017).
Relations between theory of mind and executive function in middle
childhood: A short-term longitudinal study. <em>Journal of experimental
child psychology</em>, <em>163</em>, 69-86.</p>
<p>Lecce, S., &amp; Devine, R. T. (2021). Social interaction in early
and middle childhood. <em>The cognitive basis of social interaction
across the lifespan</em>, 47-69.</p>
<p>Lecce, S., Ronchi, L., &amp; Devine, R. T. (2022). Mind what teacher
says: Teachers’ propensity for mental‐state language and children's
theory of mind in middle childhood. <em>Social Development</em>,
<em>31</em>(2), 303-318.</p>
<p>Lecce, S., Ronchi, L., &amp; Devine, R. T. (2024). The Effect of
Peers’ Theory of Mind on Children’s Own Theory of Mind development: A
Longitudinal Study in Middle Childhood and Early Adolescence.
<em>Developmental Psychology</em>.</p>
<p>Leslie, A. M. (1987). Pretense and representation: The origins of"
theory of mind.". <em>Psychological review</em>, <em>94</em>(4),
412.</p>
<p>Leslie, A. M., Friedman, O., &amp; German, T. P. (2004). Core
mechanisms in ‘theory of mind’. <em>Trends in cognitive sciences</em>,
<em>8</em>(12), 528-533.</p>
<p>Lewis, D. K. (1972). Psychophysical and theoretical identifications.
Australasian Journal of Philosophy, 50(3), 249–258.</p>
<p>Lillard, A. (1998). Ethnopsychologies: cultural variations in
theories of mind. <em>Psychological bulletin</em>, <em>123</em>(1),
3.</p>
<p>Locke, J. (1689/1975) <em>An Essay Concerning Human
Understanding</em>. P.H. Nidditch (ed.), Oxford: Oxford University
Press.</p>
<p>Long, E. L., Cuve, H. C., Conway, J. R., Catmur, C., &amp; Bird, G.
(2022). Novel theory of mind task demonstrates representation of minds
in mental state inference. <em>Scientific reports</em>, <em>12</em>(1),
21133.</p>
<p>Long, E. L., Catmur, C., &amp; Bird, G. (2024). The Theory of Mind
hypothesis of autism: A critical evaluation of the
status-quo. <em>Psychological Review</em>.</p>
<p>Marangoni, C., Garcia, S., Ickes, W., &amp; Teng, G. (1995). Empathic
accuracy in a clinically relevant setting. <em>Journal of personality
and social psychology</em>, <em>68</em>(5), 854.</p>
<p>Martin, A., &amp; Santos, L. R. (2016). What cognitive
representations support primate theory of mind?. <em>Trends in cognitive
sciences</em>, <em>20</em>(5), 375-382.</p>
<p>McGeer, V. (1996). “Is ‘Self-Knowledge’ an Empirical Problem?
Renegotiating the Space of Philosophical Explanation”. <em>Journal of
Philosophy</em>, 93(10): 483–515.</p>
<p><mark>McLoughlin, N., &amp; Over, H. (2017). Young children are more
likely to spontaneously attribute mental states to members of their own
group.</mark> <em>Psychological Science</em><mark>,</mark>
<em>28</em><mark>(10), 1503-1509.</mark></p>
<p>McNeill, W. E. S. (2012). On Seeing That Someone Is Angry.
<em>European Journal of Philosophy</em> 20(4), 575–97.</p>
<p>Mead, G. H. (1934)<em>. Mind, self and society from the standpoint of
a social behaviorist. University of Chicago Press.</em></p>
<p>Meinhardt‐Injac, B., Daum, M. M., &amp; Meinhardt, G. (2020). Theory
of mind development from adolescence to adulthood: Testing the
two‐component model. <em>British Journal of Developmental
Psychology</em>, <em>38</em>(2), 289-303.</p>
<p>Meins, E. (2013). <em>Security of attachment and the social
development of cognition</em>. Psychology press.</p>
<p><mark>Meins, E., Fernyhough, C., Wainwright, R., Clark‐Carter, D.,
Das Gupta, M., Fradley, E., &amp; Tuckey, M. (2003). Pathways to
understanding mind: Construct validity and predictive validity of
maternal mind‐mindedness.</mark> <em>Child
development</em><mark>,</mark> <em>74</em><mark>(4),
1194-1211.</mark></p>
<p>Moore, R. (2021). The cultural evolution of mind-modelling.
<em>Synthese</em>, <em>199</em>(1), 1751-1776.</p>
<p>Moran, R. (2001). <em>Authority and Estrangement: An Essay on
Self-Knowledge</em>. Princeton, NJ: Princeton University Press.</p>
<p>Morris, A., Phillips, J., Huang, K., &amp; Cushman, F. (2021).
Generating options and choosing between them depend on distinct forms of
value representation. <em>Psychological science</em>, <em>32</em>(11),
1731-1746.</p>
<p>Nelson, K. (1998). <em>Language in cognitive development: The
emergence of the mediated mind</em>. Cambridge University Press.</p>
<p>Osterhaus, C., Koerber, S., &amp; Sodian, B. (2016). Scaling of
advanced theory‐of‐mind tasks. <em>Child development</em>,
<em>87</em>(6), 1971-1991.</p>
<p>Osterhaus, C., &amp; Bosacki, S. L. (2022). Looking for the
lighthouse: A systematic review of advanced theory-of-mind tests beyond
preschool. <em>Developmental Review</em>, <em>64</em>, 101021.</p>
<p><mark>Perez-Zapata, D., Slaughter, V., &amp; Henry, J. D. (2016).
Cultural effects on mindreading.</mark> <em>Cognition</em><mark>,</mark>
<em>146</em><mark>, 410-414.</mark></p>
<p>Perner, J. (1991). <em>Understanding the representational mind</em>.
The MIT Press.</p>
<p>Pickering, M. J., &amp; Garrod, S. (2004). Toward a mechanistic
psychology of dialogue. <em>Behavioral and Brain Sciences</em>,
<em>27</em>(2), 169-190.Scott, R. M., &amp; Baillargeon, R. (2017).
Early false-belief understanding. <em>Trends in cognitive sciences</em>,
<em>21</em>(4), 237-249.</p>
<p>Pomareda, C., Devine, R. T., &amp; Apperly, I. A. (2024a). Social
Motivation, Over and Above Mindreading, is Associated With Social
Support, Autistic Traits, and Depressive Symptoms in Adults.
<em>Manuscript submitted for publication.</em></p>
<p>Pomareda, C., Devine, R. T., &amp; Apperly, I. A. (2024b).
Mindreading quality versus quantity: A theoretically and empirically
motivated two-factor structure for individual differences in adults’
mindreading. <em>Plos one</em>, <em>19</em>(6), e0305270.</p>
<p>Qureshi, A.W., Monk, R.L., Samson, D. &amp; Apperly, I.A. (2020) Does
interference between self and other perspectives in Theory of Mind Tasks
reflect a common underlying process? Evidence from individual
differences in theory of mind and inhibitory control. <em>Psychonomic
Bulletin and Review, 27(1),</em> 178-190<em>.</em></p>
<p>Redcay, E., &amp; Schilbach, L. (2019). Using second-person
neuroscience to elucidate the mechanisms of social interaction.
<em>Nature Reviews Neuroscience</em>, <em>20</em>(8), 495-505.</p>
<p>Ronchi, L., Banerjee, R., &amp; Lecce, S. (2020). Theory of mind and
peer relationships: The role of social anxiety. <em>Social
Development</em>, <em>29</em>(2), 478-493.</p>
<p>Russell, B. (1917). Knowledge by Acquaintance and Knowledge by
Description. In <em>Mysticism and Logic</em>, London: George Allen and
Unwin.</p>
<p>Ryskin, R. A., Benjamin, A. S., Tullis, J., &amp; Brown-Schmidt, S.
(2015). Perspective-taking in comprehension, production, and memory: An
individual differences approach. <em>Journal of Experimental Psychology:
General</em>, <em>144</em>(5), 898.</p>
<p>Schank, R. C., &amp; Abelson, R. P. (1977/2013). <em>Scripts, plans,
goals, and understanding: An inquiry into human knowledge
structures</em>. Psychology Press.</p>
<p>Schelling, T. (1960). <em>The strategy of conflict.</em> Harvard
University Press. </p>
<p>Schilbach, L., Timmermans, B., Reddy, V., Costall, A., Bente, G.,
Schlicht, T., &amp; Vogeley, K. (2013). Toward a second-person
neuroscience 1. <em>Behavioral and Brain Sciences</em>, <em>36</em>(4),
393-414.</p>
<p>Sebanz, N., Bekkering, H., &amp; Knoblich, G. (2006). Joint action:
bodies and minds moving together. <em>Trends in Cognitive Sciences</em>,
<em>10</em>(2), 70-76.</p>
<p><mark>Selcuk, B., Gonultas, S., &amp; Ekerim‐Akbulut, M. (2023).
Development and use of theory of mind in social and cultural
context.</mark> <em>Child Development Perspectives</em><mark>,</mark>
<em>17</em><mark>(1), 39-45.</mark></p>
<p>Shoemaker, S. (1994). Self-Knowledge and ‘Inner Sense’.
<em>Philosophy and Phenomenological Research</em>, 54(2): 249–314.</p>
<p>Smith, J. (2010). Seeing Other People. <em>Philosophy and
Phenomenological Research</em> 81(3), 731–48.</p>
<p>Spaulding, S. (2018). <em>How we understand others: Philosophy and
social cognition</em>. Routledge.</p>
<p>Sperber, D., &amp; Wilson, D. (1987). Precis of relevance:
Communication and cognition. <em>Behavioral and Brain Sciences</em>,
<em>10</em>(4), 697-710.</p>
<p>Stich, S. (1983). <em>From Folk Psychology to Cognitive Science</em>.
Cambridge, Mass.: MIT Press.</p>
<p>Stuhlmüller, A., &amp; Goodman, N. D. (2014). Reasoning about
reasoning by nested conditioning: Modelling theory of mind with
probabilistic programs. <em>Cognitive Systems Research</em>,
<em>28</em>, 80-99.</p>
<p><mark>Tomasello, M. (2010).</mark> <em>Origins of human
communication</em><mark>. MIT press.</mark></p>
<p>Tomasello, M. (2018). How children come to understand false beliefs:
A shared intentionality account. <em>Proceedings of the National Academy
of Sciences</em>, <em>115</em>(34), 8491-8498.</p>
<p>Veissière, S. P., Constant, A., Ramstead, M. J., Friston, K. J.,
&amp; Kirmayer, L. J. (2020). Thinking through other minds: A
variational approach to cognition and culture. <em>Behavioral and Brain
Sciences</em>, <em>43</em>, e90.</p>
<p>Wellman, H. M. (2014). <em>Making minds: How theory of mind
develops</em>. Oxford University Press.</p>
<p>Wellman, H. M., &amp; Estes, D. (1986). Early understanding of mental
entities: A re-examination of childhood realism. <em>Child
development</em>, 910-923.</p>
<p>Wellman, H. M., Fang, F., &amp; Peterson, C. C. (2011). Sequential
progressions in a theory‐of‐mind scale: Longitudinal perspectives.
<em>Child development</em>, <em>82</em>(3), 780-792.</p>
<p>Whiten, A. (1996). When does smart behaviour-reading become
mind-reading? In P. Carruthers &amp; P. K. Smith (Eds.), <em>Theories of
Theories of Mind</em> (pp. 277–292). Cambridge: Cambridge University
Press.</p>
<p>Wilson, R., Perez, D. Hruby, A., van der Kleij, S. W. &amp; Apperly
I.A. (2023) Is Recursive “Mindreading” Really an Exception to
Limitations on Recursive Thinking?. <em>Journal of Experimental
Psychology: General 152</em>(5), 1454–1468</p>
<p>Wimmer, H., &amp; Perner, J. (1983). Beliefs about beliefs:
Representation and constraining function of wrong beliefs in young
children's understanding of deception. <em>Cognition</em>,
<em>13</em>(1), 103-128.</p>
<p>Vygotsky, L. S. (1997). Genesis of higher mental functions. In R. W.
Rieber (Ed.). <em>The collected works of L. S. Vygotsky (Vol. 4)</em>.
New York: Plenum (Original work published 1931).</p>
<p>Yeung, E. K. L. (2024) Unpublished doctoral thesis. University of
Birmingham, UK.</p>
<p>Yeung, E. K. L., Apperly, I. A., &amp; Devine, R. T. (2023). Measures
of individual differences in adult theory of mind: A systematic review.
<em>Neuroscience &amp; Biobehavioral Reviews,</em> 105481.</p>
<p>Zaki, J., Bolger, N., &amp; Ochsner, K. (2008). It takes two: The
interpersonal nature of empathic accuracy. <em>Psychological science,
19(4),</em> 399-404.</p>
<p>Zaki, J., Bolger, N., &amp; Ochsner, K. (2009). Unpacking the
informational bases of empathic accuracy. <em>Emotion, 9(4),</em>
478.</p>
<p><mark>Zawidzki, T. W. (2013).</mark> <em>Mindshaping: A new framework
for understanding human social cognition</em><mark>. MIT
Press.</mark></p>
<p>Zunshine, L. (2006). <em>Why we read fiction: Theory of mind and the
novel.</em> Ohio State University Press.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The theory’s development is presented in a series of
papers starting with Davidson (1973). The most detailed statement is
Davidson (1990).<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Davidson (1990, 297); Davidson (1985).<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>‘if we are to derive meaning and belief from evidence
concerning what causes someone to hold sentences true, it can only be …
because we stipulate a structure.’ (Davidson, 1980, 7)<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>‘What makes the task [of interpretation] practicable at
all is the structure that the normative character of thought, desire,
speech, and action imposes on correct attributions of attitudes to
others, and hence on interpretation of their speech and explanations of
their actions.’ (Davidson, 1990, 325; Davidson, 1980, 8)<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>There is occasionally confusion on this point because
Davidson famously allows that there is indeterminacy concerning what
someone thinks. Specifically, he rejects the view that ‘each belief has
a definite object’ (Davidson, 1974, 154). But indeterminacy is
consistent with there being facts about people’s mental states. As
Davidson argues, ‘[t]he consequent indeterminacy of interpretation is
not […] any more significant or troublesome than the fact that weight
may be measured in grams or in ounces’ (Davidson, 1980, 6).<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>​​‘All we should require of a theory of truth for a
speaker is that it be such that, if an interpreter had explicit
propositional knowledge of the theory, he would know the truth
conditions of utterances of the speaker.’ (Davidson, 1990, 312)<a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>You cannot say that Maxi’s mental states violate the
theory’s axioms: because the theory aims to be an elucidation of what
mental states are, if he fails to conform to the axioms there is—so the
theory—simply no way of making sense of the idea that he has mental
states at all.<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Researchers occasionally respond to a related issue in
decision theory by rejecting the idea that decision theory specifies
what preferences and subjective expectations are. On such a view, those
things exist independently of the theory (e.g. Allais, 1979, 548). This
amounts to rejecting one application of decision theory (namely, that of
characterising preferences and the rest) while endorsing other
applications of it. We agree, of course, that the bounds of rationality
are a major obstacle to interpreting decision theory as specifying what
preferences and subjective expectations are. The problem is to provide
an alternative to decision theory (or to Davidson’s theory) which can
ensure all researchers have a shared understanding of these states. As
far as we are aware, this challenge is yet to be met.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Compare Davidson (2004, 181): ‘if we are going to
explain irrationality at all, it seems we must assume that the mind can
be partitioned into quasi-independent structures that interact in ways
the Plato Principle [according to which there is no internal
irrationality] cannot accept or explain.’<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Of course this brief discussion does not exclude other
possible responses to the problems. We also acknowledge that there are
entirely different views about the conceptual foundations of
mindreading—for instance, some philosophers have held that mental states
can be perceived (Smith, 2010; McNeill, 2012), which would motivate a
different view. What we have shown here is just that the most
influential, best developed theory motivates our conclusions about what
it is to be in a position to use mindreading concepts effectively.<a
href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>The original text was numbered “ii” but context
indicates this must have been a typographical error<a href="#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>These concerns are a particular instance of a
widely-recognised set of challenges about identifying what is relevant
in problem spaces that are very large or only imprecisely specified
(e.g., Fodor 2001; Sperber &amp; Wilson, 1987). We are not proposing a
solution to these challenges, which are sometimes thought to be
intractable. We are proposing that progress can be made by recognising
the existence of these challenges, recognising their particular
character in relation to mindreading, and using this analysis to make
tractable predictions and interpretations of empirical phenomena.<a
href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>Analogous alignment phenomena occur in non-verbal
interaction and coordination (e.g., Brahimi et al., 2010; Sebanz et al.,
2006).<a href="#fnref13" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Informal feedback indicated that some readers may
perceive similarity to a widely-recognised political acronym. For the
avoidance of doubt, M-A-J-A is pronounced in the same way as the word
“major”, following the sounds of the words that it denotes.<a
href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Simulation is often thought to play a role in
interactive alignment. For example, Garrod and Pickering (2004) suggest
that “forward models” generated by one’s own processes for speech
production also serve a predictive role during speech comprehension.
This does not mean that simulation provides an account of mindreading.<a
href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>Indeed, one of his objectives is to argue that
mindreading is of secondary importance to mindshaping in explaining
human social abilities.<a href="#fnref16" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>For example, Devine and Hughes (2013) describe an item
from the “silent films” task as follows: “Harold (the main character) is
sitting on the back of a van while he ﬁlls in a form. The driver, who is
unaware of Harold’s presence, is collecting laundry. The driver, who
appears to have difﬁculty hearing, returns to his van, locks the door
and drives away. Harold is then trapped in the back of the van.” The
critical question is: “Why do you think the driver locks Harold in the
van?”. A correct answer requires participants to acknowledge the
critical role of the driver’s ignorance: e.g., “Because the driver
didn’t know Harold was in the van”. Many 3-year-olds succeed on
developmentally sensitive tests of the necessary core concepts of
understanding knowledge/ignorance (e.g., Wellman &amp; Liu, 2004), yet
there was significant variance in the success of 8- to 13-year-olds in
Devine and Hughes’ (2013) study. Many participants provided only a
partial explanation (e.g., in terms of the driver’s desire to continue
his rounds), or a completely incorrect explanation (e.g., ascribing a
desire to kidnap Harold). We think it unlikely that these participants
lacked a concept of knowledge versus ignorance or any other mindreading
concept. Instead, we suggest that their difficulty was with identifying
the most plausible and appropriate explanation.<a href="#fnref17"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>The idea that mindreaders might simulate the discussion
itself fits with the spirit of some neo-Vygotskian accounts that give
internalised dialogue a key role in higher mental functions (e.g.,
Fernyhough, 2007). Our proposal does not entail simulation of the
discussion, just the ability to simulate the results of such a
discussion.<a href="#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>


</div>


---

Title: Awareness of Belief
Authors: Stephen A. Butterfill
Year: 2001
Type: Publication

## Abstract

Is it possible to appreciate how different people may have beliefs different from one's own (including beliefs which are inconsistent with one's own beliefs) without understanding what it is for beliefs to be true or false?  In this paper I argue that it is.




---

Title: Towards a Blueprint for a Social Animal
Authors: Stephen A. Butterfill and Elisabeth Pacherie
Year: 2020
Type: Publication

## Abstract

<p>In this chapter, we attempt to answer the question, By what steps could members of a group capable of acting together with a purpose, coordinating flexibly, communicating cooperatively and deceiving competitors be constructed from creatures with minimal social skills and cognitive abilities? The method we use is creature construction: the idea is to adopt the perspective of a designer tasked with specifying a sequence of creatures, where each is independently viable and has the capacities of its predecessors together with some new capacity which enables it to overcome limits its predecessors faced. In creature construction, the aim is not to characterise actual species, nor to describe actual evolutionary or developmental processes. Instead the aims are to understand how various forms (or prototypes) of joint action are related to, and diverge from, each other; and to identify limits on what can be achieved with a given set of cognitive and social skills.</p><p>We start with Alphonso and his kin, whose social cognition is limited to tracking the goals of others’ actions. We show that despite little cognitive sophistication, the salience and triangulation heuristics enables them to initiate simple joint actions requiring coordination. One group of their descendants, Beki and her kin, develop abilities to produce pointing gestures and object-directed vocalisations, that enable them to enlist others not yet as partners but as social tools, thus extending the range of situations in which they can rely on the salience and triangulation heuristics. Another group of Alphonso’s descendants, Bemi’s kin, learn the art of strategic deception, acquiring increasingly elaborate tactics for manipulating others’ action possibilities. This advantages them in competition. Finally, the Kimi, who are mixed descendants of both the Beki and the Bemi, inherit the former’s communicative abilities and the latter’s abilities for tactical deception. Progressively integrating the two allows them to develop new capacities of selective deception.</p><p>We argue that although our creatures do not yet have all the cognitive capacities classical accounts imply are needed for joint action, they have proxies for some of these capacities. These proxies allow them to coordinate in a limited but useful range of ordinary circumstances. Further, relying on such proxies provide ways of avoiding both omni-doxasticity and omni-intentionality when acting together.</p>




---

Title: Interpersonal Functioning in Borderline Personality Disorder Traits: A Social Media Perspective
Authors: Jinnie Ooi, John Michael, Sakari Lemola, Stephen A. Butterfill, Cynthia S. Q. Siew & Lukasz Walasek
Year: 2020
Journal: Scientific Reports
Type: Publication

## Abstract

This is the first study to demonstrate interpersonal difficulties associated with borderline personality disorder (BPD) features in the domain of social media. Using crowdsourcing, we presented participants with a battery of questions about their recent social media use, and then assessed their BPD features using the short form of the Five-Factor Borderline Inventory. The results revealed that individuals with higher BPD trait scores reported posting more often on social media, as well as a higher incidence of experiencing regret after posting on social media, and of deleting or editing their posts. They also report a higher degree of importance of social media in their social behavior and daily routines. These results highlight the pervasiveness of interpersonal difficulties associated with BPD features even in the non-clinical population, and demonstrate that these difficulties are also observable in social media behavior. Our findings may provide a starting point for research using data from social media to illuminate the cognitive and emotional processes underpinning the interpersonal difficulties associated with BPD features, and to inform and assess therapeutic interventions.




---

Title: Coordinating Joint Action
Authors: Stephen A. Butterfill
Year: 2017
Type: Publication

<div class='fulltext'>
<p class="italic">
This is a slightly extended version of published chapter. (The pdf is the chapter version.)
</p>

<h1 id="sec:introduction">Introduction</h1>
<p>It is often necessary that agents’ actions are coordinated if they
are to successfully exercise shared (or ‘collective’) agency in acting
together. An eloping couple clink plastic beakers of cheap wine together
to toast their escape, sharing a smile of achievement; on the beach in
front of them a small group of roadies are putting up a marquee outside
for a concert later that evening while the musicians, having been made
to wait while the audio technicians replace a cable, playfully improvise
on stage. In cases like these, successfully exercising shared agency
involves coordinating actions precisely in space and time. Such precise
coordination is not, or not only, a matter of having intentions and
knowledge, whether individual or collective. Intentions and knowledge
states may play a role in long-term coordination—they may explain, for
instance, why the couple’s both being on the beach tonight is no
accident. But they cannot explain how the precise coordination needed to
clink beakers or to share a smile is achieved. Given that is not only
intention or knowledge, what does enable two or more agents’ actions to
be coordinated and so enables exercises of shared agency such as
these?</p>
<p>Much psychological and neuroscientific research bears directly on
this question. This chapter introduces that research: it outlines some
of the key findings and describes a minimal theoretical framework,
identifying along the way issues likely to be of interest to researchers
studying collective intentionality.</p>
<h1 id="sec:theoretical-framework">Joint Action</h1>
<p>Where philosophers tend to focus on notions such as intentional
shared agency, scientific research on coordination mechanisms is usually
interpreted in terms of a broader and simpler notion of joint action.
This is standardly defined by appeal to <span class="citation"
data-cites="Sebanz:2006yq">Sebanz, Bekkering, and Knoblich
(2006)</span>’s working definition as:</p>
<blockquote>
<p>‘any form of social interaction whereby two or more individuals
coordinate their actions in space and time to bring about a change in
the environment’ (<span class="citation"
data-cites="Sebanz:2006yq">(Sebanz, Bekkering, and Knoblich 2006,
70)</span>).</p>
</blockquote>
<p>Although widely used, this working definition has some drawbacks. It
requires that joint actions should be ‘social interactions’, thereby
raising tricky issues about which interactions are social. The working
definition also appears to require that coordinating their actions is
something the individuals involved in joint action do, perhaps even
requiring that this is done with the end of bringing about a change. As
we will see, there are reasons to consider the possibility actions can
be coordinated without both (or even either) requirements being met. We
can avoid the drawbacks while remaining true to the implicit conception
underlying scientific research with a simpler and extremely broad
definition:</p>
<blockquote>
<p>A <em>joint action</em> is an event grounded <a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> by
two or more agents’ actions.</p>
</blockquote>
<p>This definition of joint action, like <span class="citation"
data-cites="Sebanz:2006yq">Sebanz, Bekkering, and Knoblich
(2006)</span>’s working definition, is neutral on representations and
processes. So when two people swing their arms in synchrony, the event
of them swinging their arms is a joint action. Likewise, if fish are
agents then the movements of a shoal are joint actions. <a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>How does research on coordination in joint action bear on the
question about shared agency? Not all joint actions involve exercising
shared agency, but some or all exercises of shared agency are, or
involve, joint actions. It is reasonable to conjecture that what enables
the actions of agents exercising collective agency to be precisely
coordinated are mechanisms of coordination common to many different
forms of joint action. To illustrate, consider entrainment.</p>
<h1 id="sec:entrainment">Entrainment</h1>
<p>Entrainment, the process of synchronizing two or more rhythmic
behaviours with respect to phase, is a feature of everyday life. People
walking side by side may fall into the same walking patterns <span
class="citation"
data-cites="vanulzen:2008_characteristics nessler:2009_interpersonal">(Ulzen
et al. 2008; Nessler and Gilliland 2009)</span>, conversation partners
sometimes synchronize their body sway <span class="citation"
data-cites="shockley:2003_mutual">(Shockley, Santana, and Fowler
2003)</span> and gaze <span class="citation"
data-cites="richardson:2007_art">(D. C. Richardson, Dale, and Kirkham
2007)</span>, clusters of male fiddler crabs wave their claws
synchronously to attract mates <span class="citation"
data-cites="backwell:1998_synchronized merker:2009_role">(Backwell et
al. 1998; Merker, Madison, and Eckerdal 2009)</span>, and an audience
will sometimes briefly synchronise its clapping <span class="citation"
data-cites="neda:2000_self">(Néda et al. 2000)</span>.</p>
<p>As these examples suggest, entrainment enables the coordination of a
wide range of joint actions, not all of which involve shared agency. In
fact interpersonal entrainment is sometimes treated as a special case of
a process by which sequences of actions can be synchronised with
sequences of environmental stimuli such as a metronome <span
class="citation"
data-cites="repp:2013_sensorimotor konvalinka:2010_follow">(e.g. Repp
and Su 2013; Konvalinka et al. 2010)</span>, and, more boldly, sometimes
even as just one instance of what happens when oscillators are coupled
<span class="citation" data-cites="shockley:2009_conversation">(e.g.
Shockley, Richardson, and Dale 2009, 314)</span>.</p>
<p>Which exercises of shared agency might entrainment enable?
Entrainment allows for extremely precise coordination of movements <span
class="citation" data-cites="repp:2000_compensation">(Repp 2000)</span>
and is probably essential for joint actions involving rhythmic music,
dance, drill, and some martial arts.</p>
<p>How is entrainment related to agents’ intentions concerning
coordination or the lack thereof? Entrainment of two or more agents’
actions can occur without any intention concerning coordination <span
class="citation" data-cites="varlet:2015_informational">(e.g. Varlet et
al. 2015)</span>, and without the agents being aware of the coordination
of their actions <span class="citation"
data-cites="richardson:2005_effects">(Michael J. Richardson, Marsh, and
Schmidt 2005)</span>. Further, although subjects can sometimes
intentionally prevent entrainment, entrainment and related forms of
coordination do sometimes occur even despite individuals attempting not
to coordinate their actions <span class="citation"
data-cites="vanulzen:2008_characteristics issartel:2007_unintended">(e.g.
Ulzen et al. 2008; Issartel, Marin, and Cadopi 2007)</span>. So whether
two agents’ actions become entrained is not always, and perhaps not
typically, something which they do or could control.</p>
<p>But entrainment is not always independent of agents’ intentions <span
class="citation"
data-cites="miles:2010_too nessler:2009_interpersonal">(Miles et al.
2010; Nessler and Gilliland 2009)</span>. Because no one can perform two
actions without introducing some tiny variation between them,
entrainment of any kind depends on continuous monitoring and ongoing
adjustments <span class="citation"
data-cites="repp:2005_sensorimotor">(Repp 2005, 976)</span>. One kind of
adjustment is a phase shift, which occurs when one action in a sequence
is delayed or brought forwards in time. Another kind of adjustment is a
period shift; that is, an increase or reduction in the speed with which
all future actions are performed, or in the delay between all future
adjacent pairs of actions. These two kinds of adjustment, phase shifts
and period shifts, appear to be made by mechanisms acting independently,
so that correcting errors involves a distinctive pattern of
overadjustment. <a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a> <span class="citation"
data-cites="repp:2005_sensorimotor">Repp (2005, 987)</span> argues,
further, that while adjustments involving phase shifts are largely
automatic, adjustments involving changes in frequency are to some extent
controlled. This may be key to understanding the influence of intention
on entrainment. One way or another (contrast <span class="citation"
data-cites="fairhurst:2013_being">Fairhurst, Janata, and Keller (2013,
2599)</span> with <span class="citation"
data-cites="repp:2008_sensorimotor">Repp and Keller (2008)</span>’s
‘coordinative strategies’ proposal), intentions play a role in frequency
adjustments and thereby influence how tightly agents synchronise their
actions.</p>
<p>Entrainment is clearly necessary for coordination in many joint
actions requiring precise synchronisation such as those involving
rhythmic music or dance. Entrainment may also be important in ways as
yet barely understood for a much wider range of joint actions in which
such precise synchronisation initially appears unnecessary. <a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a> But there must be more to
coordinating joint actions than entrainment. After all entrainment
depends on repetition whereas many joint actions are one-off events, as
when the a couple clink plastic beakers. Which forms of coordination
enable one-off joint actions?</p>
<h1 id="sec:co-representation">Motor Simulation</h1>
<p>Many one-off joint actions—those which do not depend on repetition or
rhythm—require precise coordination. In clinking beakers, swinging a
toddler between our arms, and executing a pass in football, the window
for success may be fractions of a second in duration and but millimetres
wide. One way—perhaps the only way—of achieving such precise
coordination depends on the existence of a phenomenon often called
‘motor simulation’ or ‘mirroring’. What is this?</p>
<p>To understand motor simulation it is necessary first to get a rough
fix on the idea that motor processes and representations are involved in
performing ordinary, individual actions. Preparing for, and performing,
bodily actions involves not only intentions and practical reasoning but
also motor representations and processes. To illustrate, consider a cook
who has grasped an egg between her finger and thumb and is now lifting
it from the egg box. She will typically grip the egg just tightly enough
to secure it. But how tightly she needs to grip it depends in part, of
course, on the forces to which she will subject the egg in lifting it.
The fact that she grips eggs just tightly enough throughout such action
sequences which vary in how she lifts the egg implies that how tightly
she grips the egg depends on the path along which she will lift it. This
in turn indicates (along with much other evidence) that information
about her anticipated future hand and arm movements appropriately
influences how tightly the cook initially grips the egg <span
class="citation" data-cites="kawato:1999_internal">(Kawato 1999)</span>.
This fine-grained, anticipatory control of grasp, like many other
features of action performance (<span class="citation"
data-cites="rosenbaum:2010_human">(see Rosenbaum 2009, chap. 1)</span>
for more examples), is not plausibly a consequence of mindless
physiology, nor of intention and practical reasoning. The processes and
representations it depends on are motoric.</p>
<p>Motor processes and representations lead a double life: they occur
not only in performing actions but also observing them. For instance, in
someone observing the cook gripping and lifting the egg, there may be
motor processes and representations related to those which would occur
in her if she, the observer, were performing this action herself. One
dramatic piece of evidence for this claim comes from a study in which
activity in an observer’s motor cortex was artificially boosted with
transcranial magnetic stimulation (TMS). This caused minute patterns of
activation (specifically, motor-evoked potentials) to occur in a muscle
of the observer at just the times the agent being observed used the
corresponding muscle. <a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a> As this illustrates, motor processes
in an observer can carry detailed information about the timing of
components of actions. <em>Motor simulation</em> is the occurrence of
motor processes and representations in an observer concerning an action
which she is observing or imagining and which are driven by observing or
imagining that action.</p>
<p>Motor simulation enables observers to anticipate how others’ actions
will unfold and the likely outcomes the actions will achieve <span
class="citation" data-cites="Wolpert:2003mg Wilson:2005qu">(Wolpert,
Doya, and Kawato 2003; Wilson and Knoblich 2005)</span>. Such
anticipation is reflected both in explicit judgements <span
class="citation" data-cites="aglioti_action_2008">(e.g. Aglioti et al.
2008)</span> and in spontaneous eye movements <span class="citation"
data-cites="Flanagan:2003lm Rotman:2006xf Costantini:2012fk ambrosini:2011_grasping">(e.g.
Flanagan and Johansson 2003; Rotman et al. 2006; Costantini et al. 2014;
Ambrosini, Costantini, and Sinigaglia 2011)</span>.</p>
<p>How does any of this bear on the coordination of joint action? If
motor simulation is to play a role in coordinating joint actions, agents
must be capable of using anticipation based on motor simulation in
preparing and performing actions different from those simulated.
Accordingly, <span class="citation"
data-cites="kourtis:2012_predictive">Kourtis, Sebanz, and Knoblich
(2013)</span> used neural markers of motor activity to show that motor
simulation can occur in joint action even where agents are performing
different actions in close succession. To investigate, further, whether
motor simulation in joint action can facilitate coordination, <span
class="citation" data-cites="vesper:2012_jumping">Vesper et al.
(2013)</span> instructed pairs of people to jump and land at the same
time. They found evidence that in some subjects there was a motor
simulation of her partner’s jump which influences how she herself jumps
and so enables precise coordination in landing together. This is one
example of how motor simulation may enable coordination in joint action.
<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a></p>
<p>Reflecting on entrainment and coordination driven by motor
simulation, it is striking that one-off motor simulation allows greater
flexibility at the cost of some precision. Is there a more general
trade-off between flexibility and precision in mechanisms underpinning
coordination? If so, what might this tell us about the nature of
mechanisms underpinning coordination for joint action and their
relations to each other?</p>
<h1 id="sec:flexibility-precision-tradeoff">Flexibility vs
Precision</h1>
<p>Consider two ways of partially ordering mechanisms underpinning
coordination. The first is precision: How precise, in space and time, is
the coordination they underpin in the best cases? For instance,
mechanisms underpinning entrainment enable expert musicians to
coordinate their actions to within tens of milliseconds, whereas one-off
motor simulation permits coordination of actions to within larger
fractions of a second. A second partial ordering is flexibility: How
wide is the range of situations in which this mechanism can underpin
coordination? For instance, motor simulation can underpin coordination
whether or not repetition or rhythm is involved, unlike entrainment.
Thinking just about motor simulation and mechanisms underpinning
entrainment, there appears to be a trade-off between precision and
flexibility. This appears to generalise to other forms of coordination
too, such as forms of coordination driven by shared intention. Gains in
flexibility seem to come at the cost of precision.</p>
<p>Why? Before attempting to answer this question, it is useful to fix
terminology with some stipulations. A <em>goal</em> of an action or
behaviour is an outcome to which it is directed. Relative to a
particular action or behaviour, goals can be partially ordered by the
means-end relation. In saying that one goal is more <em>abstract</em>
than another relative to a behaviour or action, I shall mean that the
latter is linked to the former by a chain of outcomes ordered as means
to ends. A <em>goal-state</em> is a mental state (or a structure of
mental states) which represents, or otherwise specifies, an outcome and
is the kind of thing in virtue of which some actions or behaviours can
be directed to certain outcomes. Given that intentions are mental
states, they are paradigmatic goal-states. But intentions are not the
only goal-states: as we saw in <a href="#sec:co-representation"
data-reference-type="ref+label"
data-reference="sec:co-representation">4</a>, some motor representations
are also goal-states. <a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p>
<p>So why might flexibility in a mechanism underpinning coordination
come at the cost of precision? One possibility involves two conjectures.
First, achieving flexibility generally depends on representing goals,
and the more abstract the goals that can be represented, the greater the
flexibility. To illustrate, entrainment can occur without any
representations of goals at all, whereas motor simulation involves motor
representations which are goal-states. But relative to intentions or
knowledge states, motor representations are limited with respect to how
abstract the outcomes they can specify are. Motor representations can
specify outcomes such as grasping or transporting a fragile object, and
even sequences of such outcomes <span class="citation"
data-cites="Fogassi:2005nf">(see, e.g., Fogassi et al. 2005)</span>. But
they cannot specify outcomes such as selecting an organic egg or testing
for freshness: motor processes and representations are mostly blind to
things so distantly related to bodily action. A further conjecture is
that processes involving more abstract goal representations typically
(but not necessarily always) place greater demands on cognitive
resources, which typically (but not necessarily always) results in lower
precision. This conjecture is suggested by an analogy with the
physiological. Because physiological processes are a source of
variability, coordinating with a given degree of precision should get
harder as the duration and complexity of the actions to be coordinated
increases. Given that cognitive processes, like physiological processes,
are a source of variability, increasing cognitive demands by relying on
representations of more abstract goals should likewise increase
variability and so limit precision.</p>
<p>In short, flexibility may come at the cost of precision because
increasing flexibility requires representations of more abstract goals,
which impose greater cognitive demands and thereby increase variability,
so reducing how precise the coordination underpinned by a mechanism can
be in the best cases. This may be why forms of coordination such as
entrainment and motor representation can occur independently of, and
even contrary to, intentions concerning coordination: precision requires
such independence.</p>
<p>Thinking about trading precision for flexibility suggests that there
is a gap in the forms of coordination so far considered. To see why,
consider the situation of a couple alone on a beach. Having filled
plastic beakers with wine, they spontaneously and fluidly clink them
together in a toast without spilling a drop of wine. To explain how they
are able to coordinate so precisely we cannot appeal to motor simulation
alone; but it would be no less plausible to appeal only to practical
deliberation involving intentions or other propositional attitudes. We
need something more flexible than motor simulation and more precise than
practical deliberation.</p>
<h1 id="sec:task-co-repr-1">Task Co-representation</h1>
<p>Consider individual agents acting alone for a moment. A <em>task
representation</em> links an event to an outcome in such a way that,
normally, the event’s actual or expected occurrence would trigger motor
preparation for actions that should realise the outcome. Why do we need
task representations? Imagine yourself cycling up to a crossroad. Even
if you are concentrating hard on dodging potholes without being hit by
the rapidly approaching car behind you (will it slow down or should you
risk going through this hole?), it is likely—hopefully—that the traffic
light’s turning red will cause you to brake. The connection between red
light events and braking actions need not require intentional control,
thanks to task representations.</p>
<p>How is task representation relevant to coordinating joint actions?
Let us say that two individuals have a <em>task co-representation</em>
if there is a task concerning which each has a task representation. <a
href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a> <span class="citation"
data-cites="Sebanz:2006yq">Sebanz, Bekkering, and Knoblich (2006)</span>
argue that the agents of a joint action can have a task
co-representation concerning a task which only one of them is actually
supposed to perform. This, they suggest, would enable agents to exploit
motor simulation prior to, and independently of, observing the any
actual actions. Thus task co-representation could in principle greatly
extend the range of situations in which motor simulation could underpin
coordination in joint action. To illustrate, consider again the couple
on the beach filling beakers with wine and then clinking them together.
As noted earlier (in <a href="#sec:flexibility-precision-tradeoff"
data-reference-type="ref+label"
data-reference="sec:flexibility-precision-tradeoff">5</a>), their doing
this spontaneously, fluidly and with precision could not be explained by
motor simulation alone when neither of them plays the role of leader.
But it could be explained by Sebanz et al’s proposal about task
co-representation. If the couple expect to clink beakers after the wine
is poured and have task co-representations concerning each’s task in the
clinking, then they will be able to use motor simulation to anticipate
each other’s actions in advance of starting to act. This is one
illustration of how task co-representation might underpin coordination
for one-off joint actions where agents have to respond to events in ways
they have never done before.</p>
<p>The task co-representation hypothesis—agents involved in a joint
action can have a task co-representation concerning a task that only one
of them is supposed to perform—generates a variety of predictions. It
predicts interference and facilitation effects: when acting together
with another, your performance of your task will be affected by facts
about which task the other is performing, and your performance will be
impaired or enhanced in ways analogous to those in which it would be
affected if you were performing both tasks alone. This prediction has
been confirmed for a variety of tasks <span class="citation"
data-cites="Sebanz:2005fk atmaca:2011_joint bockler:2012_effects wel:2015_entrainment">(Sebanz,
Knoblich, and Prinz 2005; Atmaca, Sebanz, and Knoblich 2011; Böckler,
Knoblich, and Sebanz 2012; Wel and Fu 2015)</span>. The task
co-representation hypothesis also predicts that, in some situations when
you are acting with another, events linked to the other’s task will
trigger some preparation (but not necessarily full preparation) in you
for a task which is actually supposed to be performed by the other.
Evidence in support of this prediction includes signs that agents of a
joint action sometimes inhibit tendencies to act when another, rather
than she herself, is supposed act <span class="citation"
data-cites="sebanz:2006_twin_peaks tsai:2008_action">(Sebanz et al.
2006; C.-C. Tsai et al. 2008)</span>, as well as signs that agents of a
joint action are sometimes preparing for, or even covertly performing,
actions that another is supposed to perform <span class="citation"
data-cites="kourtis:2012_predictive baus:2014_predicting">(e.g. Kourtis,
Sebanz, and Knoblich 2013; Baus et al. 2014)</span>. <a href="#fn9"
class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>Task co-representation is valuable in coordinating joint actions at
least in part because it is more flexible than bare motor simulation
while also more precise than practical reasoning. But there is a limit
to what can be explained with either motor simulation or task
co-representation, at least as we have conceived of them so far. Suppose
motor simulation (whether or not triggered by a task co-representation)
enables agents of a joint action to anticipate each other’s actions. How
could these anticipations inform preparation for their own actions, and,
in particular, how could they do so without requiring cognitive
processes inimical to precision? To offer even a candidate answer to
this question requires going beyond motor simulation and task
co-representation as we have so far conceived them.</p>
<h1 id="sec:emergent-vs-planned">Emergent vs Planned Coordination</h1>
<p>In thinking about coordination for joint action it is useful to have
plural counterparts of the notions of goal and goal-state introduced
earlier (in <a href="#sec:co-representation" data-reference-type="ref"
data-reference="sec:co-representation">4</a>). To say of an outcome that
it is a <em>collective goal</em> of some actions or behaviours is to say
that they are collectively directed to this outcome—that is, they are
directed to this outcome and their being so directed is not, or not
only, a matter of each action or behaviour being individually directed
to that outcome. This is a broad notion: raising a brood can be a
collective goal of some eusocial insects’ behaviours, <a href="#fn10"
class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>
and repairing a broken fence can be a collective goal of some
neighbours’ actions. A <em>collective goal-state</em> is a mental state
or, more likely, a structure of mental states, which specifies an
outcome and is the kind of thing in virtue of which some pluralities of
actions or behaviours can be collectively directed to certain outcomes.
Bratman’s account of shared intention aims to describe one kind of
collective goal-state <span class="citation"
data-cites="Bratman:1993je">(Bratman 1993)</span>.</p>
<p>Following <span class="citation"
data-cites="Knoblich:2010fk">Knoblich, Butterfill, and Sebanz
(2011)</span>, we can distinguish between emergent and planned
coordination. <em>Planned coordination</em> is coordination driven by a
collective goal-state, <a href="#fn11" class="footnote-ref" id="fnref11"
role="doc-noteref"><sup>11</sup></a> whereas <em>emergent
coordination</em> is coordination not so driven. Planned coordination is
familiar from philosophical discussions of shared intention, one of the
functions of which is to coordinate agents’ actions <span
class="citation" data-cites="Bratman:1993je">(Bratman 1993, 99)</span>.
By contrast, all the forms of coordination discussed in this chapter so
far—entrainment as well as coordination driven by action and task
co-representations—are naturally thought of as forms of emergent
coordination insofar as it seems they could occur independently of the
agents having any collective goal-state. <a href="#fn12"
class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>
But there is also a growing body of evidence about the existence of
planned coordination for joint action.</p>
<h1 id="sec:collective-goal-states">Collective Goal-States</h1>
<p>Two pianists are producing tones in the course of playing a duet.
Consider one of the pianists. There is an outcome to which her action is
directed, the production of a tone or melody; and there is an outcome to
which her and her partner’s actions are collectively directed, the
production of a combination of pitches or harmony. Do dueting pianists
represent collective goals, that is, outcomes to which their actions are
collectively directed?</p>
<p>One way to investigate this question involves covertly introducing
errors. <span class="citation" data-cites="loehr:2013_monitoring">Janeen
D. Loehr et al. (2013)</span> contrasted two kinds of error: those which
were errors relative to the goal of an individual pianist’s actions (the
pitch) but not relative to the collective goal of the two pianists’
actions (the harmony); and those which were errors relative to both.
They found neural signatures for both kinds of errors in expert
pianists. This is evidence that dueting pianists do indeed represent
collective goals. A further study indicates that these collective goals
are represented motorically <span class="citation"
data-cites="loehr:2015_sound">(Janeen D. Loehr and Vesper 2015)</span>.
<a href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a></p>
<p>How might motor representations of collective goals underpin
coordination for joint action? One possible answer is suggested by <span
class="citation" data-cites="gallotti:2013_social">Gallotti and Frith
(2013)</span> who propose that a ‘we-mode’ is required. They
explain:</p>
<blockquote>
<p>‘The central idea of the we-mode is that interacting agents share
their minds by representing their contributions to the joint action as
contributions to something that they are going to pursue together, as a
‘we’. […] To represent things in the we-mode is for interacting
individuals to have the content of their individual actions specified by
representing aspects of the interactive scene in a distinct
psychological attitude of intending-together, believing-together,
desiring-together, etc’ <span class="citation"
data-cites="gallotti:2013_social">(Gallotti and Frith 2013,
163)</span>.</p>
</blockquote>
<p>An alternative possible answer is suggested by what <span
class="citation" data-cites="vesper_minimal_2010">Vesper et al.
(2010)</span> call a ‘minimal architecture for joint action’. They
propose to start by attempting to characterise joint action and its
coordination without postulating distinct psychological attitudes and
without invoking representations of interacting agents as comprising a
‘we’. Instead their proposal is that some or all of the representations
underpinning coordination for joint action are ordinary motor
representations, task representations and other representations that are
also involved in the coordination of ordinary, individual action.
Relatedly, in at least some cases, coordination is driven by
representations which are <em>agent-neutral</em>, that is, which do not
specify any particular agent or agent. This proposal is consistent with
theories about the roles of motor simulation and task co-representation
in coordinating joint action (see <a href="#sec:co-representation"
data-reference-type="ref+label"
data-reference="sec:co-representation">4</a> and <a
href="#sec:task-co-repr-1" data-reference-type="ref+label"
data-reference="sec:task-co-repr-1">6</a>): anticipating another’s
actions and their effects appears to involve much the same agent-neutral
motor and task representations which would be involved if one were
actually performing those actions oneself. Of course, motor and task
representations concerning actions others will eventually perform must
ultimately have effects different from those concerning actions the
agent will perform; but this is necessary for both observation and joint
action and need not involve a novel kind of attitude.</p>
<p>But how, given <span class="citation"
data-cites="vesper_minimal_2010">Vesper et al. (2010)</span>’s ‘minimal
architecture’ proposal, could motor representations of collective goals
underpin coordination for joint action? In each agent of a joint action,
the motor representations of collective goals trigger preparation for
action in just the way any motor representations do. This has the effect
that each agent is preparing to perform all of the actions comprising a
joint action, although not necessarily in much detail <span
class="citation" data-cites="loehr:2015_sound">(compare Janeen D. Loehr
and Vesper 2015)</span>. Now this may appear wasteful given that each
agent will only perform a subset of the actions prepared for. But it is
not. One agent’s preparing (to some extent) to perform all of the
actions that will comprise a joint action ensures that the resulting
motor plan for her actions will be constrained by her motor plan for the
others’ actions. And, given that she is sufficiently similar to the
others and that the possibilities for action are sufficiently
constrained in their situation, her motor plan for the others’ actions
will reliably match their motor plans for their actions. So one agent’s
preparing to perform all of the actions has the effect that her motor
plan for her actions is indirectly constrained by the others’ motor
plans for their actions. In this way, motor representations of
collective goals could in principle underpin coordination for joint
action by enabling agents to meet relational constraints on their
actions <span class="citation"
data-cites="butterfill:2015_planning">(see further Butterfill
2016)</span>.</p>
<p>The conjecture that motor representations of collective goals
underpin coordination for joint action provides one response to a
question raised at the end of <a href="#sec:task-co-repr-1"
data-reference-type="ref+label"
data-reference="sec:task-co-repr-1">6</a>. The question was how
anticipations concerning another’s actions arising from motor simulation
(whether bare motor simulation or occurring as a consequence of task
co-representation) feed into preparing and monitoring your own actions.
When coordination depends on motor representations of collective goals,
the presupposition this question makes is incorrect. There are not two
processes but one. Anticipation of another’s actions and preparation for
your own are not two separate things. They are parts of a single process
in the same sense that, in preparing to perform a bimanual action,
preparation for the actions to be performed by the left hand and
anticipation of the movements of the right hand are parts of a single
process. So where motor simulation and task co-representation involve
collective goals to which a joint action is directed, motor processes
themselves can ensure the integration of anticipations concerning
another’s actions with preparation for your own.</p>
<p>This is not quite the end of the story about collective goals.
Research on perceiving joint affordances points to a second way in which
motor representations of collective goals may underpin coordination in
joint action.</p>
<h1 id="sec:joint-affordances">Joint Affordances</h1>
<p>A <em>joint affordance</em> is an affordance for the agents of a
joint action collectively—that is, it is an affordance for these agents
and this is not, or not only, a matter of its being an affordance for
any of the individual agents. Perceiving (or otherwise detecting) joint
affordances is critical for many mundane joint actions such as
appropriately gripping objects and applying the right force in moving
them together, and crossing a busy road while holding hands. It is
possible that motor representations of collective goals enable the
agents of some joint actions to perceive joint affordances, or so I will
suggest in this section. <a href="#fn14" class="footnote-ref"
id="fnref14" role="doc-noteref"><sup>14</sup></a> But first, what
grounds are there for supposing that joint affordances even exist?</p>
<p><span class="citation"
data-cites="doerrfeld:2012_expecting">Doerrfeld, Sebanz, and Shiffrar
(2012, 474)</span> argue that ‘the joint action abilities of a group
shape the individual perception of its members.’ In their experiment,
perceptual judgements of weight were affected by whether the perceiver
was about to lift the box alone or with another. Others have
investigated different situations in which performing actions
independently or as part of a joint action can affect how you perceive
affordances. For instance, consider two individuals walking through a
doorway. How wide must the doorway be for them to walk though it without
rotating their shoulders? <span class="citation"
data-cites="davis:2010_perceiving">Davis et al. (2010, Experiment
1)</span> show that the answer cannot be obtained simply by adding the
minimum widths for each individual, and (in Experiments 2–4) that people
can perceive whether doorway-like openings will allow a particular pair
of walkers to pass through comfortably. <a href="#fn15"
class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>
Importantly, people can perceive joint affordances for walkers not only
when they are one of those walking but also when they are merely
observing others walking together <span class="citation"
data-cites="davis:2010_perceiving">(Davis et al. 2010, Experiment
4)</span>. This suggests that the perceptual capacity does not depend on
the perceiver’s own current possibilities for action. So what makes
perception of joint affordances possible?</p>
<p>Consider the conjecture that joint affordances are perceived as a
consequence of motor simulation (this is one of two possibilities
discussed by <span class="citation"
data-cites="doerrfeld:2012_expecting">(Doerrfeld, Sebanz, and Shiffrar
2012)</span>). This conjecture is made plausible by independent evidence
for two hypotheses. First, motor representations can modulate perceptual
experience; for instance, how an event is represented motorically can
affect how a pair of tones are perceived with respect to pitch (<span
class="citation" data-cites="repp:2007_action repp:2009_performed">(Repp
and Knoblich 2007, 2009)</span>; for discussion, see <span
class="citation" data-cites="sinigaglia:2015_puzzle">(Sinigaglia and
Butterfill 2015)</span>). Second, perceiving another’s affordance
involves motor activity <span class="citation"
data-cites="cardellicchio:2012_grasping">(Cardellicchio, Sinigaglia, and
Costantini 2012)</span>. These two findings make it plausible that, in
general, perceiving some affordances is facilitated or even enabled by
motor simulation. The findings just discussed suggest that the same may
be true for joint affordances, that is, affordances for agents involved
in one or another kind of joint action. But of course this is possible
only given that there are motor representations of collective goals.
After all, perceiving joint affordances requires motor simulation
concerning the joint action, which would be triggered by a motor
representation of a collective goal of the actions grounding the joint
action; merely having separate motor simulations of each agent’s actions
could not underpin the identification of a joint affordance. This is why
motor representations of collective goals may facilitate coordination in
joint actions not only by enabling the agents to meet relational
constraints on their actions (see <a href="#sec:collective-goal-states"
data-reference-type="ref+label"
data-reference="sec:collective-goal-states">8</a>) but also by enabling
them to perceive joint affordances.</p>
<h1 id="sec:conclusion">Conclusion</h1>
<p>What forms of coordination for joint action enable humans to exercise
shared agency in doing things such as clinking beakers, sharing smiles,
erecting marquees, or producing rhythmic music? We have seen that there
is much diversity. Coordination for joint action includes not only
emergent varieties such as entrainment (see <a href="#sec:entrainment"
data-reference-type="ref+label" data-reference="sec:entrainment">3</a>)
as well as the forms underpinned by motor simulation (see <a
href="#sec:co-representation" data-reference-type="ref+label"
data-reference="sec:co-representation">4</a>) and task co-representation
(see <a href="#sec:task-co-repr-1" data-reference-type="ref+label"
data-reference="sec:task-co-repr-1">6</a>), but also planned
coordination underpinned by motor representations of collective goals
(see <a href="#sec:collective-goal-states"
data-reference-type="ref+label"
data-reference="sec:collective-goal-states">8</a>). <a href="#fn16"
class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a></p>
<p>This diversity in forms of coordination may exist in part because of
a trade-off between flexibility and precision for individual mechanisms
underpinning coordination (see <a
href="#sec:flexibility-precision-tradeoff"
data-reference-type="ref+label"
data-reference="sec:flexibility-precision-tradeoff">5</a>). Having
multiple mechanisms is useful partly because each makes a different
trade-off between flexibility and precision.</p>
<p>Many exercises of shared agency appear to require both flexibility
and extremely precise coordination. Improvising musicians ideally
achieve temporal synchrony without becoming enslaved to a rhythm. How is
this possible? Exercises of shared agency can depend on multiple forms
of coordination, of course. Individual mechanisms underpinning
coordination may be constrained by the precision–flexibility trade-off,
but this constraint does not apply to a diversity of mechanisms
considered in aggregate. So there is no theoretical obstacle to relying
on highly flexible mechanisms yet achieving extremely precise
coordination. This requires only that diverse mechanisms can have
synergistic effects on coordination.</p>
<p>Just here we encounter the <em>synergy challenge</em>. Achieving
precise coordination in space and time probably demands that mechanisms
underpinning different forms of coordination are to a significant degree
independent of each other (see <a
href="#sec:flexibility-precision-tradeoff"
data-reference-type="ref+label"
data-reference="sec:flexibility-precision-tradeoff">5</a>). Yet acting
flexibility requires that the different mechanisms sometimes
nonaccidentally operate synergistically—the shared intention, the task
co-representation, and the motor representation of the collective goal
cannot all be pulling in different directions. The challenge is to
understand how, in some situations, mechanisms underpinning different
forms of coordination and which are driven by largely independent
representational structures can nevertheless nonaccidentally have
synergistic effects. Meeting this challenge may require attention to
differences between novices and experts, to why practice is sometimes
necessary, to the effects of common knowledge on moment-by-moment
coordination (see, for example, <span class="citation"
data-cites="richardson:2007_art">(D. C. Richardson, Dale, and Kirkham
2007)</span>), and to phenomenal aspects of coordination (as <span
class="citation" data-cites="keller:2014_rhythm">(Keller, Novembre, and
Hove 2014)</span> hint), among other things. The synergy challenge is
currently a significant obstacle to progress is understanding how high
degrees of flexibility and precision can be combined in the coordination
of joint actions.</p>
<p>Another issue likely to demand future research concerns which, if
any, forms of coordination require postulating novel kinds of
representations or processes specific to shared agency (see <a
href="#sec:collective-goal-states" data-reference-type="ref+label"
data-reference="sec:collective-goal-states">8</a>). Although scientists
sometimes adopt terms from philosophical discussions of collective
intentionality such as ‘shared’ and ‘we-’ representations, the
discoveries about the representations and processes underpinning
coordination reviewed in this chapter do not require representations to
be shared other than in the sense in which barrel organ aficionados
share a taste in music.</p>
<p>One theme in this chapter was that much coordination of joint action
appears to involve not fully distinguishing others’ actions from your
own. Take motor simulation, task co-representation and motor
representation of collective goals. In each case, coordination involves
motor or task representations of actions, tasks or goals that relate
primarily to another’s part in the joint action. This is not a matter of
representing another’s goals or plans as an observer: it is a matter of
preparing actions and representing tasks she will perform in ways that
would also be appropriate if it were you, not her, who was about to
perform them. To a limited but significant extent, then, coordination
involves representing both another’s actions and your own in ways that
give them equal status as parts of a single activity. The existence of
such a perspective on the actions grounding a joint action might just
turn out to matter not only for coordination but also for other aspects
of collective intentionality such as commitment and cooperation. <a
href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a></p>
<div class="refcontext">

</div>
<div id="refs" class="references csl-bib-body hanging-indent"
data-entry-spacing="0" role="list">
<div id="ref-aglioti_action_2008" class="csl-entry" role="listitem">
Aglioti, Salvatore M, Paola Cesari, Michela Romani, and Cosimo Urgesi.
2008. <span>“Action Anticipation and Motor Resonance in Elite Basketball
Players.”</span> <em>Nature Neuroscience</em> 11 (9): 1109–16. <a
href="https://doi.org/10.1038/nn.2182">https://doi.org/10.1038/nn.2182</a>.
</div>
<div id="ref-ambrosini:2011_grasping" class="csl-entry" role="listitem">
Ambrosini, Ettore, Marcello Costantini, and Corrado Sinigaglia. 2011.
<span>“Grasping with the Eyes.”</span> <em>Journal of
Neurophysiology</em> 106 (3): 1437–42. <a
href="https://doi.org/10.1152/jn.00118.2011">https://doi.org/10.1152/jn.00118.2011</a>.
</div>
<div id="ref-ambrosini:2012_tie" class="csl-entry" role="listitem">
Ambrosini, Ettore, Corrado Sinigaglia, and Marcello Costantini. 2012.
<span>“Tie My Hands, Tie My Eyes.”</span> <em><span>Journal of
Experimental Psychology: Human Perception and Performance</span></em> 38
(2): 263–66. <a
href="https://doi.org/10.1037/a0026570">https://doi.org/10.1037/a0026570</a>.
</div>
<div id="ref-atmaca:2011_joint" class="csl-entry" role="listitem">
Atmaca, Silke, Natalie Sebanz, and Günther Knoblich. 2011. <span>“The
Joint Flanker Effect: Sharing Tasks with Real and Imagined
Co-Actors.”</span> <em>Experimental Brain Research</em> 211 (3-4):
371–85. <a
href="https://doi.org/10.1007/s00221-011-2709-9">https://doi.org/10.1007/s00221-011-2709-9</a>.
</div>
<div id="ref-backwell:1998_synchronized" class="csl-entry"
role="listitem">
Backwell, Patricia, Michael Jennions, Neville Passmore, and John
Christy. 1998. <span>“Synchronized Courtship in Fiddler Crabs.”</span>
<em>Nature</em> 391 (6662): 31–32. <a
href="https://doi.org/10.1038/34076">https://doi.org/10.1038/34076</a>.
</div>
<div id="ref-baus:2014_predicting" class="csl-entry" role="listitem">
Baus, Cristina, Natalie Sebanz, Vania de la Fuente, Francesca Martina
Branzi, Clara Martin, and Albert Costa. 2014. <span>“<span
class="nocase">On predicting others’ words: Electrophysiological
evidence of prediction in speech production</span>.”</span>
<em><span>Cognition</span></em> <span>133</span> (2): 395–407. <a
href="https://doi.org/10.1016/j.cognition.2014.07.006">https://doi.org/10.1016/j.cognition.2014.07.006</a>.
</div>
<div id="ref-bockler:2012_effects" class="csl-entry" role="listitem">
Böckler, Anne, Günther Knoblich, and Natalie Sebanz. 2012.
<span>“Effects of a Coactor’s Focus of Attention on Task
Performance.”</span> <em>Journal of Experimental Psychology: Human
Perception and Performance</em> 38 (6): 1404–15. <a
href="https://doi.org/10.1037/a0027523">https://doi.org/10.1037/a0027523</a>.
</div>
<div id="ref-Bratman:1993je" class="csl-entry" role="listitem">
Bratman, Michael E. 1993. <span>“Shared Intention.”</span>
<em>Ethics</em> 104: 97–113.
</div>
<div id="ref-butterfill:2015_planning" class="csl-entry"
role="listitem">
Butterfill, Stephen A. 2016. <span>“Planning for Collective
Agency.”</span> In <em>Collective Agency and Cooperation in Natural and
Artificial Systems</em>, edited by Catrin Misselhorn, 122:149–68.
Philosophical Studies Series. New York: Springer. <a
href="http://joint-action.butterfill.com/pdf/planning_for_collective_agency.pdf">http://joint-action.butterfill.com/pdf/planning_for_collective_agency.pdf</a>.
</div>
<div id="ref-butterfill:2012_intention" class="csl-entry"
role="listitem">
Butterfill, Stephen A., and Corrado Sinigaglia. 2014. <span>“Intention
and Motor Representation in Purposive Action.”</span> <em>Philosophy and
Phenomenological Research</em> 88 (1): 119–45. <a
href="https://doi.org/10.1111/j.1933-1592.2012.00604.x">https://doi.org/10.1111/j.1933-1592.2012.00604.x</a>.
</div>
<div id="ref-cardellicchio:2012_grasping" class="csl-entry"
role="listitem">
Cardellicchio, Pasquale, Corrado Sinigaglia, and Marcello Costantini.
2012. <span>“Grasping Affordances with the Other’s Hand: A
<span>TMS</span> Study.”</span> <em>Social Cognitive and Affective
Neuroscience</em>. <a
href="https://doi.org/10.1093/scan/nss017">https://doi.org/10.1093/scan/nss017</a>.
</div>
<div id="ref-Costantini:2012fk" class="csl-entry" role="listitem">
Costantini, Marcello, Ettore Ambrosini, Pasquale Cardellicchio, and
Corrado Sinigaglia. 2014. <span>“How Your Hand Drives My Eyes.”</span>
<em>Social Cognitive and Affective Neuroscience</em> 9 (5): 705–11.
</div>
<div id="ref-davis:2010_perceiving" class="csl-entry" role="listitem">
Davis, Tehran J., Michael A. Riley, Kevin Shockley, and Sarah
Cummins-Sebree. 2010. <span>“Perceiving Affordances for Joint
Actions.”</span> <em>Perception</em> 39 (12): 1624–44. <a
href="https://doi.org/10.1068/p6712">https://doi.org/10.1068/p6712</a>.
</div>
<div id="ref-doerrfeld:2012_expecting" class="csl-entry"
role="listitem">
Doerrfeld, Adam, Natalie Sebanz, and Maggie Shiffrar. 2012.
<span>“Expecting to Lift a Box Together Makes the Load Look
Lighter.”</span> <em>Psychological Research</em> 76 (4): 467–75. <a
href="https://doi.org/10.1007/s00426-011-0398-4">https://doi.org/10.1007/s00426-011-0398-4</a>.
</div>
<div id="ref-dolk:2011_how" class="csl-entry" role="listitem">
Dolk, Thomas, Bernhard Hommel, Lorenza S Colzato, Simone Schütz-Bosbach,
Wolfgang Prinz, and Roman Liepelt. 2011. <span>“How
<span>‘Social’</span> Is the Social Simon Effect?”</span> <em>Frontiers
in Psychology</em> 2. <a
href="https://doi.org/10.3389/fpsyg.2011.00084">https://doi.org/10.3389/fpsyg.2011.00084</a>.
</div>
<div id="ref-dolk:2014_joint" class="csl-entry" role="listitem">
Dolk, Thomas, Bernhard Hommel, Wolfgang Prinz, and Roman Liepelt. 2014.
<span>“<span class="nocase">The joint flanker effect: Less social than
previously thought</span>.”</span> <em><span>Psychonomic Bulletin &amp;
Review</span></em> <span>21</span> (5): 1224–30. <a
href="https://doi.org/10.3758/s13423-014-0583-8">https://doi.org/10.3758/s13423-014-0583-8</a>.
</div>
<div id="ref-Fadiga:2005gq" class="csl-entry" role="listitem">
Fadiga, Luciano, Laila Craighero, and Etienne Olivier. 2005.
<span>“Human Motor Cortex Excitability During the Perception of Others’
Action.”</span> <em>Current Opinion in Neurobiology</em> 15 (2): 213–18.
</div>
<div id="ref-fairhurst:2013_being" class="csl-entry" role="listitem">
Fairhurst, Merle T., Petr Janata, and Peter E. Keller. 2013.
<span>“Being and Feeling in Sync with an Adaptive Virtual Partner: Brain
Mechanisms Underlying Dynamic Cooperativity.”</span> <em>Cerebral
Cortex</em> 23 (11): 2592–2600. <a
href="https://doi.org/10.1093/cercor/bhs243">https://doi.org/10.1093/cercor/bhs243</a>.
</div>
<div id="ref-Flanagan:2003lm" class="csl-entry" role="listitem">
Flanagan, J. Randall, and Roland S. Johansson. 2003. <span>“Action Plans
Used in Action Observation.”</span> <em>Nature</em> 424 (6950): 769–71.
</div>
<div id="ref-Fogassi:2005nf" class="csl-entry" role="listitem">
Fogassi, Leonardo, Pier Francesco Ferrari, Benno Gesierich, Stefano
Rozzi, Fabian Chersi, and Giacomo Rizzolatti. 2005. <span>“Parietal
Lobe: From Action Organization to Intention Understanding.”</span>
<em>Science</em> 308 (5722): 662–67.
</div>
<div id="ref-gallotti:2013_social" class="csl-entry" role="listitem">
Gallotti, Mattia, and Chris D. Frith. 2013. <span>“Social Cognition in
the We-Mode.”</span> <em>Trends in Cognitive Sciences</em> 17 (4):
160–65. <a
href="https://doi.org/10.1016/j.tics.2013.02.002">https://doi.org/10.1016/j.tics.2013.02.002</a>.
</div>
<div id="ref-Gangitano:2001ft" class="csl-entry" role="listitem">
Gangitano, Massimo, Felix M. Mottaghy, and Alvaro Pascual-Leone. 2001.
<span>“Phase-Specific Modulation of Cortical Motor Output During
Movement Observation.”</span> <em>Neuroreport</em> 12 (7): 1489–92.
</div>
<div id="ref-issartel:2007_unintended" class="csl-entry"
role="listitem">
Issartel, Johann, Ludovic Marin, and Marielle Cadopi. 2007.
<span>“Unintended Interpersonal Co-Ordination: <span>‘Can We March to
the Beat of Our Own Drum?’</span>”</span> <em>Neuroscience Letters</em>
411 (3): 174–79. <a
href="https://doi.org/10.1016/j.neulet.2006.09.086">https://doi.org/10.1016/j.neulet.2006.09.086</a>.
</div>
<div id="ref-kawato:1999_internal" class="csl-entry" role="listitem">
Kawato, Mitsuo. 1999. <span>“Internal Models for Motor Control and
Trajectory Planning.”</span> <em>Current Opinion in Neurobiology</em> 9
(6): 718–27. <a
href="https://doi.org/10.1016/S0959-4388(99)00028-8">https://doi.org/10.1016/S0959-4388(99)00028-8</a>.
</div>
<div id="ref-keller:2007_pianists" class="csl-entry" role="listitem">
Keller, Peter E., Günther Knoblich, and Bruno H. Repp. 2007.
<span>“Pianists Duet Better When They Play with Themselves: On the
Possible Role of Action Simulation in Synchronization.”</span>
<em>Consciousness and Cognition</em> 16 (1): 102–11. <a
href="https://doi.org/10.1016/j.concog.2005.12.004">https://doi.org/10.1016/j.concog.2005.12.004</a>.
</div>
<div id="ref-keller:2014_rhythm" class="csl-entry" role="listitem">
Keller, Peter E., Giacomo Novembre, and Michael J. Hove. 2014.
<span>“Rhythm in Joint Action: Psychological and Neurophysiological
Mechanisms for Real-Time Interpersonal Coordination.”</span>
<em>Philosophical Transactions of the Royal Society of London B:
Biological Sciences</em> 369 (1658): 20130394. <a
href="https://doi.org/10.1098/rstb.2013.0394">https://doi.org/10.1098/rstb.2013.0394</a>.
</div>
<div id="ref-Knoblich:2010fk" class="csl-entry" role="listitem">
Knoblich, Günther, Stephen A. Butterfill, and Natalie Sebanz. 2011.
<span>“Psychological Research on Joint Action: Theory and Data.”</span>
In <em>Psychology of Learning and Motivation</em>, edited by Brian Ross,
51:59–101. San Diego, CA: Academic Press.
</div>
<div id="ref-konvalinka:2010_follow" class="csl-entry" role="listitem">
Konvalinka, Ivana, Peter Vuust, Andreas Roepstorff, and Chris D. Frith.
2010. <span>“Follow You, Follow Me: Continuous Mutual Prediction and
Adaptation in Joint Tapping.”</span> <em>The Quarterly Journal of
Experimental Psychology</em> 63 (11): 2220–30. <a
href="https://doi.org/10.1080/17470218.2010.497843">https://doi.org/10.1080/17470218.2010.497843</a>.
</div>
<div id="ref-kourtis:2012_predictive" class="csl-entry" role="listitem">
Kourtis, Dimitrios, Natalie Sebanz, and Günther Knoblich. 2013.
<span>“Predictive Representation of Other People’s Actions in Joint
Action Planning: An <span>EEG</span> Study.”</span> <em>Social
Neuroscience</em> 8 (1): 31–42. <a
href="https://doi.org/10.1080/17470919.2012.694823">https://doi.org/10.1080/17470919.2012.694823</a>.
</div>
<div id="ref-loehr:2013_monitoring" class="csl-entry" role="listitem">
Loehr, Janeen D, Dimitrios Kourtis, Cordula Vesper, Natalie Sebanz, and
Günther Knoblich. 2013. <span>“Monitoring Individual and Joint Action
Outcomes in Duet Music Performance.”</span> <em>Journal of Cognitive
Neuroscience</em> 25 (7): 1049–61.
</div>
<div id="ref-loehr:2011_temporal" class="csl-entry" role="listitem">
Loehr, Janeen D, and Caroline Palmer. 2011. <span>“Temporal Coordination
Between Performing Musicians.”</span> <em>The Quarterly Journal of
Experimental Psychology</em> 64 (11): 2153–67.
</div>
<div id="ref-loehr:2015_sound" class="csl-entry" role="listitem">
Loehr, Janeen D., and Cordula Vesper. 2015. <span>“The Sound of You and
Me: Novices Represent Shared Goals in Joint Action.”</span> <em>The
Quarterly Journal of Experimental Psychology</em> 0 (ja): 1–30. <a
href="https://doi.org/10.1080/17470218.2015.1061029">https://doi.org/10.1080/17470218.2015.1061029</a>.
</div>
<div id="ref-marsh_social_2009" class="csl-entry" role="listitem">
Marsh, Kerry L., Michael J. Richardson, and Richard C. Schmidt. 2009.
<span>“Social Connection Through Joint Action and Interpersonal
Coordination.”</span> <em>Topics in Cognitive Science</em> 1 (2):
320–39. <a
href="https://doi.org/10.1111/j.1756-8765.2009.01022.x">https://doi.org/10.1111/j.1756-8765.2009.01022.x</a>.
</div>
<div id="ref-Menoret:2013fk" class="csl-entry" role="listitem">
Ménoret, Mathilde, L. Varnet, R. Fargier, A. Cheylus, A. Curie, V. des
Portes, T. A. Nazir, and Y. Paulignan. 2014. <span>“Neural Correlates of
Non-Verbal Social Interactions: A Dual-EEG Study.”</span>
<em>Neuropsychologia</em> 55: 75–97.
</div>
<div id="ref-merker:2009_role" class="csl-entry" role="listitem">
Merker, Bjorn H., Guy S. Madison, and Patricia Eckerdal. 2009. <span>“On
the Role and Origin of Isochrony in Human Rhythmic Entrainment.”</span>
<em>Cortex</em>, Special issue on <span>“the rhythmic brain,”</span> 45
(1): 4–17. <a
href="https://doi.org/10.1016/j.cortex.2008.06.011">https://doi.org/10.1016/j.cortex.2008.06.011</a>.
</div>
<div id="ref-meyer:2011_joint" class="csl-entry" role="listitem">
Meyer, Marlene, Sabine Hunnius, Michiel van Elk, Freek van Ede, and
Harold Bekkering. 2011. <span>“Joint Action Modulates Motor System
Involvement During Action Observation in 3-Year-Olds.”</span>
<em>Experimental Brain Research</em> 211 (3-4): 581–92. <a
href="https://doi.org/10.1007/s00221-011-2658-3">https://doi.org/10.1007/s00221-011-2658-3</a>.
</div>
<div id="ref-meyer:2013_higher-order" class="csl-entry" role="listitem">
Meyer, Marlene, Robrecht P. R. D. van der Wel, and Sabine Hunnius. 2013.
<span>“Higher-Order Action Planning for Individual and Joint Object
Manipulations.”</span> <em>Experimental Brain Research</em> 225 (4):
579–88. <a
href="https://doi.org/10.1007/s00221-012-3398-8">https://doi.org/10.1007/s00221-012-3398-8</a>.
</div>
<div id="ref-miles:2010_too" class="csl-entry" role="listitem">
Miles, Lynden K., Jordan L. Griffiths, Michael J. Richardson, and C.
Neil Macrae. 2010. <span>“Too Late to Coordinate: Contextual Influences
on Behavioral Synchrony.”</span> <em>European Journal of Social
Psychology</em> 40 (1): 52–60. <a
href="https://doi.org/10.1002/ejsp.721">https://doi.org/10.1002/ejsp.721</a>.
</div>
<div id="ref-neda:2000_self" class="csl-entry" role="listitem">
Néda, Z., E. Ravasz, Y. Brechet, T. Vicsek, and A.-L. Barabási. 2000.
<span>“Self-Organizing Processes: The Sound of Many Hands
Clapping.”</span> <em>Nature</em> 403 (6772): 849–50. <a
href="https://doi.org/10.1038/35002660">https://doi.org/10.1038/35002660</a>.
</div>
<div id="ref-nessler:2009_interpersonal" class="csl-entry"
role="listitem">
Nessler, Jeff A., and Sara J. Gilliland. 2009. <span>“Interpersonal
Synchronization During Side by Side Treadmill Walking Is Influenced by
Leg Length Differential and Altered Sensory Feedback.”</span> <em>Human
Movement Science</em> 28 (6): 772–85. <a
href="https://doi.org/10.1016/j.humov.2009.04.007">https://doi.org/10.1016/j.humov.2009.04.007</a>.
</div>
<div id="ref-novembre:2013_motor" class="csl-entry" role="listitem">
Novembre, G., L. F. Ticini, S. Schutz-Bosbach, and P. E. Keller. 2014.
<span>“Motor Simulation and the Coordination of Self and Other in
Real-Time Joint Action.”</span> <em>Social Cognitive and Affective
Neuroscience</em> 9 (8): 1062–68. <a
href="https://doi.org/10.1093/scan/nst086">https://doi.org/10.1093/scan/nst086</a>.
</div>
<div id="ref-pacherie:2008_action" class="csl-entry" role="listitem">
Pacherie, Elisabeth. 2008. <span>“The Phenomenology of Action: A
Conceptual Framework.”</span> <em>Cognition</em> 107 (1): 179–217. <a
href="https://doi.org/10.1016/j.cognition.2007.09.003">https://doi.org/10.1016/j.cognition.2007.09.003</a>.
</div>
<div id="ref-pietroski_actions_1998" class="csl-entry" role="listitem">
Pietroski, Paul M. 1998. <span>“Actions, Adjuncts, and Agency.”</span>
<em>Mind</em>, New series, 107 (425): 73–111. <a
href="http://www.jstor.org/stable/2659808">http://www.jstor.org/stable/2659808</a>.
</div>
<div id="ref-prinz:1997_perception" class="csl-entry" role="listitem">
Prinz, Wolfgang. 1997. <span>“Perception and Action Planning.”</span>
<em>European Journal of Cognitive Psychology</em> 9 (2): 129–54. <a
href="https://doi.org/10.1080/713752551">https://doi.org/10.1080/713752551</a>.
</div>
<div id="ref-ramenzoni:2014_scaling" class="csl-entry" role="listitem">
Ramenzoni, Verónica C., Natalie Sebanz, and Günther Knoblich. 2014.
<span>“Scaling up Perception<span></span>action Links: Evidence from
Synchronization with Individual and Joint Action.”</span> <em>Journal of
Experimental Psychology: Human Perception and Performance</em> 40 (4):
1551–65. <a
href="https://doi.org/10.1037/a0036925">https://doi.org/10.1037/a0036925</a>.
</div>
<div id="ref-repp:2000_compensation" class="csl-entry" role="listitem">
Repp, Bruno H. 2000. <span>“Compensation for Subliminal Timing
Perturbations in Perceptual-Motor Synchronization.”</span>
<em>Psychological Research</em> 63 (2): 106–28. <a
href="https://doi.org/10.1007/PL00008170">https://doi.org/10.1007/PL00008170</a>.
</div>
<div id="ref-repp:2005_sensorimotor" class="csl-entry" role="listitem">
———. 2005. <span>“Sensorimotor Synchronization: A Review of the Tapping
Literature.”</span> <em>Psychonomic Bulletin &amp; Review</em> 12 (6):
969–92. <a
href="https://doi.org/10.3758/BF03206433">https://doi.org/10.3758/BF03206433</a>.
</div>
<div id="ref-repp:2008_sensorimotor" class="csl-entry" role="listitem">
Repp, Bruno H., and Peter E. Keller. 2008. <span>“Sensorimotor
Synchronization with Adaptively Timed Sequences.”</span> <em>Human
Movement Science</em> 27 (3): 423–56. <a
href="https://doi.org/10.1016/j.humov.2008.02.016">https://doi.org/10.1016/j.humov.2008.02.016</a>.
</div>
<div id="ref-repp:2007_action" class="csl-entry" role="listitem">
Repp, Bruno H., and Günther Knoblich. 2007. <span>“Action Can Affect
Auditory Perception.”</span> <em>Psychological Science</em> 18 (1): 6–7.
<a
href="https://doi.org/10.1111/j.1467-9280.2007.01839.x">https://doi.org/10.1111/j.1467-9280.2007.01839.x</a>.
</div>
<div id="ref-repp:2009_performed" class="csl-entry" role="listitem">
———. 2009. <span>“Performed or Observed Keyboard Actions Affect
Pianists’ Judgements of Relative Pitch.”</span> <em>The Quarterly
Journal of Experimental Psychology</em> 62 (11): 2156–70. <a
href="https://doi.org/10.1080/17470210902745009">https://doi.org/10.1080/17470210902745009</a>.
</div>
<div id="ref-repp:2013_sensorimotor" class="csl-entry" role="listitem">
Repp, Bruno H., and Yi-Huang Su. 2013. <span>“Sensorimotor
Synchronization: A Review of Recent Research
(2006<span></span>2012).”</span> <em>Psychonomic Bulletin &amp;
Review</em> 20 (3): 403–52. <a
href="https://doi.org/10.3758/s13423-012-0371-2">https://doi.org/10.3758/s13423-012-0371-2</a>.
</div>
<div id="ref-richardson_looking_2005" class="csl-entry" role="listitem">
Richardson, Daniel C., and Rick Dale. 2005. <span>“Looking to
Understand: The Coupling Between Speakers’ and Listeners’ Eye Movements
and Its Relationship to Discourse Comprehension.”</span> <em>Cognitive
Science</em> 29 (6): 1045–60. <a
href="https://doi.org/10.1207/s15516709cog0000_29">https://doi.org/10.1207/s15516709cog0000_29</a>.
</div>
<div id="ref-richardson:2007_art" class="csl-entry" role="listitem">
Richardson, Daniel C., Rick Dale, and Natasha Z. Kirkham. 2007.
<span>“The Art of Conversation Is Coordination Common Ground and the
Coupling of Eye Movements During Dialogue.”</span> <em>Psychological
Science</em> 18 (5): 407–13. <a
href="https://doi.org/10.1111/j.1467-9280.2007.01914.x">https://doi.org/10.1111/j.1467-9280.2007.01914.x</a>.
</div>
<div id="ref-richardson:2008_synchrony" class="csl-entry"
role="listitem">
Richardson, Daniel, Rick Dale &amp; Schockley, and Kevin. 2008.
<span>“Synchrony and Swing in Conversation: Coordination, Temporal
Dynamics and Communication.”</span> In <em>Embodied Communication in
Humans and Machines</em>, edited by Ipke Wachsmuth, Manuela Lenzen, and
Günther Knoblich. Oup Oxford.
</div>
<div id="ref-richardson:2005_effects" class="csl-entry" role="listitem">
Richardson, Michael J., Kerry L. Marsh, and Richard C. Schmidt. 2005.
<span>“Effects of Visual and Verbal Interaction on Unintentional
Interpersonal Coordination.”</span> <em>Journal of Experimental
Psychology: Human Perception and Performance</em> 31 (1): 62–79. <a
href="https://doi.org/10.1037/0096-1523.31.1.62">https://doi.org/10.1037/0096-1523.31.1.62</a>.
</div>
<div id="ref-richardson_judging_2007" class="csl-entry" role="listitem">
Richardson, Michael J, Kerry L Marsh, and Reuben M Baron. 2007.
<span>“Judging and Actualizing Intrapersonal and Interpersonal
Affordances.”</span> <em>Journal of Experimental Psychology: Human
Perception and Performance. Vol. 33(4)</em> 33 (4): 845–59.
</div>
<div id="ref-rizzolatti_functional_2010" class="csl-entry"
role="listitem">
Rizzolatti, Giacomo, and Corrado Sinigaglia. 2010. <span>“The Functional
Role of the Parieto-Frontal Mirror Circuit: Interpretations and
Misinterpretations.”</span> <em>Nature Reviews: Neuroscience</em> 11
(4): 264–74. <a
href="https://doi.org/10.1038/nrn2805">https://doi.org/10.1038/nrn2805</a>.
</div>
<div id="ref-rosenbaum:2010_human" class="csl-entry" role="listitem">
Rosenbaum, David A. 2009. <em>Human Motor Control</em>. 2nd ed. San
Diego, <span>CA</span>, <span>US</span>: Academic Press.
</div>
<div id="ref-Rotman:2006xf" class="csl-entry" role="listitem">
Rotman, Gerben, Nikolaus F. Troje, Roland S. Johansson, and J. Randall
Flanagan. 2006. <span>“Eye Movements When Observing Predictable and
Unpredictable Actions.”</span> <em>J Neurophysiol</em> 96 (3): 1358–69.
</div>
<div id="ref-schulze:2005_keeping" class="csl-entry" role="listitem">
Schulze, Hans-Henning, Andreas Cordes, and Dirk Vorberg. 2005.
<span>“Keeping Synchrony While Tempo Changes: Accelerando and
Ritardando.”</span> <em>Music Perception: An Interdisciplinary
Journal</em> 22 (3): 461–77. <a
href="http://www.jstor.org/stable/10.1525/mp.2005.22.3.461">http://www.jstor.org/stable/10.1525/mp.2005.22.3.461</a>.
</div>
<div id="ref-Sebanz:2006yq" class="csl-entry" role="listitem">
Sebanz, Natalie, Harold Bekkering, and Günther Knoblich. 2006.
<span>“Joint Action: Bodies and Mind Moving Together.”</span> <em>Trends
in Cognitive Sciences</em> 10 (2): 70–76.
</div>
<div id="ref-Sebanz:2005fk" class="csl-entry" role="listitem">
Sebanz, Natalie, Günther Knoblich, and W. Prinz. 2005. <span>“How Two
Share a Task: Corepresenting Stimulus-Response Mappings.”</span>
<em>Journal of Experimental Psychology: Human Perception and
Performance</em> 31 (6): 1234–46. <a
href="https://doi.org/10.1037/0096-1523.31.6.1234">https://doi.org/10.1037/0096-1523.31.6.1234</a>.
</div>
<div id="ref-sebanz:2006_twin_peaks" class="csl-entry" role="listitem">
Sebanz, Natalie, Günther Knoblich, Wolfgang Prinz, and Edmund Wascher.
2006. <span>“Twin Peaks: An <span>ERP</span> Study of Action Planning
and Control in Coacting Individuals.”</span> <em>Journal of Cognitive
Neuroscience</em> 18 (5): 859–70. <a
href="https://doi.org/10.1162/jocn.2006.18.5.859">https://doi.org/10.1162/jocn.2006.18.5.859</a>.
</div>
<div id="ref-shockley:2009_conversation" class="csl-entry"
role="listitem">
Shockley, Kevin, Daniel C. Richardson, and Rick Dale. 2009.
<span>“Conversation and Coordinative Structures.”</span> <em>Topics in
Cognitive Science</em> 1 (2): 305–19. <a
href="https://doi.org/10.1111/j.1756-8765.2009.01021.x">https://doi.org/10.1111/j.1756-8765.2009.01021.x</a>.
</div>
<div id="ref-shockley:2003_mutual" class="csl-entry" role="listitem">
Shockley, Kevin, Marie-Vee Santana, and Carol A. Fowler. 2003.
<span>“Mutual Interpersonal Postural Constraints Are Involved in
Cooperative Conversation.”</span> <em>Journal of Experimental
Psychology: Human Perception and Performance</em> 29 (2): 326–32. <a
href="https://doi.org/10.1037/0096-1523.29.2.326">https://doi.org/10.1037/0096-1523.29.2.326</a>.
</div>
<div id="ref-sinigaglia:2015_puzzle" class="csl-entry" role="listitem">
Sinigaglia, Corrado, and Stephen A. Butterfill. 2015. <span>“On a Puzzle
about Relations Between Thought, Experience and the Motoric.”</span>
<em>Synthese</em> 192 (6): 1923–36. <a
href="https://doi.org/10.1007/s11229-015-0672-x">https://doi.org/10.1007/s11229-015-0672-x</a>.
</div>
<div id="ref-tsai:2008_action" class="csl-entry" role="listitem">
Tsai, Chia-Chin, Wen-Jui Kuo, Daisy L. Hung, and Ovid J. L. Tzeng. 2008.
<span>“Action Co-Representation Is Tuned to Other Humans.”</span>
<em>Journal of Cognitive Neuroscience</em> 20 (11): 2015–24. <a
href="https://doi.org/10.1162/jocn.2008.20144">https://doi.org/10.1162/jocn.2008.20144</a>.
</div>
<div id="ref-tsai:2011_groop_effect" class="csl-entry" role="listitem">
Tsai, Jessica Chia-Chin, Natalie Sebanz, and Günther Knoblich. 2011.
<span>“The <span>GROOP</span> Effect: Groups Mimic Group
Actions.”</span> <em>Cognition</em> 118 (1): 135–40. <a
href="https://doi.org/10.1016/j.cognition.2010.10.007">https://doi.org/10.1016/j.cognition.2010.10.007</a>.
</div>
<div id="ref-vanulzen:2008_characteristics" class="csl-entry"
role="listitem">
Ulzen, Niek R. van, Claudine J. C. Lamoth, Andreas Daffertshofer, Gün R.
Semin, and Peter J. Beek. 2008. <span>“Characteristics of Instructed and
Uninstructed Interpersonal Coordination While Walking
Side-by-Side.”</span> <em>Neuroscience Letters</em> 432 (2): 88–93. <a
href="https://doi.org/10.1016/j.neulet.2007.11.070">https://doi.org/10.1016/j.neulet.2007.11.070</a>.
</div>
<div id="ref-varlet:2015_informational" class="csl-entry"
role="listitem">
Varlet, Manuel, Colleen Bucci, Michael J. Richardson, and Richard C.
Schmidt. 2015. <span>“Informational Constraints on Spontaneous
Visuomotor Entrainment.”</span> <em>Human Movement Science</em> 41:
265–81. <a
href="https://doi.org/10.1016/j.humov.2015.03.011">https://doi.org/10.1016/j.humov.2015.03.011</a>.
</div>
<div id="ref-vesper_minimal_2010" class="csl-entry" role="listitem">
Vesper, Cordula, Stephen Butterfill, Günther Knoblich, and Natalie
Sebanz. 2010. <span>“A Minimal Architecture for Joint Action.”</span>
<em>Neural Networks</em> 23 (8-9): 998–1003. <a
href="https://doi.org/10.1016/j.neunet.2010.06.002">https://doi.org/10.1016/j.neunet.2010.06.002</a>.
</div>
<div id="ref-vesper:2012_jumping" class="csl-entry" role="listitem">
Vesper, Cordula, Robrecht P. R. D. van der Wel, Günther Knoblich, and
Natalie Sebanz. 2013. <span>“Are You Ready to Jump? Predictive
Mechanisms in Interpersonal Coordination.”</span> <em>Journal of
Experimental Psychology: Human Perception and Performance</em> 39 (1):
48–61. <a
href="https://doi.org/10.1037/a0028066">https://doi.org/10.1037/a0028066</a>.
</div>
<div id="ref-wel:2015_entrainment" class="csl-entry" role="listitem">
Wel, Robrecht P. R. D. van der, and En Fu. 2015. <span>“Entrainment and
Task Co-Representation Effects for Discrete and Continuous Action
Sequences.”</span> <em>Psychonomic Bulletin &amp; Review</em>, 1–7. <a
href="https://doi.org/10.3758/s13423-015-0831-6">https://doi.org/10.3758/s13423-015-0831-6</a>.
</div>
<div id="ref-wenke:2011_what" class="csl-entry" role="listitem">
Wenke, Dorit, Silke Atmaca, Antje Holländer, Roman Liepelt, Pamela
Baess, and Wolfgang Prinz. 2011. <span>“What Is Shared in Joint Action?
Issues of Co-Representation, Response Conflict, and Agent
Identification.”</span> <em>Review of Philosophy and Psychology</em> 2
(2): 147–72. <a
href="https://doi.org/10.1007/s13164-011-0057-0">https://doi.org/10.1007/s13164-011-0057-0</a>.
</div>
<div id="ref-Wilson:2005qu" class="csl-entry" role="listitem">
Wilson, Margaret, and Günther Knoblich. 2005. <span>“The Case for Motor
Involvement in Perceiving Conspecifics.”</span> <em>Psychological
Bulletin</em> 131 (3): 460–73.
</div>
<div id="ref-Wolpert:2003mg" class="csl-entry" role="listitem">
Wolpert, Daniel M., Kenji Doya, and Mitsuo Kawato. 2003. <span>“A
Unifying Computational Framework for Motor Control and Social
Interaction.”</span> <em>Philosophical Transactions: Biological
Sciences</em> 358 (1431): 593–602. <a
href="http://www.jstor.org/stable/3558137">http://www.jstor.org/stable/3558137</a>.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Events <span
class="math inline"><em>D</em><sub>1</sub></span>, ... <span
class="math inline"><em>D</em><sub><em>n</em></sub></span>
<em>ground</em> <span class="math inline"><em>E</em></span> just if:
<span class="math inline"><em>D</em><sub>1</sub></span>, ... <span
class="math inline"><em>D</em><sub><em>n</em></sub></span> and <span
class="math inline"><em>E</em></span> occur; <span
class="math inline"><em>D</em><sub>1</sub></span>, ... <span
class="math inline"><em>D</em><sub><em>n</em></sub></span> are each part
of <span class="math inline"><em>E</em></span>; and every event that is
a part of <span class="math inline"><em>E</em></span> but does not
overlap <span class="math inline"><em>D</em><sub>1</sub></span>,
... <span class="math inline"><em>D</em><sub><em>n</em></sub></span> is
caused by some or all of <span
class="math inline"><em>D</em><sub>1</sub></span>, ... <span
class="math inline"><em>D</em><sub><em>n</em></sub></span>. (This is a
generalisation of the notion specified by <span class="citation"
data-cites="pietroski_actions_1998">(Pietroski 1998)</span>.)<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Note that what follows is neutral on whether joint
actions are actions. As a terminological stipulation, I shall say that
an individual is an <em>agent of a joint action</em> just if she is an
agent of an action which, together with some other events, grounds this
joint action. (Depending on your views about events, causation and
agents, getting some edge cases right may require adding that for this
individual to be an agent of this joint action, this particular
plurality of grounding events—her action and the other events—must
include actions with agents other than her.)<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>See <span class="citation"
data-cites="schulze:2005_keeping">Schulze, Cordes, and Vorberg (2005,
474–76)</span>. <span class="citation"
data-cites="keller:2014_rhythm">Keller, Novembre, and Hove (2014)</span>
suggest, further, that the two kinds of adjustment involve different
brain networks. Note that this view is currently controversial: <span
class="citation" data-cites="loehr:2011_temporal">Janeen D. Loehr and
Palmer (2011)</span> could be interpreted as providing evidence for a
different account of how entrainment is maintained.<a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>See, for example, <span class="citation"
data-cites="richardson_looking_2005">D. C. Richardson and Dale
(2005)</span>. For relatively speculative discussions, see <span
class="citation"
data-cites="richardson:2008_synchrony merker:2009_role keller:2014_rhythm">D.
Richardson, Schockley, and Kevin (2008; Merker, Madison, and Eckerdal
2009; Keller, Novembre, and Hove 2014, sec. 4)</span>.<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><span class="citation"
data-cites="Gangitano:2001ft">Gangitano, Mottaghy, and Pascual-Leone
(2001)</span>; see further <span class="citation"
data-cites="Fadiga:2005gq ambrosini:2012_tie">Fadiga, Craighero, and
Olivier (2005; Ambrosini, Sinigaglia, and Costantini 2012)</span>. For a
review of evidence that, when observing an action, motor processes and
representations occur in the observer like those which would occur if
she were performing an action of the kind observed rather than merely
observing it, see <span class="citation"
data-cites="rizzolatti_functional_2010">Rizzolatti and Sinigaglia
(2010)</span>.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>For evidence that motor simulation also enables
coordination in musical performances, see <span class="citation"
data-cites="keller:2007_pianists loehr:2011_temporal novembre:2013_motor">Keller,
Knoblich, and Repp (2007; Janeen D. Loehr and Palmer 2011; Novembre et
al. 2014)</span>. <span id="fn:pianist-motor"
data-label="fn:pianist-motor"></span> For evidence on development, see
<span class="citation" data-cites="meyer:2011_joint">Meyer et al.
(2011)</span>’s investigation of motor processes and coordination in
three-year-old children.<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>For more detailed arguments that some motor
representations are goal-states, see <span class="citation"
data-cites="prinz:1997_perception">Prinz (1997, 143–46)</span>, <span
class="citation" data-cites="pacherie:2008_action">Pacherie
(2008)</span> and <span class="citation"
data-cites="butterfill:2012_intention">Butterfill and Sinigaglia
(2014)</span>.<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>This definition needs refining in various ways not
directly relevant to the present discussion.<a href="#fnref8"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><span class="citation"
data-cites="wenke:2011_what">Wenke et al. (2011)</span> and <span
class="citation" data-cites="dolk:2011_how dolk:2014_joint">Dolk et al.
(2011, 2014)</span> have defended hypotheses which, if true, would
enable some of the evidence for these predictions to be explained
without accepting the task co-representation hypothesis.<a
href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>The insects’ behaviours cannot be regarded as directed
to raising a brood just in virtue of each individual insect behaviour
being so directed because there is (typically, at least) a division of
labour.<a href="#fnref10" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>Note that, despite the name, planned coordination does
not by definition involve planning.<a href="#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>Some forms of entrainment are probably a hybrid of
emergent and planned coordination since, as we saw in <a
href="#sec:entrainment" data-reference-type="ref+label"
data-reference="sec:entrainment">3</a>, the precision with which
entrained actions are synchronised can be influenced by the agents’
intentions concerning coordination and therefore probably also by
collective goal-states.<a href="#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>Further evidence for motor representations of
collective goals is provided by <span class="citation"
data-cites="tsai:2011_groop_effect ramenzoni:2014_scaling Menoret:2013fk">J.
C.-C. Tsai, Sebanz, and Knoblich (2011; Ramenzoni, Sebanz, and Knoblich
2014; Ménoret et al. 2014)</span> and <span class="citation"
data-cites="meyer:2013_higher-order">Meyer, Wel, and Hunnius
(2013)</span>.<a href="#fnref13" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>The notion of a collective goal was introduced in <a
href="#sec:emergent-vs-planned" data-reference-type="ref+label"
data-reference="sec:emergent-vs-planned">7</a>; evidence for the
existence of motor representations of collective goals was discussed in
<a href="#sec:collective-goal-states" data-reference-type="ref+label"
data-reference="sec:collective-goal-states">8</a>.<a href="#fnref14"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>See <span class="citation"
data-cites="richardson_judging_2007">Michael J. Richardson, Marsh, and
Baron (2007)</span> for a further study involving jointly lifting
planks.<a href="#fnref15" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>This is not a comprehensive list. Relevant reviews
include <span class="citation"
data-cites="Knoblich:2010fk keller:2014_rhythm marsh_social_2009">Knoblich,
Butterfill, and Sebanz (2011; Keller, Novembre, and Hove 2014; Marsh,
Richardson, and Schmidt 2009)</span>.<a href="#fnref16"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>ACKNOWLEDGMENTS. I have benefitted immeasurably from
extended collaborations with Natalie Sebanz, Guenther Knoblich and
Corrado Sinigaglia as well as from shorter (so far) collaborations with
Cordula Vesper and Lincoln Colling. I am also indebted to many people
for discussion. Thank you!</p>
<p>BIOGRAPHICAL NOTE. Stephen Butterfill researches and teaches on joint
action, mindreading and other philosophical issues in cognitive science
at the University of Warwick (UK).<a href="#fnref17"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</div>

---

Title: What Mindreading Reveals about the Mental Lives of Machines
Authors: Butterfill, Stephen A.
Year: 2024
Type: Publication



---

Title: Three strategies for shared intention: plural, aggregate and reductive
Authors: Butterfill, Stephen A.
Year: 2025
Journal: Philosophical Psychology
Type: Publication

<div class="fulltext">


<h1 id="sec:abstract">Abstract</h1>
<div class="abstract">
When deciding on a strategy for explicating shared intention, we all face two fundamental questions. First, can an intention or any other mental state have more than one subject? A positive answer to this allows the plural subject strategy: shared intention is a matter of there being one mental state with two or more subjects. Mental states are shared in the same sense that siblings share a parent; no simpler view exists. A negative answer blocks the plural subject strategy. This motivates asking the second fundamental question. Are there aggregate subjects and, if so, can they have intentions? The aggregate strategy depends on a positive answer to this question: the idea is that shared intention is a matter of there being aggregate subjects of mental states, that is subjects of mental states with proper parts that include subjects of mental states. By contrast, a negative answer to this question limits us to the reductive strategy: shared intention is a structure of ordinary, individual subjects’ emotions, intentions and other mental states. I contribute a limited review of the three strategies. I also defend a novel thesis. Whereas these strategies are often presented as conflicting attempts to characterise a single set of phenomena, my thesis is that for each strategy there are phenomena which can be correctly characterised only by following that strategy. Instead of attempting to one true strategy, we may need to seek ways to combine insights from different strategies.
</div>

<h1 id="sec:introduction">Introduction</h1>
<p>Start with the idea that shared intention, whatever that is, is
something which makes things we do together the genuinely joint
activities they are. We manifest shared intention in walking together,
playing a piano duet, or painting a house together. Philosophers, in
attempting to elucidate ideas about shared intention, have followed
three distinct strategies. One involves plural subjects, one aggregate
subjects,<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> and one a reduction of the
apparently plural or aggregate to the merely individual.<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>
Whereas these strategies are usually presented as conflicting attempts
to characterise a single set of phenomena, my thesis is that for each
strategy there are phenomena which can be correctly characterised only
by following that strategy.</p>
<p>This thesis is not entirely novel. Both <span class="citation"
data-cites="list_pettit:2011">List and Pettit (2011)</span> and <span
class="citation" data-cites="bratman:2022_shared">Bratman
(2022a)</span>, for instance, have developed views on which, roughly
speaking, a reductive strategy is applied to small-scale, informal
interactions whereas the aggregate strategy is applied to corporate or
institutional agents.<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a> My thesis is that, similarly, a
combination of strategies may be needed even when restricting attention
to small-scale interactions involving two or three people.</p>
<p>What consequences would follow from this thesis if true—if, that is,
each of the three strategies is needed to characterise some phenomena
associated with shared intention? This would make things easier in one
way: it is not necessary for proponents of one strategy to refute the
theories invented by those following a different strategy. This would be
a good outcome because, despite much effort, few if any existing
attempts to refute particular theories of shared intention are widely
regarded as successful. But it would also make things harder in another
way. For if there is not one set of things that the different theories
are aiming to fully capture, then it will not be possible to specify the
target of a theory simply by reference to shared intention. We will need
a deeper understanding of what each particular theory is aiming to
explain.</p>
<p>Superficially, the need for a deeper understanding of targets of
explanation might not seem like much of a challenge. After all, we
already know that some theorists primarily target semantics <span
class="citation" data-cites="ludwig_collective_2007">(Ludwig
2007)</span>, others ‘the deep structure of our thought about acting
together’ <span class="citation"
data-cites="gilbert:2022_simple">(Gilbert 2022, 2)</span>, and yet
others ‘the explanatory structures that directly underlie [...] cases of
acting together’ <span class="citation"
data-cites="bratman:2022_planning">(Bratman 2022b, 7)</span>. There are,
then, already things written about what theories of shared intention aim
to explain. Yet little attention has been given to the possibility of
co-existence. The usual assumption is that the various strategies lead
to theories which do contradict each other; or else, more rarely, that
multiple strategies can be combined in pursuit of a single explanatory
target.</p>
<p>We already know that it is coherent to pursue a combination of
strategies because some have already done this. <span class="citation"
data-cites="bratman:2014_book">Bratman (2014, 127ff)</span>, for
example, considers the possibility that his reductive strategy yields a
theory on which there are also what he calls ‘group agents’ (for which I
shall use the term ‘aggregate agents’; see section <a
href="#sec:aggregate" data-reference-type="ref"
data-reference="sec:aggregate">5</a>). This is a relatively conservative
way of combining strategies. Not only is there a single explanatory
target, but the group agents are merely epiphenomena of the reductive
strategy. The novel feature of what follows is the observation that
different explanatory targets require different strategies, which, as we
will see, appears to create a challenge to understanding
co-existence.</p>
<p>If, as the following argues, multiple different strategies for shared
intention really are needed, then we all face a problem. The problem is
that we, as researchers, need, but lack, a common understanding of what
theories of shared intention are theories of.</p>
<h1 id="sec:live-it-out">Living Out a Theory</h1>
<p>My thesis is that, for each strategy for explicating shared
intention, there are phenomena which can be correctly characterised only
by following that strategy. The argument for this thesis (in section <a
href="#sec:multiple-strategies" data-reference-type="ref"
data-reference="sec:multiple-strategies">8</a>) will hinge on the idea
that it is possible, in some cases, to make a theory true by living it
out. To avoid surprises later, this section introduces that idea.</p>
<p>While laws of mechanics apply no less to us agents than to anything
else, it would usually be futile, perhaps even incoherent, to attempt to
move according to these laws. By contrast, one of the roles of mental
state attribution is to provide norms which individuals can measure
themselves against and aim to live by <span class="citation"
data-cites="mcgeer:2007_regulative zawidzki:2013_mindshaping">(McGeer
2007; Zawidzki 2013)</span>.</p>
<p>To illustrate, consider the norm of agglomeration: it is a mistake to
knowingly have several intentions if it would be a mistake to knowingly
have one large intention agglomerating the several intentions (<span
class="citation" data-cites="Bratman:1987xw">(Bratman 1987)</span>).
Whether this is actually a mistake is controversial—several philosophers
have defended views of intention which are incompatible with it <span
class="citation" data-cites="setiya:2022_intention">(Setiya 2022, sec.
4)</span>. But regardless of that, it is possible some people might,
however mistakenly, take agglomeration as an ideal by which to live.
They check their intentions against the norm and criticise each other
for failing to implement it. It is equally possible that another group
of people, having considered the matter deeply, intentionally disregard
the norm of agglomeration. In their view, adhering to this norm would be
a mistake.</p>
<p>The possibility that some ordinary agents might adopt or reject the
norm of agglomeration in practice raises a question. Are ordinary
agents’ views ever relevant to whether the norm is correct? Imagine we
were to say, crudely, that whether the norm holds is just a matter of
whether people take it to hold. Such a view faces myriad challenges. One
is to accommodate the fact that ordinary agents are wrong about norms,
at least occasionally (as the present author can attest). Another
challenge is to avoid a regress. This is not a line I propose to
develop. Alternatively, one might take a hard line and insist that
ordinary agents’ views are irrelevant to whether the norm of
agglomeration holds. Taking this line is complicated by the fact that
ordinary agents’ views shape at least some of their thoughts and
actions. Their views are not idle speculations about themselves but can
form ideals which they attempt to live out. Someone who takes the hard
line cannot therefore claim to be explaining how ordinary agents think
or act. Minimally, then, anyone pursuing this line would have to
identify which phenomena their position is supposed to explain. A
further challenge is that philosophers’ methods involve intuition,
imagination and reasoning about consistency. These methods are good for
identifying possible ways things could be. But where there are multiple
theoretically coherent positions on which fully-informed ordinary agents
reasonably differ, these methods are not likely to yield insight into
how things actually are.</p>
<p>Resolving the issue of how, if at all, ordinary agents’ views are
relevant to the correctness of the norm of agglomeration is beyond
anything I can offer here (or anywhere else). But for our purposes, what
matters is a relatively uncontroversial point. There is a difference
between, on the one hand, things which are merely described and
predicted by a set of attributions and, on the other hand, agents who
are attempting to live out a set of attributions together with some
norms governing them. You might have a view about how combinations of
yeast, sugar and heat can be used to influence how dough rises, but the
dough itself has no perspective. And even if the dough achieved
self-awareness, that would matter only insofar as its self-awareness
influenced variables you care about. When ascribing attitudes and norms
to agents, by contrast, philosophers are not required to adopt the
outsiders’ perspective—they can also take into account the agents’ own
perspective.</p>
<p>Characterising intentions and norms from some agents’ own perspective
is a familiar and coherent philosophical project. Where some agents are
attempting to live out a theory, it is reasonable to accept, in the
absence of overriding reasons such as incoherence, ignorance or
inertness, that the theory could be true of them.</p>
<p>Perhaps this will seem too hypothetical to be worth taking seriously.
We have no idea which, if any, ordinary agents aim to live by the norm
of agglomeration and which, if any, aim not to. My sense, however, is
that philosophical theories are not supposed to depend on any such
facts. They are, after all, usually developed independently of any
investigation into what ordinary agents think.<a href="#fn4"
class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>Not that it has to be hypothetical. Consider the familiar distinction
between revealed and stated preferences. To illustrate, in investigating
the value people place on a life, we could observe how much less people
pay to own a house near a known source of carcinogenic pollution. Or,
alternatively, we could give them a questionnaire asking how much they
would pay to eliminate the same risk. A wide range of research has
examined how revealed and stated preferences diverge (<span
class="citation"
data-cites="carson:1996_contingent alberini:2019_revealed">(Carson et
al. 1996; Alberini 2019)</span>, for example). There is also research on
the factors that ‘often create a wedge between revealed and normative
preferences’ <span class="citation"
data-cites="beshears:2008_how">(Beshears et al. 2008, 1788)</span>.
Divergences between revealed and stated preferences matter in practice
because they create difficult questions for policy makers on how much to
invest in preventing deaths. For our, more theoretical purposes, the
divergence illustrates how understanding agents’ actions requires taking
into account their own perspectives. Agents’ stated preferences are
views about how a model applies to them. Because agents sometimes aim to
live out these views, they are not inert commentary. The problem is not
fundamentally that this complicates predicting behaviour. It is that
where agents aim to conform to a model, incorrect predictions do not
have the same significance.</p>
<p>The distinction between revealed and stated preferences illustrates
the dual role of theories of attitudes and norms, in prediction and in
offering ideals which people can attempt to live out. There is a
difference between, on the one hand, things which are merely described
and predicted by a set of attributions and, on the other hand, agents
who are are attempting to live out a set of attributions together with
some laws governing them. In the latter case, the agents’ aiming to live
out a theory is a reason not to reject that theory insofar our aims
include understanding the agents’ own perspective.</p>
<p>The argument that follows is an attempt to apply this general point
to philosophical theories of shared intention. My aim is to show that
for each of the three strategies for shared intention—plural, aggregate
and reductive—there is at least one consistent theory following this
strategy which it is possible for people to intentionally live out. This
thesis is probably either too odd or too obvious to be interesting in
its own right, but I will suggest that it has consequences which
complicate existing attempts to understand shared intention. As these
consequences depend on the aims of a theory of shared intention, I start
with the aims.</p>
<h1 id="sec:background">Background on Shared Intention</h1>
<p>Why do we need a notion of shared intention at all? Because it is
what distinguishes genuinely joint activities from things people do in
parallel but merely individually <span class="citation"
data-cites="gilbert_walking_1990 bratman:2022_planning">(Gilbert 1990;
Bratman 2022b)</span>. This is, of course, at most a partial answer. The
hope is that investigating a notion such as shared intention will enable
us, eventually, to ‘discover the nature of social groups in general’
<span class="citation" data-cites="gilbert_walking_1990">(Gilbert 1990,
2)</span> and to understand the conceptual, metaphysical and normative
aspects of basic forms of sociality <span class="citation"
data-cites="bratman:2014_book">(Bratman 2014, 3)</span>. But one route
to these lofty goals is to focus on distinguishing genuinely joint from
merely parallel activities in mundane cases involving two or three
people.</p>
<p>Ayesha and Ahmed have spent the morning in the kitchen washing the
dishes together. This is a paradigm case of joint activity. We can
contrast Ayesha and Ahmed’s activities with those of two anti-social
people who act in parallel but merely individually. The idea is that
these other, anti-social people wash the dishes side-by-side, but their
actions are merely performed in parallel and so do not involve any joint
activity. What distinguishes Ayesha and Ahmed’s activities from these
other people’s?</p>
<p>A temptingly simple idea is to appeal to coordination. Could Ayesha
and Ahmed’s activities be distinguished by virtue of being coordinated?
The obstacle is that acting in parallel can also involve coordination.
The actions of the other, anti-social people, who are merely acting in
parallel, may nevertheless need to be tightly coordinated because space
in their communal kitchen is limited. They may also politely anticipate
each other’s movements and work around them. Mere coordination, then,
cannot distinguish joint activity.</p>
<p>The failure of this and other simple ideas hints that distinguishing
joint activities from their parallel but merely individual counterparts
is a deep and difficult problem. This problem is a variant of one about
ordinary, individual action. The ‘Problem of Action’ is to distinguish a
person’s actions from things that merely happen to them <span
class="citation" data-cites="frankfurt1978problem">(Frankfurt
1978)</span>. If ordinary, individual intention is key to solving that
problem, perhaps some joint counterpart of intention is the key to
solving the problem of joint action. This motivates using the term
<em>shared intention</em> to label whatever the normative or
psychological structure is needed to distinguish joint activities from
things people do in parallel but merely individually.</p>
<p>Introducing a label for the problem does not take us very far towards
a solution. The problem now becomes to say what shared intention is. One
possibility is the plural subject strategy: shared intention is a matter
of there being one mental state with two or more subjects.</p>
<h1 id="sec:plural">The Plural Subject Strategy</h1>
<p>A plural subject is two or more people who are each among the
subjects of a single intention or other mental state.</p>
<p>The difficulty of understanding the plural subject strategy is mainly
that it is so simple. Intentions and other mental states involve
subjects, attitudes and contents. The content is what distinguishes two
intentions from each other—the intention to cook dinner from the
intention to go for a walk, say, differ in content. Attitude is what
distinguishes intentions from other mental states—the intention to go
for a walk differs in attitude from the desire to go for a walk. And the
subject is what distinguishes your mental states from mine. The idea of
the plural subject strategy is just that intentions can have more than
one subject. You and I can share an intention in the same sense that
siblings share a parent. Your intention to walk may also be my intention
to walk: you and I are equally subjects of this intention.</p>
<p>It is helpful, in thinking about the contrast between individual and
plural subjects, to draw on a related distinction between distributive
and collective interpretations of sentences. Consider these
sentences:</p>
<ol>
<li><p>The fans left the stadium.</p></li>
<li><p>The fans completely blocked the road. <span
id="item:fans-blocking" label="item:fans-blocking"></span></p></li>
</ol>
<p>The first sentence is naturally read distributively: it is a matter
of each fan individually leaving. But the second sentence is naturally
read collectively. As the road is very wide, not even the largest
individual fan did much at all to block the road. But because so many
fans were milling around in the road, it was impossible to traverse it.
So understood, the second sentence’s truth is not, or not only, a matter
of each fan individually blocking the road. This is a collective
reading. The distinction seems applicable to sentences about
intention:</p>
<ol>
<li><p>The twins intended to win the race. <span
id="item:twins-intention" label="item:twins-intention"></span></p></li>
</ol>
<p>If we imagine a race that can only have one winner, a 100 meter
sprint, say, then it is natural to read this sentence distributively.
Its truth is just a matter of each twin intending to win the race. But
if we imagine the twins running in a three-legged race together, it
seems possible to read the sentence collectively. On this reading, there
is one intention whose subject is the twins. They are, to put it
colourfully, of one mind.</p>
<p>We can describe the twins as a <em>plural subject</em>. But note that
the plural subject is nothing other than the twins themselves. We must
avoid confusion on this point in order to distinguish plural subjects
from aggregate subjects, which are fundamentally different (more on this
in section <a href="#sec:aggregate" data-reference-type="ref"
data-reference="sec:aggregate">5</a>).</p>
<p>The plural subject strategy requires no novel conceptual,
metaphysical or normative ingredients over and above those already
required in a theory of ordinary, individual action—it can be
implemented in ways that respect Bratman’s continuity thesis. <a
href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a> Just as the truth of the collective
reading of (<a href="#item:fans-blocking" data-reference-type="ref"
data-reference="item:fans-blocking">[item:fans-blocking]</a>) () does
not require anything other than the fans to mill in the road, so the
truth of statements about intention collectively read requires nothing
other than intentions and their subjects.<a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>But are there really plural subjects of intention? One possibility is
that there merely seem to be, and are not actually, collective readings
of sentences about intentions like (<a href="#item:twins-intention"
data-reference-type="ref"
data-reference="item:twins-intention">[item:twins-intention]</a>) above.
There are a range of objections along these lines. Most extreme is the
claim that all apparently collective predication is really disguised
distributive predication. A more limited objection is that statements
about actions and intentions merely seem to have collective readings.
<span class="citation" data-cites="ludwig:2016_individual">Ludwig (2016,
chap. 9)</span> offers a detailed discussion along these lines. His
conclusion is carefully nuanced:</p>
<blockquote>
<p>‘we do not need to accept genuine plural [...] agents into our
ontology in order to accept what we say about [...] collective action,
at least insofar as we express this using plural subject terms.’ <span
class="citation" data-cites="ludwig:2016_individual">(Ludwig 2016,
168)</span></p>
</blockquote>
<p>Ludwig might be right that semantic considerations do not force us to
accept that plural subjects exist. Given his further premise that plural
subjects should be avoided if possible, this would be a compelling
argument against the existence of coherent collective readings. But,
importantly, Ludwig finds nothing forcing us to reject their existence
either. So as long as there is either no general presumption against
plural subjects or else sufficient reason to suppose that they are
necessary, it is not incoherent to imagine statements about intention
have true collective readings. Minimally, collective readings are a
helpful tool for clarifying what the plural subject strategy is.</p>
<p>But is it really coherent to suppose that intentions might have more
than one subject? One might object that to have an intention it is
necessary to have a mind; and that having a mind minimally involves
having a range of mental states, and perhaps even being self-aware. <a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> <span class="citation"
data-cites="Schmid:2013_self">Schmid (2013)</span>, who has perhaps the
best-developed version of the plural subject strategy, accepts this
constraint but argues that there are no good grounds for supposing that
it could not be met. Likewise, <span class="citation"
data-cites="helm_plural_2008">Helm (2008)</span> argues that there are
plural subjects with a range of ‘emotions and desires in the right sort
of rational structure’ <span class="citation"
data-cites="helm_plural_2008">(Helm 2008, 29)</span>. Of course this
would mean that plural subjects are unlikely to be involved in
spontaneous interactions between strangers, as when I am struggling to
propel my heavy push chair on to the bus and you helpfully seize the
front and we lift together. Plural subjects on views like Schmid’s or
Helm’s would require vastly more intimate, long-term connections between
individuals.</p>
<p>If we follow Schmid or Helm, it is possible to wonder how there could
be plural subjects. And the sense of mystery one might have about this
could, perhaps, motivate rejecting the entire strategy in favour of
apparently less mysterious alternatives. But this would be an error. Any
of the strategies can be developed in ways that will seem mysterious to
at least some philosophers. But one of my aims is to draw attention to
the existence of straightforward, nonmysterious ways of developing each
strategy.</p>
<p>An alternative, potentially less mysterious plural subject view might
be based on rejecting the claim that having an intention entails having
a range of mental states. This view could be inspired by reflection that
humans are prone to attribute mental states on the slightest of pretexts
to things which, as they know, lack not only minds but even physical
bodies <span class="citation" data-cites="Heider:1944ts">(Heider and
Simmel 1944)</span>.<a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a> Whether or not things cannot
actually have intentions without having minds, no such constraint
appears to apply to at least one significant strand of everyday
thinking. Perhaps, then, the plural subject strategy is needed for
capturing ways in which some people sometimes think.</p>
<p>We can take this one step further. Here is a way in which you and I
could become the plural subject of an intention. We each somehow become
convinced, however mistakenly, that you and I are the plural subjects of
an intention to cook dinner. This thought might influence our behaviour:
thinking, perhaps mistakenly, that having this intention means we are
subject to various norms, we might aim to act in ways that conform to
them. We are, by our lights, acting as if we had this intention. We
could also be taking for granted that we were plural subjects of a range
of other beliefs, desires and mental states, and perhaps explicitly
attributing some as our activity unfolds. And others, if they became
convinced, perhaps mistakenly, that we had this intention, might also
think and act accordingly. In this way, what began as merely a mistake
became real enough to shape the social world through being adopted as a
normative ideal.<a href="#fn9" class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a></p>
<p>In this section I have introduced the plural subject strategy and
offered a preliminary and superficial case for its theoretical
coherence. Following this strategy can lead to various quite different
theories. On some theories, the existence of plural subjects involves
long-term, intimate connections capable of supporting a shared mental
life. On other possible theories, plural subjects can be temporary
phenomena arising from the specific needs of a moment.</p>
<p>This falls short of showing that the plural subject strategy is
successful. For it to succeed, minimally there must be cases in which
the existence of plural subjects is actually what distinguishes joint
activities from things people do in parallel but merely individually.
(At least that is what one quite prominent approach requires, as we saw
in section <a href="#sec:background" data-reference-type="ref"
data-reference="sec:background">3</a>.) I have tried to indicate the
difficulties involved in showing that no such cases could exist. But of
course we have not seen positive grounds to suppose that there are now,
or have ever been, any intentions (or other mental states) which do have
plural subjects. Following the approach of section <a
href="#sec:live-it-out" data-reference-type="ref"
data-reference="sec:live-it-out">2</a>, the possibility that there is a
theoretically coherent plural subject theory which some people could aim
to live out is reason to accept that such a theory could capture an
aspect of shared intention.</p>
<p>For what it is worth, my own sense is that it would be quite hard to
establish, in practice, that a particular situation did involve a plural
subject, and that the difficulty of doing so may have been
underestimated. To illustrate, <span class="citation"
data-cites="Schmid:2008">Schmid (2008)</span> claims that plural agents
feature in common sense thinking. This claim is hard to evaluate because
other philosophers would probably reject it (<span class="citation"
data-cites="ludwig:2016_individual">(Ludwig 2016)</span>, perhaps).
Certainly philosophers seem vulnerable to making wrong assumptions about
common sense thinking in other cases <span class="citation"
data-cites="starmans:2012_folk nagel:2013_authentic starmans:2013_taking">(e.g.
Starmans and Friedman 2012, 2013; Nagel, Mar, and San Juan 2013)</span>.
One as yet unresolved challenge is to develop an operationalisation
which would enable us to distinguish someone thinking and acting in
terms of plural subjects from someone operating with a different
conception of shared intention. Whereas we have multiple methods for
identifying stated preferences (including contingent valuation and
choice modelling), we currently lack any hint about how we might
identify attitudes towards plural subjects. This challenge is made
harder by the need to distinguish plural subjects from aggregate
subjects.</p>
<h1 id="sec:aggregate">The Aggregate Subject Strategy</h1>
<p>An aggregate subject is a subject with proper parts which are
themselves subjects in their own right. If you have intentions and some
proper parts of you also have intentions of their own, then you are an
aggregate subject.</p>
<p>Although our interest is in subjects of intention, and of mental
states generally, a non-mental illustration may be helpful. The
Portuguese man o’war, <em>Physalia physalis</em>, is an animal composed
of polyps which are themselves born as animals in their own right. Why
is the man o’war an aggregate subject rather than a plural subject?
Because it is numerically distinct from the animals which compose it.
These may change over its lifetime. By contrast, in the case of a plural
subject, there is nothing that could continue to exist if one of the
individuals ceases to exist. A plural subject is not a thing at all: it
is just some individuals. An aggregate subject, even one which right now
consists of nothing but some individuals, is nevertheless a thing that
is logically distinct from the individuals which comprise it.</p>
<p>For a non-mental illustration which features both plural and
aggregate subjects, consider:</p>
<ol>
<li><p>The protestors formed a barrier which blocked the
entrance.</p></li>
</ol>
<p>Forming the barrier is something the protestors do collectively. They
(and no other thing) are the plural subject of the forming. But in
talking about the barrier we have introduced an aggregate entity.
Although it is composed of the protestors and nothing else, it is
numerically distinct from them. We know the barrier is distinct from the
protestors because one of the protestors might abandon the barrier and
be replaced by a new protestor.</p>
<p>Not everything true of an aggregate subject is true of a
corresponding plural subject, even when, as in the protestors’ case, the
only parts of the aggregate subject are the plural subject. For example,
the barrier may be capable of surviving an assault which would destroy
the plural subject. And, conversely, it is true that the plural subject
formed the barrier but false that the aggregate subject did so. The
mental case is similar. To be an aggregate subject, a thing must have
its own intentions (or other mental states) which are at least
potentially distinct from those of its parts <span class="citation"
data-cites="bjornsson:2017_corporate">(Björnsson and Hess 2017,
274)</span>.</p>
<p>How could there be aggregate subjects of intention? As List and
Pettit put it:</p>
<blockquote>
<p>‘Let a collection of individuals form and act on a single, robustly
rational body of attitudes [...] and it will be an agent.’</p>
</blockquote>
<p>Individuals sometimes act in this way only because their interests
are so closely aligned, as when a variety of finance professionals all
rush to exploit a tax loophole so that state finances appear ravaged by
a many-handed beast.<a href="#fn10" class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a> Alternatively, individuals may
authorise a representative to speak for them as a group. Such cases are
unlikely to be theoretically interesting given our aim of investigating
shared intention more broadly <span class="citation"
data-cites="list_pettit:2011">(List and Pettit 2011, 7ff)</span>.
Instead we should focus on cases where an aggregate agent has what
Sugden calls <em>autonomy</em>:</p>
<blockquote>
<p>An aggregate subject has autonomy if there is ‘the possibility that
every member of the group has an individual preference for y over x
(say, each prefers wine bars to pubs) while the group acts on an
objective that ranks x above y.’ <span class="citation"
data-cites="Sugden:2000mw">(Sugden 2000)</span></p>
</blockquote>
<p>The challenge, then, is to explain how there can be aggregate
subjects which are autonomous from the subjects which compose them.</p>
<p>One approach to meeting this challenge borrows from decision theory.
It is possible to use decision theory as an ‘elucidation of the notions
of subjective probability [roughly, belief] and subjective desirability
or utility [roughly, desire]’ <span class="citation"
data-cites="Jeffrey:1983oe">(Jeffrey 1983, xi)</span>. Whether or not
there are other ways of elucidating attitudes, decision theory provides
one coherent way of thinking about them. But decision theory is also
agnostic about what subjects are. As long as a thing’s behaviour fits a
certain pattern, one that is specified by axioms linking attitudes to
actions, the thing can coherently be attributed preferences. This is why
decision theory and its derivatives can be applied not only in
describing humans but also bacteria, business organisations and
countries <span class="citation" data-cites="dixit:2014_games">(Dixit,
Skeath, and Reiley 2014, chap. 10)</span>. Being agnostic about what
subjects are makes it a useful tool for constructing a theory of
aggregate agents.</p>
<p>In essence, the construction goes like this.<a href="#fn11"
class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>
Two or more individuals take themselves, rightly or wrongly, to be
components of an aggregate agent. These individuals each ascribe
preferences, and perhaps other attitudes, to the aggregate agent, and
they all ascribe the same attitudes. They then use these preferences to
rank combinations of individual actions, and each individual selects an
action from a highest-ranking combination. Given the usual axioms about
preferences being transitive and so on <span class="citation"
data-cites="steele:2020_decision">(Steele and Stefánsson 2020)</span>,
and given some background assumptions about the individuals’ knowledge
of their situation, it will be possible to use decision theory to model
the situation as if there were an aggregate agent. And if we follow
Jeffrey in taking decision theory as elucidating preference and other
attitudes, we can infer that there actually is an aggregate agent.
Further, because the preferences and other attitudes ascribed by the
individuals need not be their own, the aggregate agent has autonomy in
the above sense.</p>
<p>How might the aggregate subject strategy provide a notion of shared
intention? And how might it enable us to distinguish joint actions from
things people do in parallel but merely individually (see section <a
href="#sec:background" data-reference-type="ref"
data-reference="sec:background">3</a>)? One possibility is to stipulate
that the intentions arrived at by individuals through the process of
determining how the aggregate agent will act comprise a shared intention
(<span class="citation" data-cites="Gold:2007zd">(Gold and Sugden
2007)</span>; alternative views are offered by <span class="citation"
data-cites="bardsley:2007_collective">(Bardsley 2007)</span> and <span
class="citation" data-cites="pacherie:2013_lite">(Pacherie
2013)</span>). On this view, one way for an activity to be genuinely
joint is for it to issue from reasoning about the preferences of an
aggregate subject where each reasoner is a part of that aggregate
subject.<a href="#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a></p>
<p>None of this shows, of course, that there actually are aggregate
subjects of preference or intention. Even assuming there are, we cannot
yet say whether their existence is actually what distinguishes joint
activities from things people do in parallel but merely individually. My
aim in this section was merely to defend the theoretical possibility of
aggregate subjects.</p>
<h1 id="sec:reductive">The Reductive Strategy</h1>
<p>If you seek to characterise shared intention entirely in terms of
ordinary, individual subjects and their ordinary, individual attitudes
then you are pursuing the reductive strategy.</p>
<p>Contemporary interest in the reductive strategy starts with <span
class="citation" data-cites="sellars:1963_imperatives">Sellars (1963,
203)</span>’s observation that statements to the effect that we intend
that we cook dinner are ‘clearly not the logical sum of’ statements
about each of us individually intending that we cook dinner (<span
class="citation" data-cites="tuomela_we-intentions_1988">(Tuomela and
Miller 1988)</span>). Apparently, then, our having a shared intention
that we cook dinner together cannot consist simply in our each intending
this. A natural question is whether there is any combination of
ordinary, individual intentions, knowledge states or other mental
attitudes our having which could be necessary or sufficient for us to
have a shared intention that we cook dinner.</p>
<p>The most extensively developed and widely discussed attempt to
provide sufficient conditions for shared intention is <span
class="citation" data-cites="bratman:2014_book">Bratman (2014)</span>’s.
The full account is complex but the core idea, put roughly, is this. For
us to have a shared intention that we cook dinner, it suffices that we
each intend that we cook dinner, that we intend to do so by way and
because of these intentions, and that this is all common knowledge among
us.</p>
<p>Proponents of the reductive strategy have succeeded in providing sets
of necessary or sufficient conditions which have intuitive pull for some
and against which none of the published counterexamples have been widely
accepted as successful. This is remarkable given that the model for
Bratman and several others is Grice’s analysis of meaning <span
class="citation" data-cites="Bratman:1992mi">(Bratman 1992, footnote 13
to p. 334)</span>, which met a different fate. A ‘flood’ of
counterexamples to Grice’s analysis led to extensive revisions, to which
further counterexamples were developed <span class="citation"
data-cites="searle:2007_grice">(Searle 2007, 11)</span>. Confidence in
the project’s eventual success was shaken when, in a dramatic change of
direction, Schiffer, who was formerly a leading proponent of the Gricean
analysis, argued that the whole project was based on a mistake. <a
href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a> While Grice’s analysis has
continued to inspire various projects (<span class="citation"
data-cites="moore:2016_gricean">(Moore 2017)</span>, for example), we
are no closer to a successful reductive analysis. By contrast, generally
accepted counterexamples to reductive sets of necessary or sufficient
conditions for shared intention appear to be rare.</p>
<p>A diversity of views about the features of shared intentions can be
found in the reductive strategy. The various conditions proposed imply
conflicting views about whether having a shared intention invariably
involves dispositions to help (for: <span class="citation"
data-cites="bratman:2014_book">(Bratman 2014, 56–57)</span>; against:
<span class="citation" data-cites="Bratman:1992mi">(Bratman
1992)</span>, <span class="citation"
data-cites="ludwig_collective_2007">(Ludwig 2007)</span>), common
knowledge (for: <span class="citation"
data-cites="Bratman:1993je">(Bratman 1993)</span>; against: <span
class="citation" data-cites="blomberg:2015_common">(Blomberg
2016)</span>), and corresponding individual intentions on each subject’s
part (for: <span class="citation" data-cites="Bratman:1992mi">(Bratman
1992)</span>; against: <span class="citation"
data-cites="sellars:1963_imperatives">(Sellars 1963)</span>). There are
also further issues on which theorists could disagree, including on
whether shared intention invariably involves contralateral commitment
(for: <span class="citation" data-cites="gilbert:2009shared">(Gilbert
2009)</span>; against: <span class="citation"
data-cites="Roth:2004ki">(Roth 2004, 361)</span>), cooperation <span
class="citation"
data-cites="salomone-sehr:2022_cooperation">(Salomone-Sehr 2022)</span>
or nonobservational knowledge <span class="citation"
data-cites="roessler:2020_plural">(Roessler 2024)</span>.</p>
<p>This gives rise to a challenge to the reductive strategy. For the
diversity makes it unclear when proponents of the reductive strategy can
coherently be interpreted as offering competing attempts to characterise
a single thing and when as offering compatible attempts to characterise
different things.<a href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a></p>
<p>The reductive strategy allows us to construct many theories, each
internally theoretically coherent but inconsistent with other reductive
theories that share an explanandum. For any combination of views about
the features of shared intention, it would be possible to construct a
coherent reductive theory. If we simplify and regard the six features
mentioned above as binary, this yields 64 reductive theories. The
scarcity of counterexamples cuts two ways.</p>
<h1 id="the-limits-of-a-metatheoretical-principle">The Limits of a
Metatheoretical Principle</h1>
<p>We have seen that the three strategies each yield theoretically
coherent positions, and, further, that at least one of these strategies
alone yields many theoretically coherent positions. Can we decide
between the positions by invoking metatheoretical principles? This idea
has been carefully developed by Bratman:</p>
<blockquote>
<p>‘If we can get a plausible model of modest sociality without
appealing to a fundamental discontinuity in the step from individual
planning agency to such sociality, then there is a presumption against
an appeal to such a discontinuity in our theorising.’ <span
class="citation" data-cites="bratman:2014_book">(Bratman 2014,
36)</span></p>
</blockquote>
<p>If true, this principle provides a good reason to prefer the
reductive strategy over theories like that of <span class="citation"
data-cites="Searle:1990em">Searle (1990)</span> and perhaps also that of
<span class="citation" data-cites="gilbert:2014_book">Gilbert
(2013)</span>.<a href="#fn15" class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a> This is because each of those
theorists postulates a fundamental discontinuity. In Searle’s case, this
is a novel kind of attitude, the ‘we-intention’, which differs from
ordinary intention along the same dimension as desire differs from
intention.<a href="#fn16" class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a> For her part, Gilbert postulates a
novel kind of commitment and associated nonmoral norms. The novel kinds
of intention and commitment are fundamental discontinuities.</p>
<p>Although Bratman’s metatheoretical principle rules against some
theories, it does not exclude many of those derived from the reductive
strategy. Nor does it exclude the plural and aggregate subject
strategies outright. After all, the whole point of plural subjects is
that they are nothing but some subjects <span class="citation"
data-cites="boolos:1984_value">(Boolos 1984)</span>. And the bare idea
of an aggregate subject is no more a fundamental discontinuity than is a
barrier composed of protestors. Further, as we have seen (in sections <a
href="#sec:plural" data-reference-type="ref"
data-reference="sec:plural">4</a> and <a href="#sec:aggregate"
data-reference-type="ref" data-reference="sec:aggregate">5</a>), both
plural subject and the aggregate subject strategies can be implemented
without appealing to fundamental discontinuities.</p>
<p>Apparently, then, Bratman’s metatheoretical principle is limited.
There are theories from each of the three strategies—plural, aggregate
and reductive—between which it fails to discriminate.</p>
<p>This is why I have presented the strategies in an unusual order. The
usual way is to start with the reductive strategy and then possibly to
justify adopting one of the others by some failure of that strategy
(see, for example, <span class="citation"
data-cites="helm_plural_2008">(Helm 2008)</span> ). In my view that is a
mistake. There is no consensus on attempts to demonstrate failure of the
reductive strategy generally. Quite the opposite: after three decades
there is not yet even a successful published counterexample to the most
widely discussed reductive theory (<span class="citation"
data-cites="Bratman:1992mi">(Bratman 1992)</span>; <span
class="citation" data-cites="bratman:2022_planning">(Bratman
2022b)</span>). But, equally, the mere absence of successful objections
to a theory is not enough to establish its truth. The plural and
aggregate subject strategies are significant not because the reductive
strategy can be shown to fail but because they also yield theoretically
coherent, as yet unfalsified theories.</p>
<p>These are deep waters. Some researchers hold that plural subjects
should be avoided if possible, even narrowly logical ones (see <span
class="citation" data-cites="ludwig:2016_individual">(Ludwig
2016)</span> cited in section <a href="#sec:plural"
data-reference-type="ref" data-reference="sec:plural">4</a>). Some even
suggest that ‘all plural locutions should be paraphrased away’. <a
href="#fn17" class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a> Were this true, the plural subject
strategy might be ruled out for reasons not specifically psychological.
As this illustrates, the considerations offered here fall far short of
demonstrating that it would be impossible to find general principles
which do discriminate among the three strategies for shared
intention.</p>
<p>But there is also a positive argument for my thesis that all three
strategies are needed.</p>
<h1 id="sec:multiple-strategies">Do We Need Multiple Strategies for
Shared Intention?</h1>
<p>It is possible for people to intentionally live out one or another
theory of shared intention: to think and act as if that theory were true
of them. This indicates that no one theory alone could be sufficient to
fully characterise shared intention. Or so I will argue in this
section.</p>
<p>For each of the three strategies, there are recipes you and I could
explicitly aim to follow. To illustrate, suppose the time for us to face
the growing pile of dirty dishes in our kitchen has finally come. Having
both been inspired by <span class="citation"
data-cites="Schmid:2008">Schmid (2008)</span>, we might regard ourselves
as the plural subject of an intention to wash the dishes and act
accordingly (see section <a href="#sec:plural" data-reference-type="ref"
data-reference="sec:plural">4</a>). Or perhaps what comes to mind is
instead an idea about ascribing preferences to an aggregate subject and
doing our parts to fulfill them (see section <a href="#sec:aggregate"
data-reference-type="ref" data-reference="sec:aggregate">5</a>). Or
maybe we have both just been reading <span class="citation"
data-cites="bratman:2014_book">Bratman (2014)</span> and are impressed
that we could benefit by forming and making explicit the intentions he
identifies, thereby meeting his sufficient conditions for shared
intention (see section <a href="#sec:reductive"
data-reference-type="ref" data-reference="sec:reductive">6</a>). This
being new to us, we even decide to write everything down so that we can
track the attitudes and actions. Things go well and we continue to use
the recipe for shared intention in our future activities. Over time our
use of the chosen recipe becomes so familiar that we hardly need to
think about it at all.</p>
<p>The possibility of our aiming to follow a recipe associated with any
one of the three strategies for shared intention, first explicitly and
then with greater skill, suggests that no one strategy can claim to be
uniquely correct. Instead, capturing the full range of phenomena
involving shared intention will require theories associated with several
different strategies.</p>
<p>The extent to which we actually succeed in following a recipe may be
quite limited, much as our stated preferences alone may explain only a
small part of our behaviour (see section <a href="#sec:live-it-out"
data-reference-type="ref" data-reference="sec:live-it-out">2</a>). What
matters for our purposes, however, is just that the aim of living out
the theory is not entirely inert. It should influence some of our
thoughts and actions. This is what makes it reasonable to accept, in the
absence of overriding reasons, that the theory could be true of us.</p>
<p>It may be helpful to consider possible responses to this position.
One response starts with the observation that following a recipe
together may involve us having a shared intention to do so. Probably,
then, not all shared intention is a consequence of our intentionally
living out a theory of shared intention. We might therefore be motivated
to search for phylogenically or ontogenically foundational forms of
shared intention (see, for example, <span class="citation"
data-cites="Tollefsen:2005vh Rakoczy:2007ou pacherie:2013_lite">(Tollefsen
2005; Rakoczy and Tomasello 2007; Pacherie 2013)</span>). Perhaps it
would even be possible, eventually, to relate strategies and theories to
different stages and needs. This is a radical response which breaks from
the most extensively developed, best defended theories currently
available, which give no such importance to evolutionary or
developmental considerations.</p>
<p>An alternative response would aim to distinguish recipes that humans
actually follow, noting that these may be fewer than those which could
in principle be used.<a href="#fn18" class="footnote-ref" id="fnref18"
role="doc-noteref"><sup>18</sup></a> There are at least two potential
sources of inspiration for this response. One is narrowly philosophical
attempts to establish that aggregate or plural subjects of shared
intention are either practically indispensable or required for certain
explanatory purposes. (<span class="citation"
data-cites="roth:2014_indispensability">(Roth 2014)</span> presents both
kinds of argument, for example.) The other source of inspiration for
this response could be taken from <span class="citation"
data-cites="gomez-lavin:2019_normativity">Gomez-Lavin and Rachar
(2019)</span>, who offer findings which they interpret as showing that
everyday thinking involves distinctive features of <span
class="citation" data-cites="gilbert:2014_book">Gilbert (2013)</span>’s
account of shared intention. Just here we encounter a dilemma. Narrowly
philosophical arguments may establish that humans do follow one recipe
but appear unlikely to show that they do not also follow other recipes.
On the other hand, taking inspiration from experimental research
involves a radical departure from the kinds of consideration usually
taken to motivate a theory of shared intention. This is clear from
responses to <span class="citation"
data-cites="gomez-lavin:2019_normativity">Gomez-Lavin and Rachar
(2019)</span>’s work, which include <span class="citation"
data-cites="lohr:2022_recent">Löhr (2022)</span> who challenges their
interpretation on methodological grounds and <span class="citation"
data-cites="michael:2022_intuitions">Michael and Butterfill
(2022)</span> who offer apparently contrasting findings. Those authors’
interest in discovering how people actually think about joint activities
has no counterpart in the work of the leading philosophers.</p>
<p>A bolder and more orthodox response might be to allow that we could
coherently follow any of the recipes but deny that all of them yield
shared intention (or, more ambitiously, even that any do). The challenge
for proponents of this response is to identify grounds for rejecting the
view that following the recipes yields genuine shared intention. They
would need to enable all of us, as researchers, to know which things a
theory of shared intention should explain independently of our knowing
which theory is true. As things stand now, philosophers typically use
particular examples of joint activities to introduce the topic (see
section <a href="#sec:introduction" data-reference-type="ref"
data-reference="sec:introduction">1</a>, and <span class="citation"
data-cites="bratman:2014_book">(Bratman 2014, 5–6)</span>, for example).
The usual assumption is that the examples are sufficient to identify
‘shared activity of the sort we are trying to understand’ <span
class="citation" data-cites="bratman:2014_book">(Bratman 2014,
6)</span>. But intentionally following one of the recipes is, of course,
one way of walking together, playing a piano duet, or painting a house
together. So if examples of joint activities provide us as researchers
with a common understanding of the things to be explained, that common
understanding supports the view that more than one strategy’s recipes
are needed to capture them. Opponents of this view need further
theory-independent ways of identifying what is to be explained.</p>
<p>Overall, it seems plausible that at least three different strategies
for shared intention are needed. This is because each of the plural,
aggregate and reductive strategies is associated with a recipe people
could intentionally follow and thereby manifest phenomena for
characterising which the corresponding strategy is needed.</p>
<h1 id="conclusion">Conclusion</h1>
<p>I have explored three strategies for elucidating ideas about shared
intention. The plural, aggregate and reductive strategies are often
regarded as competing attempts to characterise a single target.
Proponents of the plural and aggregate subject strategies typically
object that the reductive strategies fail, while proponents of reductive
strategies aim to show that the other strategies are not needed (or, if
they are needed, that they can be tacked on to a reductive strategy; see
<a href="#sec:introduction" data-reference-type="ref"
data-reference="sec:introduction">1</a>). Despite much effort, no such
arguments currently enable us to determine which strategy is correct. In
contrast, I have appealed to the possibility of intentionally living out
different theories to argue that for each strategy there are phenomena
which can be correctly characterised only by following that strategy
(section <a href="#sec:multiple-strategies" data-reference-type="ref"
data-reference="sec:multiple-strategies">8</a>). There may also be many
theories derived from the reductive strategy for which the same is true
(section <a href="#sec:reductive" data-reference-type="ref"
data-reference="sec:reductive">6</a>).</p>
<p>If correct, this conclusion marks a collective success. Whereas it
was initially assumed that at most one strategy would work, the careful
development of multiple theories by their various proponents suggests
there are multiple theoretically coherent possibilities, each having
intuitive appeal to some.</p>
<p>Despite the success, this conclusion is not a tenable stopping point.
Whereas progress surely requires that we can discover grounds to reject
some theories, the conclusion that we need multiple strategies seems to
imply that anything goes in constructing theories of shared
intention.</p>
<p>What to do? The conclusion that we need multiple strategies rests on
the premise that we need at least one theory of shared intention. One
way to avoid it might be to reject this premise (see footnote <a
href="#fn:no-shared-intention" data-reference-type="ref"
data-reference="fn:no-shared-intention">2</a> on page for discussions
which may motivate considering this option). But while questioning the
premise may lead to fresh insights, the idea that we might completely do
away with theories of shared intention seems unpromising insofar as some
existing theories have been fruitfully applied beyond philosophy. <a
href="#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a></p>
<p>A more hopeful response to the untenable conclusion would be to take
inspiration from other domains where multiple apparently incompatible
approaches have been discovered. We might draw a very inexact parallel
with the twin possibilities of using sets to replace plural
quantification and of using plural quantification to construct sets
<span class="citation" data-cites="linnebo:2022_plural">(Linnebo 2022,
sec. 4.3)</span>. Perhaps—so the hopeful response—we can show that the
strategies for shared intention yield theories which are in some sense
equivalent ways of elucidating a single set of ideas about shared
intention.<a href="#fn20" class="footnote-ref" id="fnref20"
role="doc-noteref"><sup>20</sup></a> Or perhaps the informal nature of
the theories and their diversity means that this response is just too
hopeful.</p>
<p>A simpler response is also available. Several researchers have
pointed to things which stand in need of explanation and which, they
suggest, might be explained using a theory of shared intention. These
include behavioural and neuroscientific findings <span class="citation"
data-cites="gallotti:2013_social">(Gallotti and Frith 2013)</span>,
patterns in cognitive development <span class="citation"
data-cites="Tomasello:2007gl">(Tomasello and Carpenter 2007)</span>, and
decision making <span class="citation"
data-cites="Sugden:2000mw">(Sugden 2000)</span>. In some cases this has
led to debate on which things theories of shared intention are supposed
to explain (see, for example, <span class="citation"
data-cites="bratman:2014_book">(Bratman 2014)</span> on <span
class="citation" data-cites="Gold:2007zd">(Gold and Sugden
2007)</span>). One way to make further progress would be, in offering a
theory about shared intention, to specify things which stand in need of
explanation in a way that can be understood independently of the
theory’s truth or falsity; and to formulate the theory in such a way
that makes it possible to determine, eventually, whether it does
actually explain those things.</p>
<p>To illustrate how this might go, consider a relatively easy family of
questions. How do various groups of individuals represent the activities
of some agents acting together in particular situations? Instead of
interpreting existing theories as claims about how shared intention is,
we can also interpret (or usefully misinterpret) them as theories about
how people represent situations involving shared intention. Generating
predictions from existing theories is difficult but there are signs that
this might be possible.<a href="#fn21" class="footnote-ref"
id="fnref21" role="doc-noteref"><sup>21</sup></a> Relative to this
project—that of discovering how individuals represent joint
activities—the existence of many theories is not a bad thing. After all,
there may well be differences between species, between infants, children
and adults, and between cultures. Further, a single individual may adopt
different models in different situations. Diversity in the theories of
shared intention may enable us to discover genuine diversity in the
things to be explained.</p>
<p>In conclusion, we researchers need, but lack, a common understanding
of what theories of shared intention are theories of. It has been
fruitful to construct different models of how aspects of shared
intention might be. The next step is to find out which models explain
which things.</p>
<div id="refs" class="references csl-bib-body hanging-indent"
role="doc-bibliography">
<div id="ref-alberini:2019_revealed" class="csl-entry"
role="doc-biblioentry">
Alberini, Anna. 2019. <span>“Revealed Versus <span>Stated</span>
<span>Preferences</span>: What <span>Have</span> <span>We</span>
<span>Learned</span> <span>About</span> <span>Valuation</span> and
<span>Behavior</span>?”</span> <em>Review of Environmental Economics and
Policy</em> 13 (2). <a
href="https://doi.org/10.1093/reep/rez010">https://doi.org/10.1093/reep/rez010</a>.
</div>
<div id="ref-Bacharach:2006fk" class="csl-entry" role="doc-biblioentry">
Bacharach, Michael. 2006. <em>Beyond Individual Choice</em>. Princeton:
Princeton University Press. <a
href="http://webcat.warwick.ac.uk/record=b3272720~S1">http://webcat.warwick.ac.uk/record=b3272720~S1</a>.
</div>
<div id="ref-baier:1997_joint" class="csl-entry" role="doc-biblioentry">
Baier, Annette C. 1997. <span>“Doing <span>Things With Others</span>:
<span>The Mental Commons</span>.”</span> In <em>Commonality and
Particularity in Ethics</em>, edited by Lilli Alanen, Sarah Heinamaa,
and Thomas Wallgren, 15–44. Palgrave Macmillan. <a
href="https://doi.org/10.1007/978-1-349-25602-0_2">https://doi.org/10.1007/978-1-349-25602-0_2</a>.
</div>
<div id="ref-bardsley:2007_collective" class="csl-entry"
role="doc-biblioentry">
Bardsley, Nicholas. 2007. <span>“On Collective Intentions: Collective
Action in Economics and Philosophy.”</span> <em>Synthese</em> 157 (2):
141–59. <a
href="https://doi.org/10.1007/s11229-006-9034-z">https://doi.org/10.1007/s11229-006-9034-z</a>.
</div>
<div id="ref-beshears:2008_how" class="csl-entry"
role="doc-biblioentry">
Beshears, John, James J. Choi, David Laibson, and Brigitte C. Madrian.
2008. <span>“How Are Preferences Revealed?”</span> <em>Journal of Public
Economics</em> 92 (8): 1787–94. https://doi.org/<a
href="https://doi.org/10.1016/j.jpubeco.2008.04.010">https://doi.org/10.1016/j.jpubeco.2008.04.010</a>.
</div>
<div id="ref-bjornsson:2017_corporate" class="csl-entry"
role="doc-biblioentry">
Björnsson, Gunnar, and Kendy Hess. 2017. <span>“Corporate
<span>Crocodile</span> <span>Tears</span>?: On the <span>Reactive</span>
<span>Attitudes</span> of <span>Corporate</span>
<span>Agents</span>.”</span> <em>Philosophy and Phenomenological
Research</em> 94 (2): 273–98. <a
href="https://www.jstor.org/stable/48578761">https://www.jstor.org/stable/48578761</a>.
</div>
<div id="ref-blomberg:2015_common" class="csl-entry"
role="doc-biblioentry">
Blomberg, Olle. 2016. <span>“Common <span>Knowledge</span> and
<span>Reductionism</span> about <span>Shared Agency</span>.”</span>
<em>Australasian Journal of Philosophy</em> 94 (2): 315–26. <a
href="https://doi.org/10.1080/00048402.2015.1055581">https://doi.org/10.1080/00048402.2015.1055581</a>.
</div>
<div id="ref-boolos:1984_value" class="csl-entry"
role="doc-biblioentry">
Boolos, George. 1984. <span>“To Be Is to Be a Value of a Variable (or to
Be Some Values of Some Variables).”</span> <em>The Journal of
Philosophy</em> 81 (8): 430–49.
</div>
<div id="ref-Bratman:1987xw" class="csl-entry" role="doc-biblioentry">
Bratman, Michael E. 1987. <em>Intentions, Plans, and Practical
Reasoning</em>. Cambridge, MA: Harvard University Press.
</div>
<div id="ref-Bratman:1992mi" class="csl-entry" role="doc-biblioentry">
———. 1992. <span>“Shared Cooperative Activity.”</span> <em>The
Philosophical Review</em> 101 (2): 327–41.
</div>
<div id="ref-Bratman:1993je" class="csl-entry" role="doc-biblioentry">
———. 1993. <span>“Shared Intention.”</span> <em>Ethics</em> 104: 97–113.
</div>
<div id="ref-bratman:2014_book" class="csl-entry"
role="doc-biblioentry">
———. 2014. <em>Shared Agency: A Planning Theory of Acting Together</em>.
Oxford: Oxford University Press. <a
href="http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199897933.001.0001">http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199897933.001.0001</a>.
</div>
<div id="ref-bratman:2015_shareda" class="csl-entry"
role="doc-biblioentry">
———. 2015. <span>“Shared <span>Agency</span>: <span>Replies</span> to
<span>Ludwig</span>, <span>Pacherie</span>, <span>Petersson</span>,
<span>Roth</span>, and <span>Smith</span>.”</span> <em>Journal of Social
Ontology</em> 1 (1): 59–76.
</div>
<div id="ref-bratman:2022_shared" class="csl-entry"
role="doc-biblioentry">
———. 2022a. <em>Shared and <span>Institutional</span>
<span>Agency</span>: Toward a <span>Planning</span> <span>Theory</span>
of <span>Human</span> <span>Practical</span>
<span>Organization</span></em>. Oxford: Oxford University Press.
</div>
<div id="ref-bratman:2022_planning" class="csl-entry"
role="doc-biblioentry">
———. 2022b. <span>“A <span>Planning Theory</span> of <span>Acting
Together</span>.”</span> <em>Journal of the American Philosophical
Association</em> 8 (3): 1–8. <a
href="https://doi.org/10.1017/apa.2021.17">https://doi.org/10.1017/apa.2021.17</a>.
</div>
<div id="ref-carson:1996_contingent" class="csl-entry"
role="doc-biblioentry">
Carson, Richard T., Nicholas E. Flores, Kerry M. Martin, and Jennifer L.
Wright. 1996. <span>“Contingent Valuation and Revealed Preference
Methodologies: Comparing the Estimates for Quasi-Public Goods.”</span>
<em>Land Economics</em> 72 (1): 80–99. <a
href="http://0-www-jstor-org.pugwash.lib.warwick.ac.uk/stable/3147159">http://0-www-jstor-org.pugwash.lib.warwick.ac.uk/stable/3147159</a>.
</div>
<div id="ref-chant_unintentional_2007" class="csl-entry"
role="doc-biblioentry">
Chant, Sara Rachel. 2007. <span>“Unintentional Collective
Action.”</span> <em>Philosophical Explorations: An International Journal
for the Philosophy of Mind and Action</em> 10 (3): 245. <a
href="https://doi.org/10.1080/13869790701535246">https://doi.org/10.1080/13869790701535246</a>.
</div>
<div id="ref-dixit:2014_games" class="csl-entry" role="doc-biblioentry">
Dixit, Avinash, Susan Skeath, and David Reiley. 2014. <em>Games of
Strategy</em>. New York: W. W. Norton; Company.
</div>
<div id="ref-frankfurt1978problem" class="csl-entry"
role="doc-biblioentry">
Frankfurt, H. G. 1978. <span>“<span class="nocase">The problem of
action</span>.”</span> <em>American Philosophical Quarterly</em> 15 (2):
157–62.
</div>
<div id="ref-gallotti:2013_social" class="csl-entry"
role="doc-biblioentry">
Gallotti, Mattia, and Chris D. Frith. 2013. <span>“Social Cognition in
the We-Mode.”</span> <em>Trends in Cognitive Sciences</em> 17 (4):
160–65. <a
href="https://doi.org/10.1016/j.tics.2013.02.002">https://doi.org/10.1016/j.tics.2013.02.002</a>.
</div>
<div id="ref-gilbert_walking_1990" class="csl-entry"
role="doc-biblioentry">
Gilbert, Margaret P. 1990. <span>“Walking Together: A Paradigmatic
Social Phenomenon.”</span> <em>Midwest Studies in Philosophy</em> 15:
1–14.
</div>
<div id="ref-gilbert:2007_searle" class="csl-entry"
role="doc-biblioentry">
———. 2007. <span>“Searle and <span>Collective Intentions</span>.”</span>
In <em>Intentional Acts and Institutional Facts</em>, edited by Savas L.
Tsohatzidis, 31–48. Springer. <a
href="https://doi.org/10.1007/978-1-4020-6104-2_1">https://doi.org/10.1007/978-1-4020-6104-2_1</a>.
</div>
<div id="ref-gilbert:2009shared" class="csl-entry"
role="doc-biblioentry">
———. 2009. <span>“Shared Intention and Personal Intentions.”</span>
<em>Philosophical Studies</em> 144 (1): 167–87. <a
href="https://doi.org/10.1007/s11098-009-9372-z">https://doi.org/10.1007/s11098-009-9372-z</a>.
</div>
<div id="ref-gilbert:2014_book" class="csl-entry"
role="doc-biblioentry">
———. 2013. <em>Joint Commitment: How We Make the Social World</em>.
Oxford: Oxford University Press. <a
href="http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199970148.001.0001">http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199970148.001.0001</a>.
</div>
<div id="ref-gilbert:2022_simple" class="csl-entry"
role="doc-biblioentry">
———. 2022. <span>“A <span>Simple Theory</span> of <span>Acting
Together</span>.”</span> <em>Journal of the American Philosophical
Association</em> X (X): 1–10.
</div>
<div id="ref-Gold:2007zd" class="csl-entry" role="doc-biblioentry">
Gold, Natalie, and Robert Sugden. 2007. <span>“Collective Intentions and
Team Agency.”</span> <em>Journal of Philosophy</em> 104 (3): 109–37.
</div>
<div id="ref-gomez-lavin:2019_normativity" class="csl-entry"
role="doc-biblioentry">
Gomez-Lavin, Javier, and Matthew Rachar. 2019. <span>“Normativity in
Joint Action.”</span> <em>Mind and Language</em> 34 (1): 97–120. <a
href="https://doi.org/10.1111/mila.12195">https://doi.org/10.1111/mila.12195</a>.
</div>
<div id="ref-Grafenhain:2010zl" class="csl-entry"
role="doc-biblioentry">
Gräfenhain, Maria, Tanya Behne, Malinda Carpenter, and Michael
Tomasello. 2009. <span>“Young Children’s Understanding of Joint
Commitments.”</span> <em>Developmental Psychology</em> 45 (5): 1430–43.
</div>
<div id="ref-Heider:1944ts" class="csl-entry" role="doc-biblioentry">
Heider, Fritz, and Marianne Simmel. 1944. <span>“An Experimental Study
of Apparent Behaviour.”</span> <em>American Journal of Psychology</em>
57 (2): 243–59.
</div>
<div id="ref-helm_plural_2008" class="csl-entry" role="doc-biblioentry">
Helm, Bennett W. 2008. <span>“Plural Agents.”</span> <em>Nous</em> 42
(1): 17–49. <a
href="https://doi.org/10.1111/j.1468-0068.2007.00672.x">https://doi.org/10.1111/j.1468-0068.2007.00672.x</a>.
</div>
<div id="ref-Jeffrey:1983oe" class="csl-entry" role="doc-biblioentry">
Jeffrey, Richard C. 1983. <em>The Logic of Decision, Second
Edition</em>. Chicago: University of Chicago Press.
</div>
<div id="ref-linnebo:2022_plural" class="csl-entry"
role="doc-biblioentry">
Linnebo, Øystein. 2022. <span>“Plural
<span>Quantification</span>.”</span> In <em>The <span>Stanford
Encyclopedia</span> of <span>Philosophy</span></em>, edited by Edward N.
Zalta, Spring 2022. <span>Metaphysics Research Lab, Stanford
University</span>.
</div>
<div id="ref-list_pettit:2011" class="csl-entry" role="doc-biblioentry">
List, Christian, and Philip Pettit. 2011. <em>Group Agency: The
Possibility, Design, and Status of Corporate Agents</em>. Oxford: Oxford
University Press.
</div>
<div id="ref-lohr:2022_recent" class="csl-entry" role="doc-biblioentry">
Löhr, Guido. 2022. <span>“Recent <span>Experimental</span>
<span>Philosophy</span> on <span>Joint</span> <span>Action</span>: Do
<span>We</span> <span>Need</span> a <span>New</span>
<span>Normativism</span> <span>About</span> <span>Collective</span>
<span>Action</span>?”</span> <em>The Philosophical Quarterly</em> 72
(3): 754–62. <a
href="https://doi.org/10.1093/pq/pqab070">https://doi.org/10.1093/pq/pqab070</a>.
</div>
<div id="ref-longworth:2019_sharing" class="csl-entry"
role="doc-biblioentry">
Longworth, Guy. 2019. <span>“Sharing Non-Observational
Knowledge.”</span> <em>Inquiry</em> 0 (0): 1–21. <a
href="https://doi.org/10.1080/0020174X.2019.1680430">https://doi.org/10.1080/0020174X.2019.1680430</a>.
</div>
<div id="ref-ludwig_collective_2007" class="csl-entry"
role="doc-biblioentry">
Ludwig, Kirk. 2007. <span>“Collective Intentional Behavior from the
Standpoint of Semantics.”</span> <em>Nous</em> 41 (3): 355–93. <a
href="https://doi.org/10.1111/j.1468-0068.2007.00652.x">https://doi.org/10.1111/j.1468-0068.2007.00652.x</a>.
</div>
<div id="ref-ludwig:2016_individual" class="csl-entry"
role="doc-biblioentry">
———. 2016. <em>From <span>Individual</span> to <span>Plural
Agency</span>: <span>Collective Action</span></em>. <span>Oxford
University Press</span>.
</div>
<div id="ref-mcgeer:2007_regulative" class="csl-entry"
role="doc-biblioentry">
McGeer, Victoria. 2007. <span>“The <span>Regulative Dimension</span> of
<span>Folk Psychology</span>.”</span> In <em>Folk Psychology
Re-Assessed</em>, edited by Daniel D. Hutto and Matthew Ratcliffe,
137–56. Dordrecht: Springer. <a
href="https://doi.org/10.1007/978-1-4020-5558-4_8">https://doi.org/10.1007/978-1-4020-5558-4_8</a>.
</div>
<div id="ref-michael:2022_intuitions" class="csl-entry"
role="doc-biblioentry">
Michael, John, and Stephen Butterfill. 2022. <span>“Intuitions about
Joint Commitment.”</span> <em>Philosophical Psychology</em> 0 (0): 1–16.
<a
href="https://doi.org/10.1080/09515089.2022.2153659">https://doi.org/10.1080/09515089.2022.2153659</a>.
</div>
<div id="ref-Moll:2007gu" class="csl-entry" role="doc-biblioentry">
Moll, Henrike, and Michael Tomasello. 2007. <span>“Cooperation and Human
Cognition: The Vygotskian Intelligence Hypothesis.”</span>
<em>Philosophical Transactions of the Royal Society B</em> 362 (1480):
639–48.
</div>
<div id="ref-moore:2016_gricean" class="csl-entry"
role="doc-biblioentry">
Moore, Richard. 2017. <span>“Gricean <span>Communication</span> and
<span>Cognitive Development</span>.”</span> <em>The Philosophical
Quarterly</em> forthcoming. <a
href="https://doi.org/10.1093/pq/pqw049">https://doi.org/10.1093/pq/pqw049</a>.
</div>
<div id="ref-nagel:2013_authentic" class="csl-entry"
role="doc-biblioentry">
Nagel, Jennifer, Raymond Mar, and Valerie San Juan. 2013.
<span>“Authentic Gettier Cases: A Reply to Starmans and
Friedman.”</span> <em>Cognition</em> 129 (3): 666–69. <a
href="https://doi.org/10.1016/j.cognition.2013.08.016">https://doi.org/10.1016/j.cognition.2013.08.016</a>.
</div>
<div id="ref-pacherie:2013_lite" class="csl-entry"
role="doc-biblioentry">
Pacherie, Elisabeth. 2013. <span>“Intentional Joint Agency: Shared
Intention Lite.”</span> <em>Synthese</em> 190 (10): 1817–39. <a
href="https://doi.org/10.1007/s11229-013-0263-7">https://doi.org/10.1007/s11229-013-0263-7</a>.
</div>
<div id="ref-petersson_collectivity_2007" class="csl-entry"
role="doc-biblioentry">
Petersson, Björn. 2007. <span>“Collectivity and Circularity.”</span>
<em>Journal of Philosophy</em> 104 (3): 138–56.
</div>
<div id="ref-Rakoczy:2007ou" class="csl-entry" role="doc-biblioentry">
Rakoczy, Hannes, and Michael Tomasello. 2007. <span>“The Ontogeny of
Social Ontology: Steps to Shared Intentionality and Status
Functions.”</span> In <em>Intentional Acts and Intentional Facts</em>,
edited by S. L. Tsohatzidis, 113–37. Springer.
</div>
<div id="ref-roessler:2020_plural" class="csl-entry"
role="doc-biblioentry">
Roessler, Johannes. 2024. <span>“Plural Practical Knowledge.”</span>
<em>Inquiry</em> 67 (4): 1–20. <a
href="https://doi.org/10.1080/0020174X.2020.1787221">https://doi.org/10.1080/0020174X.2020.1787221</a>.
</div>
<div id="ref-Roth:2004ki" class="csl-entry" role="doc-biblioentry">
Roth, Abraham Sesshu. 2004. <span>“Shared Agency and Contralateral
Commitments.”</span> <em>The Philosophical Review</em> 113 (3): 359–410.
</div>
<div id="ref-roth:2014_indispensability" class="csl-entry"
role="doc-biblioentry">
———. 2014. <span>“Indispensability, the <span>Discursive</span>
<span>Dilemma</span>, and <span>Groups</span> with <span>Minds</span> of
<span>Their</span> <span>Own</span>.”</span> In <em>From
<span>Individual</span> to <span>Collective</span>
<span>Intentionality</span>: New <span>Essays</span></em>, edited by
Gerhard Preyer, Frank Hindriks, and Sara Rachel Chant, 137–62. Oxford
University Press.
</div>
<div id="ref-rovane:1998_bounds" class="csl-entry"
role="doc-biblioentry">
Rovane, Carol A. 1998. <em>The Bounds of Agency: An Essay Inrevisionary
Metaphysics</em>. Princeton, N.J: Princeton University Press. <a
href="http://ebookcentral.proquest.com/lib/warw/detail.action?docID=668953">http://ebookcentral.proquest.com/lib/warw/detail.action?docID=668953</a>.
</div>
<div id="ref-russell:2018_intention" class="csl-entry"
role="doc-biblioentry">
Russell, Devlin. 2018. <span>“Intention as Action Under Development: Why
Intention Is Not a Mental State.”</span> <em>Canadian Journal of
Philosophy</em> 48 (5): 742–61. <a
href="https://doi.org/10.1080/00455091.2017.1414524">https://doi.org/10.1080/00455091.2017.1414524</a>.
</div>
<div id="ref-salomone-sehr:2022_cooperation" class="csl-entry"
role="doc-biblioentry">
Salomone-Sehr, Jules. 2022. <span>“Cooperation: With or Without
<span>Shared</span> <span>Intentions</span>.”</span> <em>Ethics</em> 132
(2): 414–44. <a
href="https://doi.org/10.1086/716877">https://doi.org/10.1086/716877</a>.
</div>
<div id="ref-Schiffer:1987zb" class="csl-entry" role="doc-biblioentry">
Schiffer, Stephen R. 1987. <em>Remnants of Meaning</em>. Bradford Book.
Cambridge, Mass ; London: MIT Press.
</div>
<div id="ref-Schmid:2008" class="csl-entry" role="doc-biblioentry">
Schmid, Hans Bernhard. 2008. <span>“Plural Action.”</span>
<em><span>Philosophy of the Social Sciences</span></em> 38 (1): 25–54.
<a
href="https://doi.org/10.1177/0048393107310877">https://doi.org/10.1177/0048393107310877</a>.
</div>
<div id="ref-Schmid:2013_self" class="csl-entry" role="doc-biblioentry">
———. 2013. <span>“Plural Self-Awareness.”</span> <em><span>Phenomenology
and the Cognitive Sciences</span></em> 13 (1): 1–18. <a
href="https://doi.org/10.1007/s11097-013-9317-z">https://doi.org/10.1007/s11097-013-9317-z</a>.
</div>
<div id="ref-schweikard:2021_collective" class="csl-entry"
role="doc-biblioentry">
Schweikard, David P., and Hans Bernhard Schmid. 2021. <span>“Collective
<span>Intentionality</span>.”</span> In <em>The <span>Stanford
Encyclopedia</span> of <span>Philosophy</span></em>, edited by Edward N.
Zalta, Fall 2021. <span>Metaphysics Research Lab, Stanford
University</span>.
</div>
<div id="ref-Searle:1990em" class="csl-entry" role="doc-biblioentry">
Searle, John R. 1990. <span>“Collective Intentions and Actions.”</span>
In <em>Intentions in Communication</em>, edited by P. Cohen, J. Morgan,
and M. E. Pollack, 90–105. Cambridge: Cambridge University Press.
</div>
<div id="ref-searle:2007_grice" class="csl-entry"
role="doc-biblioentry">
———. 2007. <span>“Grice on <span>Meaning</span>: 50 <span>Years</span>
<span>Later</span>.”</span> <em>Teorema: Revista Internacional de
Filosof<span>í</span>a</em> 26 (2): 9–18. <a
href="https://www.jstor.org/stable/43046682">https://www.jstor.org/stable/43046682</a>.
</div>
<div id="ref-sellars:1963_imperatives" class="csl-entry"
role="doc-biblioentry">
Sellars, Wilfred. 1963. <span>“Imperatives, Intentions, and the Logic of
’Ought".”</span> In <em>Morality and the Language of Conduct</em>,
edited by Héctor-Neri Castaneda and George Nakhnikian, 159–218. Detroit:
Wayne State University Press.
</div>
<div id="ref-setiya:2022_intention" class="csl-entry"
role="doc-biblioentry">
Setiya, Kieran. 2022. <span>“Intention.”</span> In <em>The
<span>Stanford Encyclopedia</span> of <span>Philosophy</span></em>,
edited by Edward N. Zalta and Uri Nodelman, Winter 2022.
<span>Metaphysics Research Lab, Stanford University</span>.
</div>
<div id="ref-smith:2015_shared" class="csl-entry"
role="doc-biblioentry">
Smith, Thomas H. 2015. <span>“Shared <span>Agency</span> on
<span>Gilbert</span> and Deep Continuity.”</span> <em>Journal of Social
Ontology</em> 1 (1): 49–57. <a
href="https://doi.org/10.1515/jso-2014-0045">https://doi.org/10.1515/jso-2014-0045</a>.
</div>
<div id="ref-starmans:2012_folk" class="csl-entry"
role="doc-biblioentry">
Starmans, Christina, and Ori Friedman. 2012. <span>“The Folk Conception
of Knowledge.”</span> <em>Cognition</em> 124 (3): 272–83. <a
href="https://doi.org/10.1016/j.cognition.2012.05.017">https://doi.org/10.1016/j.cognition.2012.05.017</a>.
</div>
<div id="ref-starmans:2013_taking" class="csl-entry"
role="doc-biblioentry">
———. 2013. <span>“Taking <span>‘Know’</span> for an Answer: A Reply to
Nagel, San Juan, and Mar.”</span> <em>Cognition</em> 129 (3): 662–65. <a
href="https://doi.org/10.1016/j.cognition.2013.05.009">https://doi.org/10.1016/j.cognition.2013.05.009</a>.
</div>
<div id="ref-steele:2020_decision" class="csl-entry"
role="doc-biblioentry">
Steele, Katie, and H. Orri Stefánsson. 2020. <span>“Decision
<span>Theory</span>.”</span> In <em>The <span>Stanford
Encyclopedia</span> of <span>Philosophy</span></em>, edited by Edward N.
Zalta, Winter 2020. <span>Metaphysics Research Lab, Stanford
University</span>.
</div>
<div id="ref-Sugden:2000mw" class="csl-entry" role="doc-biblioentry">
Sugden, Robert. 2000. <span>“Team Preferences.”</span> <em>Economics and
Philosophy</em> 16: 175–204.
</div>
<div id="ref-thompson:2008_life" class="csl-entry"
role="doc-biblioentry">
Thompson, Michael. 2008. <em>Life and Action: Elementary Structures of
Practice and Practical Thought</em>. <span>Cambridge,
Massachusetts</span>: <span>Harvard University Press</span>.
</div>
<div id="ref-Tollefsen:2005vh" class="csl-entry" role="doc-biblioentry">
Tollefsen, Deborah. 2005. <span>“Let’s Pretend: Children and Joint
Action.”</span> <em>Philosophy of the Social Sciences</em> 35 (75):
74–97.
</div>
<div id="ref-Tomasello:2007gl" class="csl-entry" role="doc-biblioentry">
Tomasello, Michael, and Malinda Carpenter. 2007. <span>“Shared
Intentionality.”</span> <em>Developmental Science</em> 10 (1): 121–25.
</div>
<div id="ref-tuomela_we-intentions_1988" class="csl-entry"
role="doc-biblioentry">
Tuomela, Raimo, and Kaarlo Miller. 1988. <span>“We-Intentions.”</span>
<em>Philosophical Studies</em> 53 (3): 367–89. <a
href="https://doi.org/10.1007/BF00353512">https://doi.org/10.1007/BF00353512</a>.
</div>
<div id="ref-zawidzki:2013_mindshaping" class="csl-entry"
role="doc-biblioentry">
Zawidzki, Tadeusz Wieslaw. 2013. <em>Mindshaping</em>. Cambridge, MA.:
<span>MIT Press</span>.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Where I use ‘aggregate’, others have used ‘collective’
<span class="citation" data-cites="bjornsson:2017_corporate">(Björnsson
and Hess 2017, 274)</span> and ‘group’ <span class="citation"
data-cites="list_pettit:2011">List and Pettit (2011, 74)</span>.
Although more familiar, I have avoided these terms because they seem to
me to risk inviting confusing aggregate subjects and plural subjects.<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><span id="fn:no-shared-intention"
label="fn:no-shared-intention"></span> This is not an exhaustive
division of strategies. It would also be possible to reject the idea
that we need a notion of shared intention at all. Although beyond the
scope of this essay, there are interesting discussions which may
motivate considering this view in <span class="citation"
data-cites="baier:1997_joint">Baier (1997)</span>, <span
class="citation" data-cites="chant_unintentional_2007">Chant
(2007)</span>, <span class="citation"
data-cites="petersson_collectivity_2007">Petersson (2007)</span>, and
<span class="citation" data-cites="longworth:2019_sharing">Longworth
(2019, 13ff)</span>.</p>
<p>It is also not the only way of dividing strategies. <span
class="citation" data-cites="schweikard:2021_collective">Schweikard and
Schmid (2021, sec. 3)</span> offer a division into ‘content-, mode-, and
subject-accounts of collective intentionality.’ These cut across the
division into plural, aggregate and reductive. Both the plural subject
and the aggregate subject strategies yield ‘subject-accounts’ while the
reductive strategy would yield content-accounts.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>See <span class="citation"
data-cites="list_pettit:2011">List and Pettit (2011, 33)</span> on
‘joint intentions’ and <span class="citation"
data-cites="bratman:2022_shared">Bratman (2022a, 135ff)</span> on
‘institutional intentions’.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><span class="citation"
data-cites="gilbert:2009shared">Gilbert (2009, 175)</span> does offer a
theory which appears to involve stipulations about ordinary agents’
views. But this is not supported by investigation, nor is there any
explicit suggestion that an investigation would support the theory.
Others have attempted to investigate aspects of how well Gilbert’s
theory captures ordinary agents’ views <span class="citation"
data-cites="gomez-lavin:2019_normativity michael:2022_intuitions">(Gomez-Lavin
and Rachar 2019; Michael and Butterfill 2022)</span>. But those
researchers are careful to distinguish the aims of their investigations
from supporting, or refuting, Gilbert’s philosophical position. The
leading philosophical theories of attitudes and norms are about ways
people might reasonably be. It is all entirely hypothetical.<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>See <span class="citation"
data-cites="bratman:2014_book">Bratman (2014, 8)</span>: ‘This is the
continuity thesis. As we might try saying: once God created individual
planning agents and placed those agents in a world in which they have
relevant knowledge of each other’s minds, nothing fundamentally
new-conceptually, metaphysically, or normatively-needs to be added for
there to be modest sociality.’<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Here I am assuming Ontological Innocence, which is a
controversial claim <span class="citation"
data-cites="linnebo:2022_plural">(Linnebo 2022, sec. 5)</span>.<a
href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Note that this line of objection could be pursued
independently of whether intentions are mental states. On some views,
intentions are not mental states <span class="citation"
data-cites="thompson:2008_life russell:2018_intention">(Thompson 2008;
Russell 2018)</span> but having them might nevertheless require having a
mind.<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Alternative motivation for intentions without much in
the way of other mental states is offered by Bratman’s characterisation
of what he calls ‘social-procedural-rule-based institutional Intentions’
<span class="citation" data-cites="bratman:2022_shared">(Bratman 2022a,
147–50)</span>.<a href="#fnref8" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>I am grateful to an anonymous reviewer for observing
that <span class="citation" data-cites="rovane:1998_bounds">Rovane
(1998, 137ff)</span> offers an extended discussion of the possibility
that very committed people might, over time, achieve such a high degree
of rational unity that ‘it would not be possible to engage just one of
its human constituents separately’ (p. 141). (The scenario I am
imagining is merely one in which being a plural subject is taken as a
normative ideal.)<a href="#fnref9" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>See
https://correctiv.org/top-stories/2021/10/21/cumex-files-2/<a
href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>The construction is borrowed from <span
class="citation" data-cites="Bacharach:2006fk">Bacharach (2006)</span>
and <span class="citation" data-cites="Sugden:2000mw">Sugden
(2000)</span>. I am not claiming that their views require aggregate
subjects, only that some of their ideas can be (mis?)used to develop the
aggregate subject strategy.<a href="#fnref11" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>Whereas <span class="citation"
data-cites="Gold:2007zd">Gold and Sugden (2007)</span> appear to defend
their view as the only kind of shared intention, <span class="citation"
data-cites="pacherie:2013_lite">Pacherie (2013)</span> explicitly offers
a view on which the aggregate subject strategy and the reductive
strategy each characterise forms of shared intention. Also, as none of
these researchers present their views as involving aggregate subjects,
my suggestion is only that we can use their ideas in pursuing the
aggregate subject strategy.<a href="#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>See <span class="citation"
data-cites="Schiffer:1987zb">Schiffer (1987, 265)</span>: ‘if one were
to make a list of all the things philosophers have in mind when they
talk of “theories of meaning or intentional content,” then I would claim
that there are no true theories satisfying the descriptions on that
list. The questions being asked [...] that would require positive
theories as answers all have false presuppositions.’<a href="#fnref13"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Individual theorists have expressed both views. For
instance, <span class="citation"
data-cites="ludwig_collective_2007">Ludwig (2007)</span> positions his
view as characterising something distinct from Bratman’s, while <span
class="citation" data-cites="pacherie:2013_lite">Pacherie (2013)</span>
positions her view as a revision of Bratman’s. My question is whether
interpreting their views contrary to their statements would be
theoretically coherent.<a href="#fnref14" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>There is room for uncertainty about whether Gilbert’s
theory meets the requirement about no fundamental discontinuities. <span
class="citation" data-cites="smith:2015_shared">Smith (2015,
55ff)</span> argues that it does, at least ‘to the extent that
Bratman’s’ does. <span class="citation"
data-cites="bratman:2015_shareda">Bratman (2015, 75)</span> objects to
this claim on the grounds that ‘[t]he capacity to participate in the
creation of [...] plural commitments does [...] go beyond capacities
that are involved in individual agency.’<a href="#fnref15"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>Searle does not use the term ‘we-intention’, which was
notably used by <span class="citation"
data-cites="tuomela_we-intentions_1988">Tuomela and Miller
(1988)</span>. (Those authors credit <span class="citation"
data-cites="sellars:1963_imperatives">Sellars (1963)</span>, although he
does not use exactly that term.) Following <span class="citation"
data-cites="gilbert:2007_searle">Gilbert (2007, 33)</span>, it has
become common to use this term in discussing Searle.<a href="#fnref16"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><span class="citation"
data-cites="linnebo:2022_plural">Linnebo (2022, sec. 5)</span>
identifies this as ‘the traditional view in analytic philosophy’ (which
Linnebo does not endorse).<a href="#fnref17" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>I am grateful to an anonymous referee for suggesting
this possibility.<a href="#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p>See, for example, <span class="citation"
data-cites="Tomasello:2007gl">Tomasello and Carpenter (2007)</span>,
<span class="citation" data-cites="Rakoczy:2007ou">Rakoczy and Tomasello
(2007)</span>, <span class="citation" data-cites="Moll:2007gu">Moll and
Tomasello (2007)</span> and <span class="citation"
data-cites="Grafenhain:2010zl">Gräfenhain et al. (2009)</span>. Note
that these researchers smoosh together incompatible philosophical
theories when introducing notions of shared intention. The insights
being applied are common to many theories and do not depend on the
correctness of any one theory.<a href="#fnref19" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>For an illustration of how this might begin, see <span
class="citation" data-cites="bratman:2014_book">Bratman (2014, chap.
6)</span> who investigates how a reductive approach may enable the
construction of plural and aggregate subjects.<a href="#fnref20"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>See <span class="citation"
data-cites="gomez-lavin:2019_normativity">Gomez-Lavin and Rachar
(2019)</span>. Although their study is not directly concerned with
shared intention, their approach may illuminate how their participants
represent joint activities.<a href="#fnref21" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</div>

---

Title: Coordinated decision-making boosts altruistic motivation—But not trust
Authors: Chennells, Matthew and Woźniak, Mateusz and Butterfill, Stephen and Michael, John
Year: 2022
Journal: PLOS ONE
Type: Publication

# Abstract  

In the current study, we separately tested whether coordinated decision-making increases altruism and whether it increases trust. To this end, we implemented a paradigm in which participants repeatedly perform a coordinated decision-making task either with the same partner on every trial, or with a different partner on each trial. When both players coordinate on the same option, both are rewarded. In Experiment 1 (N=52) , participants were sometimes presented with tempting opportunities to defect. In Experiment 2 (N=97) , participants sometimes had to decide whether or not to trust that their partners had resisted such tempting opportunities. The results show that repeatedly coordinating with the same partner increased participants’ resistance to temptation (Experiment 1) but did not increase trust (Experiment 2). These findings support the hypothesis that coordinating with a partner increases altruistic motivation towards that partner; they do not support the hypothesis that coordinating boosts trust.  


<div class="fulltext">

# Introduction  

The versatility and flexibility of human cooperation is unparalleled by any other species. We routinely work together to achieve ends that we could not achieve alone, even setting aside short-term interests to maximize the benefits to our interaction partners and larger social groups. In recent decades, a substantial body of research in evolutionary theory, experimental economics and psychology has been devoted to investigating the evolutionary origins of human cooperation [1–5].  

This research on the evolution of cooperation also informs and constrains research into the cognitive and motivational mechanisms that proximally support cooperation. For example, theoretical work on the evolution of cooperation–specifically, on direct [6] and indirect reciprocity [7], competitive altruism [8], and the interdependence hypothesis [8]–provides us with reasons to expect that people’s willingness to cooperate with another agent should be strengthened by any cue that one is likely to interact with that agent in the future. One such cue could be the act of coordination itself: when two agents have coordinated with each other–i.e. when they mutually adapt their decisions or actions to bring about a shared goal or compatible but distinct individual goals [4, 9]–each may come to perceive the other as an in-group member or a valuable partner, or both. If so, then coordination with a partner now may boost people’s  

Competing interests: The authors have declared that no competing interests exist.  

willingness to cooperate with that partner in future–i.e., to coordinate with them despite the availability of alternative options which may be individually preferable [9]. And indeed, previous research has shown that people’s willingness to cooperate in social dilemmas may be fostered by repeated coordination in decision-making [10, 11] or in action [12, 13].  

This raises the further question as to what the specific cognitive and motivational mechanisms are by which coordination increases cooperation. One possibility is that coordination may enhance trust in one’s partner. This is the hypothesis put forward by Rusch and Luetge [11]; we will refer to it as the ‘trust hypothesis’. They reasoned that coordination with a partner may lead people to perceive their partner as being reliable in general, and therefore also as someone who is likely to resist the temptation to behave selfishly. As a result, people should be more likely to cooperate with a partner with whom they share a history of coordination. And indeed, this rationale is consistent with the results of an earlier study [14] in which it was shown that cooperation rates in a prisoners’ dilemma were higher if participants had previously performed a coordination game together than if they had not. Building on this, it was found [11] that cooperation rates in a prisoners’ dilemma were boosted when rounds of the prisoners’ dilemma were interspersed among rounds of a coordination game (i.e. the stag hunt) played together with a fixed partner.  

But while the trust hypothesis may explain why people would be more likely to expect their partners to cooperate in a prisoners’ dilemma when they have repeatedly been coordinating with the same partner than when they have been coordinating with different partners, it does not directly explain why people would then themselves be motivated to cooperate. Indeed, if one expects the other player in a prisoners’ dilemma to cooperate, then one can expect to attain the highest possible reward by defecting. An increase in trust could only explain why people who want to cooperate do not defect in order to avoid being exploited, not why they would be willing to cooperate at a cost to themselves. Moreover, it is worth noting that a track record involving feedback on the results of coordination with a partner who coordinated when it was in her interest to do so does not directly provide evidence that that partner would resist tempting alternatives if they were to arise. Taken together, these considerations provide grounds to scan the conceptual landscape for potential alternative hypotheses to explain the documented effects of coordination upon cooperation in prisoners’ dilemmas.  

Our starting point in this regard is the observation, alluded to above, that cooperation in prisoners’ dilemmas requires not only trust that the other player will cooperate, but also a willingness to pay a cost in order to cooperate. On this basis, the alternative hypothesis that suggests itself is that coordination may increase cooperation by eliciting altruistic motivation–i.e. by boosting the willingness to pay a cost in order to cooperate. In referring to the willingness to pay a cost to cooperate as an altruistic motivation, we are relying on ‘a behavioural—in contrast to a psychological—definition of altruism as being [willing to perform] costly acts that confer economic benefits on other individuals’ [15, p.1]. In this sense, an altruistic motivation is any motivation to perform costly acts that benefit others, and the hypothesis under consideration, which we will call the ‘altruism hypothesis’, is that coordination boosts any motivation to perform costly acts that benefit others.  

Accordingly, the altruism hypothesis that we are considering here is broad in the sense that it is consistent with a range of specific hypotheses about the nature of the altruistic motivation elicited by coordination (i.e. the proximal mechanism), and also with a range of specific hypotheses about evolutionary origins (i.e. the distal mechanism). For example, it is consistent with a line of reasoning based upon the interdependence hypothesis, which states that human cooperation arose in a period in which our ancestors lived in small groups of individuals whose interests were largely interdependent, and for whom it was therefore not typically beneficial to act selfishly to the detriment of other group members [8]. Insofar as repeated coordination with a partner may provide a cue that one has a stake in their welfare, this line of reasoning suggests that coordination may boost cooperation by boosting altruistic motivation towards one’s partner. But the altruism hypothesis is also consistent with direct or indirect reciprocity, as well as competitive altruism, insofar as repeated coordination may indicate that one is likely to interact with the same partner in the future or that the interaction is relevant for one’s reputation.  

Moreover, the altruism hypothesis under consideration here is also consistent with the idea that a history of collaboration with a partner creates a sense of debt, boosting altruistic sharing with that partner due to feeling obligated to share or be generous [16]. The altruism hypothesis is also consistent with the idea that coordination makes social expectations salient and thereby gives rise to a sense of commitment to one’s coordination partner [17, 18]. And it is consistent with the conjecture that interpersonal synchrony and minimal forms of interpersonal engagement trigger altruistic behaviour [19–23].  

Research to date has not distinguished the trust hypothesis from the altruism hypothesis. For example, the authors of one study conclude simple reciprocal interactions lead children to believe their relationships are characterised by mutual care and commitment [21]. Yet their evidence of children acting being more willing to act for others’ benefit after coordinating is consistent with the altruism hypothesis under consideration: the additional commitment that coordination leads to a level of mutual care for each other is not further tested. Importantly, a similar point applies to the studies using prisoners’ dilemmas to measure agents’ willingness to cooperate [11, 14] which are used to support the trust hypothesis: as altruistic motivation can increase participants’ willingness to cooperate even in the absence of trust, it is difficult to determine to what extent, if at all, people’s trust that their partner will cooperate mediates cooperation rates in prisoners’ dilemmas.  

# The current research  

We conducted two pre-registered experiments. As outlined in Fig 1, the experiments separately tested two distinct, albeit compatible, hypotheses about the mechanisms by which coordination increases cooperation. We aimed in Experiment 1 to investigate whether coordination might boost cooperation via an increase in altruistic motivation (the altruism hypothesis), and in Experiment 2 to investigate whether it does so via an increase in trust (the trust hypothesis). The experiments were designed to tease apart the potential effects of altruistic motivation and trust, with each study design isolating one of these hypotheses. Importantly, our main interest was in the effect of coordination per se; that is, whether the mere act of coordinating with a partner cued one or both proximal mechanisms, independently of evidence participants receive about their partners’ behaviour (i.e. feedback). Our two hypotheses were as follows:  

The Altruism Hypothesis (Hypothesis 1): Repeated coordination elicits altruistic motivation towards one’s partner (Experiment 1).  

The Trust Hypothesis (Hypothesis 2): Repeated coordination elicits trust towards one’s partner (Experiment 2).  

# Experiment 1  

To test Hypothesis 1, Experiment 1 probed the effects of repeated coordination upon altruism independently of trust. To this end, we implemented a sequential joint decision-making task in which participants could choose whether or not to coordinate with a partner. We varied whether and to what degree the option not to coordinate constituted a temptation and measured the frequency with which participants chose to coordinate despite this temptation  

![](/public/img/articles/chennells2022_coordinated/804a86ab0555546c45a4ea1ca5ad380c23fe9907531dfd2397eb531b6aed885c.jpg)  
Fig 1. The current study aims to answer the question of why it is that repeated coordination may boost one’s willingness to cooperate with one’s partner, by testing separately for the emergence of altruistic motivation (Hypothesis 1) and trust (Hypothesis 2) towards one’s partner.  

Ourquestion:Whichvariableorvariables mediatetherelationbetweenrepeated coordination and willingness to cooperate?  

Hypothesis 1: Repeated coordination boosts cooperation by eliciting altruistic motivation towards one's partner (Experiment 1).  

Hypothesis 2: Repeated coordination boosts cooperation by eliciting trust towards one's partner (Experiment 2).  

(altruism rates). In a within-subjects design, we manipulated the partner’s relationship: in one experimental block, participants played with the same partner on every trial (Fixed Partner Condition), whereas in a separate experimental block they played with different partner on each trial (Variable Partners Condition). Crucially, the choices made by their partners could not affect them negatively, and they were informed that their partners would receive no feedback about their choices. This ensured that participants’ willingness to coordinate could only be explained by altruistic motivation, not by trust or by any expectation of reciprocity.  

The data from both experiments, as well as the base regression models mentioned in Tables 1 and 3, can be found at: https://osf.io/f4rqj/. The pre-registration for this experiment can be accessed at: https://osf.io/fnj6r/.  

# Participants  

Using $\mathbf{G}^{*}$ Power 3.1 [24] we determined that a sample size of 52 in a within-subjects design would provide $80\%$ statistical power for detecting a medium-sized effect (Cohen’s $\mathrm{d}=0.4$ ) equivalent to what we observed in a pilot study. We therefore recruited 52 participants (33 females, 18 males, 1 other; age range: 18–40, $M=21.9$ , $S D=4.4$ ). All participants were recruited through the University of Warwick SONA System. All participants reported speaking and understanding English. Participants provided their informed written consent prior to the testing. Ethics clearance for Experiment 1 was obtained from the University of Warwick Humanities and Social Sciences Research Ethics Committee (HSSREC), and all methods were performed in accordance with the Declaration of Helsinki.  

# Apparatus and stimuli  

The experiment was displayed on a 24-inch wide screen (16:9) computer monitor (resolution: $1920\mathrm{~x~}1080$ pixels, framerate $=60\mathrm{Hz}.$ ), consistent across participants and experiment sessions.  

Table 1. Analysis results from Experiment 1 using mixed-effects logistic regressions of partner condition and temptation level on subject’s choices. Model 1 is used for inferring the effect of partner condition on altruism rates; it contains a by-subject random coefficient for this variable. Likewise, Model 2 is used for inferring the effect of temptation level on altruism rates; it contains a by-subject random coefficient for this variable.   


<html><body><table><tr><td rowspan="4">Dependentvariable=Altruism choice</td><td colspan="5">Model 1</td><td colspan="5">Model2</td></tr><tr><td></td><td colspan="3">95%CIfor oddsratio</td><td></td><td></td><td></td><td colspan="3">95%CIforoddsratio</td></tr><tr><td>B (SE)</td><td>p=</td><td>Lower</td><td>Odds Ratio</td><td>Upper</td><td>B (SE)</td><td>p=</td><td>Lower</td><td>Odds Ratio</td><td>Upper</td></tr><tr><td>0.426</td><td>.038</td><td>1.023</td><td>1.532</td><td>2.371</td><td>0.301</td><td>.029</td><td>1.025</td><td>1.351</td><td>1.782</td></tr><tr><td></td><td>(0.205)</td><td></td><td></td><td></td><td></td><td>(0.138)</td><td></td><td></td><td></td><td></td></tr><tr><td>TemptationLevel</td><td>-0.898</td><td>.000</td><td>0.390</td><td>0.407</td><td>0.425</td><td>-1.277</td><td>.000</td><td>0.190</td><td>0.279</td><td>0.397</td></tr><tr><td></td><td>(0.022)</td><td></td><td></td><td></td><td></td><td>(0.181)</td><td></td><td></td><td></td><td></td></tr><tr><td>Constant</td><td>1.162</td><td>.001</td><td>1.594</td><td>3.195</td><td>6.546</td><td>0.252</td><td>.582</td><td>0.510</td><td>1.288</td><td>3.255</td></tr><tr><td></td><td>(0.352)</td><td></td><td></td><td></td><td></td><td>(0.460)</td><td></td><td></td><td></td><td></td></tr><tr><td>By-subjectrandomcoefficient</td><td colspan="6">PartnerCondition</td><td colspan="4">Temptation Level</td></tr><tr><td>Observations</td><td colspan="6">8,320 8,320</td><td colspan="5"></td></tr><tr><td>Log Likelihood</td><td colspan="6">-2,813.80</td><td colspan="5">-2,394.80</td></tr><tr><td>AIC</td><td colspan="6">5,641.60</td><td colspan="5">4,803.70</td></tr></table></body></html>  

Dependent variable is a choice dummy equal to 1 if subject chose altruistic option and 0 if alternative option. Partner Condition dummy equal to 1 in Fixed Partner Condition and 0 in Variable Partners Condition. Both regressions include as covariates a by-subject random intercept and a by-subject random coefficient for trial number.  

Table 2. Overview of differences in how participant and partner are impacted by each other’s choices in Experiments 1 and 2.   


<html><body><table><tr><td></td><td>Whochooseswhethertocoordinate</td><td>Partnerimpacted byParticipant's choice</td><td>ParticipantimpactedbyPartner'schoice</td></tr><tr><td>Experiment1(altruism,nottrust)</td><td>Participant only</td><td>yes</td><td>no</td></tr><tr><td>Experiment2(trust,notaltruism)</td><td>Partner only</td><td>no</td><td>yes</td></tr></table></body></html>  

Table 3. Analysis results from Experiment 2 using mixed-effects logistic regressions of partner condition and partner temptation level on participants’ choices. Regression models are identical to those used in Experiment 1. Again, Model 1 and Model 2 are used for inferring the effects of partner condition and temptation level, respectively, on trust rates, given the inclusion of their corresponding by-subject random coefficients.   


<html><body><table><tr><td rowspan="3">DependentVariable=Trust Choice</td><td colspan="4">Model 1</td><td colspan="5">Model2</td></tr><tr><td></td><td colspan="3">95%CI for odds ratio</td><td></td><td colspan="4">95%CI for odds ratio</td></tr><tr><td>B (SE)</td><td>p= Lower</td><td colspan="2">Odds Ratio</td><td>Upper B (SE)</td><td>p=</td><td colspan="3">Lower Odds Ratio</td></tr><tr><td>Partner Condition</td><td>-0.337</td><td>.000</td><td>0.589</td><td>0.714</td><td>0.860</td><td>-0.493 .000</td><td>0.508</td><td>0.611</td><td>Upper 0.725</td></tr><tr><td></td><td>(0.096)</td><td></td><td></td><td></td><td></td><td>(0.089)</td><td></td><td></td><td></td></tr><tr><td rowspan="2">PartnerTemptationLevel</td><td>-0.927</td><td>.000</td><td>0.382</td><td>0.396</td><td>0.409</td><td>-2.030 .000</td><td>0.082</td><td>0.131</td><td>0.198</td></tr><tr><td>(0.017)</td><td></td><td></td><td></td><td>(0.215)</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan="2">Constant</td><td>-0.958</td><td>.052</td><td>1.678</td><td>2.607</td><td>4.064</td><td>1.240</td><td>.000 2.239</td><td>3.457</td><td>5.405</td></tr><tr><td>(0.223)</td><td></td><td></td><td></td><td>(0.221)</td><td></td><td></td><td></td><td></td></tr><tr><td>By-subjectrandom coefficient</td><td colspan="5">Partner Condition</td><td colspan="4">PartnerTemptationLevel</td></tr><tr><td>Observations</td><td colspan="5">12,339</td><td colspan="4">12,339</td></tr><tr><td>Log Likelihood</td><td colspan="5">-4,635.10</td><td colspan="5">-3,724.10</td></tr><tr><td>Akaike Inf. Crit.</td><td colspan="5">9,284.20</td><td colspan="5">7,462.30</td></tr></table></body></html>  

Dependent variable is a choice dummy equal to 1 if subject chose trusting option and 0 if alternative option. Partner condition dummy equal to 1 in Fixed Partner Condition and 0 in Variable Partners Condition. Both regressions include as covariates a by-subject random intercept and a by-subject random coefficient for trial number.  

The program for the experiment was written in Open Sesame [25]. The two choice options were presented as $7\mathrm{cm}\mathrm{\bfx}5\mathrm{cm}$ rectangular fields, separated by $36\mathrm{cm}$ . The mouse start field was also $7\ c m\times5\mathrm{cm}$ and was positioned $18\mathrm{cm}$ lower at the midpoint between the two choice options. During trials, participants used the mouse to select by clicking on one of their choice options. The computer screen provided participants with real-time visual feedback on their inputs.  

# Design  

Experiment 1 had a 2 (Partner Condition: Fixed Partner vs. Variable Partners) $\mathbf{x}8$ (participant reward temptation level) repeated measures design. Both factors were within-subject.  

# Procedure  

After participants had given their informed written consent, they were told that they would be paired with various partners during the experiment. They performed the experiment in group sessions of 12–16 people. Participants were instructed that both their own and their partner’s monetary payments at the end of the experiment would depend on the points accumulated during their task. They were informed that in addition to the £5 show-up fee, they would also be paid a bonus up to a maximum £5 based on the number of points they earned during one randomly selected trial of the experiment, and that the same was true for their partner(s). Instructions were displayed on the screen and participants read them on their own. Participants were encouraged to take as much time as they needed and had the opportunity to ask clarification questions during the instructions phase; questions and their answers were repeated in public for all participants to hear. The task began when all participants confirmed that they understood the instructions. At the beginning of the experiment participants were assigned a player number between 0 and 20. They were told that their partner(s) would see this number when interacting together, that they would, in turn, also see their partner’s number, and that these numbers remained constant throughout the experiment. Participants were thus led to believe they were interacting with real people; in reality, player numbers were pre-set and participants interacted with pre-programmed virtual partners.  

The experiment lasted approximately 40 minutes, during which participants performed two experimental blocks, one with a Fixed Partner and one with Variable Partners. The order of blocks was counterbalanced across participants. In each experimental block participants underwent an induction phase consisting of 10 trials, which was immediately followed by a test phase consisting of 80 trials, making both phases look like one uninterrupted block.  

At the beginning of each trial (See Figs 2 and 3), a partner’s player number was displayed for $4000\mathrm{ms}$ , which was either the same (Fixed Partner Condition) or different (Variable Partners Condition) on each trial within a block. Afterwards a message “Your partner is choosing. . .” was displayed for a fixed duration of $3000\mathrm{ms}$ , to indicate to participants that their partner was choosing between two unseen options. The time was kept constant between trials so that participants could not infer anything about their partner’s decisions from the timing. Then, the participant was presented with a blank screen including a grey square and fixation cross where the mouse cursor began. Moving the cursor out of this square revealed to the participant two values to choose between. One of these, indicated in green or blue, was the value that their partner had chosen (coordination option); the other, indicated in orange, was the alternative value (alternative option). If the participant chose the coordination option, then both the participant and the partner would each receive the amount of points corresponding to the selected value. If the participant chose the alternative option, they received that amount of points, while her partner did not receive any points. The alternative option was tempting  

![](/public/img/articles/chennells2022_coordinated/f275eb73d897a73492d38aae4a8e3da592924d3f981be634de92975ad4a6c86f.jpg)  
Fig 2. Experiment 1 trial structure. At the beginning of each trial, an image of the partner’s player number was displayed, which was either the same (Fixed Partner Condition) or different (Variable Partners Condition) on every trial. Then, the partner chose one of two values. The participant did not see what these two values were, and did not see what the partner had chosen, but was then herself presented with two values to choose between. One of these, indicated in green or blue, was the same value that the partner had chosen (coordination option); the other, indicated in orange, was an alternative value (alternative option). We varied whether, and to what extent, the alternative option constituted a temptation.  

![](/public/img/articles/chennells2022_coordinated/058c78cec828fff2623d4e685614db761da13120c73a0e017554247dae003879.jpg)  
Fig 3. Experiment 1 payoff structure. Payoffs for each trial were determined as follows. If the participant chose the coordination option, then each received the corresponding amount (left box above). If the participant chose the alternative option, then the participant received the amount corresponding to the alternative option and their partner received no reward (right box above). Participants were thus aware that both their and their partner’s payoffs depended on the choice they made. Payoffs were displayed for $3000\mathrm{ms}$ before participants proceeded to the next trial. The amounts associated with the payoffs for participants’ coordination and alternative options varied, over pre-specified intervals and ranges, unpredictably across trials.  



when its value was greater than that of the coordination option, and the level of temptation which it presented was a function of the value of the alternative option. The values for the coordination options ranged from 250 to 450 points in increments of 50. The value of the alternative option was either 100 or 50 points lower, the same, or 50, 100, 150, 200, or 250 points higher than the coordination option, leading to eight different temptation levels present during the test phase within each block (resulting in 10 trials with each temptation level per block) presented in random order. In contrast to the test phase, the induction phase included 10 trials (presented in random order) with the following temptation levels: 4 trials in which the alternative option was 100 points less than the coordination option; 4 in which it was 50 less; and 2 in which it was the same. In each phase the position of the two options (coordinative and alternative) varied equally between the left- and right-hand sides of the screen, and the colour of the coordination option varied equally between blue and green.  

A trial proceeded when participant mouse-clicked on one of two options or after $3000\mathrm{ms}$ elapsed. After the participant made a choice, there was a $500\mathrm{ms}$ delay, and the payoffs were displayed for $3000\mathrm{ms}$ . The payoff display showed the participant’s choice, their partner’s ostensible choice, and the payoffs for each player. Participants were told that their partner would receive no feedback on the choices the participant made until one trial was randomly selected for payment at the end of the experiment. Payment was automatically calculated based on the choice made in the selected trial and participants were paid at the end of the experiment after all participants finished.  

# Results  

Hypothesis 1 predicts that altruism rates should be higher in the Fixed Partner Condition than in the Variable Partners Condition. To test this, we employed a mixed-effects logistic regression model on our dependent variable (DV), altruism rate, an indicator of participants’ trialby-trial choice (0: alternative option; 1: coordination option). Our two independent variables (IVs) of interest in the model were partner condition, a dummy equal to 1 if the participant’s trial in question was in the Fixed Partner block and 0 if in the Variable Partners block, and temptation level, a numerical variable ranging from -2 to 5 indicating the attractiveness of the  

![](/public/img/articles/chennells2022_coordinated/4d4e0c9f61b17ccc4b5607d062b434358de6191813f13638ddd502f69da54e09.jpg)  
Fig 4. Experiment 1 data. Graphs show mean altruism rates (proportion of trials in which participants chose the coordination option) by Partner Condition for the corresponding temptation level (see: Methods) of participants’ alternative option. Points represent where empirical data was collected, and error bars represent $95\%$ confidence intervals calculated using binomial tests. Regression results (see Table 1) show that altruism rates were significantly higher when participants coordinated with the same partner (Fixed Partner) on every trial than when coordinating with different partners (Variable Partners) on each trial. In addition, altruism rates are significantly decreasing with increases in the level of temptation of the alternative option.  



participant’s alternative option. We included a random effect to allow the intercept to vary by participant and a by-subject random coefficient for trial number to control for a time effect.  

One concern when using multiple-regression models to analyse data for confirmatory hypothesis testing is the possibility of inflated Type I error rates when specifying models with random effects–i.e. when incorrect random-effect structures are specified in the model, which do not reflect random effects present in the underlying population or fail to control for random measurement error in the data [26, 27]. It has been shown [26] that this is of particular concern with data generated by experimental designs which involve within-subject manipulations and multiple observations per treatment level per unit and where fixed effects of interest are estimated and tested for significance, as in the case of our paradigm. Not including random coefficients for fixed variables in the sample risks giving overconfident estimates that fail to account for weaker conditional independence between multiple within-subject observations [28]. To control for this, we include in our analysis by-subject random coefficients for both of our fixed independent variables of interest. This allows for participants to differ in the slopes of their responses, thus accounting for the nonindependence of data points. Given the models’ failure to converge when both random coefficients are present, we follow [26] in pursuing separate analyses for each.  

Table 1 shows the results of two regression models, each including the by-subject random coefficient corresponding to one of the IVs–partner condition (Model 1) and temptation level (Model 2). Fig 4 presents the data from Experiment 1, showing mean altruism rates by partner condition and by temptation level.  

Results shown in the column for Model 1 corroborate our prediction that altruism rates were significantly higher $(b=0.426,p=.038)$ when participants coordinated with the same partner (partner condition $=0$ ) on every trial than when coordinating with different partners on each trial (partner condition $=1$ ). The odds of subjects choosing the coordination option change by 1.53 ( $95\%$ conf. int.: 1.02, 2.37) when they coordinate with a fixed partner relative to coordinating with variable partners.  

As a manipulation check, we also predicted a negative main effect of temptation level (Model 2), with participants more likely to choose the alternative option as the payoff for doing so relative to the coordination option increased. The results confirm this prediction: temptation level is significantly associated with reduced altruism rates $b=-1.277$ , $p=.000)$ , all else constant. From Model 2, an increase in temptation level by one unit is associated with a 0.28 ( $95\%$ conf. int.: 0.19, 0.40) change in the odds of an altruistic choice.  

Finally, we ran an additional exploratory statistical test (not shown here; see Data Availability section), categorising temptation level into two factors (one factor for all levels less than or equal to 0 and another for all levels greater than zero; that is, temptation to act selfishly is either present or absent) and checking for an interaction with partner condition. We found a significant main effect of temptation level though not of partner condition, while finding an interaction between the two, implying that participants were more likely to cooperate with a fixed versus variable partner but only when there was a temptation to defect, thus supporting our hypothesis.  

# Experiment 2  

In Experiment 2, we adapted the paradigm used in Experiment 1 to investigate whether repeated coordination enhances trust (Hypothesis 2). While in Experiment 1, participants unilaterally chose whether to coordinate and thereby benefit or harm their partners, in Experiment 2 it was the partner who unilaterally chose whether to coordinate. This meant that participants in Experiment 2, who were not informed about which choice the partner had made, had to decide whether to trust that the partner had coordinated (see Table 2), or take a smaller, but safe, option which did not rely on the partner’s choice.  

To this end, in Experiment 2 we introduced a new game that differed in two ways from the previous game. First, participants could choose whether or not to trust their partners, where choosing to trust would potentially gain participants a higher reward but also implied a risk of receiving a lower reward if the trust was misplaced. Second, we ensured that participants’ choices in Experiment 2 had no effect on their partner’s payoffs, thereby excluding the possibility that any altruistic motivation could influence their choices.  

The pre-registration for this experiment can be accessed at: https://osf.io/kepj8.  

# Participants  

Using $\mathbf{G}^{*}$ Power 3.1 [24] we determined that for an increased statistical power of $95\%$ a sample size of 88 would detect a medium-sized effect (Cohen’s $\mathrm{d}=0.4$ ) equivalent to what we observed in our previous study. Sessions were structured to include between 16–20 participants and our stopping rule was such that we included data from all participants up to and including those participating in the final session in which we crossed the participant threshold. We therefore recruited 97 participants (53 females, 44 males; age range: 18–35, $M=20.8$ , $S D=2.4$ ), seated in the same computer lab under identical conditions as in Experiment 1. Participants who participated in Experiment 1 were not permitted to participate in Experiment 2. All participants were recruited through the University of Warwick SONA System. All participants reported speaking and understanding English. Participants provided their informed written consent prior to the testing. As with Experiment 1, ethics clearance for Experiment 2 was obtained from the University of Warwick Humanities and Social Sciences Research Ethics Committee (HSSREC), and all methods were performed in accordance with the Declaration of Helsinki.  

# Apparatus and stimuli  

The experiment was conducted using the same computers and settings (size, resolution, keyboard and mouse input) as in Experiment 1. The program for the experiment was written in JavaScript using the jsPsych toolbox [29]. Boxes were presented in a horizontal line on the screen, with partners’ choices separated from participants by a dark vertical line, while choice buttons were shown on a line below the boxes. During trials, participants responded using a computer mouse by clicking on one of two choice options. The computer screen displayed real-time visual feedback.  

# Design  

Experiment 2 had a 2 (partner condition: Fixed Partner vs. variable partner) $\mathbf{x}8$ (partner reward temptation condition) repeated-measures design. Both factors were within-subject.  

# Procedure  

The procedure of Experiment 2 was designed visually and procedurally to be as similar as possible to Experiment 1. In particular, the presentation of the partner’s player number showed either the same number (Fixed Partner Condition) or different numbers (Variable Partners Condition) on each trial, depending on the experiment block. Again, participants were instructed that both their own and their partner’s monetary payments at the end of the experiment would depend on the points accumulated during their task, which would vary between £5 and £10 and take maximum 1 hour. The procedure was therefore the same as in Experiment 1, except for the following changes (See Figs 5 and 6). First, after displaying one’s partner’s number, two boxes (colours green and blue) containing payoff options appeared horizontally on the screen (purportedly visible to both participant and partner), one box positioned in the middle of the screen (coordination option) and the other on either the right- or left-hand side of the screen (partner’s alternative option). Each box contained two values representing points: a value on top for the partner’s points and a value on the bottom for the participant’s points. The box in the middle always contained a value of 500 for both partner and participant. The partner’s alternative box always contained some positive value, ‘A’, for the partner and a value of zero for the participant. Value ‘A’ ranged, unpredictably, between 400–700 points in increments of 50. Thus, the differential between the partner’s value in the middle box (500) and the side-aligned box (value A) ranged from 100 points lower to 250 higher. Participants waited while their partner ostensibly selected b7etween one of these two green and blue boxes. The duration of the partner’s selection phase was always $4000\mathrm{ms}$ , matching the amount of time available to the participant to make their own choice.  

Then, an additional box of a different colour (orange) appeared on the empty side of the screen (participant alternative option). The partner’s value in this box was unknown while the participant’s value was either 200 or 400. Thus, participant’s alternative option value was always lower than the central coordination option value. Two buttons simultaneously also appeared below the boxes, one to the left and one to the right-hand side of the screen. One contained the text “Enter” and the other “Exit”; participants clicked the former to choose coordination option and the latter if they wanted to select the guaranteed alternative option.  

Participants thus used these buttons to make their choices, based on how they believed their partner had previously behaved, with payoffs for each trial determined as follows. If both participant and partner chose their alternative options, each received the corresponding amount for certain. Conversely, if both chose the coordination option, each received the amount corresponding to coordination. However, crucially, if the participant chose the coordination option and the partner did not, then the partner received the amount corresponding  

![](/public/img/articles/chennells2022_coordinated/984550b11ea2827e37d2563e9b266725ce09ac5b9de13fdbcc4f7bc3e51c1fb7.jpg)  
Fig 5. Experiment 2 trial structure. At the beginning of each trial an image of the partner’s player number was displayed, which was either the same (Fixed Partner Condition) or different (Variable Partners Condition) on every trial. Next, two boxes (coloured in green and blue respectively) containing payoff options appeared on the screen, and the participant waited for a fixed duration of $4000\mathrm{ms}$ while the partner ostensibly selected one of these two boxes. Crucially, participants were led to believe that one of the options presented to the partner was a more or less tempting alternative option. Participants then chose whether to trust (i.e. to select the blue or green box) if they expected that their partner had previously chosen this same option, or to exit (i.e. to select the alternative option, in orange) if they did not trust their partner to have chosen the mutually beneficial option. Participants’ alternative options always entailed a lower reward.  


to their tempting alternative option, while the participant received nothing. If the partner chose the coordination option but the participant did not, the partner would nevertheless receive the amount corresponding to the coordination option, and the participant would receive the (lower) guaranteed amount of their alternative option.  

Participants therefore had the option of joining their partner (coordination option) if they trusted that their partner had previously chosen this option; or they could exit (alternative option) if they did not trust that their partner had chosen the mutually beneficial option. Their exit option entailed a guaranteed, yet lower, reward. Participants would thus only choose the  

![](/public/img/articles/chennells2022_coordinated/024263d7162aceccefec52353824b0ac7ee610f174fbbb4f34966abc840954d8.jpg)  
Payoff screen if participant chooses alternative option  

Fig 6. Experiment 2 payoff structure. If the participant chose the alternative option (orange), then payoffs were determined as in the top half of the figure above: the participant received the guaranteed amount (300), and the partner received the amount corresponding to the option s/he had chosen: 600 if $\mathsf{s/h e}$ had chosen the alternative option (blue) or 500 if she had chosen the coordination option (green). Conversely, if the participant chose the coordination option, the payoffs were determined as in the bottom half of the figure above: If the partner had chosen the coordination option (green), then each player received the corresponding amount (500); if the partner had chosen the then both chosen the alternative option (blue), the partner received the corresponding amount and the participant received 0. Participants should thus only choose the coordination option if they believed their partner had likewise done so. While payoffs for the coordination option and for participants’ alternative options were fixed, we varied the amount associated with the partner’s alternative option unpredictably across trials. Payoffs were displayed for a set amount of time before participants proceeded to the next trial.  


coordination option if they believed that their partner had also done so. Note that their partners’ rewards were unaffected by the participant’s decisions. While the payoffs for the coordination options and for participants’ alternative options were fixed (as described above), we varied the amount associated with partner’s alternative option unpredictably across trials. This allowed us to measure participants’ trust in their partner at varying levels of reward temptation for their partner; e.g. in some trials, the partner faced a high temptation to not coordinate while in other trials the reward for coordination and non-coordination were identical.  

Each trial ended when the participant clicked on one of the buttons to make a choice, or when $4000~\mathrm{ms}$ has elapsed (i.e. they automatically progressed to the next trial, receiving a bonus of zero for the missed attempt). After the participant made their selection, there was a $500\mathrm{ms}$ delay after which possible payoffs were displayed for $3000\mathrm{ms}$ . The reward display showed the following: the participant’s choice, their partner’s ostensible choice and the rewards for each player.  

The experiment lasted approximately 40 minutes, during which participants performed two experimental blocks, one in each condition, in counterbalanced order. In each experimental block, participants first underwent an induction phase consisting of 10 trials: 4 trials for which the alternative option was 100 less than the value for the coordination options; 4 for which it was 50 less; and 2 for which it was the same. There was no perceptible gap between the induction and test phases. As in Experiment 1, in the test phase of each experimental block, there were 64 test trials (80 including those in the induction phase), giving a total 124 trials across the two blocks. Within each block, for each of the 8 different levels of temptation there were 8 trials, drawn in random order. The position of the two options (coordination  

option and alternative option) varied equally between the left- and right-hand sides of the screen, and the colour of the coordination option varied equally between blue and green.  

Participants received no information about their partners’ choices, and were told that their partners would receive no feedback on the choices the participant made until one trial was randomly selected for payment at the end of the experiment. Payment was automatically calculated based on the choice made in the selected trial and participants were paid at the end of the experiment after all participants finished.  

# Results  

Table 3 shows the results of two regression models, each including, as in Experiment 1, the respective IV of interest’s corresponding by-subject random coefficient. Fig 7 presents the data from Experiment 2, showing mean trust rates by partner temptation level and by partner condition.  

Hypothesis 2 predicts higher trust rates in the Fixed Partner Condition than in the Variable Partners Condition. The results of mixed-effects logistic regressions do not corroborate this prediction. In fact, from Model 1, predicted trust rates were significantly lower $(b=-0.337,p=$ .000) when participants coordinated with the same partner across trials than when coordinating with different partners on every trial. The odds of choosing the coordination option change by 0.714 ( $95\%$ conf. int.: 0.589, 0.860) when subjects coordinate with a Fixed Partner relative to Variable Partners. This finding is difficult to reconcile with the hypothesis that repeated coordination enhances trust.  

As in Experiment 1, we performed a manipulation check by testing the prediction that there would be a negative main effect of partner temptation level. This was because participants should be less likely to expect their partner to coordinate when their partner’s alternative option was more tempting. The results in Model 2 confirm this prediction: at higher partner  

![](/public/img/articles/chennells2022_coordinated/3d17ab909ff84e06dcbd33f155e685036df449dc9c5977e567709c0118b089a9.jpg)  
Fig 7. Experiment 2 data. Graphs show mean trust rates (proportion of trials in which participants chose the coordination option) by partner condition for the corresponding temptation level of partners’ alternative option. Points represent where data was collected, and error bars represent $95\%$ confidence intervals calculated using binomial tests. Regression results (see Table 2) show that trust rates were significantly lower when participants coordinated with the same partner (Fixed Partner) on every trial than when coordinating with different partners (Variable Partners) on each trial. In addition, trust rates are significantly decreasing with increases in the level of partners’ temptation of the alternative option.  

temptation levels, participants were significantly less likely $(b=-2.03,p=.000)$ to trust their partner had chosen the coordination option.  

Finally, we again ran an additional exploratory statistical test (not shown), with temptation level categorised into two factors and checking for an interaction with partner condition. We found significant main effects for both temptation level and partner condition and a significant interaction between the two. This suggests that participants were (surprisingly) more likely to act as if they expected their partner to defect when facing a fixed versus variable partner, but only in situations in which there was no temptation for their partner to do so.  

# Discussion  

The findings from two experiments presented here build upon previous research showing that repeated coordination over time with the same partner can increase people’s willingness to cooperate with that partner–i.e. to coordinate even when doing so is not in their own shortterm interest [10, 11, 14]–relative to their willingness to cooperate with changing partners. Our findings (see Fig 8) extend this previous research by illuminating the underlying cognitive and motivational mechanisms underpinning the effects of coordination per se upon the willingness to cooperate. Specifically, the results from Experiment 1 provide evidence that pure repeated coordination with the same partner increases altruistic motivation towards that partner (the altruism hypothesis); the results of Experiment 2 do not support the hypothesis that pure repeated coordination (without the history of coordination success) with the same partner increases trust (the trust hypothesis).  

Our design also permits us to exclude the possibility that the effect of repeated coordination upon altruism was driven by adherence to specific conventions arising during the experiment, as in one earlier study [11]. This is because the values, colours and positions of the choices varied stochastically from one trial to the next, such that the coordination option could not take on the character of a convention.  

The absence of any positive effect of repeated coordination upon trust is consistent with rational decision-making insofar as a partner’s willingness to coordinate when it is in her interest does not directly provide evidence that she would resist tempting alternative offers. The finding that participants in fact exhibited less trust when playing with the same partner on every trial than when playing with a different partner in non-tempting trials is, on the face of it, more surprising. However, it is worth emphasizing that trust requires an element of risk due to dependence on another person. In Experiment 2 the balance of power was against participants–their partner could influence their payoff but they could not influence their partner’s payoff. Given this setup, a participant with variable partners likely expected that their partners will simply follow their own interests and predominantly choose the best options for them. However, in a condition with fixed partner the asymmetry of power might have also led a participant to believe that their partner might want to not only maximize their own payoff, but also to gain competitive advantage over the participant by choosing non-cooperative options even in non-tempting trials. As such our results suggest that in the absence of consistent feedback, repeated interaction when there is a power asymmetry might in fact lead to the decrease rather than increase of trust. The need to explore this and other possibilities provides an important avenue for further research.  

Further research on the cognitive and motivational foundations of human cooperativity may also draw upon the novel experimental designs developed here. One key innovation is the technique, employed in both experiments, of seamlessly alternating between coordination problems with aligned interests and social dilemmas without having to change the task structure. Moreover, the task designed for Experiment 2 constitutes an important innovation  

![](/public/img/articles/chennells2022_coordinated/57425969e45110ab2e3eb4969b545c5d5e239dec3431246607da477ec9f14467.jpg)  

Ourexperiments observedrelations Ourinferencesreliedonthe assumptionthat among these variables (cooperation was either trust or altruistic motivation or both not observed or manipulated) would increase willingness to cooperate  

There may be other mediating factors which we did not observe.  

![](/public/img/articles/chennells2022_coordinated/c1ce2662f3eb3ed7ece769b770db707259a93f2e976ecf1c474848d287779737.jpg)  
Fig 8. Our research investigated two competing hypotheses for why repeated coordination may boost an agent’s willingness to cooperate with their partner. Our studies relied on the background assumption that either trust or altruistic motivation, or both, would increase agents’ willingness to cooperate with their partners. In each of our two separate studies, we tested a distinct hypothesis and found evidence that repeated coordination boosts altruistic motivation towards one’s partner but found no evidence of an effect of repeated coordination on trust.  


insofar as it precisely isolates trust as a factor in decision-making, ruling out any influence of altruistic motivations or of expectations of reciprocity that may be confounded with trust in standard economic trust games [30]. This innovation does however also imply a limitation with respect to the possibility of comparing our two studies. This is that the decision to coordinate is up to participants in Experiment 1 but not in Experiment 2. In Experiment 2, participants cannot know whether their decision leads to coordination. Though we designed our tasks to be as similar as possible, our first priority was to separately isolate altruism  

(Experiment 1) and trust (Experiment 2), leading to an inherent imbalance of decision-making power between the two contexts.  

It is also worth reiterating that our experimental procedures did not involve feedback–i.e., participants in Experiment 1 were informed that their partners would receive not feedback about their decisions, and participants in Experiment 2 did not receive feedback about their partners’ decisions. The rationale for this implementation was that the inclusion of feedback would introduce other potential processes which may boost cooperation over and above the processes picked out by the hypotheses we aimed to test. And indeed some studies have shown that feedback and reputational concerns play an important role in sustaining cooperation between participants, perhaps by allowing inferences of trustworthiness and providing incentives to act in others’ interests. The fact that we found no evidence of a direct effect of coordination on trusting behaviour in the absence of feedback suggests that feedback about others’ trustworthiness may play an important role in leading people to draw such inferences. However, the fact that we found a direct effect on participants’ own willingness to bear personal costs suggests that an effect of coordination upon altruistic motivation may play an important role even without feedback in dynamically supporting cooperation in contexts involving imperfectly aligned interests. A fruitful direction for future research would be to manipulate the presence or absence of feedback using our experimental designs.  

An additional avenue for future investigation would be to disentangle various more specific hypotheses that could account for agents’ motivation to bear a cost to benefit their partner, as observed in Experiment 1. For example, participants may have other-regarding preferences over their partner’s outcomes, or they may be unwilling to incur obligations to their partner. Insofar as Experiment 1 was designed to test the more general hypothesis that coordination boosts altruistic motivation, the results do not allow us to adjudicate among these and other more specific hypotheses which would generate the same prediction regarding the effect of coordination on cooperation in the context of our Experiment 1. It bears emphasizing that our starting point for the current research was the observation that cooperation in a prisoner’s dilemma can be boosted by increasing trust, by increasing altruism (a willingness to bear a cost for your interaction partner), or by increasing both. Differentiating among additional diverse hypotheses that explain our positive finding in Experiment 1 would be an important next step. A related limitation concerns the extent to which participants believed they might interact with certain partners again in the future, despite this not being indicated in the study design and participant numbers being anonymous. If such beliefs differ when one’s partner is fixed versus variable, controlling for these beliefs in future research might be useful.  

In sum, our results support the hypothesis that repeatedly coordinating with a partner increases altruistic motivation towards one’s partner, whereas they do not support the hypothesis that repeated coordination boosts trust. These findings, together with the paradigms introduced in the two experiments, provide new insights and directions for further investigation into the cognitive and motivational underpinnings of human cooperation.  

# Supporting information  

S1 File. Analyses of interaction between temptation to defect and partner condition. (DOCX)  

# Acknowledgments  

We would like to thank Sebastian Gruineisen, Clément Letesson, Marcell Szekely and Wayne Christensen, who provided valuable input into the design and testing process, and Jonas  

Lindeløv for advice on the analysis. We are also grateful to two anonymous reviewers for helping us to clarify key aspects of our proposal and for suggesting fruitful ideas for future research.  

# Author Contributions  

Conceptualization: Matthew Chennells, Mateusz Woźniak, Stephen Butterfill, John Michael.  

Formal analysis: Matthew Chennells, Mateusz Woźniak.  

Funding acquisition: John Michael.  

Investigation: John Michael.  

Project administration: John Michael.  

Software: Matthew Chennells.  

Supervision: Stephen Butterfill, John Michael.  

Visualization: Matthew Chennells.  

Writing – original draft: Stephen Butterfill, John Michael.  

Writing – review & editing: Matthew Chennells, Mateusz Woźniak, John Michael.  



# References  

1. Henrich J., & Henrich N. (2007). Why humans cooperate: A cultural and evolutionary explanation. Oxford, UK: Oxford University Press. 2. Nowak M. A. (2012). Evolving cooperation. Journal of Theoretical Biology, 299, 1–8. https://doi.org/10. 1016/j.jtbi.2012.01.014 PMID: 22281519 3. Tomasello M. (2009). Why we cooperate. Cambridge, MA: MIT Press. 4. Skyrms B. (2004). The stag hunt and the evolution of social structure. Cambridge, UK: Cambridge University Press.   

5. West S. A., Griffin A. S., & Gardner A. (2007). Evolutionary explanations for cooperation. Current Biology, 17, R661–R672. https://doi.org/10.1016/j.cub.2007.06.004 PMID: 17714660 6. Trivers R. L. (1971). The evolution of reciprocal altruism. The Quarterly Review of Biology, 46(1), 35– 57.   

7. Nowak M. A., & Sigmund K. (2005). Evolution of indirect reciprocity. Nature 437(7063), 1–8. https://doi. org/10.1038/nature04131 PMID: 16251955   

8. Roberts G. (2005). Cooperation through interdependence. Animal Behaviour, 70(4), 901–908.   

9. Michael J. & Pacherie E. (2015) On commitments and other uncertainty reduction tools in joint action. Journal of Social Ontology, 1(1), 89–120.   

10. Guala F & Mittone L (2010). How history and convention create norms, Journal of Economic Psychology, 31(4): 749–756.   

11. Rusch H. & Luetge C. (2016). Spillovers from coordination to cooperation: Evidence for the interdependence hypothesis? Evolutionary Behavioral Sciences, 10(4): 284–296.   

12. Van Baaren R. B., Holland R. W., Kawakami K., & Van Knippenberg A. (2004). Mimicry and prosocial behavior. Psychological Science, 15(1), 71–74. https://doi.org/10.1111/j.0963-7214.2004.01501012.x PMID: 14717835   

13. Wiltermuth S. S. & Heath C. (2009) Synchrony and cooperation. Psychological Science 20(1), 1–5. https://doi.org/10.1111/j.1467-9280.2008.02253.x PMID: 19152536   

14. Knez M., Camerer C. (2000) Increasing cooperation in Prisoner’s Dilemmas by establishing a precedent of efficiency in coordination games. Organisational Behaviour and Human Decision Processes, 82(2), 194–216. https://doi.org/10.1006/obhd.2000.2882 PMID: 10891295   

15. Fehr E., & Fischbacher U. (2003). The nature of human altruism. Nature, 425 (6960), 785–791. https:// doi.org/10.1038/nature02043 PMID: 14574401   

16. McGrath M. C., & Gerber A. S. (2019). Experimental evidence for a pure collaboration effect. Nature Human Behaviour, 3(4), 354–360. https://doi.org/10.1038/s41562-019-0530-9 PMID: 30971785   

17. Michael J., Sebanz N., & Knoblich G. (2016). Observing joint action: Coordination creates commitment. Cognition, 157, 106–113. https://doi.org/10.1016/j.cognition.2016.08.024 PMID: 27610745   

18. Michael J., Sebanz N., & Knoblich G. (2016). The sense of commitment: a minimal approach. Frontiers in Psychology, 6(1968). https://doi.org/10.3389/fpsyg.2015.01968 PMID: 26779080   

19. Kokal I., Engel A., Kirschner S., & Keysers C. (2011). Synchronized drumming enhances activity in the caudate and facilitates prosocial commitment-if the rhythm comes easily. PLoS One, 6(11), e27272. https://doi.org/10.1371/journal.pone.0027272 PMID: 22110623   

20. Valdesolo P., & DeSteno D. (2011). Synchrony and the social tuning of compassion. Emotion, 11(2), 262–266. https://doi.org/10.1037/a0021302 PMID: 21500895   

21. Barragan R. C., & Dweck C. S. (2014). Rethinking natural altruism: Simple reciprocal interactions trigger children’s benevolence. Proceedings of the National Academy of Sciences, 111(48), 17071–17074.   

22. Cirelli L. K., Einarson K. M., & Trainor L. J. (2014). Interpersonal synchrony increases prosocial behavior in infants. Developmental Science, 17(6), 1003–1011. https://doi.org/10.1111/desc.12193 PMID: 25513669   

23. Michael J., McEllin L., & Felber A. (2020). Prosocial effects of coordination–What, how and why?. Acta Psychologica, 207, 103083. https://doi.org/10.1016/j.actpsy.2020.103083 PMID: 32422420   

24. Faul F., Erdfelder E., Buchner A., & Lang A. G. (2009). Statistical power analyses using $\Game^{*}$ Power 3.1: Tests for correlation and regression analyses. Behavior Research Methods, 41(4), 1149–1160. https:// doi.org/10.3758/BRM.41.4.1149 PMID: 19897823   

25.  Mathot S., Schreij D., & Theeuwes J. (2012). OpenSesame: An open-source, graphical experiment builder for the social sciences. Behavior Research Methods, 44(2), 314–324. https://doi.org/10.3758/ s13428-011-0168-7 PMID: 22083660   

26. Barr D. J., Levy R., Scheepers C. & Tily H. J. (2013) Random effects structure for confirmatory hypothesis testing: keep it maximal. Journal of Memory and Language 68, 255–278. https://doi.org/10.1016/j. jml.2012.11.001 PMID: 24403724   

27. Schielzeth H., & Forstmeier W. (2009). Conclusions beyond support: Overconfident estimates in mixed models. Behavioral Ecology, 20(2), 416–420. https://doi.org/10.1093/beheco/arn145 PMID: 19461866   

28. Shear B. R. & Zumbo B. D. (2013) False positives in multiple regression: unanticipated consequences of measurement error in the predictor variables. Educational and Psychological Measurement 73(5), 733–756.   

29. de Leeuw J. R., & Motz B. A. (2016). Psychophysics in a Web browser? Comparing response times collected with JavaScript and Psychophysics Toolbox in a visual search task. Behavior Research Methods, 48(1), 1–12.   

30. Berg J., Dickhaut J., & McCabe K. (1995). Trust, reciprocity, and social history. Games and Economic Behavior, 10(1), 122–142.  


</div>

---

Title: Children’s Selective Learning from Others
Authors: Erika Nurmsoo, Elizabeth Robinson, and Stephen A. Butterfill
Year: 2010
Journal: Review of Philosophy and Psychology
Type: Publication

## Abstract

Psychological research into children's sensitivity to testimony has primarily focused on their ability to judge the likely reliability of speakers. However, verbal testimony is only one means by which children learn from others. We review recent research exploring children's early social referencing and imitation, as well as their sensitivity to speakers' knowledge, beliefs, and biases, to argue that children treat information and informants with reasonable scepticism. As children's understanding of mental states develops, they become ever more able to critically evaluate whether to believe new information.




---

Title: Joint Action Goals Reduce Visuomotor Interference Effects from a Partner’s Incongruent Actions
Authors: Sam Clarke, Luke McEllin, Anna Francová, Marcell Székely, Stephen A. Butterfill and John Michael
Year: 2019
Journal: Scientific Reports
Type: Publication

<div class="fulltext">

# Abstract

Joint actions often require agents to track others’ actions while planning and executing physically incongruent actions of their own. Previous research has indicated that this can lead to visuomotor interference effects when it occurs outside of joint action. How is this avoided or overcome in joint actions? We hypothesized that when joint action partners represent their actions as interrelated components of a plan to bring about a joint action goal, each partner’s movements need not be represented in relation to distinct, incongruent proximal goals. Instead they can be represented in relation to a single proximal goal – especially if the movements are, or appear to be, mechanically linked to a more distal joint action goal. To test this, we implemented a paradigm in which participants produced finger movements that were either congruent or incongruent with those of a virtual partner, and either with or without a joint action goal (the joint flipping of a switch, which turned on two light bulbs). Our findings provide partial support for the hypothesis that visuomotor interference effects can be reduced when two physically incongruent actions are represented as mechanically interdependent contributions to a joint action goal.
  

# Joint action goals reduce visuomotor interference effects from a partner’s incongruent actions  

Joint actions often require agents to track others’ actions while planning and executing physically incongruent actions of their own. Previous research has indicated that this can lead to visuomotor interference effects when it occurs outside of joint action. How is this avoided or overcome in joint actions? We hypothesized that when joint action partners represent their actions as interrelated components of a plan to bring about a joint action goal, each partner’s movements need not be represented in relation to distinct, incongruent proximal goals. Instead they can be represented in relation to a single proximal goal – especially if the movements are, or appear to be, mechanically linked to a more distal joint action goal. To test this, we implemented a paradigm in which participants produced finger movements that were either congruent or incongruent with those of a virtual partner, and either with or without a joint action goal (the joint flipping of a switch, which turned on two light bulbs). Our findings provide partial support for the hypothesis that visuomotor interference effects can be reduced when two physically incongruent actions are represented as mechanically interdependent contributions to a joint action goal.  

From handshakes to music-making, dance and team sports, social interactions often require an efficient means of tracking others’ actions while simultaneously planning and executing actions of one’s own1. A basketball player, for example, must monitor and anticipate her teammate’s movements in order to successfully contribute to a pick and roll play.  

Given the broad range of social interactions in which it is important to anticipate, monitor and respond to others’ actions, it is no surprise that a considerable amount of research has been devoted to investigating how we achieve this2–5. An influential idea that has emerged is that the representation of others’ actions is often supported by one’s own motor system, implying that representations of others’ actions are often functionally equivalent to the representations involved in action production $^{2-4,6,7}$ . As a result, the observation of others’ actions can result in action representations that do not clearly distinguish self from other8–10.  

An upshot is that the observation of others’ actions can give rise to representations that interfere with one’s own task performance. In a striking illustration of this, Brass et al.2 found that participants who were instructed to produce finger movements in response to symbolic cues responded more quickly when simultaneously observing irrelevant finger movements that were physically congruent to the ones they were instructed to produce, and more slowly when simultaneously observing irrelevant finger movements that were physically incongruent to these. These findings – and others that build on them11–13 – are taken to indicate that, when observing others’ actions, we automatically represent those actions using motor representations of the same type as those subserving action production.  

This neatly explains why the observation of congruent actions facilitates task performance, while the observation of incongruent actions leads to visuomotor interference effects. However, it also raises a challenge. This is because many joint actions require individuals to produce physically incongruent yet complementary actions14.  

![](public/img/articles/clarke2019_joint/b167ef5857e70a74d3ea3d887fa9189cc71e08eca40b84f06a76ad4a211da543.jpg)  
Figure 1.  Two physically incongruent actions become part of a larger Joint Action plan. If there is no need to represent the other partner’s incongruent action (i.e. if the agent can produce their contribution to the joint action without taking their partner’s behaviour into account), then this may allow agents to bypass the representation of a partner’s actions altogether, allowing interference effects to be reduced or avoided. However, when one agent has to select an action based on which action their partner performs, their individual action cannot be represented only in terms of the more distal joint action or its goal.  

A proficient basketball player, for example, may need to coordinate her movement towards the basket with her teammate’s passing of the ball. But if tracking her teammate’s action elicits motor representations that compete with those underpinning the action she herself must perform, then they may interfere with her own action preparation. In more general terms: where the tracking of others’ actions involves motor representations that are functionally equivalent to the representations underpinning action production, this could give rise to interference effects and prove counter-productive in many cases of joint action.  

This problem can, however, be overcome. In a recent paper by Sacheli, Arcangeli, & Paulesu15 participants played learned melodies with, or merely alongside, a virtual partner. In both cases, this required them to sequentially produce actions that were either physically congruent (e.g. point-point) or physically incongruent to those that had just been produced by the partner (e.g. point-grasp). When participants and their partners performed these actions alongside one another (i.e. in a Non-Interactive Condition) performance was affected by the physical (in)congruence of the movements, as expected. But, when these actions were directed towards a joint action goal (i.e. the joint production of a single melody in a Joint Action Condition), physical congruence became irrelevant: task performance was affected by a reversal in movement-note associations, but not by the congruence or incongruence of the two agents’ movements. This raises the question: why would doing something in the context of a joint action eliminate interference from the perception of incongruent movements but create interference from the perception of anomalous sounds?  

Sacheli et al's proposed answer is that the representation of a joint action goal enables joint action partners to integrate representations of their own and their partner’s actions within a single dyadic (multi-person) motor plan15. As they put it, this dyadic motor plan enables agent’s to select appropriate responses to their partner’s actions on the basis of their predicted outcomes (e.g. the production of a musical note). This explains why anomalous movement-note associations would have generated interference in their study. However, it does not appear to explain why the joint action frame would have reduced interference from physically incongruent movements. In principle, integrating representations of incongruent movements within a larger motor plan could have increased interference effects instead16.  

One possibility, left open by the aforementioned study, is that a joint action frame may lead participants to represent their partner’s actions in relation to a more distal joint action goal (i.e. a string of musical notes) instead of the more proximal goals that bring this about (i.e. grasping or pointing). In cases where the physical incongruence of the actions only obtains at the level of these more proximal goals, this might allow agents to bypass the representation of their partners’ physically incongruent movements altogether, reducing or eliminating visuomotor interference effects (See Fig. 1). The trouble is: there seem to be cases of joint action where it is not sufficient to bypass the representation of a partner’s proximal goal altogether and to merely consider the more distal outcome of the joint action goal. Rather, as illustrated by the basketball players mentioned above, it is often necessary to represent the more proximal goals of a partner’s action in order to select actions that would complement these with respect to the more distal joint action goal. Indeed, this can be true of even the most basic motor movements involved. Thus, basic questions remain. Specifically: can the introduction of a distal joint action goal reduce visuomotor interference effects in cases where incongruent proximal goals are contingently related to one another, and attention to these is required for the selection of appropriate motor movements? And, if so, how might this be achieved?  

![](public/img/articles/clarke2019_joint/2ce08eda33eca62224a293e71a0c157330240c67bd5c7e88f6cd27a6749bb08a.jpg)  
Figure 2.  Where one agent has to select an action based on which action the other performs, interference effects may be reduced if the agent can represent both actions as interrelated components of a single goal and not only in terms of the more distal goal (e.g. passing the ball, in a pick and roll play).  

In addressing the latter question, a natural starting point is the observation that action production typically involves the simultaneous representation of multiple, instrumentally related actions at multiple, instrumentally related levels of abstraction17–20. For example, we represent the action of turning the steering wheel not only at the level of the comparably distal goal (turned steering wheel) but also at the level of comparatively proximal goals, designed to bring this about (e.g. raised left arm; lowered right arm). Importantly, this hierarchical structure must capture instrumental relations between these different goals. Plainly, proximal goals must function to bring about comparatively distal goals. But, in addition to this, the comparatively proximal goals must (themselves) be sensitive to each other such that a modification to one will lead others to change appropriately. For instance, one need not bother moving one’s arms if one is no longer grasping the wheel; and even when one is grasping the wheel, it may be no use raising one’s left arm if one does not simultaneously lower one’s right arm.  

Here, the individual agent must simultaneously produce physically incongruent movements (arm lifting and arm lowering). But, in this case, it is not possible to avoid motoric interference by simply considering each arm’s movement independently of the other, or by simply considering the more distal goal outcome to which these are both directed (a turned wheel). This is because all of these goals are interrelated. Thus, the introduction of the more distal goal must change the way in which the more proximal goals are represented. Specifically, it must lead to their representation as interrelated, and not simply independent contributions to a larger action.  

This raises the possibility that the actions of our joint action partners can be represented in relation to the same action hierarchy (See Fig. 2). Here, the introduction of a comparably distal joint action goal might enable the physically incongruent movements of self and other to be represented as interrelated components of a plan to bring about the joint action goal. If this is possible, then it might reduce or even eliminate interference from the observation of a partner’s physically incongruent movements, even when success in joint action requires one’s selective response to these. Thus, we hypothesise that where agents represent their actions as interrelated components of a plan to bring about a joint action goal, each partner’s movements need not always be represented in relation to distinct, incongruent proximal goals. Instead, they might be represented as interrelated contributions to a single goal. If true, the joint action frame could potentially reduce or even eliminate visuomotor interference effects arising from the observation of what an outsider might take to be a physically incongruent action.  

To test this, we adapted Brass and colleagues’12 paradigm to incorporate a joint action goal, namely turning on two light bulbs by jointly flicking a switch. Here, participants were required to perform one of two finger-lifting movements depending on which numerical cue was presented on a screen, in between a virtual partner’s index and middle fingers (See Fig. 3). These movements could be physically congruent or physically incongruent with a movement performed by the virtual partner. In a Joint Action Goal Condition, lightbulbs were turned on when the participant and the partner simultaneously performed physically incongruent actions, but not when they performed physically congruent actions (something about which our hypothesis makes no predictions). In the Individual Goal Condition, the lights were never turned on (i.e. there was no joint action goal). We reasoned that if participants are able to utilize the joint action goal (turning on the lightbulbs) to represent a planning structure in which their partner’s movement forms a complementary and mutually interrelated contribution, then the physical incongruence of their own and the partner’s movement should be less relevant. This generates the prediction that we should observe reduced visuomotor interference effects in the Joint Action Goal Condition compared to the Individual Goal Condition. In other words, the difference in response times between Congruent trials (wherein the participant and the partner lift the same fingers) and Incongruent trials (wherein the participant and the partner lift different fingers) should be smaller in the Joint Action Goal Conditions than in the Individual Goal Condition.  

![](public/img/articles/clarke2019_joint/d75395a848b5add6a8f3181ec24e0a3e20bb0d29a2c7d5258c059f67da47a62f.jpg)  
Figure 3.  Illustration of the task. Participants were instructed to lift the same finger as the hand in the video when a ‘1’ is displayed (Congruent Condition) and to lift the other finger when a $\cdot_{2},$ is displayed (Incongruent Condition). The left side illustrates the Individual Goal Condition, in which the lights never turn on. The right side illustrates the Joint Action Goal Condition, in which the lights are turned on when two conditions are fulfilled: the number cue $(^{\leftarrow}2^{>})$ indicates that the participant should perform the ‘incongruent’ action, and the participant correctly does so.  

The predictions, sample size, methods, and planned analyses were all pre-registered before data collection and can be accessed at: http://aspredicted.org/blind.php? $\mathbf{X}{=}$ cr4cg2. Unless otherwise noted, we implemented all steps as pre-registered.  

# Results  

To control for speed-accuracy tradeoffs, reaction time (RT) for correct responses and hit rates (HR) were merged into inverse efficiency scores (IES), a combined measure which homogenizes different patterns of speed-accuracy trade-offs $(\mathrm{IES})^{21}$ , by dividing RTs by accuracy for each condition in each group (lower scores mean more efficient responses). We also analyzed the participants’ RT’s.  

For the IES, we conducted a $2\times2\times2$ mixed ANOVA with Jointness (Joint vs Individual Action Goal) and Congruence (Congruent vs Incongruent) as within participants factors, and Group (Joint First, Joint Last) as a between participants factor. The ANOVA revealed a significant main effect of Congruence $F(1,70)=44.41$ , $p<0.001$ , $\eta\mathrm{p}2=0.39$ , with lower IES in the Congruent condition, $(M=1168.67$ , $S D=211.75)$ than in the Incongruent condition $M=1243.39$ , $S D=230.94_{,}$ ; but no significant main effect of Jointness, $F(1,70)=0.49$ , $\ensuremath{p}=0.48$ , $\eta{\bf p}2=0.007$ , and no significant main effect of Group $F(1,70)=1.72$ , $p{=}0.19$ , $\upeta{\sf p}2=0.02$ . There was no significant interaction between Jointness and Congruence, $F\left(1,70\right)=0.05\:p{=}0.82$ , $\eta\mathbf{p}2=0.001$ , no significant interaction between Congruence and Group, $F(1,70)=3.68,p=0.06,\eta\mathrm{p}2=0.05$ (although this was close to significance, we cannot make conclusions on the basis of this statistic), but a significant interaction between Jointness and Group, $F(1,70)=9.61$ , $p=0.003$ , $\eta\mathrm{p}2=0.12$ . There was also a three way interaction between Jointness, Group and Congruence, $F(1,70)=14.49,p<0.001,\eta\mathsf{p}2=0.17$ (see Fig. 4).  

Post-hoc t-tests for the Joint First Group revealed IES did not differ between congruent and incongruent trials for the Individual Goal condition, $t(35)=-1.99$ , $p=0.054$ , $d=-0.33$ but IES were significantly lower for congruent trials than incongruent trials for the Joint Goal condition, $t(35)=-4.89,p<0.001$ , $d=-0.82$ . Congruent trials’ IES in the Individual Goal condition were not significantly different from congruent trials’ IES in the Joint Goal condition $t(35)=-0.55$ , $p{=}0{.}59$ , $d=-0.09$ and incongruent trials’ IES in the Individual Goal condition were not significantly different from incongruent trials’ IES in the Joint Goal condition, $t(35)=-1.93$ , $p{=}0.06$ , $d=-0.32$ .  

Post-hoc t-tests for the Joint Last Group revealed that congruent IES were significantly lower than incongruent trials’ IES for the Individual Goal condition, $t(35)=-5.25$ , $p<0.001$ , $d=-0.88$ and congruent trials’ IES were significantly lower than incongruent trials’ IES for the Joint Goal condition, $t(35)=-3.43,p=0.002,d=-0.57$ . Congruent trials’ IES in the Joint Goal condition were not different from congruent trials’ IES in the Individual Goal condition, $t(35)=2.05,p=0.05$ , $d=0.34$ , however incongruent trials’ IES in the Joint Goal condition were significantly lower than incongruent trials’ IES in the Individual Goal condition, $t(35)=3.98$ , $p<0.001$ , $d=0.66$ .  

![](public/img/articles/clarke2019_joint/c9726129a6cc300a7af6aaae40813cb91a9b35831ccdb5dcf4cf439dec4082f5.jpg)  
Figure 4. $2\times2\times2$ ANOVA. Mean Inverse Efficiency Scores (IES) are plotted separately for Congruent and Incongruent trials in the Joint Action Goal and the Individual Goal Conditions, for each group. Error bars represent the within-subject confidence intervals29,30.  

![](public/img/articles/clarke2019_joint/73a2f98764f6be81b08db60d53ba70853846b91da9a1438d6d8c115c98290400.jpg)  
Figure 5. $2\times2$ ANOVA. Mean difference between Congruent and Incongruent Inverse Efficiency Scores (IES) for Joint Action Goal and the Individual Goal Conditions, for each group. Error bars represent the withinsubject confidence intervals29,30.  

We believe that the three-way interaction was likely the result of the incongruent trials causing comparatively little visuomotor interference in the first block of trials when there was a Joint Action Goal, compared to when there was not a Joint Action Goal. To further investigate the three-way interaction, we subtracted the IES of congruent trials from the IES of incongruent trials (IES difference) for each participant, for each condition, giving us an index of how much the incongruent trials interfered with participants’ responses in each of the conditions. We conducted a $2\times2$ mixed ANOVA, with Jointness as a within participants factor, and Group as a between participants factor, which revealed no main effect of Jointness, $F(1,70)=0.05$ , $\ensuremath{p}=0.82$ , $\eta\mathbf{p}2=0.001$ , and no main effect of Group, $F(1,70)=3.69\:p{=}0.06$ , $\eta\mathrm{p}2=0.05$ (although this is close to significance, it does not permit us to draw any conclusions). However, there was an interaction between Jointness and Group, $F(1,70)=14.49$ , $p<0.001$ , $\eta\mathrm{p}2=0.17$ (see Fig. 5). Bonferroni corrected post-hoc t-tests revealed that Joint Action Goal IES differences were significantly larger than Individual Goal IES differences for the Joint First group, $t(35)=-2.64$ , $p=0.012$ , $d=-0.44$ , and Joint Action Goal IES differences were significantly smaller than Individual Goal IES differences for the Joint Last Group, $t(35)=2.74$ , $p=0.01$ , $d=0.46$ . There was no significant difference between the Joint First group and Joint Last group for Joint Action Goal Trials, $t(70)=0.4\dot{3}$ , $p{=}0.67$ , $d=0.1$ , but Joint First IES differences were significantly smaller than Joint Last IES differences for Individual Goal trials, $t(70)=-3.51$ , $p<0.001$ , $d=0.83$ .  

# Discussion  

Our results revealed a three-way interaction of Congruence, Jointness and Group. In the group which performed the Joint Action Goal Condition last, the difference between congruent and incongruent trials was significantly smaller when there was a joint action goal than when there was none. In the group which performed the Joint Action Goal Condition first, in contrast, the difference between congruent and incongruent trials was significantly greater when there was a joint action goal than when there was none.  

The results from the group which performed the Joint Action Goal Condition last indicate that a joint action goal representation may, as we predicted, reduce visuomotor interference effects arising from the observation of a physically incongruent action. These results build upon earlier research indicating that the visuomotor interference effects arising from the perception of a virtual partner’s physically incongruent movement can be reduced when two physically incongruent movements are represented as complementary contributions to a joint action goal15,22. Our results extend this research by suggesting that a joint action goal representation can reduce visuomotor interference effects even when agents must detect a joint action partner’s physically incongruent movement while simultaneously producing actions that are contingently related to these. This supports the hypothesis that where agents represent their actions as interrelated components of a plan to bring about a joint action goal, the movements of each partner’s effectors need not always be represented in relation to distinct, incongruent proximal goals. Instead they can be represented as interrelated contributions to a single goal – especially if the movements are, or appear to be, mechanically linked to a more distal joint action goal.  

The results from the group which performed the Joint Action Goal Condition first, in contrast, are not consistent with our prediction. For this group, the joint action framing did not lead to a reduction of visuomotor interference effects. Indeed, the difference in performance between congruent and incongruent trials was significantly larger in the Joint Action Goal condition than in the Individual Goal condition for this group. This pattern may be partially be attributed to a carryover effect: having completed the Joint Action Goal Condition first, participants in this group may have continued representing incongruent trials as contributing towards a joint action goal, even once this goal (turning on lightbulbs) had been removed. This conjecture would explain why, for participants in this group, performance on incongruent trials did not worsen from the first block (Joint Action Goal Condition) to the second block (Individual Goal Condition). However, it does not explain why performance on congruent trials did worsen slightly from the first block (Joint Action Goal Condition) to the second block (Individual Goal Condition). We might speculate that this was due to fatigue: it may have been difficult to maintain the high level of performance that we observed in this group on congruent trials in the first block (Joint Action Goal Condition).  

The mixed pattern of results between our two groups underscores the broader point that we should not expect the introduction of a joint action goal representation to always eliminate or reduce visuomotor interference effects arising from the concurrent performance and perception of physically incongruent actions. And indeed, there is evidence that it does not always do so. For instance, it has been shown that under certain circumstances joint action goal representations can lead to an increase in this form of interference. In one study16, participants were instructed to draw either circles or straight vertical lines on tablet screens resting on a table in front of them while a second participant, sitting diagonally across from them, performed the other (i.e. incongruent) action. On a screen directly in front of each participant, they could see the outcome of their partner’s action (i.e. a straight line or a circle appearing on the screen). One group of participants (the Joint Action Condition) were informed that, together, their own and their partner’s drawings constituted complementary components of a single drawing. A second group of participants (the Parallel Condition) were informed that the other agent’s action was irrelevant to their own task. Within this setup, the joint action goal (i.e. in the Joint Action condition) led to an increase in interference effects. If our hypothesis is correct, this finding is not surprising: since participants did not have to identify their partner’s movement in order to select their own movement, and since they were unable to see the outcome of their combined efforts, they did not perceive their own and their partner’s actions as mechanically linked to a more distal joint action goal. Thus, participants simply represented their own and their partner’s movements in relation to distinct and incongruent proximal goals.  

This would be consistent with research showing the facilitatory effects of Lissajous plots on bimanual coordination23,24. In this research, participants are instructed to perform two separate rhythmic actions, one with each hand. Lissajous plots are used to display the location of one limb on the x-axis, and the location of the other limb on the y-axis, as well as the location of a dot integrating the locations of the two hands. This visual feedback enables participants to represent the two hand movements as mechanically linked to a single, combined outcome. As a result, they are able to maintain otherwise unstable phase relations25,26.  

It would be important for future research to investigate other contexts in which individuals must efficiently represent and respond to others’ physically incongruent actions. In particular, it would be valuable to probe competitive scenarios in which there are no joint action goals but in which the outcomes of two agents’ are interdependent and to investigate the extent to which the representation of a partner’s actions can be modulated by the degree of coordination required by a joint action goal. Future research should also investigate the neural mechanisms that underpin the integration of physically incongruent actions into unified motor plans. One important starting point in this respect is provided Sacheli, Tieri, Aglioti, & Candidi’s22 study demonstrating that virtual lesions (created using continuous theta-burst stimulation) in the left anterior intraparietal sulcus led to an increase in visuomotor interference effects in a scenario in which participants observed a partner’s action and were required to select a physically incongruent action to perform synchronously.  

# Methods  

Participants.  Using $\mathrm{G*}$ Power $3.1^{27}$ we determined that a sample size of thirty would provide $80\%$ statistical power for detecting a small-to-medium-sized effect of the interaction of the two main factors, Jointness (Joint Action Goal vs Individual Goal) and Congruence (Congruent vs Incongruent), assuming a two-way repeated measures ANOVA and an alpha level of 0.05. We therefore recruited 30 participants. Because of the high exclusion rate in this initial data collection, we had to recruit more participants to replace those who had been excluded, and overestimated the number of participants needed to compensate for exclusions. This resulted in a total of 36 participants. Due to experimenter error, all of these 36 participants were administered the Joint Last condition, so we then collected 36 participants for the Joint First group to counterbalance.  

Thus, our sample included 72 participants (13 females; age range: 21–46, $\mathrm{M}=27.1$ , $\mathrm{{SD}}=4.77$ ). All participants were recruited from student organizations in the Budapest and Warwick areas, were naïve to the purpose of the study, and reported normal or corrected to normal vision. All participants signed informed consent prior to the experiment, and received gift vouchers or money for their participation. The experiment was conducted in accordance with the Declaration of Helsinki and was approved by the (EPKEB) United Ethical Review Board for Research in Psychology.  

Apparatus and stimuli.  The experiment was displayed on a 13-inch computer screen (resolution: $2560\times1600$ pixels, refresh rate: $60\mathrm{Hz}$ ). The program for the experiment was written in OpenSesame Python28, with a frame rate of 17 frames per second. Figure 3 illustrates the task environment.  

Procedure.  After giving their informed written consent, participants were seated alone at a desk in a lab room and provided with further instructions, after which they had the opportunity to ask clarificatory questions to the experimenter.  

They then performed two test blocks (Joint Action Goal Condition and Individual Action Goal Condition) consisting of 80 trials each (40 Congruent, 40 Incongruent; 20 of each required index finger movements and 20 middle finger movements). Each test block was preceded by 4 practice trials (i.e. 8 in total). The order of test blocks was counterbalanced across participants; Incongruent and Congruent trials were evenly distributed across blocks and randomly mixed within each block.  

At the beginning of each trial, participants were instructed to hold down the left and right buttons of the mouse with the index and middle fingers of their right hand. The stimuli were short video sequences of simple finger movements (lifting), as illustrated in Fig. 3. Then a picture of the hand was presented for $2000\mathrm{ms}$ with a number displayed between the index and middle finger, indicating the participant’s instruction for that trial: the participant was instructed to lift the same finger as her/his virtual partner on trials in which a $^{\circ}{}_{1}{}^{\circ}$ was displayed below the picture of the hand (Congruent trials), and to lift the other finger on trials in which the number $\ '2^{\flat}$ was displayed (Incongruent trials). Participants were instructed to respond as quickly and accurately as possible as soon as the virtual partner’s finger began to move. Next, a still frame of the virtual partner’s hand was displayed with the index or the middle finger having been lifted. The onset of this image was the participant’s go-signal to lift the appropriate finger.  

In the Individual Action Goal Condition, the two light bulbs were displayed on the two sides of the screen (See Fig. 3) during all trials, but remained switched off at all times.  

In the Joint Action Goal Condition, the instructions were the same as in the Individual Action Goal Condition except that participants were informed there would sometimes be a ‘bonus’ effect: when the participant and her/ his partner correctly lifted different fingers (i.e. this was only possible on incongruent trials), they would jointly flip the switch, causing the lights to be switched on (See Fig. 3). Participants were explicitly informed that this could happen only on the trials in which the correct response was to perform the incongruent action.  

At the end of each trial, the scene was displayed for $2000\mathrm{ms}$ . When the switch was flipped and the lightbulbs turned on, the scene was displayed with the switch having been flipped and the lightbulbs turned on. On trials when participants performed the incorrect action, the background turned red and the scene was displayed, otherwise unchanged, for $2000\mathrm{ms}$ . On trials when participants performed the correct action but the switch was not flipped and the lightbulbs not turned on, the scene was displayed just as in the previous frame.  

Data processing and analysis.  For the analysis, we had several exclusion criteria. Firstly, we excluded four participants (three in the Joint First Group and one in the Joint Last Group) from all of our analysis as they had an unusually high rate of premature responses $(\mathrm{all}>90\%)$ , meaning that it is likely that they did not understand the instructions and that their data cannot be relied on. Secondly, we excluded any participants with an overall accuracy more than $2.5\mathrm{SD}$ below the group mean (either Joint First group or Joint Last group) from all our analyses, as their data is likely unreliable. This resulted in the exclusion of 480 trials $(7.6\%)$ or 3 participants from the Joint First group, and 480 trials $(7.6\%)$ or 3 participants from the Joint Last group. Secondly, we excluded 72 $(1.1\%)$ premature responses (responses before the stimulus onset) from the Joint First group, and 58 $\left(0.9\%\right)$ premature responses from the Joint Last group, from all of our analysis. Thirdly, 147 $(2.3\%)$ trials with RTs more than 2.5 standard deviations (SDs) removed from the mean (calculated for each participant for each condition) were excluded from the Joint First group, and 128 trials $(2.1\%)$ were excluded from the Joint Last group. Finally, 240 trials $\left(3.9\%\right)$ incorrect responses for the Joint First group, and 297 trials $\left(4.7\%\right)$ from the Joint Last group were excluded from the RTs. Although these criteria were not pre-registered, we determined to apply them prior to analysing any data. Our rationale was that the hypothesis being tested pertained to the processes engaged when people perform actions while perceiving a physically incongruent action from a joint action partner; on trials on which participants committed errors, we could not be confident that these processes were actually engaged.  

For each participant, we calculated the mean RT’s and accuracy (proportion correct), for congruent and incongruent trials for each condition (see Supplementary File for means per condition). We divided the RTs by the accuracy in order to compute Inverse Efficiency Scores $(\mathrm{IES})^{21}$ as an index of efficiency, appropriately weighting speed and accuracy.  

# References  

1.	 Hassin, R. R., Aarts, H. & Ferguson, M. Automatic goal inferences. Journal of Experimental Social Psychology. 41(2), 129–40 (2005).   
2.	 Brass, M., Bekkering, H., Wohlschläger, A. & Prinz, W. Compatibility between Observed and Executed Finger Movements: Comparing Symbolic, Spatial, and Imitative Cues. Brain and Cognition. 44, 124–143 (2000).   
3.	 Kilner, J. M., Paulignan, Y. & Blakemore, S. J. An interference effect of observed biological movement on action. Current Biology. 13(6), 522–5 (2003).   
4.	 Sebanz, N., Knoblich, G. & Prinz, W. Representing others’ actions: just like one’s own? Cognition. 88, B11–B21 (2003).   
5.	 Ramsey, R. What are reaction time indices of automatic imitation measuring? Consciousness & Cognition. 65, 240–54 (2018).   
6.	 Craighero, L., Fadiga, L., Umiltà, C. A. & Rizzolatti, G. Evidence for visuomotor priming effect. Neuroreport. 8, 347–349 (1996).   
7.	 Craighero, L., Fadiga, L., Rizzolatti, G. & Umiltà, C. A. Visuomotor priming. Visual Cognition. 5, 347–349 (1998).   
8.	 Jeannerod, M. & Pacherie, E. Agency, Simulation and Self-identification. Mind & Language. 19(2), 113–46 (2004).   
9.	 Prinz, W. Perception and Action Planning. European Journal of Cognitive Psychology. 9, 129–54 (1997).   
10. Rizzolatti, G. & Sinigaglia, C. The functional role of the parieto-frontal mirror circuit: interpretations and misinterpretations. Nature Reviews Neuroscience. 11(4), 264–74 (2010).   
11. Stirmer, B., Aschersleben, G. & Prinz, W. Corresponce effects with manual gestures and postures: A study of imitation. Journal of Experimental Psychology: Human Perception and Performance. 26(6), 1746–59 (2000).   
12. Brass, M., Bekkering, H. & Prinz, W. Movement observation affects movement execution in a simple response task. Acta Psychologica. 106(1–2), 3–22 (2001).   
13. Wang, Y., Ramsey, R. & Hamilton,A. F. The control of mimicry by eye contact is mediated by medial prefrontal cortex. Journal of Neuroscience. 31(33), 12001–10 (2011).   
14. Sartori, L. & Betti, S. Complementary actions. Frontiers in Psychology. 6(557) (2015).   
15. Sacheli, L.M,Arcangeli,E.&Palesu, E. Evidence for a dyadic motr plan in joint action. Scientifc Reports. 8, 5027, https:/di. org/10.1038/s41598-018-23275-9 (2018).   
16. della Gatta, F et al. Drawn together: When motor representations ground joint actions. Cognition. 165, 53-60 (2017).   
17. Candidi, M., Sacheli, L. M.&Aglioti, S. M.From muscles synergies and individual goals to interpersonal synergies and shared goals: mirror neurons and interpersonal action hierarchies: comment on “Grasping synergies: a motor-control approach to the mirror neuron mechanism” by D’Ausilio et al. Phys. Life Rev 12, 126–128 (2015).   
18. Chersi, F Neural mechanisms and models underlying joint action. Experimental brain research 211(3-4), 643-653 (2011).   
19. Kilner,J. M. More than one pathway to action understanding. Trends in Cognitive Sciences 15(8), 352-7 (2011).   
20. Grafton, S. T. & Hamilton, A. F. C. Evidence for a distributed hierarchy of action representation in the brain. Human Movement Science 26(4), 590–616 (2007).   
21. Bruyer, R. & Brysbaert, M. Combining speed and accuracy in cognitive psychology: Is the inverse efficiency score (IES) a better dependent variable than the mean reaction time (RT) and the percentage of errors (PE)? Psychologica Belgica 51(1), 5–13 (2011).   
22. Sacheli, L. M., Tieri, G., Aglioti, S. M. & Candidi, M. Transitory Inhibition of the Left Anterior Intraparietal Sulcus Impairs Joint Actions: A Continuous Theta-Burst Stimulation Study. Journal of Cognitive Neuroscience. 30(5), 737–51 (2018).   
23. Kovacs, A. J., Buchanan, J J & Shea, C. H. Bimanual 1: 1 with $90^{\circ}$ continuous relative phase: difficult or easy! Experimental Brain Research. 193(1), 129–136 (2009).   
24. Kennedy, D. M., Boyle,J B. &Shea, C. H. The role of auditory and visual models in the production of bimanual taping pattens. Experimental brain research. 224(4), 507–518 (2013).   
25. Kovacs, A. J,Buchanan,JJ &Shea,C. H. Impossible is nothing: 5: 3 and 4: 3 multi-frequency bimanual cordination Experimental brain research. 201(2), 249–259 (2010).   
26. Kovacs, A. J. & Shea, C. H. The learning of 90 continuous relative phase with and without Lisajous feedback: external and internally generated bimanual coordination. Acta psychologica. 136(3), 311–320 (2011).   
27. Faul F, Erdfelder, E,uchner, A.&Lang, A.G.Statistical power analyses sin $\mathrm{G}^{*}$ Power 3:1 tests for correlation and regression analyses. Behavioral Research Methods. 41(4), 1149–60 (2009).   
28. Mathot,S., Schreij, D. & Theeuwes, J. OpenSesame: An open-source, graphical experiment builder for the social sciences. Behavioral Research Methods. 44(2), 314–24 (2012).   
29. Cousineau, D. Confidence intervals in within-subject designs: A simpler solution to Loftus and Masson's method. Tutorials in Quantitative Methods for Psychology. 1(1), 42–45 (2005).   
30. Loftus, G. & Masson, M. Using confidence intervals in within-subject designs. Psychonomic Bulletin é Review. 1(4), 476-490 (1994).  

</div>

---

Title: Cognitive Architecture of Belief Reasoning in Children and Adults: A Primer on the Two-Systems Account
Authors: Jason Low, Ian Apperly, Stephen A. Butterfill and Hannes Rakoczy
Year: 2016
Journal: Child Development Perspectives
Type: Publication

## Abstract

Characterizing the cognitive architecture of human mindreading 
forces us to address two puzzles in people’s attributions of belief:
why children show inconsistent expectations about others’ belief-based actions, and why adults’ belief reasoning is sometimes automatic and sometimes not. The seemingly puzzling data suggest humans have multiple mindreading systems that use different models of the mental. The efficient system is shared by infants, children and adults, and uses a minimal model of mind, which enables belief-like states to be tracked. The flexible system is late-developing and uses a canonical model, which incorporates propositional attitudes. A given model’s operation has signature limits that produce performance contrasts, in children as well as adults, between certain types of mindreading tasks




---

Title: Towards a Mechanistically Neutral Account of Acting Jointly: The Notion of a Collective Goal 
Authors: Stephen A. Butterfill and Corrado Sinigaglia
Year: 2022
Journal: Mind
Type: Publication

<div class="fulltext">

<h1 id="sec:abstract"><strong>Abstract</strong></h1>
<div class='abstract'>
Anyone who has ever walked, cooked or crafted with a friend is in a position to know that acting jointly is not just acting side-by-side.  But what distinguishes acting jointly from acting in parallel yet merely individually?  Four decades of philosophical research have yielded broad consensus on a strategy for answering this question.  This strategy is emph{mechanistically committed}; that is, it hinges on invoking states of the agents who are acting jointly (often dubbed ‘shared’, ‘we-’ or ‘collective’ intentions).  Despite the consensus, enduring disagreement remains. The disagreement may be a consequence of the strategy; at least this is plausible enough to motivate considering the prospects for an alternative. Our aim is therefore to draw attention to a coherent alternative that is present in the literature but often overlooked. This alternative is emph{mechanistically neutral}: it avoids invoking states of agents. Implementing the alternative, we introduce the notion of a collective goal and a characterisation of acting jointly which meets criteria standardly used in evaluating other accounts and may
</div>

<h1 id="sec:intro"><strong>Introduction</strong></h1>
<p><span id="sec:problems" data-label="sec:problems"></span></p>
<p>Many of the things we do are, or could be, done with others. Mundane
examples favoured by philosophers include painting a house together
<span class="citation" data-cites="Bratman:1992mi">(Bratman
1992)</span>, lifting a heavy sofa together <span class="citation"
data-cites="Velleman:1997oo">(Velleman 1997)</span>, preparing a
hollandaise sauce together <span class="citation"
data-cites="Searle:1990em">(Searle 1990)</span>, going to Chicago
together <span class="citation" data-cites="Kutz:2000si">(Kutz
2000)</span>, and walking together <span class="citation"
data-cites="gilbert_walking_1990">(Gilbert 1990)</span>. These examples
are supposed to be paradigm cases of a phenomenon, or class of
phenomena, we shall call <em>acting jointly</em>, although a variety of
labels have been used. <a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> To delimit which cases are of
interest, philosophers have also contrasted things they take to be cases
of acting jointly with things they take to be cases of people merely
acting in parallel with each other. For instance, when members of a
flash mob in the Central Cafe respond to a pre-arranged cue by noisily
opening their newspapers in order to create a salient marker for the
opening of their performance, they are held to be acting jointly. But
when someone not part of the mob just happens to noisily open her
newspaper in response to the same cue, she is held to be acting in
parallel with the others but merely individually. <a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> To
give another example, two former members of the mob are held to be
acting jointly when they later walk to the metro station together. But
two people who merely happen to be walking to the metro station
side-by-side among a crowd of people heading that way are held to be
acting in parallel but merely individually. (This example is adapted
from <span class="citation" data-cites="bratman:2014_book">Bratman
(2014, 5–6)</span>, who borrowed it from <span class="citation"
data-cites="gilbert_walking_1990">Gilbert (1990)</span>.) These paradigm
and contrast cases invite the question, What features distinguish acting
jointly from acting in parallel but merely individually?</p>
<p>Although some philosophers may question some of these claims about
paradigm cases and contrast cases, <a href="#fn3" class="footnote-ref"
id="fnref3" role="doc-noteref"><sup>3</sup></a> we shall follow those
cited above in assuming, provisionally, <a href="#fn4"
class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>
that reflection on the examples and contrasts can ensure sufficient
agreement on the topic that it makes sense to ask which features
distinguish acting jointly from acting in parallel but merely
individually. This assumption is consistent with neutrality both on
whether there is just one distinction or several to be drawn, and also
on which of the above claims about paradigm cases and contrast cases are
correct.</p>
<p>A standard strategy for distinguishing acting jointly from acting in
parallel but merely individually involves invoking states of the agents
who are acting jointly, often dubbed ‘we-’, ‘shared’ or ‘collective
intentions’. <a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a> The idea, very roughly, is that
acting jointly (or one kind of acting jointly if there are several) is
distinguished from acting in parallel but merely individually by these
states playing some particular role. The central task, on this strategy,
is to characterise the states and their explanatory relation to acting
jointly (compare <span class="citation"
data-cites="bratman:2014_book">(Bratman 2014, 10)</span>). There is,
however, considerable debate about the nature of the states on which
this distinction hinges. Some hold that the states in question involve a
novel attitude <span class="citation"
data-cites="Searle:1990em gallotti:2013_social">(Searle 1990; Gallotti
and Frith 2013)</span>. Others have explored the notion that the primary
distinguishing feature of these states is not the kind of attitude
involved but rather the kind of subject, which is plural <span
class="citation" data-cites="helm_plural_2008">(Helm 2008)</span>. Or
they may differ from ordinary intentions in involving distinctive
obligations or commitments to others (<span class="citation"
data-cites="Gilbert:1992rs">(Gilbert 1992)</span>; <span
class="citation" data-cites="Roth:2004ki">(Roth 2004)</span>). <a
href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a> Or perhaps the most fundamental
distinguishing mark of these states is the way they arise, namely
through team reasoning <span class="citation"
data-cites="Gold:2007zd pacherie:2013_lite">(Gold and Sugden 2007;
Pacherie 2013)</span>. Opposing all such views, <span class="citation"
data-cites="Bratman:1992mi bratman:2014_book">Bratman (1992,
2014)</span> argues that the distinctive states, which he calls ‘shared
intentions’, can be realised by multiple ordinary individual intentions
and other attitudes whose contents interlock in a distinctive way. <a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a> Bratman’s approach has inspired a
family of accounts along broadly these lines, including <span
class="citation" data-cites="asarnow:2020_shared">Asarnow (2020)</span>,
<span class="citation" data-cites="blomberg:2015_common">Blomberg
(2016)</span>, <span class="citation"
data-cites="ludwig_collective_2007 ludwig:2016_individual">Ludwig (2007,
2016)</span> and <span class="citation"
data-cites="Tollefsen:2005vh">Tollefsen (2005)</span>.</p>
<p>How are we to determine when any two of these accounts should be
regarded as competing attempts to characterise a single phenomenon and
when they should be regarded as compatible attempts to characterise
different phenomena? And how are we to single out, from among all of
these accounts, those which are correct? The growing number and
increasing diversity of accounts make urgent these twin problems. It may
be that they can be solved. But we believe that there is sufficient
doubt to motivate investigating an alternative to the standard strategy,
one which makes available a distinctive way of singling out correct
accounts. And our aim in this paper is to do just this.</p>
<p>In investigating an alternative strategy, we are not promising to
adjudicate among accounts which follow the standard strategy. However,
we will show how those accounts can be recast in line with the
alternative strategy and their main insights adjudicated. To anticipate,
one consequence of this will be that some accounts which appeared
incompatible from the point of view of the standard strategy turn out
not to be incompatible when recast.</p>
<h1 id="sec:alternative_strategy"><strong>An alternative
strategy</strong></h1>
<p>Proponents of what we call the standard strategy differ in important
ways but have one thing in common: in attempting to distinguish acting
jointly from acting in parallel but merely individually, they are
invoking states of the agents. On the standard strategy, there is no way
of drawing this distinction without being committed to a claim about
which states, or structures of states, cause the actions agents perform
when they act jointly.</p>
<p>To see that this is not the only possible strategy, consider
philosophical accounts of ordinary, individual action. We might ask,
following <span class="citation" data-cites="Davidson:1971fz">Davidson
(1971)</span>, what distinguishes those events which are actions from
events which merely happen to an agent? In answering this question many
have, like Davidson, focussed on intentional actions only. Some
philosophers answer the question by saying—to put it very roughly and
incompletely—that intentional actions are those caused in a certain way
by beliefs, desires, intentions or other kinds of state. <a href="#fn8"
class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>
This is an example of what we shall call a <em>mechanistically
committed</em> answer: that is, an answer which involves making
commitments concerning which states, or structures of states, cause
intentional actions. Although this is the dominant approach, and one
which has provided a framework for much philosophy of action (<span
class="citation" data-cites="brand:1984_intending">(Brand 1984)</span>
is a nice illustration), it is not the only way philosophers have
attempted to answer the question. An intentional action may be
characterised, very roughly and incompletely, as an action that happens
because its agent has certain reasons for bringing an outcome about, or
at least for attempting to do so. This is an example of what we shall
call a <em>mechanistically neutral</em> answer: that is, one which does
not involve making commitments concerning which states, or structures of
states, cause intentional actions. <a href="#fn9" class="footnote-ref"
id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<p>Proponents of a mechanistically neutral characterisation need not
deny that intentional actions are caused by intentions or other states
of agents. They merely insist on separating two questions:</p>
<ol>
<li><p>What distinguishes intentional actions from things which merely
happen to an agent (and from nonintentional actions, if there are
any)?</p></li>
<li><p>Which states cause intentional actions?</p></li>
</ol>
<p>All sides can agree that fully understanding action requires
answering both questions (and more). <a href="#fn10"
class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>
But whereas a mechanistically committed characterisation answers the
first question in a way that involves answering, partially or wholly,
the second, a mechanistically neutral characterisation answers the first
question in a way that does not. <a href="#fn11" class="footnote-ref"
id="fnref11" role="doc-noteref"><sup>11</sup></a> What makes an approach
mechanistically neutral is not the pattern of answers given to the
questions but the recognition that the answers are to an interesting
degree theoretically independent.</p>
<p>To see when a mechanistically neutral characterisation could be
useful, consider Bratman’s position as an example. He allows that
actions can be intentional ‘even though [the agent] has no distinctive
attitude of intending’ <span class="citation"
data-cites="Bratman:1987xw">(Bratman 1987, 132)</span>, and even though
the agent lacks the capacity to form intentions altogether <span
class="citation" data-cites="bratman:2000_valuing">(Bratman 2000,
51)</span>. This view follows from two claims: first, intentions are
distinct from any combination of beliefs and desires; and second,
beliefs and desires alone may, in certain cases, determine what an agent
intentionally does. Of course, this second claim would make no sense if
we answered the first question above by saying that intentional actions
are things caused by intentions. But Bratman’s position clearly makes
sense if we rely on a mechanistically neutral characterisation of
intentional action. If we anchor the notion of intentional action by
saying that intentional actions are things which happen because an agent
has reasons, we can then coherently postulate variety in the states and
processes which cause intentional actions.</p>
<p>Until now we have considered approaches which focus on intentional
actions only. But this is not the only coherent approach. Another
possibility is to first characterise a notion of purposive action
(invoking goals) and then elaborate on this in characterising
intentional action (invoking reasons concerning the goals). In this case
there is also a divide between mechanistically committed and
mechanistically neutral characterisations. A purposive action is an
action directed to one or more goals. Some take goals to be states of
agents <span class="citation" data-cites="austin:1996_goal">(Austin and
Vancouver 1996, 338)</span>. Any characterisation relying on such a
notion of goal is mechanistically committed: purposive actions are
characterised in terms of states which cause them. By contrast, others
have used ‘goal’ as a label for those outcomes to which an action is
directed <span class="citation" data-cites="wilson:2016_action">(e.g.
Wilson, Shpall, and Pin̄eros Glasscock 2016)</span> and have offered, or
relied on, mechanistically neutral characterisations of purposive action
(<span class="citation" data-cites="Bennett:1976rg">(Bennett 1976,
42)</span>; <span class="citation"
data-cites="Butterfill:2001kc">(Butterfill 2001)</span>; <span
class="citation" data-cites="Gergely:1995sq Csibra:2007hm">(Gergely et
al. 1995; Csibra and Gergely 2007)</span>; <span class="citation"
data-cites="Wright:1976ls">(Wright 1976)</span>).</p>
<p>How does any of this bear on our question about which features
distinguish acting jointly from acting in parallel but merely
individually? Consideration of ordinary, individual action suggests two
things. First, that it may also be possible to provide a mechanistically
neutral characterisation of acting jointly. And, second, that it is
coherent not to focus exclusively on a notion of acting jointly where
acting jointly is intentional. We can therefore separate two
questions:</p>
<ol>
<li><p>What distinguishes acting jointly from acting in parallel but
merely individually?</p></li>
<li><p>Which states cause the actions agents perform when they act
jointly?</p></li>
</ol>
<p>We shall extend our terminology and distinguish <em>mechanistically
committed</em> from <em>mechanistically neutral</em> answers to the
first question according to whether they do, or do not, involve making
commitments concerning the second question.</p>
<p>Giving a mechanistically neutral answer is consistent with denying
that the second question bears on the first at all, perhaps because you
see the first as a normative question and one quite separate from any
concern about causes. But, as we explain in §<a
href="#sec:objection-evidence" data-reference-type="ref"
data-reference="sec:objection-evidence">7</a>, giving a mechanistically
neutral answer is also consistent with allowing that the questions are
mutually constraining.</p>
<p>In what follows, we explore the prospects for an alternative strategy
which deviates from the standard strategy in aiming to provide a
mechanistically neutral characterisation. The initial focus is not on
joint counterparts of intentional action but on the notion of acting
jointly (allowing that intentional cases of acting jointly may
eventually turn out to be in some respect more fundamental). We shall
argue that the alternative yields a characterisation of acting jointly
which, although probably incomplete, meets criteria standardly used in
evaluating other accounts. We shall also argue that the alternative
strategy offers an advantage in solving the twin problems from §<a
href="#sec:intro" data-reference-type="ref"
data-reference="sec:intro">1</a>: the problem of singling out correct
accounts, and the problem of determining when two accounts are competing
attempts to characterise a single phenomenon rather than compatible
attempts to characterise different phenomena.</p>
<h1 id="sec:collective_vs_distributive"><strong>Collective vs
distributive</strong></h1>
<p>This and the following sections sketch a mechanistically neutral
answer to the question, What distinguishes acting jointly from acting in
parallel but merely individually? We focus initially on the purposive
aspect of acting jointly, and will only later (in §<a
href="#sec:intentional" data-reference-type="ref"
data-reference="sec:intentional">8</a>) turn to its intentional aspect.
Just as the notion of a goal is central to any account of ordinary,
individual purposive action, so our central notion will be that of a
collective goal. In order to introduce this notion (in §<a
href="#sec:collective_goals" data-reference-type="ref"
data-reference="sec:collective_goals">5</a>), we first need to clarify
how we will use the term ‘collective’ (in this section) and what it
means for an action to have a goal (in §<a href="#sec:goals"
data-reference-type="ref" data-reference="sec:goals">4</a>).</p>
<p>Consider these sentences:</p>
<ol>
<li><p>The tiny leaves fell from the tree.</p></li>
<li><p>The tiny leaves blocked the drain.</p></li>
</ol>
<p>The first sentence is naturally read <em>distributively</em>; that
is, as specifying something that each leaf did individually. Perhaps
first one leaf fell, then another fell. But the second sentence is
naturally read <em>collectively</em>. No one leaf blocked the drain;
rather the blocking was something that the leaves accomplished together.
For the sentence to be true on this collective reading, the tiny leaves’
blocking the drain cannot be, or cannot only be, a matter of each leaf
blocking the drain. <a href="#fn12" class="footnote-ref" id="fnref12"
role="doc-noteref"><sup>12</sup></a></p>
<p>Now consider an example involving actions and their outcomes:</p>
<ol>
<li><p>Those thoughtless actions blocked the drain.</p></li>
</ol>
<p>This sentence can be read in at least two ways, distributively or
collectively. We can read it distributively as concerning a sequence of
actions done over a period of time, each of which blocked the drain. In
this case, the truth of the sentence is just a matter of the same type
of outcome, namely blocking the drain, being an outcome of each action.
Alternatively we can read it as concerning several actions which have
this outcome collectively—perhaps a bunch of people dropped cigarette
butts into the drain more or less simultaneously. In this case the
outcome, blocking the drain, is not necessarily an outcome of any of the
individual actions, but it is an outcome of all of them taken together
(or, depending on your views about the semantics of plural
quantification, an outcome of one thing that somehow bundles together
the actions). This is the collective reading.</p>
<p>Note that the difference is not merely terminological. To see this,
consider how many times the drain must have been blocked. On the
distributive reading it was blocked at least as many times as there were
actions. On the collective reading it was not necessarily blocked more
than once. So the difference between collective and distributive is not
just a matter of words: it concerns how the actions and outcomes are
related.</p>
<h1 id="sec:goals"><strong>Goals</strong></h1>
<p>Our aim (in the next section) will be to show that there are
collective readings not only of sentences about the actual outcomes of
actions but also of sentences about the outcomes to which actions are
directed—that is, about the goals of actions. <a href="#fn13"
class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>
To this end we first need to say what it is for an action to be directed
to an outcome.</p>
<p>The challenge is to cash out the metaphor of directedness. One
familiar response involves intention. To a first approximation, the
directedness of an action to an outcome consists in an agent acting on
an intention where the intention plays a role in coordinating (and maybe
in planning) the agent’s actions in such a way that would normally
facilitate the outcome’s occurrence. This is one coherent way of
thinking about directedness. But it may not be the whole story about the
goals of actions. For some have argued that actions can be directed to
outcomes in virtue of states other than intentions, including desires
<span class="citation" data-cites="bratman:2000_valuing">(e.g. Bratman
2000)</span> and motor representations <span class="citation"
data-cites="butterfill:2012_intention">(e.g. Butterfill and Sinigaglia
2014)</span>. Note that regardless of which states of an agent
(intentions or others) are invoked, we can use the same basic pattern:
directedness is grounded by states which coordinate the action in such a
way that would normally facilitate the outcome’s occurrence. <a
href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a></p>
<p>Is it possible to characterise directedness without appealing to any
states of an agent at all? <span class="citation"
data-cites="Bennett:1976rg">Bennett (1976, 61)</span> suggests that the
directedness of an action to an outcome is a matter of the agent acting
because she is ‘so structured and situated’ as to do things which
increase the probability of the outcome occurring. We take Bennett to be
introducing two ideas. First, directedness is not always only a matter
of states of the agent but can also involve her environment and history.
Second, directedness can be characterised independently of any
particular mechanism. Borrowing these ideas we can draw a parallel with
the core idea about intention mentioned above: the directedness of an
action to an outcome consists in there being a state, structure or
situation which plays a role in coordinating the agent’s actions in such
a way that would normally facilitate the outcome’s occurrence. <a
href="#fn15" class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a> The state, structure or situation
may be intention, habit, biological function or other
behaviour-organizing circumstance connecting the agent’s actions to the
outcome (or any combination of these). The key to characterising
directedness is not any specific state, structure or situation but the
role of those in linking actions to outcomes.</p>
<p>This proposal about directedness is, to put it politely,
theoretically modest. It captures nothing but the bare structure of how
actions and goals relate. (And even that incompletely, for goals can be
partially ordered by the means–ends relation and actions by the
part–whole relation; directedness needs to be understood, more
generally, as a relation of structures of actions to structures of
outcomes.) But theoretical modesty is an advantage in one respect: the
proposal leaves open for discovery questions about what it is in virtue
of which actions are directed to outcomes.</p>
<p>This openness is valuable because we can make discoveries about the
goals of particular actions without yet knowing anything about the kind
of state, structure or situation in virtue of which the actions are
directed to the goal. For example, consider that ant behaviour is
routinely and uncontroversially characterized in terms of goals:</p>
<blockquote>
<p>The ants protect their fungal cultivar from pathogens and parasites,
provide the fungus with a constant source of nutrients, and aid in its
growth and dispersal. […] To promote the initial degradation of plant
biomass this material is masticated, mixed with ant fecal droplets, and
inoculated with fungal mycelia. <span class="citation"
data-cites="scott:2010_microbial">(Scott et al. 2010, e9922)</span></p>
</blockquote>
<p>Facts about the specific goals of the ants’ actions are important
discoveries. But for the most part, these discoveries were made
independently of much insight into what grounds the directedness of the
actions to the goals. Indeed, discoveries about goals are often
foundational for understanding mechanisms. To illustrate with another
species, knowing that the goal of certain actions is hunting enabled the
discovery that portid spiders use information about routes to prey even
after that information is no longer available in their environment <span
class="citation" data-cites="jackson:2011_spider">(Jackson and Cross
2011, 118–21)</span>, suggesting that representation may be
involved.</p>
<p>One quirk of our proposal is that we have characterised directedness
as linking actions, not agents, to outcomes. Our concern here is to
avoid a commitment. Consider:</p>
<blockquote>
<p>The goal of her action is to compost the leaf cuttings.</p>
</blockquote>
<p>and:</p>
<blockquote>
<p>Her goal is to compost the leaf cuttings.</p>
</blockquote>
<p>To some, the first may sound like an awkward paraphrase of the
second. But others might deny that the first implies the second—perhaps
on the grounds that the first can be true of ants but ants cannot have
goals; or perhaps on the grounds that actions can be subagential in
something like the way that (on some views) mental states can be
subpersonal. To avoid such controversies, we characterise directedness
as a relation between an action and an outcome. However what follows
could be adapted to work with directedness as a relation between agents
and outcomes.</p>
<h1 id="sec:collective_goals"><strong>Collective goals</strong></h1>
<p>Having clarified our use of ‘collective’ (in §<a
href="#sec:collective_vs_distributive" data-reference-type="ref"
data-reference="sec:collective_vs_distributive">3</a>) and characterised
goals (in the previous section) we are in a position to see how the
distinction between collective and distributive readings appears to
apply to sentences concerning the goals of actions. Consider the
sentence:</p>
<ol>
<li><p>Those actions had the goal of blocking the drain.</p></li>
</ol>
<p>Whereas the previous sentence (in §<a
href="#sec:collective_vs_distributive" data-reference-type="ref"
data-reference="sec:collective_vs_distributive">3</a>) was about causal
relations between actions and outcomes, this sentence concerns
teleological relations. We claim that, like the previous sentence, this
sentence has both distributive and collective readings. On the
distributive reading, each of the actions had the goal of blocking the
drain. This would fit a sequence of events in which someone attempted to
block the drain first by covering it with a metal sheet and then, after
this failed to block it, removing the metal sheet and pouring cement
powder into it. On the collective reading, by contrast, the actions’
having the goal of blocking the drain was not, or not only, a matter of
each of the actions having that goal. This would fit an episode in which
someone maliciously and patiently blocks a drain by dropping just one
cigarette butt into it each day, counting on their accumulation to do
its work.</p>
<p>The collective reading also appears to be possible in many mundane
cases. Imagine kneading some dough. This involves a sequence of folding
and stretching actions, and perhaps adding some flour as you go. The
point of all this is to get the dough into a condition that it will
later rise in a particular way. So we might say, of the sequence, that
those actions had the goal of getting the dough into a state where it
will rise nicely. If we are describing an ordinary baking activity, this
statement would be true on a collective reading.</p>
<p>So far we have considered actions with just one agent. But we can
also read sentences about goals collectively when there are two or more
agents involved. After all, the examples of blocking the drain and
kneading the dough could just as well have involved two agents rather
than just one.</p>
<p>Where a sentence about some actions being directed to a single
outcome is true on the collective reading, we stipulate, as a matter of
terminology, that the actions are <em>collectively directed</em> to that
outcome and that the outcome is a <em>collective goal</em> of the
actions.</p>
<p>We have explicated the notion of a collective goal only negatively by
saying that it is not, or not only, a matter of each action individually
being directed to the outcome. What is it a matter of? One answer to
this question might involve using one of the existing theories about
states of agents to further explicate the notion of a collective goal.
This would be incompatible with our aim of being mechanistically
neutral, of course. But there are also other kinds of structure that can
ground collective goals. In the case of honey bees foraging <span
class="citation" data-cites="leadbeater:2005new">(Leadbeater and Chittka
2005)</span> or ants farming fungus (see §<a href="#sec:goals"
data-reference-type="ref" data-reference="sec:goals">4</a>), what
underpins collective goals may be behavioural patterns, scent marks and
other signals which ensure coordination; and of course much the same may
be true in some situations involving humans too. In characterising
collective goals we therefore avoid invoking any particular states or
structures, just as we did in characterising goals (in §<a
href="#sec:goals" data-reference-type="ref"
data-reference="sec:goals">4</a>). Indeed, our proposal about goals can
be extended to collective goals in a natural way by switching from
intra-agental to inter-agential coordination: the collective
directedness of some agents’ actions to an outcome consists in there
being a state, structure or situation which plays a role in coordinating
all the actions in such a way that would normally facilitate the
outcome’s occurrence.</p>
<p>Nothing that follows depends on the details of this proposal. We
require only that the collective readings of sentences about goals serve
to single out, within a limited but useful range of cases, which things
are collective goals.</p>
<h1 id="sec:collective-goal-account"><strong>The Collective Goal
Account</strong></h1>
<p>Can collective goals assist in providing a mechanistically neutral
account of how acting jointly differs from acting in parallel but merely
individually? Consider the least subtle attempt to give a positive
answer, which we will call <em>The Collective Goal Account</em>:</p>
<blockquote>
<p>When the actions of two or more agents have a collective goal, the
agents are, in performing those actions, acting jointly; otherwise they
are acting in parallel but merely individually.</p>
</blockquote>
<p>This account is neutral on which states of the agents make it the
case that their actions have a collective goal. It is consistent with,
but neutral on, the further claim that it is only ever in virtue of the
agents’ shared intentions that actions have collective goals.</p>
<p>How does this account fare with respect to the examples and contrast
cases we mentioned at the start of this paper? In giving the examples
standardly offered which we mentioned in opening this paper—painting a
house together, lifting a heavy sofa together, and the rest (see §<a
href="#sec:intro" data-reference-type="ref"
data-reference="sec:intro">1</a>)—philosophers are distinguishing which
thing is occurring by specifying a goal (the lifting of the sofa, for
instance). And these examples do indeed appear to be cases where the
specified goal would typically be a collective goal. It can hardly be
very controversial, therefore, that one feature of standard examples is
the presence of a collective goal. <a href="#fn16" class="footnote-ref"
id="fnref16" role="doc-noteref"><sup>16</sup></a></p>
<p>Next consider the two contrast cases we mentioned at the start of
this paper (in §<a href="#sec:intro" data-reference-type="ref"
data-reference="sec:intro">1</a>). The first contrasted the actions of
members of a flash mob who noisily crack open their newspapers in order
to create a salient marker for the start of their performance with the
actions of the flash mob plus those of an onlooker who happens to crack
open her newspaper simultaneously in response to the same cue. The
actions of the flash mob would typically have a collective goal, namely
the creation of the salient marker. By contrast, there is no single
token outcome to which the onlooker’s actions plus the flash mob
members’ actions are directed. <a href="#fn17" class="footnote-ref"
id="fnref17" role="doc-noteref"><sup>17</sup></a> It follows, of course,
that there is no collective goal. So invoking the notion of a collective
goal suffices to distinguish this contrast case.</p>
<p>The second contrast case was a contrast between two members of the
flash mob later walking to the metro station together, who (by
stipulation) are acting jointly, and two people who happen to be walking
to the station side-by-side among a crowd heading that way. The success
of the flash mob members’ activity requires at least that both walk to
the station. And this is just the kind of case in which the two agents’
arrival at the metro station would be a collective goal of their
actions. By contrast, when two people just happen to be walking to the
station side-by-side, one person’s actions may succeed even though the
other accidentally falls into the sewer through a hole and never reaches
the station. It follows that invoking the notion of a collective goal is
sufficient to distinguish this contrast case too.</p>
<p>Reflection on both contrast cases shows, however, that invoking the
notion of a collective goal is not necessary. There is a simpler way to
distinguish these contrast cases. Indeed, the presence or absence of a
single outcome to which all the agents’ actions are directed is already
sufficient to distinguish the contrast cases. Our appeal to collective
goals therefore lacks motivation. If the examples and contrast cases can
be dealt with just by invoking the existence of a single outcome to
which all agents’ actions are directed, why bother with the additional
complexity of collective goals?</p>
<p>An initially tempting idea is to introduce further contrast cases.
For instance:</p>
<blockquote>
<p>Case 1: A bear has been spotted near each of two villages on either
side of a mountain. In each village there is a hunter who sets out to
hunt the bear. The villagers are entirely unaware of each other. Despite
tracking the bear from nearly opposite directions, the bear comes into
view for both hunters at the same time. Each takes a shot at it. Neither
shot is individually fatal, but sadly their combined effect kills the
bear.</p>
</blockquote>
<blockquote>
<p>Case 2: Two friends from a city go hunting a bear together. They hide
in a tree waiting for the bear to come into view. When it does, each
takes a shot at it. Neither shot is individually fatal, but sadly their
combined effect kills the bear.</p>
</blockquote>
<p>As each villager justifiably regards herself as having succeeded in
her project, we can be confident that the actions of the villagers are
directed to a single outcome, namely the death of the bear. This implies
that there is a single outcome to which all their actions are directed.
So we cannot capture this contrast by appealing only to the idea that
the agents’ actions are all directed to a single outcome; this is a
feature of both cases. Nevertheless, there does appear to be a contrast
with respect to acting jointly between the villagers’ actions and those
of the city dwellers. We can capture this contrast by appeal to
collective goals. We might say, ‘The villagers’ actions had the goal of
killing the bear.’ This sentence is true on the distributive reading, as
each of them performed actions which were indeed directed to the goal of
killing the bear. But the sentence is untrue on the collective reading,
for there is nothing more to their actions having the goal of killing
the bear than that each villager individually performed actions directed
to this outcome. By contrast, actions performed by the two city dwellers
are coordinated in such a way that would normally facilitate the bear’s
killing and therefore collectively directed to this outcome (see §<a
href="#sec:collective_goals" data-reference-type="ref"
data-reference="sec:collective_goals">5</a>). So the Collective Goal
Account is able to distinguish acting jointly in this case.</p>
<p>We doubt that introducing further examples and contrast cases will be
sufficient, however. When we have given talks or shared drafts, there
are always researchers in the audience whose intuitions differ from what
we expect on just about any contrast case we have mentioned. Some
awkward dissenters want to say, for instance, that the village dwellers
are acting jointly no less than the city dwellers are. <a href="#fn18"
class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>
Others may dissent on the grounds that the presence of a collective goal
is insufficient for the city dwellers to be acting jointly. <a
href="#fn19" class="footnote-ref" id="fnref19"
role="doc-noteref"><sup>19</sup></a> Several lengthy conversations
combined with reflection on the diversity of philosophers’ accounts of
acting jointly have gradually shifted us away from thinking of the
awkward dissenters as people who just haven’t tuned in. Their dissent is
informative. Simply providing examples and contrast cases does not
reliably give an audience a single signal to tune in to. The contrast
cases on which there is little dissent do not enable us to lock on to
whatever phenomena those responsible for the leading accounts of acting
jointly are interested in; and the contrast cases with the potential to
do this are, to a sufficiently diverse audience, themselves too
controversial to put much weight on.</p>
<p>As far as examples and contrast cases go, we find no grounds for
preferring this account over a competitor (or conversely). In the next
section we shall therefore introduce another way of defending the
Collective Goal Account.</p>
<h1 id="sec:objection-evidence"><strong>How to defend a mechanistically
neutral account of acting jointly</strong></h1>
<p>Our problem is how to single out correct from incorrect attempts to
distinguish acting jointly from acting in parallel but merely
individually. The problem arises because it is possible to construct
multiple accounts—whether mechanistically committed (see §<a
href="#sec:intro" data-reference-type="ref"
data-reference="sec:intro">1</a>) or mechanistically neutral (see §<a
href="#sec:collective-goal-account" data-reference-type="ref"
data-reference="sec:collective-goal-account">6</a>)—where each account
will be found by at least some people to accord with how they
intuitively make the distinction. In this section we shall characterise
a strategy on which this problem is actually an advantage.</p>
<p>As mentioned in the introduction (§<a href="#sec:intro"
data-reference-type="ref" data-reference="sec:intro">1</a>), the
mechanistically neutral strategy can be found in the literature.
Consider the approach of <span class="citation"
data-cites="Sebanz:2006yq">Sebanz, Bekkering, and Knoblich
(2006)</span>, who offer this influential characterisation:</p>
<blockquote>
<p>Joint action can be regarded as any form of social interaction
whereby two or more individuals coordinate their actions in space and
time to bring about a change in the environment. <span class="citation"
data-cites="Sebanz:2006yq">(Sebanz, Bekkering, and Knoblich 2006,
70)</span></p>
</blockquote>
<p>Although this is offered as a ‘working definition’ and is not
supposed to provide deep insight (as it invokes social interaction,
which is hardly less difficult to pin down than joint action), it has
proven to be useful. We suggest its usefulness is due at least in part
to it clearly separating the thing to be explained from proposed
explanations of it. Opposing groups of researchers adopt the working
definition but propose different theories about the mechanisms of joint
action. The working definition provides the common ground necessary for
evaluating the various proposals and understanding them as broadly
compatible attempts to fill in details about the mechanisms which make
joint action possible (see <span class="citation"
data-cites="Knoblich:2010fk">(Knoblich, Butterfill, and Sebanz
2011)</span> for a review).</p>
<p>The working definition above was not intended to, and does not,
distinguish acting jointly from acting in parallel but merely
individually. This is no objection to <span class="citation"
data-cites="Sebanz:2006yq">Sebanz, Bekkering, and Knoblich
(2006)</span>, of course. But it does mean that we cannot use it for our
aim of understanding this distinction. This is why we have considered
the Collective Goal Account (§<a href="#sec:collective-goal-account"
data-reference-type="ref"
data-reference="sec:collective-goal-account">6</a>).</p>
<p>The Collective Goal Account can be used in the same way as <span
class="citation" data-cites="Sebanz:2006yq">Sebanz, Bekkering, and
Knoblich (2006)</span>’s working definition. That is, we can consider it
as one attempt to characterise some aspect of a phenomenon. Whether we
eventually accept this attempt should depend on what we discover about
mechanisms underpinning collective goals. If it turns out that there is
at least one mechanism, this will increase our confidence that the
Collective Goal Account is correct.</p>
<p>Indeed, there is already one study which explicitly sets out to
establish a mechanism underpinning collective goals <span
class="citation" data-cites="dellagatta:2017_drawn">(della Gatta et al.
2017)</span>. These authors conclude that agents’ actions can have
collective goals in virtue of motor representations. This is not an
isolated finding. Other studies might be interpreted as indirectly
supporting the same conclusion about motor representations causing
actions agents perform when their actions have collective goals <span
class="citation"
data-cites="baus:2014_predicting clarke:2019_joint kourtis:2014_attention loehr:2015_sound Menoret:2013fk meyer:2013_higher-order novembre:2013_motor ramenzoni:2014_scaling schmitz:2017_corepresentation sacheli:2018_evidence sacheli:2021_mechanisms">(these
include Baus et al. 2014; Clarke et al. 2019; Kourtis et al. 2014; Loehr
and Vesper 2015; Ménoret et al. 2014; Meyer, Wel, and Hunnius 2013;
Novembre et al. 2014; Ramenzoni, Sebanz, and Knoblich 2014; Schmitz et
al. 2017; Sacheli, Arcangeli, and Paulesu 2018; Sacheli et al.
2021)</span>. Of course, fully defending—or decisively rejecting—the
idea that collective goals can be used in distinguishing acting jointly
from acting in parallel but merely individually would require careful
analysis of these findings, and perhaps further experimental
discoveries. While that is beyond the scope of this paper, we can
already say that the Collective Goal Account receives some support from
discoveries about mechanisms.</p>
<p>Should we therefore accept the Collective Goal Account? Not yet. Some
may object that some essential feature is missing, such as cooperation
<span class="citation" data-cites="Searle:1990em">(Searle 1990)</span>
or commitment <span class="citation"
data-cites="gilbert:2014_book">(Gilbert 2013)</span>.</p>
<p>How could we discover whether the objections are justified? We need,
first, to construct mechanistically neutral accounts of cooperation and
commitment; then, second, to discover which states and processes
causally explain the actions one or another kind of agent performs when
she performs actions which are cooperative or committed in the relevant
ways; and, third, to understand whether such states and processes are
distinct from, or bound up with, those which enable two or more agents’
actions to have collective goals. If a feature such as cooperation or
commitment turns out to be enabled by the same states and processes that
enable collective goals, then we have grounds for rejecting or revising
the Collective Goal Account, and for regarding this feature as an
essential feature of (at least one kind of) acting jointly. But if such
a feature is enabled by clearly dissociable states and processes, we
would need alternative grounds for regarding it as an essential feature.
Given that all this is unknown at present, we cannot accept either the
objections or the Collective Goal Account.</p>
<p>Suppose, hypothetically, that the Collective Goal Account were
vindicated against the objections. It would not follow that the account
is uniquely correct, nor that notions such as cooperation and commitment
have no role in characterising acting jointly. Other mechanistically
neutral characterisations of acting jointly may be equally well
supported. In this case we might eventually conclude that there are
multiple correct ways of distinguishing acting jointly from acting in
parallel but merely individually. This form of pluralism about acting
jointly would be unproblematic because it is disciplined. It would be
analogous to discovering that dissociable systems map onto different
aspects of memory <span class="citation"
data-cites="jacoby:1991_process">(e.g. Jacoby 1991)</span>.</p>
<p>The approach we are describing is not limited to defending the
Collective Goal Account. Here is the general idea. Start by being
maximally permissive in considering any proposed mechanistically neutral
account of acting jointly, requiring only that the account is a
conceivably successful attempt to capture cases reasonably taken to be
paradigms of acting jointly. <a href="#fn20" class="footnote-ref"
id="fnref20" role="doc-noteref"><sup>20</sup></a> Next attempt to
discover which states and processes might enable the features identified
by these mechanistically neutral accounts to be exhibited by actual
agents. Where no such states or processes can be discovered, the
mechanistically neutral account may be disregarded. Where multiple
accounts specify features which are all enabled by the same, or
overlapping, states and processes, there is a case for treating those
mechanistically neutral accounts as fragments of some larger, unified
account. And where distinctive states and processes enable features
specified by just one mechanistically neutral account, this indicates
that the account captures one distinction between acting jointly and
acting in parallel but merely individually.</p>
<p>This way of defending mechanistically neutral accounts may be
relevant to a conflict between proponents of leading characterisations
of acting jointly. Consider two well-known attempts to specify shared
intention and its explanatory relation to action. <span class="citation"
data-cites="gilbert:2014_book">Gilbert (2013, 10)</span> does this in
terms of a special kind of mutual obligation which she labels <em>joint
commitment</em>, <span class="citation"
data-cites="bratman:2014_book">Bratman (2014, 7)</span> in terms of
interpersonal coordination of planning. Both present themselves as
offering incompatible accounts of a single phenomenon (<span
class="citation" data-cites="gilbert:2014_nature">(Gilbert 2014)</span>;
<span class="citation" data-cites="bratman:2014_book">(Bratman 2014,
chap. 5)</span>).</p>
<p>Suppose we wanted to address this conflict using the above way of
defending mechanistically neutral accounts. We could use elements from
each protagonist to construct a mechanistically neutral adaptation of
their account. <a href="#fn21" class="footnote-ref" id="fnref21"
role="doc-noteref"><sup>21</sup></a> In Gilbert’s case, this would be an
account on which, roughly, the directedness of actions to outcomes
involves an element of commitment. Where some agents are jointly
committed to bringing an outcome about, their actions are directed to
this outcome insofar as they are guided by this commitment. As long as
joint commitment is understood in a way that does not involve any
particular states of the agents, this could yield a mechanistically
neutral characterisation. In Bratman’s case, instead of using ideas
about interpersonal coordination of planning to characterise shared
intention, we can use them as characterising shared agency directly. For
instance, we might consider that shared agency involves two or more
agents’ actions being directed to an outcome where the directedness of
their action to this outcome consists not only in their actions being
coordinated in such a way that would normally facilitate the outcome’s
occurrence but also in there being a state, structure or situation which
plays a role in coordinating their plans and structuring their
bargaining and deliberation.</p>
<p>These mechanistically neutral adaptations may seem barely different
from Gilbert’s and Bratman’s original versions. Yet the difference
really is substantial because it affects whether the accounts are
incompatible and how correct accounts can be singled out. As adapted,
there are no immediate grounds to regard Gilbert’s account as
incompatible with an account which, like Bratman’s, centers on planning
abilities; nor conversely. After all, as in the case of the Collective
Goal Account, a mechanistically neutral adaptation of Gilbert would be
vindicated (or not) through discovering mechanisms which actually
underpin joint commitment and support acting jointly; and likewise for
Bratman on interpersonal coordination of planning. Any such vindication
is consistent, of course, with entirely different accounts also being
vindicated. There is a range of possibilities. Mechanisms underpinning
joint commitments could coincide with mechanisms underpinning other
mechanistically neutral accounts—perhaps, for instance, there is no
interpersonal coordination of planning without joint commitments. <a
href="#fn22" class="footnote-ref" id="fnref22"
role="doc-noteref"><sup>22</sup></a> This might motivate combining what
had initially appeared to be distinct mechanistically neutral accounts.
Alternatively, it may be that distinct mechanisms are involved, which
would lend support to the view that a mechanistically neutral adaptation
of Gilbert or of Bratman identifies one among several forms of acting
jointly. <a href="#fn23" class="footnote-ref" id="fnref23"
role="doc-noteref"><sup>23</sup></a></p>
<p>Adopting the mechanistically neutral strategy turns diversity in
people’s feelings about which cases are paradigms of acting jointly into
an advantage. It provides a way of answering questions about when two
accounts are incompatible attempts to characterise a single phenomenon
rather than compatible attempts to characterise different phenomena. To
single out which accounts of acting jointly succeed, we need to
investigate mechanisms underpinning their constructs.</p>
<h1 id="sec:intentional"><strong>From purposive to
intentional</strong></h1>
<p>As promised in §<a href="#sec:alternative_strategy"
data-reference-type="ref"
data-reference="sec:alternative_strategy">2</a>, our strategy for
characterising how acting jointly differs from acting in parallel but
merely individually deviates from the standard strategy in two respects.
Not only is it mechanistically neutral: it is also one which starts by
focussing on acting jointly without any prior assumption that this must
be understood as a joint counterpart of ordinary, individual intentional
action. This led us to the notion of a collective goal and a
corresponding attempt to characterise acting jointly. Invoking
collective goals is conceivably sufficient for capturing a sense in
which acting jointly can be purposive where the purposivity is not, or
not only, a matter of each agent’s actions being purposive (or so we
argued in §<a href="#sec:collective-goal-account"
data-reference-type="ref"
data-reference="sec:collective-goal-account">6</a>). But of course none
of this is sufficient to capture what many philosophers take the primary
target phenomena to be: cases where two or more agents’ acting jointly
is intentional. How might we provide a mechanistically neutral
characterisation of a joint counterpart of intentional action?</p>
<p>We noted earlier that an intentional action may be characterised,
very roughly and incompletely, as an action that happens because its
agent has certain reasons for bringing an outcome about, or at least for
attempting to do so. One striking feature of attempts to characterise
intentional action in this way is that they all rely, explicitly or
implicitly, on a particular way of individuating actions. Actions are
individuated by the outcomes to which they are directed. The reasons in
virtue of which an action is intentional are reasons which an agent has
for bringing about the outcome. Note that while this approach involves
no commitment to the existence of actions which are not intentional, it
does involve commitment to the possibility of individuating some actions
independently of features in virtue of which they are intentional. That
is, we are committed to a conceptual distinction between purposive and
intentional action.</p>
<p>A parallel account of acting jointly is possible. Intentional cases
of acting jointly may be characterised, very roughly and incompletely,
as actions that happen because their agents have certain reasons for
bringing an outcome about as a collective goal of their actions, or at
least for attempting to do so. <a href="#fn24" class="footnote-ref"
id="fnref24" role="doc-noteref"><sup>24</sup></a> Given that this is a
coherent, and natural, extension of a characterisation of ordinary,
individual action, we conclude that it is probably possible to provide
at least one mechanistically neutral characterisation of acting jointly
where acting jointly is intentional.</p>
<p>This characterisation of acting jointly contrasts with
mechanistically committed characterisations. According to <span
class="citation" data-cites="ludwig:2015_shared">Ludwig (2015,
12)</span>, who is formulating a claim common to a range of views,
‘collective intentional activity in general should be seen as the result
of shared intentions being satisfied’. By contrast, on our
mechanistically neutral proposal, it should be seen as the result of
agents having reasons for bringing an outcome about as a collective goal
of their actions. Of course, it may turn out that these are
extensionally equivalent because no agents have such reasons without
having corresponding shared intentions. The disagreement concerns not
whether shared intentions are necessary but whether they (or any other
states of agents) need be invoked in characterising how acting jointly
differs from acting in parallel but merely individually.</p>
<h1 id="sec:conclusion"><strong>Conclusion</strong></h1>
<p>Our question was about which features distinguish acting jointly from
acting in parallel but merely individually. We observed that twin
problems face the standard, mechanistically committed strategy for
answering this question. These problems are how to determine when two
accounts should be regarded as competing attempts to characterise a
single phenomenon; and how to single out, from a growing number and
increasing diversity of accounts, those which are correct (§<a
href="#sec:intro" data-reference-type="ref"
data-reference="sec:intro">1</a>). Taking these problems to motivate
considering an alternative, we set out to introduce and pursue a
mechanistically neutral strategy for characterising acting jointly.</p>
<p>To develop a mechanistically neutral account, we invoked
uncontroversial parts of a logical distinction between collective and
distributive prediction (§<a href="#sec:collective_vs_distributive"
data-reference-type="ref"
data-reference="sec:collective_vs_distributive">3</a>) and we outlined a
mechanistically neutral account of goals (in §<a href="#sec:goals"
data-reference-type="ref" data-reference="sec:goals">4</a>) in order to
introduce the notion of a collective goal (§<a
href="#sec:collective_goals" data-reference-type="ref"
data-reference="sec:collective_goals">5</a>). According to what we call
the Collective Goal Account, when the actions of two or more agents have
a collective goal, the agents are, in performing those actions, acting
jointly (§<a href="#sec:collective-goal-account"
data-reference-type="ref"
data-reference="sec:collective-goal-account">6</a>). We also outlined an
attempt to capture intentional aspects of acting jointly (§<a
href="#sec:intentional" data-reference-type="ref"
data-reference="sec:intentional">8</a>).</p>
<p>Our thesis is not that the Collective Goal Account is correct. We
introduced a method for defending mechanistically neutral accounts
borrowed from existing literature (§<a href="#sec:objection-evidence"
data-reference-type="ref"
data-reference="sec:objection-evidence">7</a>). This method partially
vindicates the Collective Goal Account but leaves open the possibility
that it is one among several significant ways of distinguishing acting
jointly from acting in parallel but merely individually. Indeed, we
showed that mechanistically neutral adaptations of leading accounts
might in principle be vindicated in the same way. Further, our
vindication allows that the Collective Goal Account may ultimately need
to incorporate mechanistically neutral characterisations of cooperation,
commitment, coordination and more besides. If this is right, the
Collective Goal Account is at best an incomplete first draft (albeit one
which is no worse than the leading accounts in handling contrast
cases)—but one that provides a platform on which proponents of planning
and joint commitment can build.</p>
<p>Many will reject mechanistically neutral characterisations of acting
jointly, not on the grounds that acting jointly necessarily involves
some kind of shared intention (this is consistent with a mechanistically
neutral characterisation, after all), but on the grounds that, as they
see things, there is a conceptual or constitutive connection between the
two. (Such a view might be motivated by reflection on <span
class="citation" data-cites="pacherie:2013_lite">(Pacherie
2013)</span>.) We have offered no argument against such opponents; nor
do we aim to do so. The issue should be decided according to which
strategy yields most progress in understanding what distinguishes acting
jointly. The mechanistically committed strategy has dominated discussion
to date but faces twin problems that may be challenging to overcome. By
contrast, the mechanistically neutral strategy avoids these problems and
is, we submit, a promising new contender. <a href="#fn25"
class="footnote-ref" id="fnref25"
role="doc-noteref"><sup>25</sup></a></p>
<div id="refs" class="references csl-bib-body hanging-indent"
data-entry-spacing="0" role="list">
<div id="ref-alvarez:2016_reasons" class="csl-entry" role="listitem">
Alvarez, Maria. 2016. <span>“Reasons for <span>Action</span>:
<span>Justification</span>, <span>Motivation</span>,
<span>Explanation</span>.”</span> In <em>The <span>Stanford
Encyclopedia</span> of <span>Philosophy</span></em>, edited by Edward N.
Zalta. <span>Metaphysics Research Lab, Stanford University</span>.
</div>
<div id="ref-asarnow:2020_shared" class="csl-entry" role="listitem">
Asarnow, Samuel. 2020. <span>“Shared <span>Agency Without Shared
Intention</span>.”</span> <em>The Philosophical Quarterly</em>
forthcoming. <a
href="https://doi.org/10.1093/pq/pqaa012">https://doi.org/10.1093/pq/pqaa012</a>.
</div>
<div id="ref-austin:1996_goal" class="csl-entry" role="listitem">
Austin, James, and Jeffrey Vancouver. 1996. <span>“Goal
<span>Constructs</span> in <span>Psychology</span>:
<span>Structure</span>, <span>Process</span>, and
<span>Content</span>.”</span> <em>Psychological Bulletin</em> 120 (3):
338–75.
</div>
<div id="ref-bach:1978_representational" class="csl-entry"
role="listitem">
Bach, Kent. 1978. <span>“A Representational Theory of Action.”</span>
<em>Philosophical Studies</em> 34 (4): 361–79. <a
href="https://doi.org/10.1007/BF00364703">https://doi.org/10.1007/BF00364703</a>.
</div>
<div id="ref-baier:1997_joint" class="csl-entry" role="listitem">
Baier, Annette C. 1997. <span>“Doing <span>Things With Others</span>:
<span>The Mental Commons</span>.”</span> In <em>Commonality and
Particularity in Ethics</em>, edited by Lilli Alanen, Sarah Heinamaa,
and Thomas Wallgren, 15–44. Palgrave Macmillan. <a
href="https://doi.org/10.1007/978-1-349-25602-0_2">https://doi.org/10.1007/978-1-349-25602-0_2</a>.
</div>
<div id="ref-baus:2014_predicting" class="csl-entry" role="listitem">
Baus, Cristina, Natalie Sebanz, Vania de la Fuente, Francesca Martina
Branzi, Clara Martin, and Albert Costa. 2014. <span>“<span
class="nocase">On predicting others’ words: Electrophysiological
evidence of prediction in speech production</span>.”</span>
<em><span>Cognition</span></em> <span>133</span> (2): 395–407. <a
href="https://doi.org/10.1016/j.cognition.2014.07.006">https://doi.org/10.1016/j.cognition.2014.07.006</a>.
</div>
<div id="ref-Bennett:1976rg" class="csl-entry" role="listitem">
Bennett, Jonathan. 1976. <em>Linguistic Behaviour</em>. Cambridge:
Cambridge University Press.
</div>
<div id="ref-blomberg:2015_shared" class="csl-entry" role="listitem">
Blomberg, Olle. 2015. <span>“Shared <span>Goals</span> and
<span>Development</span>.”</span> <em>The Philosophical Quarterly</em>
65 (258): 94–101. <a
href="https://doi.org/10.1093/pq/pqu059">https://doi.org/10.1093/pq/pqu059</a>.
</div>
<div id="ref-blomberg:2015_common" class="csl-entry" role="listitem">
———. 2016. <span>“Common <span>Knowledge</span> and
<span>Reductionism</span> about <span>Shared Agency</span>.”</span>
<em>Australasian Journal of Philosophy</em> 94 (2): 315–26. <a
href="https://doi.org/10.1080/00048402.2015.1055581">https://doi.org/10.1080/00048402.2015.1055581</a>.
</div>
<div id="ref-brand:1984_intending" class="csl-entry" role="listitem">
Brand, Myles. 1984. <em>Intending and Acting: Toward a Naturalized
Action Theory</em>. <span>Cambridge, Massachusetts</span>: <span>MIT
Press</span>.
</div>
<div id="ref-Bratman:1987xw" class="csl-entry" role="listitem">
Bratman, Michael E. 1987. <em>Intentions, Plans, and Practical
Reasoning</em>. Cambridge, MA: Harvard University Press.
</div>
<div id="ref-Bratman:1992mi" class="csl-entry" role="listitem">
———. 1992. <span>“Shared Cooperative Activity.”</span> <em>The
Philosophical Review</em> 101 (2): 327–41.
</div>
<div id="ref-Bratman:1999fr" class="csl-entry" role="listitem">
———. 1997. <span>“I Intend That We <span>J</span>.”</span> In
<em>Contemporary Action Theory, Volume 2: Social Action</em>, edited by
Raimo Tuomela and Ghita Holmstrom-Hintikka. Dordrecht: Kluwer.
</div>
<div id="ref-bratman:2000_valuing" class="csl-entry" role="listitem">
———. 2000. <span>“Valuing and the Will.”</span>
<em>No<span>û</span>s</em> 34 (supplement 14): 249–65. <a
href="https://doi.org/10.1111/0029-4624.34.s14.13">https://doi.org/10.1111/0029-4624.34.s14.13</a>.
</div>
<div id="ref-bratman:2014_book" class="csl-entry" role="listitem">
———. 2014. <em>Shared Agency: A Planning Theory of Acting Together</em>.
Oxford: Oxford University Press. <a
href="http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199897933.001.0001">http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199897933.001.0001</a>.
</div>
<div id="ref-brooks_joint_1981" class="csl-entry" role="listitem">
Brooks, D. H. M. 1981. <span>“Joint Action.”</span> <em>Mind</em>, New
series, 90 (357): 113–19. <a
href="http://www.jstor.org/stable/2253670">http://www.jstor.org/stable/2253670</a>.
</div>
<div id="ref-brownell:2011_early" class="csl-entry" role="listitem">
Brownell, Celia A. 2011. <span>“Early <span>Developments</span> in
<span>Joint Action</span>.”</span> <em>Review of Philosophy and
Psychology</em> 2: 193–211. <a
href="https://doi.org/10.1007/s13164-011-0056-1">https://doi.org/10.1007/s13164-011-0056-1</a>.
</div>
<div id="ref-Butterfill:2001kc" class="csl-entry" role="listitem">
Butterfill, Stephen A. 2001. <span>“Two Kinds of Purposive
Action.”</span> <em>European Journal of Philosophy</em> 9 (2): 141–65.
</div>
<div id="ref-butterfill:2012_intention" class="csl-entry"
role="listitem">
Butterfill, Stephen A., and Corrado Sinigaglia. 2014. <span>“Intention
and Motor Representation in Purposive Action.”</span> <em>Philosophy and
Phenomenological Research</em> 88 (1): 119–45. <a
href="https://doi.org/10.1111/j.1933-1592.2012.00604.x">https://doi.org/10.1111/j.1933-1592.2012.00604.x</a>.
</div>
<div id="ref-Carpenter:2009wq" class="csl-entry" role="listitem">
Carpenter, Malinda. 2009. <span>“Just How Joint Is Joint Action in
Infancy?”</span> <em>Topics in Cognitive Science</em> 1 (2): 380–92.
</div>
<div id="ref-chant_unintentional_2007" class="csl-entry"
role="listitem">
Chant, Sara Rachel. 2007. <span>“Unintentional Collective
Action.”</span> <em>Philosophical Explorations: An International Journal
for the Philosophy of Mind and Action</em> 10 (3): 245. <a
href="https://doi.org/10.1080/13869790701535246">https://doi.org/10.1080/13869790701535246</a>.
</div>
<div id="ref-clarke:2019_joint" class="csl-entry" role="listitem">
Clarke, Sam, Luke McEllin, Anna Francová, Marcell Székely, Stephen A.
Butterfill, and John Michael. 2019. <span>“Joint Action Goals Reduce
Visuomotor Interference Effects from a Partner’s Incongruent
Actions.”</span> <em>Scientific Reports</em> 9 (1): 1–9. <a
href="https://doi.org/10.1038/s41598-019-52124-6">https://doi.org/10.1038/s41598-019-52124-6</a>.
</div>
<div id="ref-Csibra:2007hm" class="csl-entry" role="listitem">
Csibra, Gergely, and György Gergely. 2007. <span>“Obsessed with Goals’:
Functions and Mechanisms of Teleological Interpretation of Actions in
Humans.”</span> <em>Acta Psychologica</em> 124 (1): 60–78.
</div>
<div id="ref-Davidson:1971fz" class="csl-entry" role="listitem">
Davidson, Donald. 1971. <span>“Agency.”</span> In <em>Agent, Action, and
Reason,</em> edited by Robert Binkley, Richard Bronaugh, and Ausonia
Marras, 3–25. Toronto: University of Toronto Press. <a
href="https://doi.org/10.1093/0199246270.001.0001">https://doi.org/10.1093/0199246270.001.0001</a>.
</div>
<div id="ref-dellagatta:2017_drawn" class="csl-entry" role="listitem">
della Gatta, Francesco, Francesca Garbarini, Marco Rabuffetti, Luca
Viganò, Stephen A. Butterfill, and Corrado Sinigaglia. 2017.
<span>“Drawn Together: <span>When</span> Motor Representations Ground
Joint Actions.”</span> <em>Cognition</em> 165: 53–60. <a
href="https://doi.org/10.1016/j.cognition.2017.04.008">https://doi.org/10.1016/j.cognition.2017.04.008</a>.
</div>
<div id="ref-dickinson:2016_instrumental" class="csl-entry"
role="listitem">
Dickinson, Anthony. 2016. <span>“Instrumental Conditioning Revisited:
<span>Updating</span> Dual-Process Theory.”</span> In <em>Associative
Learning and Cognition</em>, edited by J. B. Trobalon and V. D. Chamizo,
51:177–95. <span>Edicions Universitat Barcelona</span>.
</div>
<div id="ref-Dretske:1988sq" class="csl-entry" role="listitem">
Dretske, Fred. 1988. <em>Explaining Behavior</em>. Cambridge,
Massachusetts: MIT Press.
</div>
<div id="ref-gallotti:2013_social" class="csl-entry" role="listitem">
Gallotti, Mattia, and Chris D. Frith. 2013. <span>“Social Cognition in
the We-Mode.”</span> <em>Trends in Cognitive Sciences</em> 17 (4):
160–65. <a
href="https://doi.org/10.1016/j.tics.2013.02.002">https://doi.org/10.1016/j.tics.2013.02.002</a>.
</div>
<div id="ref-Gergely:1995sq" class="csl-entry" role="listitem">
Gergely, György, Z. Nadasky, Gergely Csibra, and S. Biro. 1995.
<span>“Taking the Intentional Stance at 12 Months of Age.”</span>
<em>Cognition</em> 56: 165–93.
</div>
<div id="ref-gilbert_walking_1990" class="csl-entry" role="listitem">
Gilbert, Margaret P. 1990. <span>“Walking Together: A Paradigmatic
Social Phenomenon.”</span> <em>Midwest Studies in Philosophy</em> 15:
1–14.
</div>
<div id="ref-Gilbert:1992rs" class="csl-entry" role="listitem">
———. 1992. <em>On Social Facts</em>. Princeton, NJ: Princeton University
Press.
</div>
<div id="ref-Gilbert:2010fk" class="csl-entry" role="listitem">
———. 2010. <span>“Collective Action.”</span> In <em>A Companion to the
Philosophy of Action</em>, edited by Timothy O’Connor and Constantine
Sandis, 67–73. Oxford: Blackwell.
</div>
<div id="ref-gilbert:2014_book" class="csl-entry" role="listitem">
———. 2013. <em>Joint Commitment: How We Make the Social World</em>.
Oxford: Oxford University Press. <a
href="http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199970148.001.0001">http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199970148.001.0001</a>.
</div>
<div id="ref-gilbert:2014_nature" class="csl-entry" role="listitem">
———. 2014. <span>“The Nature of Agreements: A Solution to Some Puzzles
about Claim-Rights andJoint Intention1.”</span> In <em>Rational and
Social Agency: The Philosophy of Michael Bratman</em>, edited by Manuel
Vargas and Gideon Yaffe, 215–56. <span>Oxford</span>: Oxford University
Press.
</div>
<div id="ref-ginet:1990_action" class="csl-entry" role="listitem">
Ginet, Carl. 1990. <em>On <span>Action</span></em>. <span>Cambridge
University Press</span>.
</div>
<div id="ref-Gold:2007zd" class="csl-entry" role="listitem">
Gold, Natalie, and Robert Sugden. 2007. <span>“Collective Intentions and
Team Agency.”</span> <em>Journal of Philosophy</em> 104 (3): 109–37.
</div>
<div id="ref-helm_plural_2008" class="csl-entry" role="listitem">
Helm, Bennett W. 2008. <span>“Plural Agents.”</span> <em>Nous</em> 42
(1): 17–49. <a
href="https://doi.org/10.1111/j.1468-0068.2007.00672.x">https://doi.org/10.1111/j.1468-0068.2007.00672.x</a>.
</div>
<div id="ref-jackson:2011_spider" class="csl-entry" role="listitem">
Jackson, Robert R., and Fiona R. Cross. 2011. <span>“Spider
<span>Cognition</span>.”</span> In <em>Advances in <span>Insect
Physiology</span></em>, edited by Jérôme Casas, 41:115–74. Spider
<span>Physiology</span> and <span>Behaviour</span>. <span>Academic
Press</span>. <a
href="https://doi.org/10.1016/B978-0-12-415919-8.00003-3">https://doi.org/10.1016/B978-0-12-415919-8.00003-3</a>.
</div>
<div id="ref-jacoby:1991_process" class="csl-entry" role="listitem">
Jacoby, Larry L. 1991. <span>“A Process Dissociation Framework:
<span>Separating</span> Automatic from Intentional Uses of
Memory.”</span> <em>Journal of Memory and Language</em> 30 (5): 513–41.
<a
href="https://doi.org/10.1016/0749-596X(91)90025-F">https://doi.org/10.1016/0749-596X(91)90025-F</a>.
</div>
<div id="ref-Knoblich:2010fk" class="csl-entry" role="listitem">
Knoblich, Günther, Stephen A. Butterfill, and Natalie Sebanz. 2011.
<span>“Psychological Research on Joint Action: Theory and Data.”</span>
In <em>Psychology of Learning and Motivation</em>, edited by Brian Ross,
51:59–101. San Diego, CA: Academic Press.
</div>
<div id="ref-kourtis:2014_attention" class="csl-entry" role="listitem">
Kourtis, Dimitrios, Günther Knoblich, Mateusz Woźniak, and Natalie
Sebanz. 2014. <span>“<span class="nocase">Attention Allocation and Task
Representation during Joint Action Planning</span>.”</span>
<em><span>Journal of Cognitive Neuroscience</span></em> 26 (10):
2275–86. <a
href="https://doi.org/10.1162/jocn_a_00634">https://doi.org/10.1162/jocn_a_00634</a>.
</div>
<div id="ref-Kutz:2000si" class="csl-entry" role="listitem">
Kutz, Christopher. 2000. <span>“Acting Together.”</span> <em>Philosophy
and Phenomenological Research</em> 61 (1): 1–31.
</div>
<div id="ref-laurence:2011_anscombian" class="csl-entry"
role="listitem">
Laurence, Ben. 2011. <span>“An Anscombian Approach to Collective
Action.”</span> In <em>Essays on Anscombe’s Intention</em>. Cambridge,
MA: Harvard University Press.
</div>
<div id="ref-leadbeater:2005new" class="csl-entry" role="listitem">
Leadbeater, Ellouise, and Lars Chittka. 2005. <span>“A New Mode of
Information Transfer in Foraging Bumblebees?”</span> <em>Current
Biology</em> 15 (12): R447–48.
</div>
<div id="ref-Linnebo:2005ig" class="csl-entry" role="listitem">
Linnebo, Øystein. 2005. <span>“Plural Quantification.”</span> In <em>The
Stanford Encyclopedia of Philosophy (Spring 2005 Edition)</em>, edited
by Edward N. Zalta. Stanford, CA: Metaphysics Research Lab, Stanford
University.
</div>
<div id="ref-loehr:2015_sound" class="csl-entry" role="listitem">
Loehr, Janeen D., and Cordula Vesper. 2015. <span>“The Sound of You and
Me: Novices Represent Shared Goals in Joint Action.”</span> <em>The
Quarterly Journal of Experimental Psychology</em> 0 (ja): 1–30. <a
href="https://doi.org/10.1080/17470218.2015.1061029">https://doi.org/10.1080/17470218.2015.1061029</a>.
</div>
<div id="ref-longworth:2019_sharing" class="csl-entry" role="listitem">
Longworth, Guy. 2019. <span>“Sharing Non-Observational
Knowledge.”</span> <em>Inquiry</em> 0 (0): 1–21. <a
href="https://doi.org/10.1080/0020174X.2019.1680430">https://doi.org/10.1080/0020174X.2019.1680430</a>.
</div>
<div id="ref-ludwig_collective_2007" class="csl-entry" role="listitem">
Ludwig, Kirk. 2007. <span>“Collective Intentional Behavior from the
Standpoint of Semantics.”</span> <em>Nous</em> 41 (3): 355–93. <a
href="https://doi.org/10.1111/j.1468-0068.2007.00652.x">https://doi.org/10.1111/j.1468-0068.2007.00652.x</a>.
</div>
<div id="ref-ludwig:2015_shared" class="csl-entry" role="listitem">
———. 2015. <span>“Shared Agency in Modest Sociality.”</span> <em>Journal
of Social Ontology</em> 1 (1): 7–15. <a
href="http://www.degruyter.com/view/j/jso.2015.1.issue-1/jso-2014-0046/jso-2014-0046.xml">http://www.degruyter.com/view/j/jso.2015.1.issue-1/jso-2014-0046/jso-2014-0046.xml</a>.
</div>
<div id="ref-ludwig:2016_individual" class="csl-entry" role="listitem">
———. 2016. <em>From <span>Individual</span> to <span>Plural
Agency</span>: <span>Collective Action</span></em>. <span>Oxford
University Press</span>.
</div>
<div id="ref-Menoret:2013fk" class="csl-entry" role="listitem">
Ménoret, Mathilde, L. Varnet, R. Fargier, A. Cheylus, A. Curie, V. des
Portes, T. A. Nazir, and Y. Paulignan. 2014. <span>“Neural Correlates of
Non-Verbal Social Interactions: A Dual-EEG Study.”</span>
<em>Neuropsychologia</em> 55: 75–97.
</div>
<div id="ref-meyer:2013_higher-order" class="csl-entry" role="listitem">
Meyer, Marlene, Robrecht P. R. D. van der Wel, and Sabine Hunnius. 2013.
<span>“Higher-Order Action Planning for Individual and Joint Object
Manipulations.”</span> <em>Experimental Brain Research</em> 225 (4):
579–88. <a
href="https://doi.org/10.1007/s00221-012-3398-8">https://doi.org/10.1007/s00221-012-3398-8</a>.
</div>
<div id="ref-novembre:2013_motor" class="csl-entry" role="listitem">
Novembre, G., L. F. Ticini, S. Schutz-Bosbach, and P. E. Keller. 2014.
<span>“Motor Simulation and the Coordination of Self and Other in
Real-Time Joint Action.”</span> <em>Social Cognitive and Affective
Neuroscience</em> 9 (8): 1062–68. <a
href="https://doi.org/10.1093/scan/nst086">https://doi.org/10.1093/scan/nst086</a>.
</div>
<div id="ref-Pacherie:2010fk" class="csl-entry" role="listitem">
Pacherie, Elisabeth. 2010. <span>“The Phenomenology of Joint Action:
Self-Agency Vs. Joint-Agency.”</span> In <em>Joint Action</em>, edited
by Axel Seemann. MIT Press.
</div>
<div id="ref-pacherie:2013_lite" class="csl-entry" role="listitem">
———. 2013. <span>“Intentional Joint Agency: Shared Intention
Lite.”</span> <em>Synthese</em> 190 (10): 1817–39. <a
href="https://doi.org/10.1007/s11229-013-0263-7">https://doi.org/10.1007/s11229-013-0263-7</a>.
</div>
<div id="ref-Pears:1971fk" class="csl-entry" role="listitem">
Pears, David. 1971. <span>“Two Problems about Reasons for
Actions.”</span> In <em>Agent, Action and Reason</em>, edited by A.
Marras R. Binkley R. Bronaugh, 128–53. Oxford: Oxford University Press.
</div>
<div id="ref-petersson_collectivity_2007" class="csl-entry"
role="listitem">
Petersson, Björn. 2007. <span>“Collectivity and Circularity.”</span>
<em>Journal of Philosophy</em> 104 (3): 138–56.
</div>
<div id="ref-pettit:2006_joint" class="csl-entry" role="listitem">
Pettit, Philip, and David Schweikard. 2006. <span>“Joint
<span>Actions</span> and <span>Group</span> <span>Agents</span>.”</span>
<em>Philosophy of the <span>Social</span> <span>Sciences</span></em> 36
(1): 18–39. <a
href="https://doi.org/10.1177/0048393105284169">https://doi.org/10.1177/0048393105284169</a>.
</div>
<div id="ref-ramenzoni:2014_scaling" class="csl-entry" role="listitem">
Ramenzoni, Verónica C., Natalie Sebanz, and Günther Knoblich. 2014.
<span>“Scaling up Perception<span></span>action Links: Evidence from
Synchronization with Individual and Joint Action.”</span> <em>Journal of
Experimental Psychology: Human Perception and Performance</em> 40 (4):
1551–65. <a
href="https://doi.org/10.1037/a0036925">https://doi.org/10.1037/a0036925</a>.
</div>
<div id="ref-Roth:2004ki" class="csl-entry" role="listitem">
Roth, Abraham Sesshu. 2004. <span>“Shared Agency and Contralateral
Commitments.”</span> <em>The Philosophical Review</em> 113 (3): 359–410.
</div>
<div id="ref-sacheli:2018_evidence" class="csl-entry" role="listitem">
Sacheli, Lucia Maria, Elisa Arcangeli, and Eraldo Paulesu. 2018.
<span>“Evidence for a Dyadic Motor Plan in Joint Action.”</span>
<em>Scientific Reports</em> 8 (1): 5027. <a
href="https://doi.org/10.1038/s41598-018-23275-9">https://doi.org/10.1038/s41598-018-23275-9</a>.
</div>
<div id="ref-sacheli:2021_mechanisms" class="csl-entry" role="listitem">
Sacheli, Lucia Maria, Margherita Adelaide Musco, Elisa Zazzera, and
Eraldo Paulesu. 2021. <span>“Mechanisms for Mutual Support in Motor
Interactions.”</span> <em>Scientific Reports</em> 11 (1): 3060. <a
href="https://doi.org/10.1038/s41598-021-82138-y">https://doi.org/10.1038/s41598-021-82138-y</a>.
</div>
<div id="ref-schlosser:2019_agency" class="csl-entry" role="listitem">
Schlosser, Markus. 2019. <span>“Agency.”</span> In <em>The
<span>Stanford Encyclopedia</span> of <span>Philosophy</span></em>,
edited by Edward N. Zalta, Winter 2019. <span>Metaphysics Research Lab,
Stanford University</span>.
</div>
<div id="ref-Schmid:2008" class="csl-entry" role="listitem">
Schmid, Hans Bernhard. 2008. <span>“Plural Action.”</span>
<em><span>Philosophy of the Social Sciences</span></em> 38 (1): 25–54.
<a
href="https://doi.org/10.1177/0048393107310877">https://doi.org/10.1177/0048393107310877</a>.
</div>
<div id="ref-schmitz:2017_corepresentation" class="csl-entry"
role="listitem">
Schmitz, Laura, Cordula Vesper, Natalie Sebanz, and Günther Knoblich.
2017. <span>“Co-Representation of Others’ Task Constraints in Joint
Action.”</span> <em>Journal of Experimental Psychology. Human Perception
and Performance</em> 43 (8): 1480–93. <a
href="https://doi.org/10.1037/xhp0000403">https://doi.org/10.1037/xhp0000403</a>.
</div>
<div id="ref-scott:2010_microbial" class="csl-entry" role="listitem">
Scott, Jarrod J., Kevin J. Budsberg, Garret Suen, Devin L. Wixon, Teri
C. Balser, and Cameron R. Currie. 2010. <span>“Microbial <span>Community
Structure</span> of <span>Leaf</span>-<span>Cutter Ant Fungus
Gardens</span> and <span>Refuse Dumps</span>.”</span> <em>PLOS ONE</em>
5 (3): e9922. <a
href="https://doi.org/10.1371/journal.pone.0009922">https://doi.org/10.1371/journal.pone.0009922</a>.
</div>
<div id="ref-Searle:1990em" class="csl-entry" role="listitem">
Searle, John R. 1990. <span>“Collective Intentions and Actions.”</span>
In <em>Intentions in Communication</em>, edited by P. Cohen, J. Morgan,
and M. E. Pollack, 90–105. Cambridge: Cambridge University Press.
</div>
<div id="ref-Sebanz:2006yq" class="csl-entry" role="listitem">
Sebanz, Natalie, Harold Bekkering, and Günther Knoblich. 2006.
<span>“Joint Action: Bodies and Mind Moving Together.”</span> <em>Trends
in Cognitive Sciences</em> 10 (2): 70–76.
</div>
<div id="ref-Tollefsen:2005vh" class="csl-entry" role="listitem">
Tollefsen, Deborah. 2005. <span>“Let’s Pretend: Children and Joint
Action.”</span> <em>Philosophy of the Social Sciences</em> 35 (75):
74–97.
</div>
<div id="ref-tuomela:2000_cooperation" class="csl-entry"
role="listitem">
Tuomela, Raimo. 2000. <em>Cooperation: <span>A Philosophical
Study</span></em>. Dordrecht: Springer.
</div>
<div id="ref-tuomela:1985_weintentions" class="csl-entry"
role="listitem">
Tuomela, Raimo, and Kaarlo Miller. 1985.
<span>“We-<span>Intentions</span> and <span>Social
Action</span>.”</span> <em>Analyse &amp; Kritik</em> 7 (1): 26–43. <a
href="https://doi.org/10.1515/auk-1985-0102">https://doi.org/10.1515/auk-1985-0102</a>.
</div>
<div id="ref-tuomela_we-intentions_1988" class="csl-entry"
role="listitem">
———. 1988. <span>“We-Intentions.”</span> <em>Philosophical Studies</em>
53 (3): 367–89. <a
href="https://doi.org/10.1007/BF00353512">https://doi.org/10.1007/BF00353512</a>.
</div>
<div id="ref-Velleman:1997oo" class="csl-entry" role="listitem">
Velleman, David. 1997. <span>“How to Share an Intention.”</span>
<em>Philosophy and Phenomenological Research</em> 57 (1): 29–50.
</div>
<div id="ref-wilson:2016_action" class="csl-entry" role="listitem">
Wilson, George, Samuel Shpall, and Juan S. Pin̄eros Glasscock. 2016.
<span>“Action.”</span> In <em>The <span>Stanford Encyclopedia</span> of
<span>Philosophy</span></em>, edited by Edward N. Zalta, Winter 2016.
<span>Metaphysics Research Lab, Stanford University</span>.
</div>
<div id="ref-Wright:1976ls" class="csl-entry" role="listitem">
Wright, Larry. 1976. <em>Teleological Explanations</em>. Berkeley:
University of California Press.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Labels include ‘joint action’ <span class="citation"
data-cites="brooks_joint_1981 Sebanz:2006yq Knoblich:2010fk Tollefsen:2005vh pettit:2006_joint Carpenter:2009wq Pacherie:2010fk brownell:2011_early sacheli:2018_evidence meyer:2013_higher-order">(Brooks
1981; Sebanz, Bekkering, and Knoblich 2006; Knoblich, Butterfill, and
Sebanz 2011; Tollefsen 2005; Pettit and Schweikard 2006; Carpenter 2009;
Pacherie 2010; Brownell 2011; Sacheli, Arcangeli, and Paulesu 2018;
Meyer, Wel, and Hunnius 2013)</span>, ‘social action’ <span
class="citation" data-cites="tuomela:1985_weintentions">(Tuomela and
Miller 1985)</span>, ‘collective action’ <span class="citation"
data-cites="Searle:1990em Gilbert:2010fk">(Searle 1990; Gilbert
2010)</span>, ‘joint activity’ <span class="citation"
data-cites="baier:1997_joint">(Baier 1997)</span>, ‘acting together’
<span class="citation" data-cites="tuomela:2000_cooperation">(Tuomela
2000)</span>, ‘shared intentional activity’ <span class="citation"
data-cites="Bratman:1999fr">(Bratman 1997)</span>, ‘plural action’ <span
class="citation" data-cites="Schmid:2008">(Schmid 2008)</span>, ‘joint
agency’ <span class="citation" data-cites="pacherie:2013_lite">(Pacherie
2013)</span>, ‘small scale shared agency’ <span class="citation"
data-cites="bratman:2014_book">(Bratman 2014)</span>, ‘intentional joint
action’ <span class="citation"
data-cites="blomberg:2015_common">(Blomberg 2016)</span>, ‘collective
intentional behavior’ <span class="citation"
data-cites="ludwig:2016_individual">(Ludwig 2016)</span>, and
‘collective activity’ <span class="citation"
data-cites="longworth:2019_sharing">(Longworth 2019)</span>. We leave
open whether these are all labels for a single phenomenon or whether
different researchers are targeting different things. As we use ‘acting
jointly’, the term applies to everything any of these labels applies
to.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>See <span class="citation"
data-cites="Searle:1990em">Searle (1990)</span>; in his example park
visitors simultaneously run to a shelter, in one case as part of dancing
together and in another case because of a storm. Compare <span
class="citation" data-cites="Pears:1971fk">Pears (1971)</span> who uses
contrast cases to argue that whether something is an ordinary,
individual action depends on its antecedents.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>For views which imply or may motivate dissent, see for
example <span class="citation" data-cites="baier:1997_joint">Baier
(1997)</span>, <span class="citation"
data-cites="chant_unintentional_2007">Chant (2007)</span>, <span
class="citation" data-cites="petersson_collectivity_2007">Petersson
(2007)</span>, and <span class="citation"
data-cites="longworth:2019_sharing">Longworth (2019, 13ff)</span>.<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>We propose a way to avoid relying on this assumption in
§<a href="#sec:objection-evidence" data-reference-type="ref"
data-reference="sec:objection-evidence">7</a> below.<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>This strategy has been pursued by a number of
philosophers. One early example (although not the first) is <span
class="citation" data-cites="tuomela:1985_weintentions">Tuomela and
Miller (1985)</span>; it may be that <span class="citation"
data-cites="tuomela_we-intentions_1988">Tuomela and Miller (1988)</span>
and <span class="citation" data-cites="Searle:1990em">Searle
(1990)</span>’s response initiated contemporary debate. This is not to
say that no philosophers have taken an alternative line. <span
class="citation" data-cites="petersson_collectivity_2007">Petersson
(2007, 138)</span>, for instance, attempts to explicate the distinction
between acting jointly and acting in parallel but merely individually
‘in terms of dispositions and causal agency’. See also <span
class="citation" data-cites="chant_unintentional_2007">Chant
(2007)</span> for another alternative line.<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><span id="fn:gilbert_mech_committed"
data-label="fn:gilbert_mech_committed"></span> Because Gilbert can be
interpreted as characterising states of an agent in terms of commitments
(compare <span class="citation" data-cites="gilbert:2014_book">Gilbert
(2013, 10)</span>: ‘I take [...] acting together to involve collective
intentions—understood in terms of joint commitment’), she does provide
materials that can be used by a proponent of the standard strategy.
However it may be more accurate to interpret her as offering an
alternative to the standard strategy, one which does not involve
invoking any states of the agents at all but only certain normative
facts (see further §<a href="#sec:objection-evidence"
data-reference-type="ref"
data-reference="sec:objection-evidence">7</a>). Related points could be
made about others cited in this paragraph (particularly <span
class="citation" data-cites="Gold:2007zd">(Gold and Sugden 2007)</span>
and <span class="citation" data-cites="bratman:2014_book">(Bratman
2014)</span>). What unites them is that they do provide materials for
proponents of the standard strategy to identify states of the agents in
distinguishing acting jointly.<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>In <span class="citation"
data-cites="Bratman:1992mi">Bratman (1992)</span>, the ordinary
individual intentions and other attitudes were offered as jointly
sufficient <span>and individually necessary</span> conditions; the
retreat to sufficient conditions only occurs in <span class="citation"
data-cites="Bratman:1999fr">Bratman (1997, 143–44)</span>: ‘for all that
I have said, shared intention might be multiply realizable.’ Because
Bratman distinguishes two tasks in characterising acting
jointly—specifying a functional role and identifying states which
realise it—his work provides materials both for proponents of the
standard strategy and also for proponents of an alternative strategy. We
return to this in §<a href="#sec:objection-evidence"
data-reference-type="ref"
data-reference="sec:objection-evidence">7</a>.<a href="#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Examples include <span class="citation"
data-cites="bach:1978_representational">Bach (1978)</span> and <span
class="citation" data-cites="Dretske:1988sq">Dretske (1988)</span>.
Although <span class="citation" data-cites="Bratman:1987xw">Bratman
(1987)</span> is sometimes said to be a proponent of this view <span
class="citation" data-cites="schlosser:2019_agency">(Schlosser
2019)</span>, we take Bratman to be primarily concerned with developing
a theory of intention—and although this involves investigating relations
between intentional action and intentions, it does not obviously require
commitment to characterising the former in terms of the latter.<a
href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>But is this second answer really mechanistically
neutral? According to <span class="citation"
data-cites="alvarez:2016_reasons">Alvarez (2016)</span>, philosophers
sometimes conceive of ‘motivating and explanatory reasons … as mental
states of agents’. Providing a mechanistically neutral characterisation
of intentional action requires a mechanistically neutral
characterisation of reasons, too. If, as we suppose, such a
characterisation exists, then there are mechanistically neutral attempts
to characterise intentional action.<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Of course there are philosophers who might deny that
the second question bears on any philosophical questions about action
(<span class="citation" data-cites="ginet:1990_action">Ginet
(1990)</span>, for example). Proponents of a mechanistically neutral
characterisation are free to oppose such philosophers on the grounds
that the answers to the two questions are mutually constraining (see §<a
href="#sec:objection-evidence" data-reference-type="ref"
data-reference="sec:objection-evidence">7</a> below). They may therefore
oppose both causal theorists (whose strategy is to answer the first
question by answering the second) and non-causal theorists (who deny
that the second question is relevant).<a href="#fnref10"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>Note that the possibility of characterising A in terms
which do not mention B does not in general imply that it is possible for
there to be As without corresponding Bs. Proponents of a mechanistically
neutral approach may therefore accept that intentional actions are
caused by intentions and could not be caused in some other way (to
borrow, with our thanks, some words from a critic).<a href="#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>This informal contrast between collective and
distributive readings is linked to a debate about the logic of plural
quantification; see <span class="citation"
data-cites="Linnebo:2005ig">Linnebo (2005)</span> for an overview of
that debate.<a href="#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>As we noted earlier (in §<a
href="#sec:alternative_strategy" data-reference-type="ref"
data-reference="sec:alternative_strategy">2</a>), the term ‘goal’ has
been used, coherently, both to label states of agents and also to label
those outcomes to which an action is directed. We shall (by stipulation)
use ‘goal’ to label outcomes.<a href="#fnref13" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><span class="citation"
data-cites="dickinson:2016_instrumental">Dickinson (2016, 177)</span>
offers a more sophisticated analysis of directedness which is also
neutral on which states are involved.<a href="#fnref14"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Perhaps directedness is better characterised in terms
of an agent’s relation to an outcome (as in <span class="citation"
data-cites="Bennett:1976rg">(Bennett 1976)</span>). We explain below why
we do not offer this as our primary candidate (our position is
neutral).<a href="#fnref15" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>This is not entirely uncontroversial, of course. If
<span class="citation" data-cites="baier:1997_joint">Baier (1997)</span>
is right, some cases of acting jointly do not involve collective
goals.<a href="#fnref16" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>This point is easily overlooked, perhaps because there
is clearly one type of outcome to which all the agents’ actions are
directed, namely the opening of some newspaper or other. But note that
the onlooker’s action may be entirely successful (she may crack open her
own newspaper) while another agent’s fails (she fumbles and drops hers).
This makes it clear that the outcomes are distinct, although they are of
the same type.<a href="#fnref17" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>We have also encountered awkward dissenters on other
influential cases in the literature including Bratman’s going to New
York ‘in the mafia sense’ <span class="citation"
data-cites="Bratman:1992mi">(Bratman 1992, 333)</span> and Blomberg’s
no-common-knowledge cases <span class="citation"
data-cites="blomberg:2015_common">(Blomberg 2016)</span>. The Collective
Goal Account broadly agrees with Bratman on the former (as the victim,
once locked in the trunk, does not perform any action directed to the
goal) and with Blomberg on the latter (as it does not necessarily
require common knowledge).<a href="#fnref18" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p><span class="citation"
data-cites="blomberg:2015_shared">Blomberg (2015)</span> provides one
means of constructing contrast cases which appear to support such
dissent.<a href="#fnref19" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>In saying that a case is ‘reasonably taken to be’ a
paradigm of acting jointly, we mean only that one or more people have
taken it to be one and would continue to do so on reflection. We do not
mean to imply that it is actually a case of acting jointly. And as we
intend the phrase to be understood, a ‘conceivably successful attempt’
need not capture every case that is reasonably taken to be paradigmatic:
what is required is just that there would appear to be insufficient
reason to regard uncaptured cases as actual cases of acting jointly if
the account were true.<a href="#fnref20" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p>We characterised mechanistically neutral in terms of
acting jointly (in §<a href="#sec:alternative_strategy"
data-reference-type="ref"
data-reference="sec:alternative_strategy">2</a>). As Gilbert and Bratman
take the primary explanandum to be cases where two or more agents’
acting jointly is intentional, we are relying on a more general notion
of <em>mechanistically neutral</em> here. We discuss intentional cases
of acting jointly in §<a href="#sec:intentional"
data-reference-type="ref" data-reference="sec:intentional">8</a>.<a
href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p><span class="citation"
data-cites="bratman:2014_book">Bratman (2014, chaps. 4–5)</span> shows
that it is possible in principle to have interpersonal coordination of
planning without joint commitment by constructing possible mechanisms.
But of course the mechanisms (if any) which actually underpin planning
and joint commitment may coincide.<a href="#fnref22"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p>Things could be more complicated, of course. Multiple
dissociable mechanisms may be associated with joint commitment, and some
but not all of these may coincide with mechanisms underpinning
interpersonal coordination of planning.<a href="#fnref23"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p>One way of advancing beyond this rough characterisation
is suggested by <span class="citation"
data-cites="laurence:2011_anscombian">Laurence (2011)</span>.<a
href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p>Heartfelt thanks to our critical and generous anonymous
referees for the many ways in which their comments have improved this
work and will guide our next steps; and to the editor, whose guidance
materially improved our work.</p>
<p>We have benefitted from discussion with many people while preparing
this work. For extended discussions and their generous support over a
long time we would especially like to thank Olle Blomberg, Chiara
Brozzo, Naomi Eilan, Peter Fossey, Mattia Gallotti, Bart Geurts,
Guenther Knoblich, Hemdat Lerman, Guy Longworth, Judith Martens, John
Michael, Elisabeth Pacherie, Johannes Roessler, Tobias Schlicht, Natalie
Sebanz, Axel Seemann, Thomas Smith, Matthew Soteriou, Anna Strasser,
Hong Yu Wong, and Cordula Vesper. Thank you!</p>
<p>CS was supported by the Department of Philosophy ‘Piero Martinetti’
of the University of Milan with the Project ‘Departments of Excellence
2018-2022’ awarded by the Italian Ministry of Education, University and
Research (MIUR) and by the PRIN 2017 project ‘The cognitive neuroscience
of interpersonal coordination and cooperation: a motor approach in
humans and non-human primates’ (Cod. Prog. 201794KEER).<a
href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>


</div>




---

Title: Cue Competition Effects and Young Children's Causal and Counterfactual Inferences
Authors: Teresa McCormack, Stephen A. Butterfill, Christoph Hoerl and Patrick Burns
Year: 2009
Journal: Developmental Psychology
Type: Publication

## Abstract

The authors examined cue competition effects in young children using the blicket detector paradigm, in which objects are placed either singly or in pairs on a novel machine and children must judge which objects have the causal power to make the machine work. Cue competition effects were found in a 5- to 6-year-old group but not in a 4-year-old group. Equivalent levels of forward and backward blocking were found in the former group. Children's counterfactual judgments were subsequently examined by asking whether or not the machine would have gone off in the absence of 1 of 2 objects that had been placed on it as a pair. Cue competition effects were demonstrated only in 5- to 6-year-olds using this mode of assessing causal reasoning.




---

Title: Drawn Together: When Motor Representations Ground Joint Actions
Authors: Francesco della Gatta, Francesca Garbarini, Marco Rabuffetti, Luca Viganò, Stephen A. Butterfill and Corrado Sinigaglia
Year: 2017
Journal: Cognition
Type: Publication

## Abstract

What enables individuals to act together? Recent discoveries suggest that a variety of mechanisms are involved. But something fundamental is yet to be investigated. In joint action, agents represent a collective goal, or so it is often assumed. But how, if at all, are collective goals represented in joint action and how do such representations impact performance? To investigate this question we adapted a bimanual paradigm, the circle-line drawing paradigm, to contrast two agents acting in parallel with two agents performing a joint action. Participants were required to draw lines or circles while observing circles or lines being drawn. The findings indicate that interpersonal motor coupling may occur in joint but not parallel action. This suggests that participants in joint actions can represent collective goals motorically.


<div class='fulltext'>


# 1. Introduction  

What enables individuals to act together? People walk, play games and draw together. Joint actions such as these are thought to involve a variety of mechanisms (Knoblich, Butterfill, & Sebanz, 2011). For instance, walking together, as well as joint actions involving music or dance, may be achieved in part thanks to entrainment, the process of synchronizing two or more rhythmic behaviours with respect to phase (Nessler & Gilliland, 2009). Entrainment can occur without any intention to coordinate (Varlet, Bucci, Richardson, & Schmidt, 2015) or even despite individuals attempting not to coordinate their actions (Issartel, Marin, & CadopiM 2007; Ulzen et al., 2008).  

Nonrhythmic joint actions can be coordinated by representations concerning others’ tasks which can modulate performance of one’s own task, facilitating or impairing it (Sebanz, Knoblich, & Prinz, 2003, 2005). For instance, which flankers distract a subject can depend not only on her own task but also on her co-actor’s task (Atmaca, Sebanz, & Knoblich, 2011). Likewise, how stimuli such as words are processed can also depend on their relevance to a coactor’s task (Baus et al., 2014). Many joint actions have rhythmic and nonrhythmic aspects; coordination of such actions may involve both entrainment and representations concerning others’ tasks (van der Wel & Fu, 2015).  

While these mechanisms are plausibly critical for enabling individuals to act together, something fundamental is missing from this picture of joint action. In joint action, agents represent not only each individual’s tasks but also a collective goal; or so it is often held (Bratman, 2014; Searle, 1990; Vesper, Butterfill, Knoblich, & Sebanz, 2010). A collective goal is an outcome to which two or more actions are directed where this is not, or not only, a matter of each action individually being directed to that outcome (Butterfill, 2016). But how, if at all, are collective goals represented in joint action? And, if they are, how do such representations impact performance in joint action? To date little research has directly addressed these questions. The aim of the present paper is to begin filling this gap.  

Previous findings indicate that in joint actions such as playing a piano duet, clinking glasses, jumping together and moving an object, agents’ motor representations and processes take into account relations between their own actions and others’ in preparing and monitoring their actions (Kourtis, Knoblich, Wozniak, & Sebanz, 2014; Loehr et al., 2013; Meyer, van der Wel, & Hunnius, 2013; Tsai, Sebanz, & Knoblich, 2011; Vesper, van der Wel, Knoblich, & Sebanz, 2013). These findings motivated us to conjecture that participants in joint actions can represent collective goals motorically. Because representing a collective goal (or any goal) triggers motor processes concerning actions that should bring the goal about, representing a collective goal would mean that in each participant there are motor processes concerning not only actions she will perform but also actions another will perform. This could facilitate prediction of, and coordination with, another’s actions; but it could also create interference.  

One recent challenge in joint action research concerns to what extent agents really do take into account relations between their own actions and others’. In a series of experiments, Dolk et al. (2011), Dolk, Hommel, Prinz, and Liepelt (2013, 2014) have proposed that effects which appear to be specific to joint action are actually merely a consequence of mechanisms for distinguishing one’s own actions from other events (see further Dittrich, Bossert, Rothe-Wulf, & Klauer, 2017; Wenke et al., 2011). On this account, what matters are relations between one’s own actions and other events rather than between one’s own actions and a co-actor’s actions. While this alternative account is unlikely to explain the full range of existing findings as it stands (e.g. Baus et al., 2014; Kourtis, Sebanz, & Knoblich, 2013), it would be useful to have a direct approach to testing the conjecture that participants in joint actions can represent collective goals motorically.  

Testing this conjecture requires a pair of situations which differ in that one involves a collective goal whereas the other does not. To create such a pair, we need to deviate from prior studies. These typically compare one person acting with two people acting. But to move from one to two agents is not necessarily to move from individual to collective goals. After all, two people creating graffiti in an underpass may merely happen to be drawing alongside each other, so that their actions are parallel but merely individual: this need not involve any collective goal. We therefore seek a pair of minimally different situations which contrast acting in parallel but merely individually with acting jointly.  

To create such a pair of situations we adapted a bimanual paradigm, the circle-line drawing paradigm, which has been extensively employed for investigating bimanual interference (Franz, Zelaznik, & McCabe, 1991). When people have to simultaneously perform incongruent movements, such as drawing lines with one hand while drawing circles with the other hand, each movement interferes with the other and line trajectories tend to become ovalized. This ‘‘ovalization” has been described as a bimanual coupling effect, suggesting that motor representations for drawing circles can affect motor representations for drawing lines (Garbarini & Pia 2013; Garbarini, Rabuffetti, Piedimonte, Solito, & Berti 2015b; Garbarini et al. 2012, 2013a, 2015a; Piedimonte, Garbarini, Rabuffetti, Pia, & Berti 2014). Importantly, merely observing another drawing a circle while drawing a line oneself does not typically result in ovalization and there are no indicators of interpersonal coupling between mere observers drawing in parallel (Garbarini et al., 2013b, 2016). Our question was therefore what happens when two people are acting together rather than merely in parallel. Would this result in ovalization indicative of interpersonal coupling?  

To answer this question we modified the circle-line drawing paradigm. Participants were first asked to act bimanually by continuously drawing lines with the right hand and lines or circles with the left hand. This bimanual task was taken as a baseline measurement in order to rule out subjective differences in bimanual coupling, which could have an influence on the experimental manipulation. Participants were then asked to act unimanually by drawing either circles or lines with their right hands while observing either lines or circles being unimanually drawn by an experimenter playing the role of a confederate (Garbarini et al., 2013b, 2016). We contrasted a Parallel Action condition with a Joint Action condition. These conditions differed only in the instructions given. In the Joint Action condition participants were instructed to perform the task together with the confederate, as if their two drawing hands gave shape to a single design. In the  

Parallel Action condition, participants were given no such instruction so that they could draw in parallel, observing each other but not acting together. If participants were to follow our instructions, their actions would have the collective goal of drawing a circle and a line in the Joint Action condition but not in the Parallel Action condition. If the collective goal were represented motorically in the Joint Action condition, then, from the point of view of each participant’s motor system, it would be almost as if she were representing the whole action bimanually. Accordingly, we predicted that there should be an interpersonal motor coupling effect. This would result in greater ovalization of the lines drawn in the Joint Action condition than in the Parallel Action condition.  

Although producing designs involving simple circle and line drawings may appear far from the sorts of joint action that matter in everyday life, the paradigm we shall use is nothing but a simplified version of what artists are doing when they unite to create joint works. And this is but one example of the myriad, and mostly more mundane ways in which performing joint actions enables us to create and do things none of us could achieve alone. In testing the hypothesis that participants in joint actions can represent collective goals motorically, we aim to understand something about what makes joint action possible.  

# 2. Method  

# 2.1. Participants  

Thirty-six healthy graduate and undergraduate volunteer students from the University of Milan took part in the experiment (16 males and 20 females; mean $\mathsf{a g e\pm s d}$ : ${25\pm3}$ years; mean educational level: 15 years). All participants were naïve to the purpose of the study and screened to exclude a family history of psychiatric, neurological or medical disease. All of them gave informed consent before the experiment in accordance with the ethical standards of the 1964 Declaration of Helsinki.  

# 2.2. Experimental design  

All participants (36) first completed a bimanual baseline experiment. In this experiment, participants individually took part in a version of the standard bimanual circle-line drawing paradigm (Franz et al., 1991) with the following two tasks:  

1. Congruent bimanual lines-lines (B-LL): participants were asked to simultaneously draw lines with both hands.   
2. Incongruent bimanual circles-lines (B-CL): participants were asked to simultaneously draw lines with the right hand and circles with the left hand.  

In both tasks, participants drew on two digitizer tablets, one for each hand, while observing a cross presented on the computer screen (Fig. 1A). The experimenter specified online what they had to draw, either lines with both hands (B-LL task) or circles with the left hand and lines with the right hand (B-CL task). The drawing tasks were presented in a random order. Participants completed twenty trials (10 for each task) with $4s$ of rest between each trial; this took around 6 min in total.  

For the unimanual main experiment, all female (20) and male subjects (16) were randomly assigned to one of two experimental conditions, either the Parallel Action condition or the Joint Action condition (18 participants for each group, 8 males and 10 females). In both conditions, participants performed four unimanual drawing tasks with a confederate (who was one of the experimenters):  

![](/public/img/articles/dellagatta2017_drawn/580cf4569c7341f879dfbcbfdbaed53e27df76e3faeb0ee219ae8d8cf71f6038.jpg)  
Fig. 1. Experimental setting. Schematic view of the Bimanual Baseline (A), Parallel Action (B) and Joint Action Conditions (C).  

1. Congruent Observation Lines: drawing lines while observing lines (O-LL).   
2. Congruent Observation Circles: drawing circles while observing circles (O-CC).   
3. Incongruent Observation Lines: drawing lines while observing circles (O-CL).   
4. Incongruent Observation Circles: drawing circles while observing lines (O-LC).  

In both Parallel Action and Joint Action conditions, participants drew circles or lines with their right hands while observing on the screen the circles or lines that were simultaneously drawn by the confederate. The drawing tasks (O-CC; O-LL; O-LC; O-CL) were presented in a random order. Participants completed forty trials (10 for each condition) with $4s$ of rest between each trial; this took around $12\mathrm{min}$ in total. Irrespective of the condition, subjects always performed the same four tasks. The only difference between the Parallel Action and Joint Action conditions concerned the instructions given in advance.  

In the Parallel Action condition, participants were instructed: ‘‘Look at the screen in front of you. You will see either circles or lines drawn by the confederate sitting across from you. Look at them while drawing either a circle or a line. While drawing, please do not lift the pen from the tablet and try to take advantage of the whole drawing area.” [Italian: ‘‘Guarda attentamente lo schermo di fronte a te. Vedrai apparire dei cerchi o delle righe disegnate dallo sperimentatore. Osservali mentre disegni a tua volta dei cerchi o delle righe. Per favore, non alzare mai la penna dal tablet e cerca di sfruttare tutta l’area disegnabile.”] In the Joint Action condition, participants were instructed: ‘‘You and Gabriele [name of confederate] are old friends who have the collective goal of drawing lines and circles together in order to produce a single design. Look at the screen in front of you. You will see either circles or lines drawn by Gabriele. Look at them while drawing either a circle or a line together with him. While drawing, please do not lift your pens from the tablet and try to take advantage of the whole drawing area.” [Italian: ‘‘Tu e Gabriele siete due vecchi amici e avete come obiettivo comune di disegnare insieme cerchi e linee in modo da creare un unico disegno. Guarda attentamente lo schermo di fronte a te. Al centro appariranno i cerchi o le righe disegnate da Gabriele. Quello che dovrai fare è disegnare insieme con lui cerchi o righe, rispettivamente. Per favore, non alzate mai la penna dal tablet e cercate di sfruttare tutta l’area disegnabile.”]  

# 2.3. Experimental setup and procedure  

The experimental setup is shown in Fig. 1. Participants sat at a table on a comfortable chair in front of a computer screen with a resolution of $1280\times1024$ pixels, at a distance of $45\mathrm{cm}$ . They drew circles and lines on Wacom Bamboo Pen Graphics digitizer tablets $(30\mathrm{cm}\times20\mathrm{cm})$ ) using a magnetic pen that did not leave a visible trace. In the main, unimanual experimental conditions, a screen displaying the confederate’s drawing was positioned on the opposite side of the table in front of the participant and a confederate sat at the table diagonally across from the participant with another PC computer and another digitizer tablet (Fig. 1B and C). The two digitizer tablets and computer screens were controlled by purpose written software. This software, written in Visual Basic (Microsoft, USA), presents a white screen on which the pen contact leaves a blue trace. The software writes a text file containing a sequence of X and Y coordinates and times, thereby recording the pen tip’s trajectory. Pen strokes confined to the upper or lower part of the tablet are dropped and ovalization is computed exclusively on strokes which cover the most part of the tablet surface.  

The tablets were calibrated at the start of each testing session. A general instruction sheet was read aloud by the participant and they were given a chance to ask any questions before signing an informed consent form. The experimenter then showed the instructions for the task that the participant was to perform and instructed them to maintain a comfort-mode position within and across trials. Once the participant had indicated that they understood the task, they performed a pre-training task phase (60 s) in which they were familiarized with the task. They then completed the bimanual baseline experiment and the unimanual main experiment. At the end of the experiment, each participant was informally debriefed in order to determine (1) if they noticed whether their movements were influenced by the visual stimulus and (2) if they guessed the purpose of the study. None of the participants guessed the purpose of the study. Nevertheless, 18 of 36 participants reported that their movements were somehow influenced by the visual stimulus. They all indicated that this was not intentional. There was no difference between the Joint Action and Parallel Action conditions in the number of participants who reported an influence on their movements (8 and 10 subjects, respectively). Interestingly, one of the participants, who had been in the Parallel Action condition, reported trying to resist the influence of the visual stimulus: ‘‘Although I did not want to follow the rhythm of the stimulus observed, I found myself unwittingly going at the same tempo as my partner”.  

# 2.4. Scoring  

An Ovalization Index (OI) was calculated, following previous studies (see Garbarini et al., 2012, 2013b, 2015b; Piedimonte et al., 2014), as the standard deviation of the pen tip trajectories drawn by the right hand from an absolute vertical axis. (For a thorough description of the steps involved in calculating the OI refer to Garbarini et al., 2012). The OI index ranges between a value of zero for straight trajectories without any sign of ovalization and a value of 100 for circular trajectories.  

The average drawing frequency was quantified for each trial as the number of drawing cycles per second (measured in $_{\mathrm{Hz}}$ ). For the bimanual baseline experiment, the Synchronization Index (SI) was calculated, for each trial, as the absolute difference between the frequency value of line/circle drawing performed by the subject’s left hand and the frequency value of line drawing performed by the subject’s right hand. For the unimanual main experiment, the SI was calculated, for each trial, as the absolute difference between the frequency value of line/circle drawing trial by the confederate and the frequency value of line/circle drawing performed by the subject’s right hand. Furthermore, for each participant, the obtained SI values were averaged across repeated trials and used as dependent variable. Thus, concerning the SI index, a zero value indicates full synchronization, and larger values indicate less synchronization. Finally, in order to assess movement fluency, the average number of speed inversions per single drawing stroke (NIV) was computed (Marquardt & Mai, 1994; Tucha, Tucha, & Lange, 2008). Perfectly fluent movements with a bell-shaped speed profile are characterised by $\Nu\mathrm{IV}=1$ . A NIV value between 1 and 2 indicates intermittently occurring speed inversions, and a NIV larger than 2 indicates constantly occurring speed inversions.  

# 3. Results  

# 3.1. Ovalization Index  

# 3.1.1. Bimanual baseline experiment  

In the bimanual baseline experiment, the OI mean values for lines drawn with the right hand were entered in a $^{2\ast2}$ ANOVA, with one between-subject factor (Condition, two levels: ‘‘Joint”; ‘‘Parallel”) and one within-subject factor (Task, two levels: ‘‘Incongruent”; ‘‘Congruent”). As residuals in the incongruent task (B-CL) were not normally distributed (Shapiro-Wilk $\mathrm{p}=0.00450\AA$ , we adopted two separate nonparametric analyses for the congruent (B-LL) and incongruent (B-CL) tasks. First, in order to detect any powerful effect of the between-subject factor, the differences between incongruent (B-CL) and congruent (B-LL) tasks for all subjects were obtained; this difference was used as the dependent variable and the values entered in a Mann-Whitney $U$ test. The Mann-Whitney $U$ Test showed no significant effect of the between-subject factor Condition (Parallel vs $\mathrm{Joint}=\mathrm{mean}\pm s\mathrm{d}$ : $12.35\pm5.28$ vs $13.27\pm7.11$ ; $Z=-0.031$ ; $\mathbf{p}=0.975^{\cdot}$ ), meaning that the bimanual coupling effect did not differ between the two conditions. We therefore directly compared the incongruent (B-CL) and congruent (B-LL) values for all subjects using a Wilcoxon signedrank test for pairwise comparisons with Bonferroni correction for each pairwise comparison (value/number of comparisons: $0.05/2=0.025;$ ). The Wilcoxon signed-rank test revealed a powerful effect of the within-subject factor Task, showing a significant difference between the incongruent task (B-CL) and the congruent task (B-LL) $({\mathrm{mean}}\pm{\mathrm{sd}}=17.10\pm6.35$ vs $4.29\pm0.72$ ; $Z=5.231$ $\mathbf{p}<0.005$ ; $\mathrm{d}z=2.5\:\cdot$ ). The significant OI increase for the right hand drawing lines in the incongruent (B-CL) compared to congruent (B-LL) task is characteristic of bimanual coupling.  

# 3.1.2. Unimanual main experiment  

Two separate analyses were performed, one for the circledrawing tasks (O-CC and O-LC) and one for the line-drawing tasks (O-LL and O-CL). In each analysis, the OI mean values were entered into a $^{2\ast2}$ ANOVA, with one between-subject factor (Condition, two levels: Joint; Parallel) and one within-subject factor (Task, two levels: Incongruent; Congruent).  

For the circle-drawing tasks, residual errors in both incongruent (O-LC) and congruent (O-LL) tasks were normally distributed (Shapiro-Wilk $\mathbf{p}=0.09069$ and $\mathtt{p}=0.14675$ . The ANOVA showed no significant effects: the between-subject factor Condition (F $(1,34)=0.543$ ; $\mathrm{p}=0.466;$ , the within-subject factor Task (F(1,34) $=0.279$ ; $\mathrm{p}=0.601$ ), and the interaction of these $(\mathrm{F}(1,34)=0.055$ ; $\mathrm{p}=0.815$ ) were all nonsignificant.  

For the line-drawing tasks, residual errors in both incongruent (O-CL) and congruent (O-LL) tasks were not normally distributed (Shapiro-Wilk $\mathbf{p}=0.01219$ and $\mathbf{p}=0.00336^{\cdot}$ . We therefore adopted nonparametric analyses. In order to detect any powerful effect in the between-subject factor, the differences between incongruent (O-CL) and congruent (O-LL) tasks for all subjects were obtained; this difference was used as the dependent variable and the values entered in a Mann-Whitney $U$ test. The Mann-Whitney $U$ Test showed a significant effect of the between-subject factor Condition (Parallel vs $\mathrm{Joint}=\mathrm{mean}\pm s\mathrm{d}$ : $0.03\pm0.19$ vs $0.45\pm0.29$ ; $Z=-4.113$ ; $\mathbf{p}<0.0005;$ . In the Joint Action condition, Wilcoxon matched-pairs tests with Bonferroni correction revealed a significant OI increase for the right hand drawing lines in the incongruent (O-CL) compared to the congruent (O-LL) task (mean $\pm s d=4.57\pm1.09$ vs $4.12\pm0.96$ ; $Z=3.680$ ; $\mathbf{p}<0.0005$ ; $\mathrm{d}z=1.08;$ . By contrast, in the Parallel Action condition, no significant difference was found between incongruent (O-CL) and congruent (O-LL) tasks $({\mathrm{mean}}\pm{\mathrm{sd}}=3.96\pm0.64$ vs $3.94\pm0.66$ ; $Z=0.566$ ; $\mathbf{p}=0.571$ ). This indicates that, for the right hand drawing lines, OI was larger in the incongruent (O-CL) compared to congruent (O-LL) task in the Joint Action condition only (see Fig. 2A).  

Finally, the variances of the OI values obtained from linedrawing tasks and circle-drawing tasks were compared by means of an F test. This showed significantly greater variance in circle drawings than in line drawings for both Congruent and Incongruent tasks (Congruent comparison: Lines-Lines $\mathrm{Var}=0.66$ vs Circles-Circles $\mathrm{Var}=55.37$ ; $\mathbf{p}<0.001$ ; Incongruent comparison: Lines-Circles $\mathrm{Var}=0.87$ vs Circles-Lines $\mathrm{Var}=61.87$ ; $\mathbf{p}<0.001$ ).  

# 3.2. Synchronization index  

In both the bimanual baseline experiment and the unimanual main experiment, the SI value was entered in an ANOVA, with one between-subject factor (Condition, two levels: ‘‘Joint”; ‘‘Parallel”) and one within-subject factor (Task, two levels: ‘‘Incongruent”; ‘‘Congruent”). Post hoc comparisons were performed by using Duncan’s test.  

# 3.2.1. Bimanual baseline experiment  

In the bimanual baseline experiment, for both congruent (B-LL) and incongruent (B-CL) tasks, residuals were not normally distributed (Shapiro-Wilk $\mathbf{p}=0.00000$ and $\mathbf{p}=0.00022$ ). We therefore adopted two separate nonparametric analyses. In order to detect any powerful effect of the between-subject factor Condition (Parallel vs Joint), the differences between incongruent (B-CL) and congruent (B-LL) values for all subjects were obtained; this difference was used as the dependent variable and entered in a Mann-Whitney $U$ -Test. The Mann-Whitney $U.$ -Test showed no significant effect of the between-subject factor Condition (Parallel vs Joint $=$ mean ± sd: $0.07\pm0.07$ vs $0.09\pm0.09$ ; $Z=-0.648$ ; $\mathbf{p}=0.517$ .  

![](/public/img/articles/dellagatta2017_drawn/8d112bd0fe25d6980271cf315c473a319330d7ce247d649c83adddb54d48f84e.jpg)  
Fig. 2. Unimanual main experiment results of all subjects for the right hand performing lines. Error bars indicate s.e.m. Asterisks indicate significance difference $^{**}\mathrm{~\bf~p~}<0.005$ ; \* $\mathbf{p}<0.0005;$ . In A, all subject’s Ovalization Index (OI) mean values are plotted: a significant OI increase was found only for the Joint Action condition in the incongruent condition. In B, all subject’s Synchronization Index (SI) mean values are plotted: no difference between conditions was found; for all participants SI was larger in the incongruent (O-CL) compared to the congruent (O-LL) tasks.  

We therefore directly compared the values from incongruent (BCL) and congruent (B-LL) tasks for all subjects using a Wilcoxon signed-rank test for pairwise comparisons in order to detect any powerful effect of the within-subject factor. Bonferroni correction was applied for both pairwise comparisons (with value/number of comparisons: $0.05/2=0.025;$ . Wilcoxon matched pairs tests, after Bonferroni correction, revealed a powerful effect of the within-subject factor Task, showing a significant difference between the incongruent (B-CL) and the congruent (B-LL) task $({\mathrm{mean}}\pm{\mathrm{sd}}=0.08\pm0.08$ vs $0.04\pm0.06$ ; $Z=2.584$ ; $\mathbf{p}=0.009^{\cdot}$ . For all participants, SI was larger in the incongruent (B-CL) than in the congruent (B-LL) task. This indicates that, in the bimanual baseline experiment, the participants assigned to the two Conditions (Joint vs Parallel) did not differ from each other in terms of synchronization.  

# 3.2.2. Unimanual main experiment  

In the unimanual main experiment, for the line drawing tasks, residual errors were not normally distributed in either the incongruent (O-CL) or the congruent (O-LL) task (Shapiro-Wilk $\mathbf{p}=0.00284$ and $\mathbf{p}=0.0001$ ). We therefore adopted two separate nonparametric analyses. In order to detect any powerful effect of the between-subject factor Condition (Parallel vs Joint), the differences between incongruent (O-CL) and congruent (O-LL) values for all subjects were obtained; this difference was used as the dependent variable and entered in a Mann-Whitney $U.$ -Test. The Mann-Whitney U-Test showed no significant effect of the between-subject factor Condition (Parallel vs $\mathrm{Joint}=\mathrm{mean}\pm\mathrm{sd}$ : $0.07\pm0.12$ vs $0.07\pm0.09$ ; $Z=0.126$ ; $\mathrm{p}=0.9$ ). We therefore directly compared the values from incongruent (O-CL) and congruent (OLL) tasks for all subjects using a Wilcoxon signed-rank test for pairwise comparisons in order to detect any powerful effect of the within-subject factor Task. Bonferroni correction was applied for both pairwise comparisons (with value/number of comparisons: $0.05/2=0.025^{\circ}\mathrm{~.~}$ ). Wilcoxon matched pairs tests, after Bonferroni correction, revealed a powerful effect of the within-subject factor Task, showing a significant difference between the incongruent (O-CL) and the congruent (O-LL) task $\mathrm{'mean}\pm{}s\mathrm{d}=0.17\pm0.13$ vs $0.09\pm0.12$ ; $Z=3.425$ ; $\mathbf{p}<0.005^{\cdot}$ ). For all participants, SI was larger in the incongruent (O-CL) than in the congruent (O-LL) task. This indicates that, in the unimanual main experiment, the participants assigned to the two Conditions (Joint vs Parallel) did not differ from each other in terms of synchronization (see Fig. 2B).  

For the circle drawing tasks, residual errors were not normally distributed in either the incongruent (O-LC) or the congruent (O-LL) task (Shapiro-Wilk $\mathbf{p}=0.01642$ and $\mathbf{p}=0.00011$ ). We therefore adopted two separate nonparametric analyses. In order to detect any powerful effect of the between-subject factor Condition (Parallel vs Joint), the differences between incongruent (O-LC) and congruent (O-LL) values for all subjects were obtained; this difference was used as the dependent variable and entered in a MannWhitney $U.$ -Test. The Mann-Whitney $U$ -Test showed no significant effect of the between-subject factor Condition (Parallel vs Join$\mathrm{t}=\mathrm{mean}\pm\mathrm{sd}$ : $0.05\pm0.09$ vs $0.01\pm0.06$ ; $Z=-1.55$ ; $\mathbf{p}=0.126,$ . We therefore directly compared the values from incongruent (OLC) and congruent (O-LL) tasks for all subjects using a Wilcoxon signed-rank test for pairwise comparisons in order to detect any powerful effect of the within-subject factor Task. Bonferroni correction was applied for both pairwise comparisons (with value/ number of comparisons: $0.05/2=0.025;$ . Wilcoxon matched pairs tests, after Bonferroni correction, revealed no powerful effect of the within-subject factor Task, showing no significant difference between the incongruent (O-LC) and the congruent (O-LL) task $({\mathrm{mean}}\pm{\mathrm{sd}}=0.15\pm0.14$ vs $0.18\pm0.15$ ; $Z=1.657$ ; $\mathbf{p}=0.097$ ). This indicates that, for all participants, SI was equal in the incongruent (O-LC) and in the congruent (O-LL) tasks, and that the participants assigned to the two Conditions (Joint vs Parallel) did not differ from each other in terms of synchronization.  

# 3.3. Number of inversions (NIV)  

Subjects performed the drawing task in a fluent manner (values ${\mathrm{NIV}}=1$ were found in $94.1\%$ of all trials) without significant differences across conditions. A Mann-Whitney $U$ -Test showed no significant effect between Parallel versus Joint Condition in both unimanual main experiment $(\mathsf{p}=0.447)$ and bimanual baseline experiment $\mathbf{\zeta}_{\mathbf{p}}=0.112\$ .  

# 4. Discussion  

The aim of the present study was to directly investigate, for the first time, how performing a joint action might differ from performing parallel but merely individual actions with respect to what is represented motorically. Can participants in joint actions represent collective goals motorically? We asked participants to draw lines or circles while observing circles or lines being drawn by a confederate; we manipulated whether each participant conceived of herself as acting jointly with, or in parallel with, the confederate. The visual feedback and the basic action required were the same in both Joint and Parallel Action conditions, and drawing performance was generally fluent (as indicated by NIV scores): only the instructions varied.  

The main finding was that lines drawn by participants observing the confederate draw circles were more ovalized by those acting jointly than by those acting in parallel. How can this difference in ovalization be explained? The difference is consistent with previous studies investigating whether and how visual feedback can induce spatial interference during unimanual action. These studies clearly indicate that observing a confederate’s hand drawing circles does not affect the trajectory of the observer’s own hand when she is drawing lines (Garbarini et al., 2013b, 2016). This would seem to exclude the possibility of explaining the difference between acting jointly and acting in parallel as a consequence merely of imitative or counter-imitative effects (e.g. Brass, Bekkering, Wohlschläger, & Prinz, 2000; Heyes, 2011). Why else might there be a difference between acting jointly and acting in parallel?  

When an individual is bimanually drawing lines and circles, the line drawing hand tends to ovalize its trajectories, as in our bimanual baseline experiment. (This experiment also demonstrated that there was no difference between participants assigned to the two conditions, ruling out the possibility of relevant individual differences in susceptibility to ovalization.) The bimanual interference we observed is a highly reproducible effect, and one present across different ages (Piedimonte et al., 2014). It has been interpreted as a motor coupling effect as it is more tightly linked to action representation than to movement execution (Swinnen et al., 2003). The link to action representation is also evident at the neuronal level. Indeed, bimanual coupling has been shown to involve a parieto-frontal network centred on the pre-supplementary motor area (pre-SMA) and the posterior parietal cortex, which is more closely linked to action representation than to movement execution (e.g., Garbarini et al., 2013a; Sadato, Yonekura, Waki, Yamada, & Ishii, 1997; Wenderoth, Debaere, Sunaert, Hecke, & Swinnen, 2004). We suggest that ovalization in the Joint Action condition has fundamentally the same source as ovalization in individual performance of a bimanual action: it is a consequence of representing the goal of drawing both a circle and a line. Our hypothesis is that individuals performing a joint action (unlike those who are merely acting in parallel) can represent the collective goal of their joint action motorically. If so, participants in the Joint Action condition may have represented the collective goal of drawing both a circle and a line even while actually only drawing a line. Representing this goal would trigger motor processes in the participant concerning both circle and line drawing actions, somewhat like those which would occur were the participant performing both drawing actions herself. These motor processes should interfere with each other, somewhat as they do in bimanual action. Of course, in joint action the hands belong to different individuals: this may explain why the interference is stronger in bimanual action than in unimanual joint action. But the critical point for us is that in both cases, bimanual action and joint action, interference is a consequence of representing motorically the goal of drawing both a circle and a line.  

Given our hypothesis that collective goals are represented motorically in joint action, why did we find a difference between joint action and parallel action in the line-drawing task but not in the circle-drawing task? No such difference was reported in the previous study of bimanual action (Franz et al., 1991), which found effects on ovalization for both circles and lines. Further, the explanation we have offered implies that collective goals should be represented motorically in both line- and circledrawing tasks. One possibility is that those performing the circledrawing task were less likely to represent collective goals than those performing the line-drawing task, perhaps because the circle-drawing task was more taxing (compare Vesper et al., 2013 for a potentially related asymmetry). An alternative possibility is that those performing the circle-drawing task did indeed represent the collective goal motorically but the effects of this representation were masked by the variability involved drawing circles. To examine this possibility, we compared the variance of the OI values obtained from drawings of lines and drawings of circles. There was significantly greater variance in drawings of circles than in drawings of lines. This greater variance, together with the fact that the joint action effect is smaller than the variance observed, may explain the apparent difference between the line-drawing and the circle-drawing tasks. Greater variability in drawing circles may mask the effect of joint action on ovalization. Indeed, other researchers have relied on line drawing rather than circle drawing to detect interference effects for just this reason (e.g. Garbarini et al., 2012, 2013a, 2013b). While the present results do not allow us to decisively distinguish these explanations for the difference between the line- and circle-drawing tasks, the important point for our purposes is this: on either explanation, at least those performing the line-drawing task represented collective goals motorically.  

One might wonder whether a simpler explanation of the difference in ovalization between acting jointly and acting in parallel might be given by appeal to attention. Manipulating whether participants were instructed to act jointly or in parallel may have induced an attentional bias. In performing joint actions, participants may have been biased to attend more to the other’s drawing than when acting in parallel. However, although attention could play some role, we regard it as implausible that differences in attention are sufficient to explain the observed differences in ovalization. Why? First, in all conditions of all tasks, the instructions explicitly required participants to focus on the confederate’s drawings. Second, if attention fully explained the difference in ovalization, we would expect it also to result in greater synchronization when acting jointly than when acting in parallel. In fact we observed no significant difference in synchronization between acting jointly and acting in parallel. There was even a nonsignificant trend towards less synchronization when acting jointly, counter to what we would expected if attention played a role.  

Alternative hypotheses about the difference in ovalization between acting jointly and acting in parallel might somehow invoke entrainment. Such an alternative is initially attractive because our task, unlike some others (e.g. Jung, Holländer, Müller, & Prinz, 2011), involved rhythmic movements. One might suppose that stronger entrainment would indicate closer coupling between participant and confederate, and that this coupling might somehow result in greater ovalization. But there is a clear obstacle to offering any such explanation of our findings: as already noted, participants were no less synchronized with the confederate when acting in parallel than when acting jointly. This indicates that if there was any difference with respect to entrainment, there was more entrainment in the parallel condition than in the joint action condition. So to explain our findings by invoking entrainment, it would be necessary to discover a theoretical link between lesser entrainment and greater ovalization.  

A related challenge would face an attempt to explain the difference in ovalization between acting jointly and acting in parallel by appeal to temporal adaptation, a mechanism whereby individuals speed up or slow down their actions to match observed actions (Keller, 2008; Konvalinka, Vuust, Roepstorff, & Frith, 2010). It has recently been suggested that coordination effects which were held to be a consequence of how actions are represented motorically are in fact due merely to temporal adaptation (e.g. Lelonkiewicz & Gambi, 2016). Could our findings similarly be explained merely by temporal adaptation and so not support the hypothesis that collective goals can be represented motorically? To show that they could it would be necessary, first, to link temporal adaptation to ovalization; and, second, to link the lower temporal adaptation observed in performing joint actions with greater ovalization.  

While our aim was not to investigate entrainment or temporal adaptation, the observation that actions are no less synchronized when acting in parallel than when performing a joint action suggests that the extent to which actions are entrained, and the extent to which temporal adaptation occurs, can be dissociated from the extent to which motor representations of collective goals influence actions (compare van der Wel & Fu, 2015). This is a topic for further investigation.  

A higher-level alternative to our hypothesis about motor representations of collective goals might involve task co-representation, which has been invoked to explain how people coordinate joint actions (e.g. Baus et al., 2014; Sebanz, Bekkering, & Knoblich, 2006). As it is typically understood, task co-representation would involve participants representing the confederate’s task in addition to representing their own task. Although this may occur in our experiment, the existing literature suggests that task corepresentation can occur when agents are merely acting in parallel (e.g. Atmaca et al., 2011; Böckler et al., 2012). If we think that ovalization can be explained by invoking task co-representation, we would therefore need some way of explaining why task corepresentation is less likely to occur in when acting in parallel than when performing joint actions. An alternative possibility would be to eschew the idea that participants represent the confederate’s task in favour of the view that in performing joint actions they represent the larger task of drawing circles and lines (compare Vesper, Knoblich, Sebanz, 2014). On this view, participants performing a joint action would have a task representation specifying a collective goal. But how could that task representation affect the drawing actions? One possibility is that it does so by triggering a motor representation of the collective goal. When understood in this way, appeal to task co-representation is an elaboration of, rather than a competitor to, our hypothesis that collective goals can be represented motorically.  

Effects associated by some with task co-representation have been interpreted as due to non-social attentional mechanisms (e.g. Dolk, Hommel, Prinz, & Liepelt, 2014). Could such interpretation be extended to cover findings such as ours? On such an interpretation, the greater ovalization effects we observed in joint action would be due to the greater salience of the confederate’s drawing together with the need to distinguish this event from the self-produced drawing (compare Dolk et al., 2014 p. 1229). Salience may have some effect, of course. But an immediate obstacle to this interpretation is the fact that we compared parallel with joint action (rather than individual with joint action, as in many studies of task co-representation). All other things being equal, a non-social attentional mechanism should be required no less when acting in parallel with others than when acting jointly with them.  

A further potential issue is that participants in our experiments were acting on our instructions. We assume that fundamentally the same processes are at work when people act spontaneously, although of course our data do not bear directly on this assumption.  

Even if alternatives involving attention, entrainment or temporal adaptation cannot fully explain our findings, there may still seem to be reason to resist our hypothesis. It may seem bizarre to suggest that participants represented actions which no individual performed and which would have required two hands to perform. After all, when performing joint actions, participants were only ever drawing with their right hands. But however bizarre it may seem, it is a natural extension of earlier studies which indicate that effects characteristic of motor coupling, such as an increase in the ovalization of a straight line, can occur even when an individual is actually acting unimanually. Such effects have been observed in hemiplegic patients affected by anosognosia for hemiplegia (Garbarini et al., 2012). Although they did not actually move both hands when asked to draw circles and lines simultaneously, these patients did claim to move their paralyzed hands and their lines were clearly ovalized. Relatedly, amputees with phantom limb experiences were also found to ovalize straight lines (Franz & Ramachandran, 1998), as were patients with hemisomatoagnosia who misidentify other’s limbs as their own (Garbarini et al., 2013b). All three cases suggest that the execution of a bimanual action is unnecessary for effects characteristic of motor coupling to occur: it is sufficient that the goal of drawing circles and lines is represented motorically. This has been strongly corroborated by a version of the task involving motor imagery in healthy subjects who were either actually drawing circles and lines with two hands or actually drawing lines with just one hand while merely imagining drawing circles with the other hand (Garbarini et al., 2013a; Piedimonte et al., 2014). The results showed clear ovalization in both conditions, suggesting that effects characteristic of motor coupling can also be a consequence of motor representation and do not require that one individual is actually using both hands. Our study takes the further step from individual to joint action and provides evidence that there can be interpersonal motor coupling. Others have taken a related step in providing evidence that an individual may take into account relations between her own actions and another’s in preparing and monitoring her actions (e.g. Kourtis et al., 2014; Meyer et al., 2013; Tsai et al., 2011; Vesper et al., 2013). For example, Loehr et al. (2013) showed that pianists playing chords together distinguish errors which affect a pianist’s own part only from errors which affect the harmony of the chord and so result in failure to achieve a collective goal. Richardson, Marsh, and Baron (2007) showed that acting together with another rather than alone can modulate how an individual grasps an object. And Novembre, Ticini, Schutz-Bosbach, and Keller (2013) showed that momentarily disrupting motor processes by means of double-pulse transcranial magnetic stimulation impairs a pianist’s ability to appropriately adjust tempo to match her (recorded) partner’s performance independently of impairing other aspects of her performance. Taken together, these findings suggest that an individual may take into account relations between her own actions and another’s in preparing, performing and anticipating actions. But does doing so involve representing collective goals? To answer this question a new approach was needed. Earlier studies all compare one individual’s performance with multiple individuals’ performances. But to isolate indicators that a collective goal is represented, it is necessary to compare multiple individuals acting in parallel with multiple individuals acting jointly (Gilbert, 1990; Searle, 1990). By doing this in the present study we show, for the first time, that participants in joint actions can indeed represent collective goals motorically. Motor representations of collective goals matter for the coordination of actions. Coordinating a bimanual action often involves representing motorically an outcome to be realised by the movements of two hands. If we are right, coordinating a joint action may sometimes be similar insofar as it involves a motor representation of an outcome to be realised by the movements of two (or more) agents. Of course, not all coordination challenges can be met by invoking motor representations---many joint actions involve collective goals that cannot be represented motorically, goals such as meeting at an airport or celebrating a birthday. But for small scale joint actions involving passing objects, playing chords or drawing together, collective goals represented motorically may be indispensable. And these are the foundations of all joint action.  

# Appendix A. Supplementary material  

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.cognition.2017. 04.008.  

# References  

Atmaca, S., Sebanz, N., & Knoblich, G. (2011). The joint flanker effect: sharing tasks with real and imagined co-actors. Experimental Brain Research, 211, 371–385.   
Baus, C., Sebanz, N., Fuente, V. d. l., Branzi, F. M., Martin, C., & Costa, A. (2014). On predicting others’ words: Electrophysiological evidence of prediction in speech production. Cognition, 133(2), 395–407.   
Böckler, A., Knoblich, G., & Sebanz, N. (2012). Effects of a co-actor’s focus of attention on task performance. Journal of Experimental Psychology: Human Perception and Performance, 38(6), 1404–1415.   
Brass, M., Bekkering, H., Wohlschläger, A., & Prinz, W. (2000). Compatibility between observed and executed finger movements: Comparing symbolic, spatial, and imitative cues. Brain and Cognition, 44(2), 124–143.   
Bratman, M. E. (2014). Shared agency: A planning theory of acting together. Oxford: Oxford University Press.   
Butterfill, S. A. (2016). Planning for collective agency. In C. Misselhorn (Ed.). Collective agency and cooperation in natural and artificial systems. Philosophical studies series (Vol. 122, pp. 149–168). New York: Springer.   
Dittrich, K., Bossert, M.-L., Rothe-Wulf, A., & Klauer, K. C. (2017). The joint flanker effect and the joint Simon effect: On the comparability of processes underlying joint compatibility effects. The Quarterly Journal of Experimental Psychology, 70 (9), 1808–1823.   
Dolk, T., Hommel, T., Colzato, L. S., Schütz-Bosbach, S., Prinz, W., & Liepelt, R. (2011). How ‘social’ is the Social Simon Effect? Frontiers in Psychology, 2, 84.   
Dolk, T., Hommel, B., Prinz, W., & Liepelt, R. (2013). The (not so) social Simon effect: A referential coding account. Journal of Experimental Psychology: Human Perception and Performance, 39(5), 1248–1260.   
Dolk, T., Hommel, B., Prinz, W., & Liepelt, R. (2014). The joint flanker effect: Less social than previously thought. Psychonomic Bulletin $\mathcal{E}$ Review, 21(5), 1224–1230.   
Franz, E. A., & Ramachandran, V. S. (1998). Bimanual coupling in amputees with phantom limbs. Nature Neuroscience, 1, 443–444.   
Franz, E. A., Zelaznik, H. N., & McCabe, G. (1991). Spatial topological constraints in a bimanual task. Acta Psychologica, 77, 137–151.   
Garbarini, F., D’Agata, F., Piedimonte, A., Sacco, K., Rabuffetti, M., Cauda, F., ... Berti, A. (2013a). Drawing lines while imagining circles: neural basis of the bimanual coupling effect during motor execution and motor imagery. Neuroimage, 88C, 100–112.   
Garbarini, F., Mastropasqua, A., Sigaudo, M., Rabuffetti, M., Piedimonte, A., Pia, L., & Rocca, P. (2016). Abnormal sense of agency in patients with schizophrenia: Evidence from bimanual coupling paradigm. Frontiers Behavioral Neuroscience, 10, 43.   
Garbarini, F., & Pia, L. (2013). Bimanual coupling paradigm as an effective tool to investigate productive behaviors in motor and body awareness impairments. Frontiers in Neuroscience, 7, 737.   
Garbarini, F., Pia, L., Piedimonte, A., Rabuffetti, M., Gindri, P., & Berti, A. (2013b). Embodiment of an alien hand interferes with intact-hand movements. Current Biology, 23. 2–r57-R58.   
Garbarini, F., Rabuffetti, M., Piedimonte, A., Pia, L., Ferrarin, M., Frassinetti, F., .. Berti, A. (2012). ‘Moving’ a paralysed hand: bimanual coupling effect in patient with anosognosia for hemiplegia. Brain, 135, 1486–1497.   
Garbarini, F., Rabuffetti, M., Piedimonte, A., Solito, G., & Berti, A. (2015b). Bimanual coupling effects during arm immobilization and passive movements. Human Movement Science, 41, 114–126.   
Garbarini, F., Turella, L., Rabuffetti, M., Cantagallo, A., Piedimonte, A., Fainardi, E., Fadiga, L. (2015a). Bimanual Non-congruent actions in motor neglect syndrome: a combined behavioral/fMRI study. Frontiers Human Neuroscience, 9, 541.   
Gilbert, M. P. (1990). Walking together: A paradigmatic social phenomenon. Midwest Studies in Philosophy, 15, 1–14.   
Heyes, C. (2011). Automatic imitation. Psychological Bulletin, 137(3), 463–483.   
Issartel, J., Marin, L., & Cadopi, M. (2007). Unintended interpersonal co-ordination: ‘Can we march to the beat of our own drum?’. Neuroscience Letters, 411, 174–179.   
Jung, C., Holländer, A., Müller, K., & Prinz, W. (2011). Sharing a bimanual task between two: Evidence of temporal alignment in interpersonal coordination. Experimental Brain Research, 211(3–4), 471–482.   
Keller, P. E (2008). Joint action in music performance. In Enacting intersubjectivity: A cognitive and social perspective to the study of interactions (pp. 205–221). IOS Press.   
Knoblich, G., Butterfill, S., & Sebanz, N. (2011). Psychological research on joint action: Theory and data. In Brian Ross (Ed.). Psychology of learning and motivation (Vol. 51). Academic Press.   
Konvalinka, I., Vuust, P., Roepstorff, A., & Frith, C. D. (2010). Follow you, follow me: Continuous mutual prediction and adaptation in joint tapping. The Quarterly Journal of Experimental Psychology, 63(11), 2220–2230.   
Kourtis, D., Knoblich, G., Wozniak, M., & Sebanz, N. (2014). Attention allocation and task representation during joint action planning. Journal of Cognitive Neuroscience, 26(10), 2275–2286.   
Kourtis, D., Sebanz, N., & Knoblich, G. (2013). Predictive representation of other people’s actions in joint action planning: An EEG study. Social Neuroscience, 8, 31–42.   
Lelonkiewicz, J. R., & Gambi, C. (2016). Spontaneous adaptation explains why people act faster when being imitated. Psychonomic Bulletin & Review. http://dx.doi.org/ 10.3758/s13423-016-1141-3.   
Loehr, J. D., Kourtis, D., Vesper, C., Sebanz, N., Knoblich, G., et al. (2013). Monitoring individual and joint action outcomes in duet music performance. Journal of Cognitive Neuroscience, 25, 1049–1061.   
Marquardt, C., & Mai, N. (1994). A computational procedure for movement analysis in handwriting. Journal of Neuroscience Methods, 52, 39–45.   
Meyer, M., van der Wel, R. P. R. D., & Hunnius, S. (2013). Higher-order action planning for individual and joint object manipulations. Experimental Brain Research, 22, 579–588.   
Nessler, J. A., & Gilliland, S. J. (2009). Interpersonal synchronization during side by side treadmill walking is influenced by leg length differential and altered sensory feedback. Human Movement Science, 28, 772–785.   
Novembre, G., Ticini, L. F., Schutz-Bosbach, S., & Keller, P. E. (2013). Motor simulation and the coordination of self and other in real-time joint action. Social Cognitive and Affective Neuroscience, 9, 1062–1068.   
Piedimonte, A., Garbarini, F., Rabuffetti, M., Pia, L., & Berti, A. (2014). Executed and imagined bimanual movements: A study across different ages. Developmental Psychology, 50, 1073–1080.   
Richardson, M. J., Marsh, K. L., & Baron, R. M. (2007). Judging and actualizing intrapersonal and interpersonal affordances. Journal of Experimental Psychology: Human Perception and Performance, 33, 845–859.   
Sadato, N., Yonekura, Y., Waki, A., Yamada, H., & Ishii, Y. (1997). Role of the supplementary motor area and the right premotor cortex in the coordination of bimanual finger movements. Journal of Neuroscience, 17, 9667–9674.   
Searle, J. R. (1990). Collective intentions and actions. In P. Cohen, J. Morgan, & M. E. Pollack (Eds.), Intentions in communication (pp. 90–105). Cambridge: Cambridge University Press.   
Sebanz, N., Bekkering, H., & Knoblich, G. (2006). Joint action: Bodies and mind moving together. Trends in Cognitive Sciences, 10(2), 70–76.   
Sebanz, N., Knoblich, G., & Prinz, W. (2003). Representing others’ actions: Just like one’s own? Cognition, 88(3), B11–B21.   
Sebanz, N., Knoblich, G., & Prinz, W. (2005). How two share a task: Corepresenting stimulus-response mappings. Journal of Experimental Psychology: Human Perception and Performance, 31, 1234–1246.   
Swinnen, S. P., Puttemans, V., Vangheluwe, S., Wenderoth, N., Levin, O., & Dounskaia, N. (2003). Directional interference during bimanual coordination: is interlimb coupling mediated by afferent or efferent processes? Behavioral Brain Research, 139(1–2), 177–195.   
Tsai, J. C.-C., Sebanz, N., & Knoblich, G. (2011). The GROOP effect: Groups mimic group actions. Cognition, 118, 135–140.   
Tucha, O., Tucha, L., & Lange, K. W. (2008). Graphonomics, automaticity and handwriting assessment. Literacy, 42, 145–155.   
van Ulzen, N. R., Lamoth, C. J., Daffertshofer, A., Semin, G. R., & Beek, P. J. (2008). Characteristics of instructed and uninstructed interpersonal coordination while walking side-by-side. Neuroscience Letters, 432, 88–93.   
Varlet, M., Bucci, C., Richardson, M. J., & Schmidt, R. C. (2015). Informational constraints on spontaneous visuomotor entrainment. Human Movement Science, 41, 265–281.   
Vesper, C., Butterfill, S., Knoblich, G., & Sebanz, N. (2010). A minimal architecture for joint action. Neural Networks, 23, 998–1003.   
Vesper, C., Knoblich, G., & Sebanz, N. (2014). Our actions in my mind: Motor imagery of joint action. Neuropsychologia, 55, 115–121.   
Vesper, C., van der Wel, R. P. R. D., Knoblich, G., & Sebanz, N. (2013). Are you ready to jump? Predictive mechanisms in interpersonal coordination. Journal of Experimental Psychology: Human Perception and Performance, 39(1), 48–61.   
van der Wel, R. P. R. D., & Fu, E. (2015). Entrainment and task co-representation effects for discrete and continuous action sequences. Psychonomic Bulletin Review, 22(6), 1–7.   
Wenderoth, N., Debaere, F., Sunaert, S., Hecke, P., & Swinnen, S. P. (2004). Parietopremotor areas mediate directional interference during bimanual movements. Cerebral Cortex, 14, 1153–1163.   
Wenke, D., Atmaca, S., Holländer, A., Liepelt, R., Baess, P., & Prinz, W. (2011). What is shared in joint action? Issues of co-representation, response conflict, and agent identification. Review of Philosophy and Psychology, 2(2), 147–172.  


</div>

---

Title: The Developing Mind: A Philosophical Introduction
Authors: Stephen A. Butterfill
Year: 2020
Type: Publication

<html>
  <head>
    <style type="text/css">
    #page-container { /* PDF container */
      position:absolute; /* required for calculating relative positions of pages in pdf2htmlEX.js */
      top:0;
      left:0px;
      margin:0; 
      padding:0;
      border:0; /* required for lazy page loading in pdf2htmlEX.js (page visibility test) */
    }
    @media screen {
      #page-container {
        /* `bottom' and `right' are required for lazy page loading in pdf2htmlEX.js (page visibility test)
        * alternatively you may set width and height
        */
        bottom:0;
        right:0;
        overflow:auto;
      }
    }
    @media print { 
      @page { margin:0; }
      html { margin:0; }
      body { 
        margin:0; 
        -webkit-print-color-adjust:exact; /* enable printing background images for WebKit */
      }
      #sidebar { display:none; }
      #page-container {
        width:auto;
        height:auto;
        overflow:visible;
        background-color:transparent;
      }
      .d { display:none; }
    }
    /* Part 2: Page Elements: Modify with caution
    * The followings are base classes, some of which are meant to be override by PDF specific classes
    * So do not increase the specificity (e.g. ".classname" -> "#page-container .classname")
    */
    .pf { /* page */
      position:relative;
      background-color:white;
      overflow: hidden;
      margin:0; 
      border:0; /* required by pdf2htmlEX.js for page visibility test */
    }
    .pc { /* content of a page */
      position:absolute;
      border:0;
      padding:0;
      margin:0;
      top:0;
      left:0;
      width:100%;
      height:100%;
      overflow:hidden;
      display:block;
      /* set transform-origin for scaling */
      transform-origin:0% 0%;
      -ms-transform-origin:0% 0%;
      -webkit-transform-origin:0% 0%;
    }
    .pc.opened { /* used by pdf2htmlEX.js, to show/hide pages */
      display:block;
    }
    .bf { /* images that occupies the whole page */
      position:absolute;
      border:0;
      margin:0;
      top:0;
      bottom:0;
      width:100%;
      height:100%;
      -ms-user-select:none;
      -moz-user-select:none;
      -webkit-user-select:none;
      user-select:none;
    }
    .bi { /* images that cover only a part of the page */
      position:absolute;
      border:0;
      margin:0;
      -ms-user-select:none;
      -moz-user-select:none;
      -webkit-user-select:none;
      user-select:none;
    }
    @media print {
      .pf {
        margin:0;
        box-shadow:none;
        page-break-after:always;
        page-break-inside:avoid;
      }
      @-moz-document url-prefix() {
        /* fix page truncation for FireFox */
        .pf {
          overflow:visible;
          border:1px solid #FFFFFF;
        }
        .pc {overflow:visible;}
      }
    }
    .c { /* clip box */
      position:absolute;
      border:0;
      padding:0;
      margin:0;
      overflow:hidden;
      display:block;
    }
    .t { /* text line */
      position:absolute;
      white-space:pre;
      font-size:1px;
      transform-origin:0% 100%;
      -ms-transform-origin:0% 100%;
      -webkit-transform-origin:0% 100%;
      unicode-bidi:bidi-override;/* For rtl languages, e.g. Hebrew, we don't want the default Unicode behaviour */
      -moz-font-feature-settings:"liga" 0;/* We don't want Firefox to recognize ligatures */
    }
    .t:after { /* webkit #35443 */
      content: '';
    }
    .t:before { /* Workaround Blink(up to 41)/Webkit bug of word-spacing with leading spaces (chromium #404444 and pdf2htmlEX #412) */
      content: '';
      display: inline-block;
    }
    .t span { /* text blocks within a line */
      /* Blink(up to 41)/Webkit have bug with negative word-spacing and inline-block (pdf2htmlEX #416), so keep normal span inline. */
      position:relative;
      unicode-bidi:bidi-override; /* For rtl languages, e.g. Hebrew, we don't want the default Unicode behaviour */
    }
    ._ { /* text shift */
      /* Blink(up to 41)/Webkit have bug with inline element, continuous spaces and word-spacing. Workaround by inline-block. */
      display: inline-block;
      color: transparent;
      z-index: -1;
    }
    /* selection background should not be opaque, for fallback mode */
    ::selection{
      background: rgba(127,255,255,0.4);
    }
    ::-moz-selection{
      background: rgba(127,255,255,0.4);
    }
    .pi { /* info for Javascript */
      display:none;
    }
    .l { /* annotation links */
    }
    /* transparent color - WebKit */
    .d { /* css drawing */
      position:absolute;
      transform-origin:0% 100%;
      -ms-transform-origin:0% 100%;
      -webkit-transform-origin:0% 100%;
    }
    /* for the forms */
    .it {
      border: none;
      background-color: rgba(255, 255, 255, 0.0);
    }
    
    .ir:hover {
      cursor: pointer;
    }
    
    /* Base CSS END */
    </style>
    <style type="text/css">
    /* vim: set shiftwidth=2 tabstop=2 autoindent cindent expandtab filetype=css: */
    /*! 
    * Fancy styles for pdf2htmlEX
    * Copyright 2012,2013 Lu Wang <coolwanglu@gmail.com> 
    * https://github.com/coolwanglu/pdf2htmlEX/blob/master/share/LICENSE
    */
    @keyframes fadein { from { opacity:0;} to { opacity:1;} }
    @-webkit-keyframes fadein { from { opacity:0;} to { opacity:1;} }
    @keyframes swing {
      0%  { transform: rotate(0deg); }
      10% { transform: rotate(0deg); }
      90% { transform: rotate(720deg); }
      100%{ transform: rotate(720deg); }
    }
    @-webkit-keyframes swing {
      0%  { -webkit-transform: rotate(0deg); }
      10% { -webkit-transform: rotate(0deg); }
      90% { -webkit-transform: rotate(720deg); }
      100%{ -webkit-transform: rotate(720deg); }
    }
    @media screen { 
      #sidebar {
        background-color:#2f3236;
        /* modified from http://philbit.com/svgpatterns/#crossstripes */
        background-image:url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0IiBoZWlnaHQ9IjQiPgo8cmVjdCB3aWR0aD0iNCIgaGVpZ2h0PSI0IiBmaWxsPSIjNDAzYzNmIj48L3JlY3Q+CjxwYXRoIGQ9Ik0wIDBMNCA0Wk00IDBMMCA0WiIgc3Ryb2tlLXdpZHRoPSIxIiBzdHJva2U9IiMxZTI5MmQiPjwvcGF0aD4KPC9zdmc+");
      }
      #outline {
        font-family:Georgia,Times,"Times New Roman",serif;
        font-size:13px;
        margin:2em 1em;
      }
      #outline ul {
        padding:0;
      }
      #outline li {
        list-style-type:none;
        margin:1em 0;
      }
      #outline li > ul {
        margin-left: 1em;
      }
      #outline a,
      #outline a:visited,
      #outline a:hover,
      #outline a:active {
        line-height:1.2;
        color:#e8e8e8;
        text-overflow:ellipsis;
        white-space:nowrap;
        text-decoration:none;
        display:block;
        overflow:hidden;
        outline:0;
      }
      #outline a:hover {
        color:rgb(0,204,255);
      }
      .pf {
        margin: 13px auto;
        box-shadow: 1px 1px 3px 1px #333;
        /* Needed by IE to make box-shadow works * https://developer.mozilla.org/en-US/docs/Web/CSS/box-shadow */
        border-collapse: separate;
      }
      .pc.opened { /* used by pdf2htmlEX.js, to show/hide pages */
        -webkit-animation: fadein 100ms;
        animation: fadein 100ms; 
      }
      .loading-indicator.active {
        /* 
        * use 0.01s instead of 0s,
        * since YUI Compressor will change 0s to 0,
        * which is not recognized by Firefox
        */
        -webkit-animation: swing 1.5s ease-in-out 0.01s infinite alternate none;
        animation: swing 1.5s ease-in-out 0.01s infinite alternate none;
      }
      .checked {
        background: no-repeat url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABYAAAAWCAYAAADEtGw7AAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH3goQDSYgDiGofgAAAslJREFUOMvtlM9LFGEYx7/vvOPM6ywuuyPFihWFBUsdNnA6KLIh+QPx4KWExULdHQ/9A9EfUodYmATDYg/iRewQzklFWxcEBcGgEplDkDtI6sw4PzrIbrOuedBb9MALD7zv+3m+z4/3Bf7bZS2bzQIAcrmcMDExcTeXy10DAFVVAQDksgFUVZ1ljD3yfd+0LOuFpmnvVVW9GHhkZAQcxwkNDQ2FSCQyRMgJxnVdy7KstKZpn7nwha6urqqfTqfPBAJAuVymlNLXoigOhfd5nmeiKL5TVTV+lmIKwAOA7u5u6Lped2BsbOwjY6yf4zgQQkAIAcedaPR9H67r3uYBQFEUFItFtLe332lpaVkUBOHK3t5eRtf1DwAwODiIubk5DA8PM8bYW1EU+wEgCIJqsCAIQAiB7/u253k2BQDDMJBKpa4mEon5eDx+UxAESJL0uK2t7XosFlvSdf0QAEmlUnlRFJ9Waho2Qghc1/U9z3uWz+eX+Wr+lL6SZfleEAQIggA8z6OpqSknimIvYyybSCReMsZ6TislhCAIAti2Dc/zejVNWwCAavN8339j27YbTg0AGGM3WltbP4WhlRWq6Q/btrs1TVsYHx+vNgqKoqBUKn2NRqPFxsbGJzzP05puUlpt0ukyOI6z7zjOwNTU1OLo6CgmJyf/gA3DgKIoWF1d/cIY24/FYgOU0pp0z/Ityzo8Pj5OTk9PbwHA+vp6zWghDC+VSiuRSOQgGo32UErJ38CO42wdHR09LBQK3zKZDDY2NupmFmF4R0cHVlZWlmRZ/iVJUn9FeWWcCCE4ODjYtG27Z2Zm5juAOmgdGAB2d3cBADs7O8uSJN2SZfl+WKlpmpumaT6Yn58vn/fs6XmbhmHMNjc3tzDGFI7jYJrm5vb29sDa2trPC/9aiqJUy5pOp4f6+vqeJ5PJBAB0dnZe/t8NBajx/z37Df5OGX8d13xzAAAAAElFTkSuQmCC);
      }
    }
    /* Fancy CSS END */
    </style>
    <style type="text/css">
    .ff0{font-family:sans-serif;visibility:hidden;}
    @font-face{font-family:ff1;src:url('data:application/font-woff;base64,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')format("woff");}.ff1{font-family:ff1;line-height:1.058000;font-style:normal;font-weight:normal;visibility:visible;}
    @font-face{font-family:ff2;src:url('data:application/font-woff;base64,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')format("woff");}.ff2{font-family:ff2;line-height:0.938000;font-style:normal;font-weight:normal;visibility:visible;}
    @font-face{font-family:ff3;src:url('data:application/font-woff;base64,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')format("woff");}.ff3{font-family:ff3;line-height:0.938000;font-style:normal;font-weight:normal;visibility:visible;}
    @font-face{font-family:ff4;src:url('data:application/font-woff;base64,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')format("woff");}.ff4{font-family:ff4;line-height:1.058000;font-style:normal;font-weight:normal;visibility:visible;}
    .m0{transform:matrix(0.250000,0.000000,0.000000,0.250000,0,0);-ms-transform:matrix(0.250000,0.000000,0.000000,0.250000,0,0);-webkit-transform:matrix(0.250000,0.000000,0.000000,0.250000,0,0);}
    .m1{transform:none;-ms-transform:none;-webkit-transform:none;}
    .v0{vertical-align:0.000000px;}
    .v1{vertical-align:17.352000px;}
    .ls2{letter-spacing:0.000000px;}
    .ls0{letter-spacing:23.910400px;}
    .ls3{letter-spacing:26.166484px;}
    .ls1{letter-spacing:47.151309px;}
    .sc_{text-shadow:none;}
    .sc0{text-shadow:-0.015em 0 transparent,0 0.015em transparent,0.015em 0 transparent,0 -0.015em  transparent;}
    @media screen and (-webkit-min-device-pixel-ratio:0){
    .sc_{-webkit-text-stroke:0px transparent;}
    .sc0{-webkit-text-stroke:0.015em transparent;text-shadow:none;}
    }
    .wse{word-spacing:-15.111373px;}
    .wsb{word-spacing:-7.460045px;}
    .wsc{word-spacing:-5.834061px;}
    .wsf{word-spacing:-5.260288px;}
    .wsa{word-spacing:-4.734061px;}
    .ws6{word-spacing:-4.208230px;}
    .ws7{word-spacing:0.000000px;}
    .ws2{word-spacing:7.125299px;}
    .ws5{word-spacing:11.907379px;}
    .ws4{word-spacing:14.288815px;}
    .ws8{word-spacing:16.402339px;}
    .ws9{word-spacing:17.502403px;}
    .wsd{word-spacing:22.523597px;}
    .ws3{word-spacing:23.862579px;}
    .ws1{word-spacing:47.103488px;}
    .ws10{word-spacing:1088.933965px;}
    .ws11{word-spacing:1211.683430px;}
    .ws0{word-spacing:1270.837760px;}
    ._2{margin-left:-26.253619px;}
    ._1{margin-left:-23.910400px;}
    ._3{margin-left:-12.337766px;}
    ._b{margin-left:-11.285709px;}
    ._19{margin-left:-9.994547px;}
    ._29{margin-left:-6.647091px;}
    ._1f{margin-left:-4.208230px;}
    ._a{margin-left:-2.630144px;}
    ._d{margin-left:-1.099878px;}
    ._11{width:1.090311px;}
    ._4{width:4.016947px;}
    ._23{width:5.164646px;}
    ._3c{width:10.520576px;}
    ._7{width:11.955200px;}
    ._40{width:13.437645px;}
    ._1b{width:14.537523px;}
    ._34{width:15.924326px;}
    ._17{width:17.024205px;}
    ._26{width:18.554470px;}
    ._37{width:20.276019px;}
    ._2c{width:21.375898px;}
    ._33{width:22.858342px;}
    ._22{width:23.910400px;}
    ._15{width:25.201562px;}
    ._24{width:28.453376px;}
    ._27{width:29.983642px;}
    ._8{width:31.753011px;}
    ._e{width:32.900710px;}
    ._1d{width:35.148288px;}
    ._28{width:36.152525px;}
    ._3a{width:37.539328px;}
    ._2b{width:38.543565px;}
    ._16{width:39.691069px;}
    ._1a{width:41.412739px;}
    ._2f{width:42.417126px;}
    ._35{width:43.421680px;}
    ._20{width:45.907968px;}
    ._13{width:47.151309px;}
    ._6{width:54.993920px;}
    ._10{width:57.384800px;}
    ._5{width:62.597360px;}
    ._c{width:63.697360px;}
    ._1e{width:64.988272px;}
    ._f{width:86.507760px;}
    ._9{width:87.607760px;}
    ._25{width:206.872781px;}
    ._14{width:680.633446px;}
    ._36{width:752.221184px;}
    ._30{width:765.283693px;}
    ._31{width:799.542418px;}
    ._39{width:804.202394px;}
    ._2a{width:855.801037px;}
    ._3e{width:875.551027px;}
    ._2d{width:893.388186px;}
    ._1c{width:896.926925px;}
    ._12{width:912.877398px;}
    ._3b{width:947.186586px;}
    ._38{width:965.884518px;}
    ._18{width:992.616346px;}
    ._21{width:996.250726px;}
    ._3d{width:1064.634470px;}
    ._3f{width:1081.419571px;}
    ._2e{width:1093.709517px;}
    ._0{width:1102.460723px;}
    ._32{width:1184.282112px;}
    .fc0{color:rgb(0,0,0);}
    .fs4{font-size:31.880400px;}
    .fs3{font-size:39.850400px;}
    .fs1{font-size:47.820800px;}
    .fs2{font-size:57.384800px;}
    .fs0{font-size:99.148400px;}
    .y1c{bottom:104.882000px;}
    .y1b{bottom:133.228000px;}
    .y42{bottom:133.229000px;}
    .y1a{bottom:148.033000px;}
    .y87{bottom:148.038000px;}
    .y41{bottom:148.106000px;}
    .y63{bottom:148.901000px;}
    .y19{bottom:162.838000px;}
    .y86{bottom:162.847000px;}
    .y40{bottom:162.983000px;}
    .y62{bottom:164.573000px;}
    .y18{bottom:177.643000px;}
    .y85{bottom:177.656000px;}
    .y3f{bottom:177.860000px;}
    .y61{bottom:180.245000px;}
    .y17{bottom:192.448000px;}
    .y84{bottom:192.465000px;}
    .y3e{bottom:192.737000px;}
    .y60{bottom:195.918000px;}
    .y16{bottom:207.252000px;}
    .y83{bottom:207.274000px;}
    .y3d{bottom:207.614000px;}
    .y5f{bottom:211.590000px;}
    .y15{bottom:222.057000px;}
    .y82{bottom:222.083000px;}
    .y3c{bottom:222.491000px;}
    .y5e{bottom:227.262000px;}
    .y81{bottom:236.892000px;}
    .y5d{bottom:242.935000px;}
    .y14{bottom:249.057000px;}
    .y3b{bottom:249.611000px;}
    .y5c{bottom:258.607000px;}
    .y13{bottom:263.861000px;}
    .y80{bottom:263.898000px;}
    .y3a{bottom:264.488000px;}
    .y12{bottom:278.666000px;}
    .y39{bottom:279.365000px;}
    .y5b{bottom:287.052000px;}
    .y11{bottom:293.471000px;}
    .y38{bottom:294.242000px;}
    .y5a{bottom:302.724000px;}
    .y7f{bottom:305.848000px;}
    .y10{bottom:308.276000px;}
    .y37{bottom:309.119000px;}
    .y59{bottom:318.397000px;}
    .y7e{bottom:320.657000px;}
    .yf{bottom:323.081000px;}
    .y58{bottom:334.069000px;}
    .y7d{bottom:335.466000px;}
    .y36{bottom:336.239000px;}
    .y57{bottom:349.741000px;}
    .ye{bottom:350.080000px;}
    .y7c{bottom:350.275000px;}
    .y35{bottom:351.116000px;}
    .yd{bottom:364.885000px;}
    .y7b{bottom:365.084000px;}
    .y56{bottom:365.414000px;}
    .y34{bottom:365.994000px;}
    .yc{bottom:379.690000px;}
    .y7a{bottom:379.893000px;}
    .y33{bottom:380.871000px;}
    .y55{bottom:381.086000px;}
    .yb{bottom:394.494000px;}
    .y32{bottom:395.748000px;}
    .y79{bottom:406.900000px;}
    .ya{bottom:409.299000px;}
    .y54{bottom:409.531000px;}
    .y31{bottom:410.625000px;}
    .y78{bottom:421.709000px;}
    .y53{bottom:425.203000px;}
    .y30{bottom:425.502000px;}
    .y9{bottom:436.298000px;}
    .y77{bottom:436.518000px;}
    .y2f{bottom:440.379000px;}
    .y52{bottom:440.876000px;}
    .y76{bottom:451.327000px;}
    .y2e{bottom:455.256000px;}
    .y51{bottom:456.548000px;}
    .y75{bottom:466.136000px;}
    .y50{bottom:472.220000px;}
    .y8{bottom:478.242000px;}
    .y74{bottom:480.945000px;}
    .y2d{bottom:482.376000px;}
    .y4f{bottom:487.893000px;}
    .y7{bottom:493.047000px;}
    .y73{bottom:495.754000px;}
    .y2c{bottom:497.253000px;}
    .y4e{bottom:503.565000px;}
    .y6{bottom:507.851000px;}
    .y72{bottom:510.563000px;}
    .y2b{bottom:512.130000px;}
    .y4d{bottom:519.237000px;}
    .y5{bottom:522.656000px;}
    .y71{bottom:525.372000px;}
    .y2a{bottom:527.007000px;}
    .y4{bottom:537.461000px;}
    .y70{bottom:540.181000px;}
    .y29{bottom:541.884000px;}
    .y4c{bottom:547.682000px;}
    .y3{bottom:552.266000px;}
    .y28{bottom:556.762000px;}
    .y4b{bottom:563.355000px;}
    .y2{bottom:567.071000px;}
    .y6f{bottom:567.187000px;}
    .y27{bottom:571.639000px;}
    .y4a{bottom:579.027000px;}
    .y6e{bottom:581.996000px;}
    .y26{bottom:586.516000px;}
    .y1{bottom:594.070000px;}
    .y49{bottom:594.699000px;}
    .y6d{bottom:596.805000px;}
    .y25{bottom:601.393000px;}
    .y48{bottom:610.372000px;}
    .y6c{bottom:611.614000px;}
    .y24{bottom:616.270000px;}
    .y47{bottom:626.044000px;}
    .y6b{bottom:626.423000px;}
    .y6a{bottom:641.232000px;}
    .y46{bottom:641.716000px;}
    .y23{bottom:643.390000px;}
    .y69{bottom:656.041000px;}
    .y45{bottom:657.389000px;}
    .y22{bottom:658.267000px;}
    .y0{bottom:664.895000px;}
    .y68{bottom:670.850000px;}
    .y44{bottom:673.061000px;}
    .y21{bottom:673.144000px;}
    .y67{bottom:685.659000px;}
    .y20{bottom:688.021000px;}
    .y66{bottom:700.468000px;}
    .y43{bottom:701.506000px;}
    .y1f{bottom:702.898000px;}
    .y89{bottom:704.048000px;}
    .y65{bottom:715.277000px;}
    .y1e{bottom:717.775000px;}
    .y64{bottom:730.086000px;}
    .y88{bottom:730.449000px;}
    .y1d{bottom:744.895000px;}
    .h5{height:32.677328px;}
    .h2{height:33.474560px;}
    .h3{height:39.213056px;}
    .h4{height:40.169360px;}
    .h6{height:43.493928px;}
    .h1{height:81.301688px;}
    .h0{height:841.890000px;}
    .w0{width:595.276000px;}
    .x0{left:113.386000px;}
    .x1{left:131.319000px;}
    .x5{left:290.988000px;}
    .x4{left:292.338000px;}
    .x3{left:293.688000px;}
    .x2{left:295.038000px;}
    </style>
    <script>
    /*
    Copyright 2012 Mozilla Foundation 
    Copyright 2013 Lu Wang <coolwanglu@gmail.com>
    Apachine License Version 2.0 
    */
    (function(){function b(a,b,e,f){var c=(a.className||"").split(/\s+/g);""===c[0]&&c.shift();var d=c.indexOf(b);0>d&&e&&c.push(b);0<=d&&f&&c.splice(d,1);a.className=c.join(" ");return 0<=d}if(!("classList"in document.createElement("div"))){var e={add:function(a){b(this.element,a,!0,!1)},contains:function(a){return b(this.element,a,!1,!1)},remove:function(a){b(this.element,a,!1,!0)},toggle:function(a){b(this.element,a,!0,!0)}};Object.defineProperty(HTMLElement.prototype,"classList",{get:function(){if(this._classList)return this._classList;
    var a=Object.create(e,{element:{value:this,writable:!1,enumerable:!0}});Object.defineProperty(this,"_classList",{value:a,writable:!1,enumerable:!1});return a},enumerable:!0})}})();
    </script>
    <script>
    /* vim: set shiftwidth=2 tabstop=2 autoindent cindent expandtab filetype=javascript : */
    /** 
    * @license pdf2htmlEX.js: Core UI functions for pdf2htmlEX 
    * Copyright 2012,2013 Lu Wang <coolwanglu@gmail.com> and other contributors 
    * https://github.com/coolwanglu/pdf2htmlEX/blob/master/share/LICENSE 
    */
    
    /*
    * Attention:
    * This files is to be optimized by closure-compiler, 
    * so pay attention to the forms of property names:
    *
    * string/bracket form is safe, won't be optimized:
    * var obj={ 'a':'b' }; obj['a'] = 'b';
    * name/dot form will be optimized, the name is likely to be modified:
    * var obj={ a:'b' }; obj.a = 'b';
    *
    * Either form can be used for internal objects, 
    * but must be consistent for each one respectively.
    *
    * string/bracket form must be used for external objects
    * e.g. DEFAULT_CONFIG, object stored in page-data
    * property names are part of the `protocol` in these cases.
    *
    */
    
    'use strict';
    
    var pdf2htmlEX = window['pdf2htmlEX'] = window['pdf2htmlEX'] || {};
    
    /** 
    * @const 
    * @struct
    */
    var CSS_CLASS_NAMES = {
      page_frame       : 'pf',
      page_content_box : 'pc',
      page_data        : 'pi',
      background_image : 'bi',
      link             : 'l',
      input_radio      : 'ir',
      __dummy__        : 'no comma'
    };
    
    /** 
    * configurations of Viewer
    * @const 
    * @dict
    */
    var DEFAULT_CONFIG = {
      // id of the element to put the pages in
      'container_id' : 'page-container',
      // id of the element for sidebar (to open and close)
      'sidebar_id' : 'sidebar',
      // id of the element for outline
      'outline_id' : 'outline',
      // class for the loading indicator
      'loading_indicator_cls' : 'loading-indicator',
      // How many page shall we preload that are below the last visible page
      'preload_pages' : 3,
      // how many ms should we wait before actually rendering the pages and after a scroll event
      'render_timeout' : 100,
      // zoom ratio step for each zoom in/out event
      'scale_step' : 0.9,
      // register global key handler, allowing navigation by keyboard
      'key_handler' : true,
      // register hashchange handler, navigate to the location specified by the hash
      'hashchange_handler' : true,
      // register view history handler, allowing going back to the previous location
      'view_history_handler' : true,
    
      '__dummy__'        : 'no comma'
    };
    
    /** @const */
    var EPS = 1e-6;
    
    /************************************/
    /* utility function */
    /**
    * @param{Array.<number>} ctm
    */
    function invert(ctm) {
      var det = ctm[0] * ctm[3] - ctm[1] * ctm[2];
      return [ ctm[3] / det
              ,-ctm[1] / det
              ,-ctm[2] / det
              ,ctm[0] / det
              ,(ctm[2] * ctm[5] - ctm[3] * ctm[4]) / det
              ,(ctm[1] * ctm[4] - ctm[0] * ctm[5]) / det
            ];
    };
    /**
    * @param{Array.<number>} ctm
    * @param{Array.<number>} pos
    */
    function transform(ctm, pos) {
      return [ctm[0] * pos[0] + ctm[2] * pos[1] + ctm[4]
            ,ctm[1] * pos[0] + ctm[3] * pos[1] + ctm[5]];
    };
    
    /**
    * @param{Element} ele
    */
    function get_page_number(ele) {
      return parseInt(ele.getAttribute('data-page-no'), 16);
    };
    
    /**
    * @param{NodeList} eles
    */
    function disable_dragstart(eles) {
      for (var i = 0, l = eles.length; i < l; ++i) {
        eles[i].addEventListener('dragstart', function() {
          return false;
        }, false);
      }
    };
    
    /**
    * @param{...Object} var_args
    */
    function clone_and_extend_objs(var_args) {
      var result_obj = {};
      for (var i = 0, l = arguments.length; i < l; ++i) {
        var cur_obj = arguments[i];
        for (var k in cur_obj) {
          if (cur_obj.hasOwnProperty(k)) {
            result_obj[k] = cur_obj[k];
          }
        }
      }
      return result_obj;
    };
    
    /** 
    * @constructor 
    * @param{Element} page The element for the page
    */
    function Page(page) {
      if (!page) return;
    
      this.loaded = false;
      this.shown = false;
      this.page = page; // page frame element
    
      this.num = get_page_number(page);
    
      // page size
      // Need to make rescale work when page_content_box is not loaded, yet
      this.original_height = page.clientHeight;     
      this.original_width = page.clientWidth;
    
      // content box
      var content_box = page.getElementsByClassName(CSS_CLASS_NAMES.page_content_box)[0];
    
      // if page is loaded
      if (content_box) {
        this.content_box = content_box;
        /*
        * scale ratios
        *
        * original_scale : the first one
        * cur_scale : currently using
        */
        this.original_scale = this.cur_scale = this.original_height / content_box.clientHeight;
        this.page_data = JSON.parse(page.getElementsByClassName(CSS_CLASS_NAMES.page_data)[0].getAttribute('data-data'));
    
        this.ctm = this.page_data['ctm'];
        this.ictm = invert(this.ctm);
    
        this.loaded = true;
      }
    };
    Page.prototype = {
      /* hide & show are for contents, the page frame is still there */
      hide : function(){
        if (this.loaded && this.shown) {
          this.content_box.classList.remove('opened');
          this.shown = false;
        }
      },
      show : function(){
        if (this.loaded && !this.shown) {
          this.content_box.classList.add('opened');
          this.shown = true;
        }
      },
      /**
      * @param{number} ratio
      */
      rescale : function(ratio) {
        if (ratio === 0) {
          // reset scale
          this.cur_scale = this.original_scale;
        } else {
          this.cur_scale = ratio;
        }
    
        // scale the content box
        if (this.loaded) {
          var cbs = this.content_box.style;
          cbs.msTransform = cbs.webkitTransform = cbs.transform = 'scale('+this.cur_scale.toFixed(3)+')';
        }
    
        // stretch the page frame to hold the place
        {
          var ps = this.page.style;
          ps.height = (this.original_height * this.cur_scale) + 'px';
          ps.width = (this.original_width * this.cur_scale) + 'px';
        }
      },
      /*
      * return the coordinate of the top-left corner of container
      * in our coordinate system
      * assuming that p.parentNode === p.offsetParent
      */
      view_position : function () {
        var p = this.page;
        var c = p.parentNode;
        return [c.scrollLeft - p.offsetLeft - p.clientLeft
              ,c.scrollTop - p.offsetTop - p.clientTop];
      },
      height : function () {
        return this.page.clientHeight;
      },
      width : function () {
        return this.page.clientWidth;
      }
    };
    
    /** 
    * @constructor
    * @param{Object=} config
    */
    function Viewer(config) {
      this.config = clone_and_extend_objs(DEFAULT_CONFIG, (arguments.length > 0 ? config : {}));
      this.pages_loading = [];
      this.init_before_loading_content();
    
      var self = this;
      document.addEventListener('DOMContentLoaded', function(){
        self.init_after_loading_content();
      }, false);
    };
    
    Viewer.prototype = {
      scale : 1,
      /* 
      * index of the active page (the one with largest visible area)
      * which estimates the page currently being viewed
      */
      cur_page_idx : 0,
    
      /*
      * index of the first visible page
      * used when determining current view
      */
      first_page_idx : 0,
    
      init_before_loading_content : function() {
        /* hide all pages before loading, will reveal only visible ones later */
        this.pre_hide_pages();
      },
    
      initialize_radio_button : function() {
        var elements = document.getElementsByClassName(CSS_CLASS_NAMES.input_radio);
        
        for(var i = 0; i < elements.length; i++) {
          var r = elements[i];
    
          r.addEventListener('click', function() {
            this.classList.toggle("checked");
          });
        }
      },
    
      init_after_loading_content : function() {
        this.sidebar = document.getElementById(this.config['sidebar_id']);
        this.outline = document.getElementById(this.config['outline_id']);
        this.container = document.getElementById(this.config['container_id']);
        this.loading_indicator = document.getElementsByClassName(this.config['loading_indicator_cls'])[0];
    
        
        {
          // Open the outline if nonempty
          var empty = true;
          var nodes = this.outline.childNodes;
          for (var i = 0, l = nodes.length; i < l; ++i) {
            var cur_node = nodes[i];
            if (cur_node.nodeName.toLowerCase() === 'ul') {
              empty = false;
              break;
            }
          }
          if (!empty)
            this.sidebar.classList.add('opened');
        }
    
        this.find_pages();
        // do nothing if there's nothing
        if(this.pages.length == 0) return;
    
        // disable dragging of background images
        disable_dragstart(document.getElementsByClassName(CSS_CLASS_NAMES.background_image));
    
        if (this.config['key_handler'])
          this.register_key_handler();
    
        var self = this;
    
        if (this.config['hashchange_handler']) {
          window.addEventListener('hashchange', function(e) {
            self.navigate_to_dest(document.location.hash.substring(1));
          }, false);
        }
    
        if (this.config['view_history_handler']) {
          window.addEventListener('popstate', function(e) {
            if(e.state) self.navigate_to_dest(e.state);
          }, false);
        }
    
        // register schedule rendering
        // renew old schedules since scroll() may be called frequently
        this.container.addEventListener('scroll', function() {
          self.update_page_idx();
          self.schedule_render(true);
        }, false);
    
        // handle links
        [this.container, this.outline].forEach(function(ele) {
          ele.addEventListener('click', self.link_handler.bind(self), false);
        });
    
        this.initialize_radio_button();
        this.render();
      },
    
      /*
      * set up this.pages and this.page_map
      * pages is an array holding all the Page objects
      * page-Map maps an original page number (in PDF) to the corresponding index in page
      */
      find_pages : function() {
        var new_pages = [];
        var new_page_map = {};
        var nodes = this.container.childNodes;
        for (var i = 0, l = nodes.length; i < l; ++i) {
          var cur_node = nodes[i];
          if ((cur_node.nodeType === Node.ELEMENT_NODE)
              && cur_node.classList.contains(CSS_CLASS_NAMES.page_frame)) {
            var p = new Page(cur_node);
            new_pages.push(p);
            new_page_map[p.num] = new_pages.length - 1;
          }
        }
        this.pages = new_pages;
        this.page_map = new_page_map;
      },
    
      /**
      * @param{number} idx
      * @param{number=} pages_to_preload
      * @param{function(Page)=} callback
      *
      * TODO: remove callback -> promise ?
      */
      load_page : function(idx, pages_to_preload, callback) {
        var pages = this.pages;
        if (idx >= pages.length)
          return;  // Page does not exist
    
        var cur_page = pages[idx];
        if (cur_page.loaded)
          return;  // Page is loaded
    
        if (this.pages_loading[idx])
          return;  // Page is already loading
    
        var cur_page_ele = cur_page.page;
        var url = cur_page_ele.getAttribute('data-page-url');
        if (url) {
          this.pages_loading[idx] = true;       // set semaphore
    
          // add a copy of the loading indicator if not already present
          var new_loading_indicator = cur_page_ele.getElementsByClassName(this.config['loading_indicator_cls'])[0];
          if (typeof new_loading_indicator === 'undefined'){
            new_loading_indicator = this.loading_indicator.cloneNode(true);
            new_loading_indicator.classList.add('active');
            cur_page_ele.appendChild(new_loading_indicator);
          }
    
          // load data
          {
            var self = this;
            var _idx = idx;
            var xhr = new XMLHttpRequest();
            xhr.open('GET', url, true);
            xhr.onload = function(){
              if (xhr.status === 200 || xhr.status === 0) {
                // find the page element in the data
                var div = document.createElement('div');
                div.innerHTML = xhr.responseText;
    
                var new_page = null;
                var nodes = div.childNodes;
                for (var i = 0, l = nodes.length; i < l; ++i) {
                  var cur_node = nodes[i];
                  if ((cur_node.nodeType === Node.ELEMENT_NODE)
                      && cur_node.classList.contains(CSS_CLASS_NAMES.page_frame)) {
                    new_page = cur_node;
                    break;
                  }
                }
    
                // replace the old page with loaded data
                // the loading indicator on this page should also be destroyed
                var p = self.pages[_idx];
                self.container.replaceChild(new_page, p.page);
                p = new Page(new_page);
                self.pages[_idx] = p;
    
                p.hide();
                p.rescale(self.scale);
    
                // disable background image dragging
                disable_dragstart(new_page.getElementsByClassName(CSS_CLASS_NAMES.background_image));
    
                self.schedule_render(false);
    
                if (callback){ callback(p); }
              }
    
              // Reset loading token
              delete self.pages_loading[_idx];
            };
            xhr.send(null);
          }
        }
        // Concurrent prefetch of the next pages
        if (pages_to_preload === undefined)
          pages_to_preload = this.config['preload_pages'];
    
        if (--pages_to_preload > 0) {
          var self = this;
          setTimeout(function() {
            self.load_page(idx+1, pages_to_preload);
          },0);
        }
      },
    
      /*
      * Hide all pages that have no 'opened' class
      * The 'opened' class will be added to visible pages by JavaScript
      * We cannot add this in the default CSS because JavaScript may be disabled
      */
      pre_hide_pages : function() {
        /* pages might have not been loaded yet, so add a CSS rule */
        var s = '@media screen{.'+CSS_CLASS_NAMES.page_content_box+'{display:none;}}';
        var n = document.createElement('style');
        if (n.styleSheet) {
          n.styleSheet.cssText = s;
        } else {
          n.appendChild(document.createTextNode(s));
        }
        document.head.appendChild(n);
      },
    
      /*
      * show visible pages and hide invisible pages
      */
      render : function () {
        var container = this.container;
        /* 
        * show the pages that are 'nearly' visible -- it's right above or below the container
        *
        * all the y values are in the all-page element's coordinate system
        */
        var container_min_y = container.scrollTop;
        var container_height = container.clientHeight;
        var container_max_y = container_min_y + container_height;
        var visible_min_y = container_min_y - container_height;
        var visible_max_y = container_max_y + container_height;
    
        var cur_page_fully_visible = false;
        var cur_page_idx = this.cur_page_idx;
        var max_visible_page_idx = cur_page_idx;
        var max_visible_ratio = 0.0;
    
        var pl = this.pages;
        for (var i = 0, l = pl.length; i < l; ++i) {
          var cur_page = pl[i];
          var cur_page_ele = cur_page.page;
          var page_min_y = cur_page_ele.offsetTop + cur_page_ele.clientTop;
          var page_height = cur_page_ele.clientHeight;
          var page_max_y = page_min_y + page_height;
          if ((page_min_y <= visible_max_y) && (page_max_y >= visible_min_y))
          {
            // cur_page is 'nearly' visible, show it or load it
            if (cur_page.loaded) {
              cur_page.show();
            } else {
              this.load_page(i);
            }
          } else {
            cur_page.hide();
          }
        }
      },
      /*
      * update cur_page_idx and first_page_idx
      * normally called upon scrolling
      */
      update_page_idx: function () {
        var pages = this.pages;
        var pages_len = pages.length;
        // there is no chance that cur_page_idx or first_page_idx is modified
        if (pages_len < 2) return;
      
        var container = this.container;
        var container_min_y = container.scrollTop;
        var container_max_y = container_min_y + container.clientHeight;
    
        // binary search for the first page
        // whose bottom border is below the top border of the container
        var first_idx = -1;
        var last_idx = pages_len;
        var rest_len = last_idx - first_idx;
        // TODO: use current first_page_idx as a hint?
        while(rest_len > 1) {
          var idx = first_idx + Math.floor(rest_len / 2);
          var cur_page_ele = pages[idx].page;
          if (cur_page_ele.offsetTop + cur_page_ele.clientTop + cur_page_ele.clientHeight >= container_min_y) {
            last_idx = idx;
          } else {
            first_idx = idx;
          }
          rest_len = last_idx - first_idx;
        }
        
        /*
        * with malformed settings it is possible that no page is visible, e.g.
        * - the container is to thin, which lies in the margin between two pages
        * - all pages are completely above or below the container
        * but we just assume that they won't happen.
        */
        this.first_page_idx = last_idx;
    
        // find the page with largest visible area
        var cur_page_idx = this.cur_page_idx;
        var max_visible_page_idx = cur_page_idx;
        var max_visible_ratio = 0.0;
    
        for(var i = last_idx; i < pages_len; ++i) {
          var cur_page_ele = pages[i].page;
          var page_min_y = cur_page_ele.offsetTop + cur_page_ele.clientTop;
          var page_height = cur_page_ele.clientHeight;
          var page_max_y = page_min_y + page_height;
          if (page_min_y > container_max_y) break;
    
          // check the visible fraction of the page
          var page_visible_ratio = ( Math.min(container_max_y, page_max_y) 
                                    - Math.max(container_min_y, page_min_y)
                                  ) / page_height;
    
          // stay with the current page if it is still fully visible
          if ((i === cur_page_idx) && (Math.abs(page_visible_ratio - 1.0) <= EPS)) {
            max_visible_page_idx = cur_page_idx;
            break;
          }
    
          if (page_visible_ratio > max_visible_ratio) {
            max_visible_ratio = page_visible_ratio;
            max_visible_page_idx = i;
          }
        }
    
        this.cur_page_idx = max_visible_page_idx;
      },
    
      /**
      * @param{boolean} renew renew the existing schedule instead of using the old one
      */
      schedule_render : function(renew) {
        if (this.render_timer !== undefined) {
          if (!renew) return;
          clearTimeout(this.render_timer);
        }
    
        var self = this;
        this.render_timer = setTimeout(function () {
          /*
          * render() may trigger load_page(), which may in turn trigger another render()
          * so delete render_timer first
          */
          delete self.render_timer;
          self.render();
        }, this.config['render_timeout']);
      },
    
      /*
      * Handling key events, zooming, scrolling etc.
      */
      register_key_handler: function () {
        /* 
        * When user try to zoom in/out using ctrl + +/- or mouse wheel
        * handle this and prevent the default behaviours
        *
        * Code credit to PDF.js
        */
        var self = this;
    
        // Firefox specific event, so that we can prevent browser from zooming
        window.addEventListener('DOMMouseScroll', function(e) {
          if (e.ctrlKey) {
            e.preventDefault();
            var container = self.container;
            var rect = container.getBoundingClientRect();
            var fixed_point = [e.clientX - rect['left'] - container.clientLeft
                              ,e.clientY - rect['top'] - container.clientTop];
            self.rescale(Math.pow(self.config['scale_step'], e.detail), true, fixed_point);
          }
        }, false);
    
        window.addEventListener('keydown', function(e) {
          var handled = false;
          /*
          var cmd = (e.ctrlKey ? 1 : 0)
                    | (e.altKey ? 2 : 0)
                    | (e.shiftKey ? 4 : 0)
                    | (e.metaKey ? 8 : 0)
                    ;
                    */
          var with_ctrl = e.ctrlKey || e.metaKey;
          var with_alt = e.altKey;
          switch (e.keyCode) {
            case 61: // FF/Mac '='
            case 107: // FF '+' and '='
            case 187: // Chrome '+'
              if (with_ctrl){
                self.rescale(1.0 / self.config['scale_step'], true);
                handled = true;
              }
              break;
            case 173: // FF/Mac '-'
            case 109: // FF '-'
            case 189: // Chrome '-'
              if (with_ctrl){
                self.rescale(self.config['scale_step'], true);
                handled = true;
              }
              break;
            case 48: // '0'
              if (with_ctrl){
                self.rescale(0, false);
                handled = true;
              }
              break;
            case 33: // Page UP:
              if (with_alt) { // alt-pageup    -> scroll one page up
                self.scroll_to(self.cur_page_idx - 1);
              } else { // pageup        -> scroll one screen up
                self.container.scrollTop -= self.container.clientHeight;
              }
              handled = true;
              break;
            case 34: // Page DOWN
              if (with_alt) { // alt-pagedown  -> scroll one page down
                self.scroll_to(self.cur_page_idx + 1);
              } else { // pagedown      -> scroll one screen down
                self.container.scrollTop += self.container.clientHeight;
              }
              handled = true;
              break;
            case 35: // End
              self.container.scrollTop = self.container.scrollHeight;
              handled = true;
              break;
            case 36: // Home
              self.container.scrollTop = 0;
              handled = true;
              break;
          }
          if (handled) {
            e.preventDefault();
            return;
          }
        }, false);
      },
    
      /**
      * @param{number} ratio
      * @param{boolean} is_relative
      * @param{Array.<number>=} fixed_point preserve the position (relative to the top-left corner of the viewer) after rescaling
      */
      rescale : function (ratio, is_relative, fixed_point) {
        var old_scale = this.scale;
        var new_scale = old_scale;
        // set new scale
        if (ratio === 0) {
          new_scale = 1;
          is_relative = false;
        } else if (is_relative)
          new_scale *= ratio;
        else
          new_scale = ratio;
    
        this.scale = new_scale;
    
        if (!fixed_point)
          fixed_point = [0,0];
    
        // translate fixed_point to the coordinate system of all pages
        var container = this.container;
        fixed_point[0] += container.scrollLeft;
        fixed_point[1] += container.scrollTop;
    
        // find the visible page that contains the fixed point
        // if the fixed point lies between two pages (including their borders), it's contained in the first one
        var pl = this.pages;
        var pl_len = pl.length;
        for (var i = this.first_page_idx; i < pl_len; ++i) {
          var p = pl[i].page;
          if (p.offsetTop + p.clientTop >= fixed_point[1])
            break;
        }
        var fixed_point_page_idx = i - 1;
    
        // determine the new scroll position
        // each-value consists of two parts, one inside the page, which is affected by rescaling,
        // the other is outside, (e.g. borders and margins), which is not affected
    
        // if the fixed_point is above the first page, use the first page as the reference
        if (fixed_point_page_idx < 0) 
          fixed_point_page_idx = 0;
    
        var fp_p = pl[fixed_point_page_idx].page;
        var fp_p_width = fp_p.clientWidth;
        var fp_p_height = fp_p.clientHeight;
    
        var fp_x_ref = fp_p.offsetLeft + fp_p.clientLeft;
        var fp_x_inside = fixed_point[0] - fp_x_ref;
        if (fp_x_inside < 0)
          fp_x_inside = 0;
        else if (fp_x_inside > fp_p_width)
          fp_x_inside = fp_p_width;
    
        var fp_y_ref = fp_p.offsetTop + fp_p.clientTop;
        var fp_y_inside = fixed_point[1] - fp_y_ref;
        if (fp_y_inside < 0)
          fp_y_inside = 0;
        else if (fp_y_inside > fp_p_height)
          fp_y_inside = fp_p_height;
    
        // Rescale pages
        for (var i = 0; i < pl_len; ++i) 
            pl[i].rescale(new_scale);  
    
        // Correct container scroll to keep view aligned while zooming
        container.scrollLeft += fp_x_inside / old_scale * new_scale + fp_p.offsetLeft + fp_p.clientLeft - fp_x_inside - fp_x_ref;
        container.scrollTop += fp_y_inside / old_scale * new_scale + fp_p.offsetTop + fp_p.clientTop - fp_y_inside - fp_y_ref;
    
        // some pages' visibility may be toggled, wait for next render()
        // renew old schedules since rescale() may be called frequently
        this.schedule_render(true);
      },
    
      fit_width : function () {
        var page_idx = this.cur_page_idx;
        this.rescale(this.container.clientWidth / this.pages[page_idx].width(), true);
        this.scroll_to(page_idx);
      },
    
      fit_height : function () {
        var page_idx = this.cur_page_idx;
        this.rescale(this.container.clientHeight / this.pages[page_idx].height(), true);
        this.scroll_to(page_idx);
      },
      /**
      * @param{Node} ele
      */
      get_containing_page : function(ele) {
        /* get the page obj containing obj */
        while(ele) {
          if ((ele.nodeType === Node.ELEMENT_NODE)
              && ele.classList.contains(CSS_CLASS_NAMES.page_frame)) {
            /*
            * Get original page number and map it to index of pages
            * TODO: store the index on the dom element
            */
            var pn = get_page_number(/** @type{Element} */(ele));
            var pm = this.page_map;
            return (pn in pm) ? this.pages[pm[pn]] : null;
          }
          ele = ele.parentNode;
        }
        return null;
      },
    
      /**
      * @param{Event} e
      */
      link_handler : function (e) {
        var target = /** @type{Node} */(e.target);
        var detail_str = /** @type{string} */ (target.getAttribute('data-dest-detail'));
        if (!detail_str) return;
    
        if (this.config['view_history_handler']) {
          try {
            var cur_hash = this.get_current_view_hash();
            window.history.replaceState(cur_hash, '', '#' + cur_hash);
            window.history.pushState(detail_str, '', '#' + detail_str);
          } catch(ex) { }
        }
        this.navigate_to_dest(detail_str, this.get_containing_page(target));
        e.preventDefault();
      },
    
      /**
      * @param{string} detail_str may come from user provided hashtag, need sanitzing
      * @param{Page=} src_page page containing the source event (e.g. link)
      */
      navigate_to_dest : function(detail_str, src_page) {
        try {
          var detail = JSON.parse(detail_str);
        } catch(e) {
          return;
        }
    
        if(!(detail instanceof Array)) return;
    
        var target_page_no = detail[0];
        var page_map = this.page_map;
        if (!(target_page_no in page_map)) return;
        var target_page_idx = page_map[target_page_no];
        var target_page = this.pages[target_page_idx];
    
        for (var i = 2, l = detail.length; i < l; ++i) {
          var d = detail[i];
          if(!((d === null) || (typeof d === 'number')))
            return;
        }
    
        while(detail.length < 6)
          detail.push(null);
    
        // cur_page might be undefined, e.g. from Outline
        var cur_page = src_page || this.pages[this.cur_page_idx];
    
        var cur_pos = cur_page.view_position();
        cur_pos = transform(cur_page.ictm, [cur_pos[0], cur_page.height()-cur_pos[1]]);
    
        var zoom = this.scale;
        var pos = [0,0];
        var upside_down = true;
        var ok = false;
    
        // position specified in `detail` are in the raw coordinate system of the page (unscaled)
        var scale = this.scale;
        // TODO: fitb*
        // TODO: BBox
        switch(detail[1]) {
          case 'XYZ':
            pos = [ (detail[2] === null) ? cur_pos[0] : detail[2] * scale
                  , (detail[3] === null) ? cur_pos[1] : detail[3] * scale ];
            zoom = detail[4];
            if ((zoom === null) || (zoom === 0))
              zoom = this.scale;
            ok = true;
            break;
          case 'Fit':
          case 'FitB':
            pos = [0,0];
            ok = true;
            break;
          case 'FitH':
          case 'FitBH':
            pos = [0, (detail[2] === null) ? cur_pos[1] : detail[2] * scale];
            ok = true;
            break;
          case 'FitV':
          case 'FitBV':
            pos = [(detail[2] === null) ? cur_pos[0] : detail[2] * scale, 0];
            ok = true;
            break;
          case 'FitR':
            /* locate the top-left corner of the rectangle */
            // TODO
            pos = [detail[2] * scale, detail[5] * scale];
            upside_down = false;
            ok = true;
            break;
          default:
            break;
        }
    
        if (!ok) return;
    
        this.rescale(zoom, false);
    
        var self = this;
        /**
        * page should of type Page 
        * @param{Page} page 
        */
        var transform_and_scroll = function(page) {
          pos = transform(page.ctm, pos);
          if (upside_down) {
            pos[1] = page.height() - pos[1];
          }
          self.scroll_to(target_page_idx, pos);
        };
    
        if (target_page.loaded) {
          transform_and_scroll(target_page);
        } else {
          // TODO: scroll_to may finish before load_page
    
          // Scroll to the exact position once loaded.
          this.load_page(target_page_idx, undefined, transform_and_scroll);
    
          // In the meantime page gets loaded, scroll approximately position for maximum responsiveness.
          this.scroll_to(target_page_idx);
        }
      }, 
    
      /**
      * @param{number} page_idx
      * @param{Array.<number>=} pos [x,y] where (0,0) is the top-left corner
      */
      scroll_to : function(page_idx, pos) {
        var pl = this.pages;
        if ((page_idx < 0) || (page_idx >= pl.length)) return;
        var target_page = pl[page_idx];
        var cur_target_pos = target_page.view_position();
    
        if (pos === undefined)
          pos = [0,0];
    
        var container = this.container;
        container.scrollLeft += pos[0] - cur_target_pos[0];
        container.scrollTop += pos[1] - cur_target_pos[1];
      },
    
      /**
      * generate the hash for the current view
      */
      get_current_view_hash : function() {
        var detail = [];
        var cur_page = this.pages[this.cur_page_idx];
    
        detail.push(cur_page.num);
        detail.push('XYZ');
    
        var cur_pos = cur_page.view_position();
        cur_pos = transform(cur_page.ictm, [cur_pos[0], cur_page.height()-cur_pos[1]]);
        detail.push(cur_pos[0] / this.scale);
        detail.push(cur_pos[1] / this.scale);
        
        detail.push(this.scale);
    
        return JSON.stringify(detail);
      }
    };
    
    // export pdf2htmlEX.Viewer
    pdf2htmlEX['Viewer'] = Viewer;
    </script>
    <script>
    try{
    pdf2htmlEX.defaultViewer = new pdf2htmlEX.Viewer({});
    }catch(e){}
    </script>
    
  </head>
  <body>
    <div class="row">
      <div class="span12">
        <h3><a href="/">Home</a> 
          >> <a href="/#writing">Writing</a> 
          >> 
        </h3>
        <h1>The Developing Mind: A Philosophical Introduction (2020)</h1>
        <p>by Stephen A. Butterfill<br/>--- London: Routledge <a href="https://www.routledge.com/The-Developing-Mind-A-Philosophical-Introduction/Butterfill/p/book/9780415566230" target="_blank">[publisher's page]</a><br/>--- links: <a href="/pdf/developing_mind_contents.pdf">contents [pdf]</a>; <a href="/pdf/developing_mind_introduction.pdf">introduction [pdf]</a></p>
        <div style="position:relative">
          <div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><div class="t m0 x0 h1 y0 ff1 fs0 fc0 sc0 ls2">Contents</div><div class="t m0 x0 h2 y1 ff2 fs1 fc0 sc0 ls2 ws0">Preface xi</div><div class="t m0 x0 h2 y2 ff2 fs1 fc0 sc0 ls2 ws1">1 Introduction<span class="_ _0"> </span>1</div><div class="t m0 x1 h3 y3 ff1 fs1 fc0 sc0 ls0 ws2">1<span class="_ _1"></span>.<span class="_ _1"></span>1 T<span class="_ _2"></span>w<span class="_ _1"></span>o<span class="_ _3"></span>B<span class="_ _1"></span>r<span class="_ _1"></span>e<span class="_ _1"></span>a<span class="_ _1"></span>k<span class="_ _1"></span>t<span class="_ _1"></span>h<span class="_ _1"></span>r<span class="_ _1"></span>o<span class="_ _1"></span>u<span class="_ _1"></span>g<span class="_ _1"></span>h<span class="_ _1"></span>s<span class="_ _4"></span>.......................<span class="_ _5"> </span>2<span class="_ _1"></span></div><div class="t m0 x1 h3 y4 ff1 fs1 fc0 sc0 ls0 ws2">1<span class="_ _1"></span>.<span class="_ _1"></span>2 K<span class="_ _1"></span>n<span class="_ _1"></span>o<span class="_ _1"></span>w<span class="_ _1"></span>l<span class="_ _1"></span>e<span class="_ _1"></span>d<span class="_ _1"></span>g<span class="_ _1"></span>e............................<span class="_ _5"> </span>3<span class="_ _1"></span></div><div class="t m0 x1 h3 y5 ff1 fs1 fc0 sc0 ls2 ws3">1.3<span class="_ _6"> </span>A<span class="_ _7"> </span>Crude<span class="_ _7"> </span>Picture<span class="_ _7"> </span>of<span class="_ _7"> </span>the<span class="_ _7"> </span>Mind<span class="_ _8"> </span>. . . . . . . . . . . . . . . . . .<span class="_ _9"> </span>4</div><div class="t m0 x1 h3 y6 ff1 fs1 fc0 sc0 ls0 ws2">1<span class="_ _1"></span>.<span class="_ _1"></span>4 C<span class="_ _1"></span>o<span class="_ _1"></span>r<span class="_ _1"></span>e<span class="_ _3"></span>K<span class="_ _1"></span>n<span class="_ _1"></span>o<span class="_ _1"></span>w<span class="_ _1"></span>l<span class="_ _1"></span>e<span class="_ _1"></span>d<span class="_ _1"></span>g<span class="_ _1"></span>e<span class="_ _a"></span>.........................<span class="_ _5"> </span>5<span class="_ _1"></span></div><div class="t m0 x1 h3 y7 ff1 fs1 fc0 sc0 ls0 ws2">1<span class="_ _1"></span>.<span class="_ _1"></span>5 T<span class="_ _2"></span>w<span class="_ _1"></span>o<span class="_ _3"></span>S<span class="_ _1"></span>t<span class="_ _1"></span>o<span class="_ _1"></span>r<span class="_ _1"></span>i<span class="_ _1"></span>e<span class="_ _1"></span>s<span class="_ _b"></span>............................<span class="_ _c"> </span>7<span class="_ _1"></span></div><div class="t m0 x1 h3 y8 ff1 fs1 fc0 sc0 ls2 ws3">1.6<span class="_ _6"> </span>Development<span class="_ _7"> </span>Is<span class="_ _7"> </span>Rediscov<span class="_ _d"></span>ery<span class="_ _e"> </span>. . . . . . . . . . . . . . . . . .<span class="_ _f"> </span>8</div><div class="t m0 x0 h4 y9 ff2 fs2 fc0 sc0 ls2 ws4">I<span class="_ _10"> </span>Physical Obje<span class="_ _11"></span>cts<span class="_ _12"> </span>11</div><div class="t m0 x0 h2 ya ff2 fs1 fc0 sc0 ls2 ws5">2<span class="_ _13"> </span>Principles of Object Perception<span class="_ _14"> </span>13</div><div class="t m0 x1 h3 yb ff1 fs1 fc0 sc0 ls2 ws3">2.1<span class="_ _6"> </span>Knowledge<span class="_ _7"> </span>of<span class="_ _7"> </span>Objects<span class="_ _7"> </span>Involves<span class="_ _7"> </span>Three<span class="_ _7"> </span>Abilities<span class="_ _15"> </span>. . . . . . . .<span class="_ _c"> </span>13</div><div class="t m0 x1 h3 yc ff1 fs1 fc0 sc0 ls0 ws6">2<span class="_ _1"></span>.<span class="_ _1"></span>2<span class="_ _8"> </span>S<span class="_ _1"></span>e<span class="_ _1"></span>g<span class="_ _1"></span>m<span class="_ _1"></span>e<span class="_ _1"></span>n<span class="_ _1"></span>t<span class="_ _1"></span>a<span class="_ _1"></span>t<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n ..........................<span class="_ _16"> </span>1<span class="_ _1"></span>5<span class="_ _1"></span></div><div class="t m0 x1 h3 yd ff1 fs1 fc0 sc0 ls2 ws3">2.3<span class="_ _6"> </span>Principles<span class="_ _7"> </span>of<span class="_ _7"> </span>Object<span class="_ _7"> </span>Perception<span class="_ _17"> </span>. . . . . . . . . . . . . . . . .<span class="_ _c"> </span>20</div><div class="t m0 x1 h3 ye ff1 fs1 fc0 sc0 ls0 ws2">2<span class="_ _1"></span>.<span class="_ _1"></span>4 C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>l<span class="_ _1"></span>u<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _d"></span>............................<span class="_ _16"> </span>2<span class="_ _1"></span>3<span class="_ _1"></span></div><div class="t m0 x0 h2 yf ff2 fs1 fc0 sc0 ls1">3<span class="ff3 ls2">�<span class="ff2 ws5">e Simple View<span class="_ _18"> </span>25</span></span></div><div class="t m0 x1 h3 y10 ff1 fs1 fc0 sc0 ls0 ws2">3<span class="_ _1"></span>.<span class="_ _1"></span>1 T<span class="_ _1"></span>h<span class="_ _1"></span>e<span class="_ _3"></span>S<span class="_ _1"></span>i<span class="_ _1"></span>m<span class="_ _1"></span>p<span class="_ _1"></span>l<span class="_ _1"></span>e<span class="_ _3"></span>V<span class="_ _1"></span>i<span class="_ _1"></span>e<span class="_ _1"></span>w<span class="_ _19"></span>.........................<span class="_ _16"> </span>2<span class="_ _1"></span>5<span class="_ _1"></span></div><div class="t m0 x1 h3 y11 ff1 fs1 fc0 sc0 ls0 ws2">3<span class="_ _1"></span>.<span class="_ _1"></span>2 P<span class="_ _1"></span>e<span class="_ _1"></span>r<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>s<span class="_ _1"></span>t<span class="_ _1"></span>e<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>e............................<span class="_ _1a"> </span>2<span class="_ _1"></span>7<span class="_ _1"></span></div><div class="t m0 x1 h3 y12 ff1 fs1 fc0 sc0 ls2 ws3">3.3<span class="_ _6"> </span>Extending<span class="_ _7"> </span>the<span class="_ _7"> </span>Simple<span class="_ _7"> </span>View<span class="_ _7"> </span>to<span class="_ _7"> </span>Persistence<span class="_ _1b"> </span>. . . . . . . . . . .<span class="_ _c"> </span>32</div><div class="t m0 x1 h3 y13 ff1 fs1 fc0 sc0 ls2 ws3">3.4<span class="_ _6"> </span>Causal<span class="_ _7"> </span>Interactions<span class="_ _16"> </span>. . . . . . . . . . . . . . . . . . . . . . .<span class="_ _c"> </span>34</div><div class="t m0 x1 h3 y14 ff1 fs1 fc0 sc0 ls2 ws3">3.5<span class="_ _6"> </span>The<span class="_ _7"> </span>Case<span class="_ _7"> </span>for<span class="_ _7"> </span>the<span class="_ _7"> </span>Simple<span class="_ _7"> </span>View<span class="_ _1a"> </span>. . . . . . . . . . . . . . . . .<span class="_ _c"> </span>36</div><div class="t m0 x0 h2 y15 ff2 fs1 fc0 sc0 ls1">4<span class="ff3 ls2">�<span class="ff2 ws5">e Linking Problem<span class="_ _1c"> </span>41</span></span></div><div class="t m0 x1 h3 y16 ff1 fs1 fc0 sc0 ls2 ws3">4.1<span class="_ _6"> </span>Against<span class="_ _7"> </span>the<span class="_ _7"> </span>Simple<span class="_ _7"> </span>View<span class="_ _1d"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _c"> </span>42</div><div class="t m0 x1 h3 y17 ff1 fs1 fc0 sc0 ls2 ws3">4.2<span class="_ _6"> </span>Further<span class="_ _7"> </span>Evidence<span class="_ _7"> </span>Against<span class="_ _7"> </span>the<span class="_ _7"> </span>Simple<span class="_ _7"> </span>View<span class="_ _8"> </span>. . . . . . . . . .<span class="_ _1e"> </span>46</div><div class="t m0 x1 h3 y18 ff1 fs1 fc0 sc0 ls2 ws3">4.3<span class="_ _6"> </span>Things<span class="_ _7"> </span>Get<span class="_ _7"> </span>Even<span class="_ _7"> </span>W<span class="_ _1f"></span>orse<span class="_ _7"> </span>for<span class="_ _7"> </span>the<span class="_ _7"> </span>Simple<span class="_ _7"> </span>View<span class="_ _1d"> </span>. . . . . . . . .<span class="_ _c"> </span>48</div><div class="t m0 x1 h3 y19 ff1 fs1 fc0 sc0 ls2 ws3">4.4<span class="_ _6"> </span>The<span class="_ _7"> </span>Linking<span class="_ _7"> </span>Problem<span class="_ _1d"> </span>. . . . . . . . . . . . . . . . . . . . . .<span class="_ _1e"> </span>50</div><div class="t m0 x1 h3 y1a ff1 fs1 fc0 sc0 ls2 ws3">4.5<span class="_ _6"> </span>Representation<span class="_ _7"> </span>Not<span class="_ _7"> </span>Knowledge<span class="_ _20"> </span>. . . . . . . . . . . . . . . .<span class="_ _1e"> </span>51</div><div class="t m0 x1 h3 y1b ff1 fs1 fc0 sc0 ls2 ws3">4.6<span class="_ _6"> </span>Graded<span class="_ _7"> </span>Representations?<span class="_ _8"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _5"> </span>53</div><div class="t m0 x2 h5 y1c ff1 fs3 fc0 sc0 ls2">v</div><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:593.008000px;width:42.221000px;height:10.516000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:565.895000px;width:89.038000px;height:10.630000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:548.472000px;width:126.207000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:533.667000px;width:84.412000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:521.516000px;width:168.385000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:504.058000px;width:110.845000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:491.907000px;width:87.185000px;height:10.032000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:474.448000px;width:168.373000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:432.024000px;width:127.908000px;height:15.421000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:405.481000px;width:188.038000px;height:13.273000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:390.701000px;width:256.076000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:375.896000px;width:96.642000px;height:12.686000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:361.091000px;width:180.758000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:348.940000px;width:84.747000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:319.263000px;width:109.971000px;height:13.272000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:304.482000px;width:112.793000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:292.331000px;width:84.376000px;height:10.033000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:274.872000px;width:232.955000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:262.722000px;width:123.661000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:245.263000px;width:174.685000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:218.240000px;width:134.192000px;height:13.272000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:203.459000px;width:150.189000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:188.654000px;width:236.936000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:173.849000px;width:245.017000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:159.044000px;width:132.914000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:144.239000px;width:182.061000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:129.435000px;width:151.480000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
          <div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><div class="t m0 x1 h3 y1d ff1 fs1 fc0 sc0 ls0 ws2">4<span class="_ _1"></span>.<span class="_ _1"></span>7 C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>l<span class="_ _1"></span>u<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _d"></span>............................<span class="_ _16"> </span>5<span class="_ _1"></span>5<span class="_ _1"></span></div><div class="t m0 x0 h2 y1e ff2 fs1 fc0 sc0 ls2 ws5">5<span class="_ _13"> </span>Core Knowledge<span class="_ _21"> </span>57</div><div class="t m0 x1 h3 y1f ff1 fs1 fc0 sc0 ls2 ws3">5.1<span class="_ _6"> </span>What<span class="_ _7"> </span>Is<span class="_ _7"> </span>Core<span class="_ _7"> </span>Knowledge?<span class="_ _1a"> </span>. . . . . . . . . . . . . . . . . . .<span class="_ _c"> </span>58</div><div class="t m0 x1 h3 y20 ff1 fs1 fc0 sc0 ls2 ws5">5.2<span class="_ _6"> </span>Can Core Knowledge Solve the Linking Pr<span class="_ _d"></span>oblem?<span class="_ _1d"> </span>.<span class="_ _22"> </span>.<span class="_ _22"> </span>.<span class="_ _22"> </span>.<span class="_ _22"> </span>.<span class="_ _22"> </span>.<span class="_ _c"> </span>60</div><div class="t m0 x1 h3 y21 ff1 fs1 fc0 sc0 ls2 ws5">5.3<span class="_ _6"> </span>How Not to De<span class="ff4"></span><span class="ls0 ws8">n<span class="_ _1"></span>e<span class="_ _3"></span>S<span class="_ _1"></span>o<span class="_ _1"></span>m<span class="_ _1"></span>e<span class="_ _1"></span>t<span class="_ _1"></span>h<span class="_ _1"></span>i<span class="_ _1"></span>n<span class="_ _1"></span>g<span class="_ _23"></span>................. 6<span class="_ _1"></span>2<span class="_ _1"></span></span></div><div class="t m0 x1 h3 y22 ff1 fs1 fc0 sc0 ls2 ws3">5.4<span class="_ _6"> </span>Will<span class="_ _7"> </span>Invoking<span class="_ _7"> </span>Modularity<span class="_ _7"> </span>Help?<span class="_ _24"> </span>. . . . . . . . . . . . . . . .<span class="_ _c"> </span>63</div><div class="t m0 x1 h3 y23 ff1 fs1 fc0 sc0 ls0 ws2">5<span class="_ _1"></span>.<span class="_ _1"></span>5 C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>l<span class="_ _1"></span>u<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _d"></span>............................<span class="_ _1a"> </span>6<span class="_ _1"></span>4<span class="_ _1"></span></div><div class="t m0 x0 h2 y24 ff2 fs1 fc0 sc0 ls2 ws5">6<span class="_ _13"> </span>Object Indexes and Motor Representations of Objects<span class="_ _25"> </span>67</div><div class="t m0 x1 h3 y25 ff1 fs1 fc0 sc0 ls2 ws3">6.1<span class="_ _6"> </span>Object<span class="_ _7"> </span>Indexes<span class="_ _7"> </span>in<span class="_ _7"> </span>Adult<span class="_ _7"> </span>Humans<span class="_ _26"> </span>. . . . . . . . . . . . . . . .<span class="_ _c"> </span>68</div><div class="t m0 x1 h3 y26 ff1 fs1 fc0 sc0 ls2 ws5">6.2<span class="_ _6"> </span>Object Indexes and the Principles of Object Perception<span class="_ _1a"> </span>.<span class="_ _22"> </span>.<span class="_ _22"> </span>.<span class="_ _c"> </span>70</div><div class="t m0 x1 h3 y27 ff1 fs1 fc0 sc0 ls2 ws3">6.3<span class="_ _6"> </span>The<span class="_ _7"> </span>CLSTX<span class="_ _7"> </span>Conjecture<span class="_ _27"> </span>. . . . . . . . . . . . . . . . . . . . .<span class="_ _1e"> </span>74</div><div class="t m0 x1 h3 y28 ff1 fs1 fc0 sc0 ls0 ws2">6<span class="_ _1"></span>.<span class="_ _1"></span>4 S<span class="_ _1"></span>i<span class="_ _1"></span>g<span class="_ _1"></span>n<span class="_ _1"></span>a<span class="_ _1"></span>t<span class="_ _1"></span>u<span class="_ _1"></span>r<span class="_ _1"></span>e<span class="_ _3"></span>L<span class="_ _1"></span>i<span class="_ _1"></span>m<span class="_ _1"></span>i<span class="_ _1"></span>t<span class="_ _1"></span>s<span class="_ _11"></span>.........................<span class="_ _16"> </span>7<span class="_ _1"></span>5<span class="_ _1"></span></div><div class="t m0 x1 h3 y29 ff1 fs1 fc0 sc0 ls2 ws3">6.5<span class="_ _6"> </span>Knowledge<span class="_ _7"> </span>or<span class="_ _7"> </span>Core<span class="_ _7"> </span>Knowledge<span class="_ _7"> </span>or<span class="_ _7"> </span>…?<span class="_ _15"> </span>. . . . . . . . . . . . .<span class="_ _1e"> </span>79</div><div class="t m0 x1 h3 y2a ff1 fs1 fc0 sc0 ls2 ws3">6.6<span class="_ _6"> </span>Against<span class="_ _7"> </span>the<span class="_ _7"> </span>CLSTX<span class="_ _7"> </span>Conjecture<span class="_ _17"> </span>. . . . . . . . . . . . . . . . .<span class="_ _1e"> </span>80</div><div class="t m0 x1 h3 y2b ff1 fs1 fc0 sc0 ls2 ws3">6.7<span class="_ _6"> </span>Motor<span class="_ _7"> </span>Representations<span class="_ _7"> </span>of<span class="_ _7"> </span>Objects<span class="_ _28"> </span>. . . . . . . . . . . . . . .<span class="_ _1e"> </span>81</div><div class="t m0 x1 h3 y2c ff1 fs1 fc0 sc0 ls0 ws2">6<span class="_ _1"></span>.<span class="_ _1"></span>8 C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>j<span class="_ _1"></span>e<span class="_ _1"></span>c<span class="_ _1"></span>t<span class="_ _1"></span>u<span class="_ _1"></span>r<span class="_ _1"></span>e<span class="_ _3"></span>O<span class="_ _29"></span>...........................<span class="_ _16"> </span>8<span class="_ _1"></span>3<span class="_ _1"></span></div><div class="t m0 x1 h3 y2d ff1 fs1 fc0 sc0 ls2 ws3">6.9<span class="_ _6"> </span>Conclusion:<span class="_ _1b"> </span>Paradox<span class="_ _7"> </span>Lost<span class="_ _17"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _1e"> </span>86</div><div class="t m0 x0 h2 y2e ff2 fs1 fc0 sc0 ls2 ws5">7<span class="_ _13"> </span>Metacognitive Feelings<span class="_ _2a"> </span>89</div><div class="t m0 x1 h3 y2f ff1 fs1 fc0 sc0 ls2 ws3">7.1<span class="_ _6"> </span>Objection<span class="_ _7"> </span>to<span class="_ _7"> </span>Conjecture<span class="_ _7"> </span>O<span class="_ _16"> </span>. . . . . . . . . . . . . . . . . . .<span class="_ _c"> </span>89</div><div class="t m0 x1 h3 y30 ff1 fs1 fc0 sc0 ls2 ws3">7.2<span class="_ _6"> </span>Metacognitive<span class="_ _7"> </span>Feelings:<span class="_ _1b"> </span>A<span class="_ _7"> </span>First<span class="_ _7"> </span>Example<span class="_ _2b"> </span>. . . . . . . . . . .<span class="_ _1e"> </span>91</div><div class="t m0 x1 h3 y31 ff1 fs1 fc0 sc0 ls2 ws3">7.3<span class="_ _6"> </span>More<span class="_ _7"> </span>Metacognitive<span class="_ _7"> </span>Feelings<span class="_ _2c"> </span>. . . . . . . . . . . . . . . . . .<span class="_ _c"> </span>92</div><div class="t m0 x1 h3 y32 ff1 fs1 fc0 sc0 ls2 ws3">7.4<span class="_ _6"> </span>What<span class="_ _7"> </span>Is<span class="_ _7"> </span>a<span class="_ _7"> </span>Metacognitive<span class="_ _7"> </span>Feeling?<span class="_ _2b"> </span>. . . . . . . . . . . . . . .<span class="_ _1e"> </span>94</div><div class="t m0 x1 h3 y33 ff1 fs1 fc0 sc0 ls2 ws3">7.5<span class="_ _6"> </span>A<span class="_ _7"> </span>Metacognitive<span class="_ _7"> </span>Feeling<span class="_ _7"> </span>of<span class="_ _7"> </span>Surprise?<span class="_ _28"> </span>. . . . . . . . . . . . .<span class="_ _1e"> </span>96</div><div class="t m0 x1 h6 y34 ff1 fs1 fc0 sc0 ls2 ws5">7.6<span class="_ _6"> </span>Conjecture O<span class="fs4 ls3 v1">m</span><span class="ls0 ws9">.......................... </span>97</div><div class="t m0 x1 h3 y35 ff1 fs1 fc0 sc0 ls2 ws3">7.7<span class="_ _6"> </span>Metacognitive<span class="_ _7"> </span>Feelings<span class="_ _7"> </span>are<span class="_ _7"> </span>Intentional<span class="_ _7"> </span>Isolators<span class="_ _28"> </span>. . . . . . .<span class="_ _c"> </span>99</div><div class="t m0 x1 h3 y36 ff1 fs1 fc0 sc0 ls0 wsa">7<span class="_ _1"></span>.<span class="_ _1"></span>8<span class="_ _8"> </span>C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>l<span class="_ _1"></span>u<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _a"></span>............................ 1<span class="_ _1"></span>0<span class="_ _1"></span>1<span class="_ _1"></span></div><div class="t m0 x0 h2 y37 ff2 fs1 fc0 sc0 ls2 ws5">8<span class="_ _13"> </span>Conclusion to Part I<span class="_ _2d"> </span>103</div><div class="t m0 x1 h3 y38 ff1 fs1 fc0 sc0 ls2 ws3">8.1<span class="_ _6"> </span>What<span class="_ _7"> </span>Is<span class="_ _7"> </span>an<span class="_ _7"> </span>Expectation?<span class="_ _1a"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>103</div><div class="t m0 x1 h3 y39 ff1 fs1 fc0 sc0 ls2 ws3">8.2<span class="_ _6"> </span>Core<span class="_ _7"> </span>Knowledge:<span class="_ _1b"> </span>A<span class="_ _7"> </span>Lighter<span class="_ _7"> </span>A<span class="_ _d"></span>ccount<span class="_ _20"> </span>. . . . . . . . . . . . .<span class="_ _1a"> </span>105</div><div class="t m0 x1 h3 y3a ff1 fs1 fc0 sc0 ls2 ws3">8.3<span class="_ _6"> </span>Development<span class="_ _7"> </span>Is<span class="_ _7"> </span>Rediscov<span class="_ _d"></span>ery<span class="_ _e"> </span>. . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>106</div><div class="t m0 x1 h3 y3b ff1 fs1 fc0 sc0 ls2 ws3">8.4<span class="_ _6"> </span>How<span class="_ _7"> </span>Does<span class="_ _7"> </span>Rediscovery<span class="_ _7"> </span>Occur?<span class="_ _26"> </span>. . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>108</div><div class="t m0 x0 h2 y3c ff2 fs1 fc0 sc0 ls2 ws1">9 Innateness<span class="_ _2e"> </span>113</div><div class="t m0 x1 h3 y3d ff1 fs1 fc0 sc0 ls0 wsb">9<span class="_ _1"></span>.<span class="_ _1"></span>1<span class="_ _8"> </span>S<span class="_ _1"></span>y<span class="_ _1"></span>n<span class="_ _1"></span>t<span class="_ _1"></span>a<span class="_ _1"></span>x ..............................<span class="_ _26"> </span>1<span class="_ _1"></span>1<span class="_ _1"></span>4<span class="_ _1"></span></div><div class="t m0 x1 h3 y3e ff1 fs1 fc0 sc0 ls2 ws3">9.2<span class="_ _6"> </span>A<span class="_ _7"> </span>Poverty<span class="_ _7"> </span>of<span class="_ _7"> </span>Stimulus<span class="_ _7"> </span>Argument<span class="_ _7"> </span>. . . . . . . . . . . . . . . .<span class="_ _2f"> </span>115</div><div class="t m0 x1 h3 y3f ff1 fs1 fc0 sc0 ls2 ws3">9.3<span class="_ _6"> </span>The<span class="_ _7"> </span>Poverty<span class="_ _7"> </span>of<span class="_ _7"> </span>Po<span class="_ _d"></span>verty<span class="_ _7"> </span>of<span class="_ _7"> </span>Stimulus<span class="_ _7"> </span>Arguments<span class="_ _7"> </span>. . . . . . . .<span class="_ _2f"> </span>118</div><div class="t m0 x1 h3 y40 ff1 fs1 fc0 sc0 ls2 ws3">9.4<span class="_ _6"> </span>Is<span class="_ _7"> </span>Core<span class="_ _7"> </span>Knowledge<span class="_ _7"> </span>Innate?<span class="_ _15"> </span>. . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>119</div><div class="t m0 x1 h3 y41 ff1 fs1 fc0 sc0 ls2 ws3">9.5<span class="_ _6"> </span>Syntax<span class="_ _7"> </span>and<span class="_ _7"> </span>Rediscovery<span class="_ _17"> </span>. . . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>120</div><div class="t m0 x1 h3 y42 ff1 fs1 fc0 sc0 ls0 wsc">9<span class="_ _1"></span>.<span class="_ _1"></span>6<span class="_ _8"> </span>C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>l<span class="_ _1"></span>u<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _a"></span>............................ 1<span class="_ _1"></span>2<span class="_ _1"></span>2<span class="_ _1"></span></div><div class="t m0 x3 h5 y1c ff1 fs3 fc0 sc0 ls2">vi</div><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:743.756000px;width:84.747000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:713.958000px;width:109.361000px;height:13.272000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:699.105000px;width:157.278000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:684.227000px;width:270.912000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:669.350000px;width:177.770000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:654.473000px;width:186.509000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:642.250000px;width:84.747000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:612.452000px;width:306.789000px;height:13.273000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:597.707000px;width:188.852000px;height:13.003000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:582.722000px;width:295.325000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:567.952000px;width:143.088000px;height:13.004000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:552.968000px;width:109.936000px;height:12.686000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:538.091000px;width:212.822000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:523.214000px;width:180.483000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:508.336000px;width:193.192000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:493.567000px;width:94.717000px;height:12.579000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:481.236000px;width:154.513000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:451.438000px;width:144.246000px;height:13.273000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:436.693000px;width:158.103000px;height:13.003000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:421.708000px;width:226.878000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:406.831000px;width:170.967000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:391.954000px;width:192.450000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:377.077000px;width:210.264000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:362.307000px;width:101.512000px;height:12.604000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:347.323000px;width:261.898000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:335.099000px;width:84.747000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:308.057000px;width:128.717000px;height:10.517000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:290.448000px;width:148.970000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:275.571000px;width:208.001000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:260.694000px;width:168.373000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:245.817000px;width:180.603000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:221.429000px;width:78.637000px;height:10.003000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:203.820000px;width:63.024000px;height:12.687000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:188.943000px;width:190.370000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:174.066000px;width:259.328000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:159.189000px;width:161.331000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:144.312000px;width:146.423000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:132.089000px;width:84.747000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
          <div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><div class="t m0 x0 h4 y1d ff2 fs2 fc0 sc0 ls2 ws4">Interlude on Innateness<span class="_ _30"> </span>113</div><div class="t m0 x0 h4 y43 ff2 fs2 fc0 sc0 ls2 ws4">II<span class="_ _10"> </span>Minds and Actions<span class="_ _31"> </span>125</div><div class="t m0 x0 h2 y44 ff2 fs1 fc0 sc0 ls2 wsd">10 Action<span class="_ _32"> </span>127</div><div class="t m0 x1 h3 y45 ff1 fs1 fc0 sc0 ls2 ws3">10.1<span class="_ _e"> </span>T<span class="_ _d"></span>racking<span class="_ _7"> </span>vs<span class="_ _7"> </span>Knowing<span class="_ _27"> </span>. . . . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>127</div><div class="t m0 x1 h3 y46 ff1 fs1 fc0 sc0 ls2 ws3">10.2<span class="_ _e"> </span>Three-month-olds<span class="_ _7"> </span>T<span class="_ _d"></span>rack<span class="_ _7"> </span>the<span class="_ _7"> </span>Goals<span class="_ _7"> </span>of<span class="_ _7"> </span>Actions<span class="_ _2f"> </span>. . . . . . . .<span class="_ _2f"> </span>128</div><div class="t m0 x1 h3 y47 ff1 fs1 fc0 sc0 ls2 ws3">10.3<span class="_ _e"> </span>Pure<span class="_ _7"> </span>Goal<span class="_ _7"> </span>T<span class="_ _d"></span>racking<span class="_ _1d"> </span>. . . . . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>131</div><div class="t m0 x1 h3 y48 ff1 fs1 fc0 sc0 ls2 ws3">10.4<span class="_ _e"> </span>The<span class="_ _7"> </span>T<span class="_ _a"></span>eleological<span class="_ _7"> </span>Stance<span class="_ _33"> </span>. . . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>134</div><div class="t m0 x1 h3 y49 ff1 fs1 fc0 sc0 ls2 ws3">10.5<span class="_ _e"> </span>Statistical<span class="_ _7"> </span>Regularities<span class="_ _34"> </span>. . . . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>137</div><div class="t m0 x1 h3 y4a ff1 fs1 fc0 sc0 ls2 ws3">10.6<span class="_ _e"> </span>A<span class="_ _7"> </span>Methodological<span class="_ _7"> </span>Explanation?<span class="_ _16"> </span>. . . . . . . . . . . . . . . .<span class="_ _35"> </span>141</div><div class="t m0 x1 h3 y4b ff1 fs1 fc0 sc0 ls2 ws3">10.7<span class="_ _e"> </span>A<span class="_ _7"> </span>Second<span class="_ _7"> </span>Puzzle:<span class="_ _1b"> </span>Acting<span class="_ _7"> </span>and<span class="_ _7"> </span>T<span class="_ _a"></span>racking<span class="_ _20"> </span>. . . . . . . . . . . .<span class="_ _1a"> </span>142</div><div class="t m0 x1 h3 y4c ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>0<span class="_ _1"></span>.<span class="_ _1"></span>8 C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>l<span class="_ _1"></span>u<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _d"></span>............................<span class="_ _17"> </span>1<span class="_ _1"></span>4<span class="_ _1"></span>5<span class="_ _1"></span></div><div class="t m0 x0 h2 y4d ff2 fs1 fc0 sc0 ls2 ws5">11<span class="_ _33"> </span>A <span class="ff3">�</span>eory of Goal Tracking<span class="_ _36"> </span>147</div><div class="t m0 x1 h3 y4e ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>1<span class="_ _1"></span>.<span class="_ _1"></span>1 T<span class="_ _1"></span>h<span class="_ _1"></span>e<span class="_ _3"></span>S<span class="_ _1"></span>i<span class="_ _1"></span>m<span class="_ _1"></span>p<span class="_ _1"></span>l<span class="_ _1"></span>e<span class="_ _3"></span>V<span class="_ _1"></span>i<span class="_ _1"></span>e<span class="_ _1"></span>w<span class="_ _19"></span>.........................<span class="_ _26"> </span>1<span class="_ _1"></span>4<span class="_ _1"></span>7<span class="_ _1"></span></div><div class="t m0 x1 h3 y4f ff1 fs1 fc0 sc0 ls2 ws3">11.2<span class="_ _e"> </span>The<span class="_ _7"> </span>Motor<span class="_ _7"> </span>Theory<span class="_ _7"> </span>of<span class="_ _7"> </span>Goal<span class="_ _7"> </span>Tracking<span class="_ _37"> </span>. . . . . . . . . . . . . .<span class="_ _1a"> </span>148</div><div class="t m0 x1 h3 y50 ff1 fs1 fc0 sc0 ls2 ws3">11.3<span class="_ _e"> </span>The<span class="_ _7"> </span>Motor<span class="_ _7"> </span>Theory<span class="_ _7"> </span>and<span class="_ _7"> </span>the<span class="_ _7"> </span>T<span class="_ _a"></span>eleological<span class="_ _7"> </span>Stance<span class="_ _15"> </span>. . . . . . . .<span class="_ _2f"> </span>151</div><div class="t m0 x1 h3 y51 ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>1<span class="_ _1"></span>.<span class="_ _1"></span>4 T<span class="_ _2"></span>a<span class="_ _1"></span>r<span class="_ _1"></span>g<span class="_ _1"></span>e<span class="_ _1"></span>t<span class="_ _3"></span>v<span class="_ _1"></span>s<span class="_ _3"></span>G<span class="_ _1"></span>o<span class="_ _1"></span>a<span class="_ _1"></span>l<span class="_ _23"></span>..........................<span class="_ _26"> </span>1<span class="_ _1"></span>5<span class="_ _1"></span>3<span class="_ _1"></span></div><div class="t m0 x1 h3 y52 ff1 fs1 fc0 sc0 ls2 ws3">11.5<span class="_ _e"> </span>A<span class="_ _7"> </span>Dual<span class="_ _7"> </span>Process<span class="_ _7"> </span>Theory<span class="_ _7"> </span>of<span class="_ _7"> </span>Goal<span class="_ _7"> </span>Tracking<span class="_ _1d"> </span>. . . . . . . . . . .<span class="_ _1a"> </span>155</div><div class="t m0 x1 h3 y53 ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>1<span class="_ _1"></span>.<span class="_ _1"></span>6 P<span class="_ _1"></span>u<span class="_ _1"></span>z<span class="_ _1"></span>z<span class="_ _1"></span>l<span class="_ _1"></span>e<span class="_ _1"></span>s<span class="_ _3"></span>S<span class="_ _1"></span>o<span class="_ _1"></span>l<span class="_ _1"></span>v<span class="_ _1"></span>e<span class="_ _1"></span>d<span class="_ _1"></span>?<span class="_ _34"> </span>.........................<span class="_ _37"> </span>1<span class="_ _1"></span>5<span class="_ _1"></span>7<span class="_ _1"></span></div><div class="t m0 x1 h3 y54 ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>1<span class="_ _1"></span>.<span class="_ _1"></span>7 C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>l<span class="_ _1"></span>u<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _d"></span>............................<span class="_ _17"> </span>1<span class="_ _1"></span>5<span class="_ _1"></span>8<span class="_ _1"></span></div><div class="t m0 x0 h2 y55 ff2 fs1 fc0 sc0 ls2 ws5">12<span class="_ _33"> </span>Mind:<span class="_ _1b"> </span>the Puzzle<span class="_ _38"> </span>161</div><div class="t m0 x1 h3 y56 ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>2<span class="_ _1"></span>.<span class="_ _1"></span>1 A<span class="_ _1"></span>l<span class="_ _1"></span>l<span class="_ _3"></span>A<span class="_ _1"></span>b<span class="_ _1"></span>o<span class="_ _1"></span>u<span class="_ _1"></span>t<span class="_ _b"></span>M<span class="_ _1"></span>a<span class="_ _1"></span>x<span class="_ _1"></span>i<span class="_ _37"> </span>.........................<span class="_ _26"> </span>1<span class="_ _1"></span>6<span class="_ _1"></span>2<span class="_ _1"></span></div><div class="t m0 x1 h3 y57 ff1 fs1 fc0 sc0 ls2 ws3">12.2<span class="_ _e"> </span>Infants<span class="_ _7"> </span>track<span class="_ _7"> </span>false<span class="_ _7"> </span>beliefs<span class="_ _8"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>166</div><div class="t m0 x1 h3 y58 ff1 fs1 fc0 sc0 ls2 ws3">12.3<span class="_ _e"> </span>A<span class="_ _7"> </span>Replication<span class="_ _7"> </span>Challenge<span class="_ _20"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>169</div><div class="t m0 x1 h3 y59 ff1 fs1 fc0 sc0 ls2 ws5">12.4<span class="_ _e"> </span>Methodological Defects or Truly Contradictory Responses?<span class="_ _34"> </span>.<span class="_ _2f"> </span>170</div><div class="t m0 x1 h3 y5a ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>2<span class="_ _1"></span>.<span class="_ _1"></span>5 M<span class="_ _1"></span>o<span class="_ _1"></span>d<span class="_ _1"></span>e<span class="_ _1"></span>l<span class="_ _1"></span>s ..............................<span class="_ _26"> </span>1<span class="_ _1"></span>7<span class="_ _1"></span>3<span class="_ _1"></span></div><div class="t m0 x1 h3 y5b ff1 fs1 fc0 sc0 ls2 ws3">12.6<span class="_ _e"> </span>The<span class="_ _7"> </span>Mindreading<span class="_ _7"> </span>Puzzle<span class="_ _1a"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>175</div><div class="t m0 x0 h2 y5c ff2 fs1 fc0 sc0 ls2 wsd">13 <span class="ff3">�</span><span class="ws5">ree Levels of Analysis<span class="_ _39"> </span>177</span></div><div class="t m0 x1 h3 y5d ff1 fs1 fc0 sc0 ls2 ws3">13.1<span class="_ _e"> </span>T<span class="_ _d"></span>racking<span class="_ _7"> </span>Beliefs<span class="_ _7"> </span>without<span class="_ _7"> </span>Representing<span class="_ _7"> </span>Them?<span class="_ _e"> </span>. . . . . . . .<span class="_ _35"> </span>177</div><div class="t m0 x1 h3 y5e ff1 fs1 fc0 sc0 ls2 ws3">13.2<span class="_ _e"> </span>Altercentric<span class="_ _7"> </span>Interference<span class="_ _1d"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>178</div><div class="t m0 x1 h3 y5f ff1 fs1 fc0 sc0 ls2 ws3">13.3<span class="_ _e"> </span>Mirroring<span class="_ _7"> </span>beliefs?<span class="_ _27"> </span>. . . . . . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>180</div><div class="t m0 x1 h3 y60 ff1 fs1 fc0 sc0 ls2 ws3">13.4<span class="_ _e"> </span>Three<span class="_ _7"> </span>Levels<span class="_ _7"> </span>of<span class="_ _7"> </span>Analysis<span class="_ _3a"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>182</div><div class="t m0 x1 h3 y61 ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>3<span class="_ _1"></span>.<span class="_ _1"></span>5 T<span class="_ _2"></span>a<span class="_ _1"></span>s<span class="_ _1"></span>k<span class="_ _3"></span>A<span class="_ _1"></span>n<span class="_ _1"></span>a<span class="_ _1"></span>l<span class="_ _1"></span>y<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>s<span class="_ _17"> </span>..........................<span class="_ _26"> </span>1<span class="_ _1"></span>8<span class="_ _1"></span>4<span class="_ _1"></span></div><div class="t m0 x1 h3 y62 ff1 fs1 fc0 sc0 ls2 ws3">13.6<span class="_ _e"> </span>Selection<span class="_ _7"> </span>and<span class="_ _7"> </span>Inhibition<span class="_ _17"> </span>. . . . . . . . . . . . . . . . . . . . .<span class="_ _35"> </span>187</div><div class="t m0 x1 h3 y63 ff1 fs1 fc0 sc0 ls2 ws3">13.7<span class="_ _e"> </span>T<span class="_ _a"></span>oo<span class="_ _7"> </span>Much<span class="_ _7"> </span>Mindreading?<span class="_ _28"> </span>. . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>192</div><div class="t m0 x1 h3 y1b ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>3<span class="_ _1"></span>.<span class="_ _1"></span>8 W<span class="_ _1"></span>h<span class="_ _1"></span>a<span class="_ _1"></span>t<span class="_ _3"></span>N<span class="_ _1"></span>o<span class="_ _1"></span>w<span class="_ _1"></span>?<span class="_ _37"> </span>...........................<span class="_ _26"> </span>1<span class="_ _1"></span>9<span class="_ _1"></span>7<span class="_ _1"></span></div><div class="t m0 x4 h5 y1c ff1 fs3 fc0 sc0 ls2">vii</div><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:743.684000px;width:157.060000px;height:12.357000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:700.295000px;width:148.323000px;height:12.357000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:671.885000px;width:56.161000px;height:10.116000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:653.595000px;width:134.480000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:640.577000px;width:251.557000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:622.250000px;width:124.557000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:606.578000px;width:144.833000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:590.906000px;width:137.971000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:575.233000px;width:183.687000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:559.561000px;width:216.907000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:546.543000px;width:84.747000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:515.420000px;width:164.271000px;height:13.272000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:499.771000px;width:112.793000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:484.099000px;width:205.769000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:468.427000px;width:256.446000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:452.754000px;width:100.468000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:437.082000px;width:227.910000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:424.064000px;width:106.098000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:408.391000px;width:84.747000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:379.910000px;width:110.685000px;height:10.630000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:364.274000px;width:105.154000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:348.602000px;width:151.301000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:330.275000px;width:147.918000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:314.603000px;width:318.828000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:301.585000px;width:64.841000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:283.258000px;width:148.539000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:254.879000px;width:151.133000px;height:13.182000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:239.141000px;width:253.984000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:226.123000px;width:150.225000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:207.796000px;width:117.384000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:192.124000px;width:149.591000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:176.452000px;width:97.407000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:163.433000px;width:146.184000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:145.107000px;width:149.818000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:132.089000px;width:87.950000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
          <div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><div class="t m0 x0 h2 y1d ff2 fs1 fc0 sc0 ls2 ws5">14<span class="_ _33"> </span>Mind:<span class="_ _1b"> </span>a Solution?<span class="_ _3b"> </span>199</div><div class="t m0 x1 h3 y64 ff1 fs1 fc0 sc0 ls2 ws3">14.1<span class="_ _e"> </span>Mindreading<span class="_ _7"> </span>Is<span class="_ _7"> </span>Sometimes<span class="_ _7"> </span>A<span class="_ _a"></span>utomatic . . . . . . . . . . . . .<span class="_ _1a"> </span>200</div><div class="t m0 x1 h3 y65 ff1 fs1 fc0 sc0 ls2 ws3">14.2<span class="_ _e"> </span>Mindreading<span class="_ _7"> </span>Is<span class="_ _7"> </span>Not<span class="_ _7"> </span>Always<span class="_ _7"> </span>A<span class="_ _a"></span>utomatic<span class="_ _16"> </span>. . . . . . . . . . . .<span class="_ _2f"> </span>201</div><div class="t m0 x1 h3 y66 ff1 fs1 fc0 sc0 ls2 ws3">14.3<span class="_ _e"> </span>A<span class="_ _7"> </span>Dual<span class="_ _7"> </span>Process<span class="_ _7"> </span>Theory<span class="_ _7"> </span>of<span class="_ _7"> </span>Mindreading<span class="_ _24"> </span>. . . . . . . . . . . .<span class="_ _1a"> </span>202</div><div class="t m0 x1 h3 y67 ff1 fs1 fc0 sc0 ls2 ws5">14.4<span class="_ _e"> </span>Speed–A<span class="_ _d"></span>ccuracy T<span class="_ _d"></span>rade-O<span class="ff4"></span><span class="ls0 wsf">s .................. 2<span class="_ _1"></span>0<span class="_ _1"></span>4<span class="_ _1"></span></span></div><div class="t m0 x1 h3 y68 ff1 fs1 fc0 sc0 ls2 ws3">14.5<span class="_ _e"> </span>What<span class="_ _7"> </span>Is<span class="_ _7"> </span>a<span class="_ _7"> </span>Model<span class="_ _7"> </span>of<span class="_ _7"> </span>Minds<span class="_ _7"> </span>and<span class="_ _7"> </span>Actions?<span class="_ _37"> </span>. . . . . . . . . . . .<span class="_ _2f"> </span>205</div><div class="t m0 x1 h3 y69 ff1 fs1 fc0 sc0 ls2 ws3">14.6<span class="_ _e"> </span>Minimal<span class="_ _7"> </span>Models<span class="_ _7"> </span>of<span class="_ _7"> </span>the<span class="_ _7"> </span>Mental<span class="_ _27"> </span>. . . . . . . . . . . . . . . . .<span class="_ _35"> </span>207</div><div class="t m0 x1 h3 y6a ff1 fs1 fc0 sc0 ls2 ws3">14.7<span class="_ _e"> </span>Signature<span class="_ _7"> </span>Limits<span class="_ _7"> </span>in<span class="_ _7"> </span>Mindreading<span class="_ _37"> </span>. . . . . . . . . . . . . . . .<span class="_ _1a"> </span>210</div><div class="t m0 x1 h3 y6b ff1 fs1 fc0 sc0 ls2 ws3">14.8<span class="_ _e"> </span>A<span class="_ _7"> </span>Developmental<span class="_ _7"> </span>Theory<span class="_ _7"> </span>of<span class="_ _7"> </span>Mindreading<span class="_ _26"> </span>. . . . . . . . . . .<span class="_ _2f"> </span>213</div><div class="t m0 x1 h3 y6c ff1 fs1 fc0 sc0 ls2 ws3">14.9<span class="_ _e"> </span>How<span class="_ _7"> </span>to<span class="_ _7"> </span>Solve<span class="_ _7"> </span>the<span class="_ _7"> </span>Mindr<span class="_ _d"></span>eading<span class="_ _7"> </span>Puzzle<span class="_ _33"> </span>. . . . . . . . . . . . .<span class="_ _1a"> </span>216</div><div class="t m0 x1 h3 y6d ff1 fs1 fc0 sc0 ls2 ws3">14.10<span class="_ _3c"> </span>T<span class="_ _a"></span>ask<span class="_ _7"> </span>Analysis<span class="_ _7"> </span>Revisited<span class="_ _33"> </span>. . . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>218</div><div class="t m0 x1 h3 y6e ff1 fs1 fc0 sc0 ls2 ws3">14.11<span class="_ _3c"> </span>Is<span class="_ _7"> </span>There<span class="_ _7"> </span>Core<span class="_ _3c"> </span>Knowledge<span class="_ _7"> </span>of<span class="_ _7"> </span>Minds? . . . . . . . . . . . . . .<span class="_ _1a"> </span>219</div><div class="t m0 x1 h3 y6f ff1 fs1 fc0 sc0 ls2 ws3">14.12<span class="_ _3c"> </span>Origins<span class="_ _7"> </span>of<span class="_ _7"> </span>Knowledge<span class="_ _7"> </span>of<span class="_ _7"> </span>Mind:<span class="_ _1b"> </span>Rediscovery<span class="_ _16"> </span>. . . . . . . . .<span class="_ _2f"> </span>219</div><div class="t m0 x0 h2 y70 ff2 fs1 fc0 sc0 ls2 ws5">15<span class="_ _33"> </span>Joint Action<span class="_ _3d"> </span>223</div><div class="t m0 x1 h3 y71 ff1 fs1 fc0 sc0 ls2 ws5">15.1<span class="_ _e"> </span>Joint Action vs Parallel but Mer<span class="_ _d"></span>ely Individual Actions<span class="_ _2c"> </span>.<span class="_ _22"> </span>.<span class="_ _22"> </span>.<span class="_ _22"> </span>.<span class="_ _35"> </span>224</div><div class="t m0 x1 h3 y72 ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>5<span class="_ _1"></span>.<span class="_ _1"></span>2 S<span class="_ _1"></span>h<span class="_ _1"></span>a<span class="_ _1"></span>r<span class="_ _1"></span>e<span class="_ _1"></span>d<span class="_ _3"></span>I<span class="_ _1"></span>n<span class="_ _1"></span>t<span class="_ _1"></span>e<span class="_ _1"></span>n<span class="_ _1"></span>t<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1f"></span>.........................<span class="_ _26"> </span>2<span class="_ _1"></span>2<span class="_ _1"></span>6<span class="_ _1"></span></div><div class="t m0 x1 h3 y73 ff1 fs1 fc0 sc0 ls2 ws3">15.3<span class="_ _e"> </span>Bratman<span class="_ _7"> </span>on<span class="_ _7"> </span>Shared<span class="_ _7"> </span>Intention<span class="_ _26"> </span>. . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>227</div><div class="t m0 x1 h3 y74 ff1 fs1 fc0 sc0 ls2 ws3">15.4<span class="_ _e"> </span>An<span class="_ _7"> </span>Inconsistent<span class="_ _7"> </span>T<span class="_ _d"></span>riad . . . . . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>228</div><div class="t m0 x1 h3 y75 ff1 fs1 fc0 sc0 ls2 ws3">15.5<span class="_ _e"> </span>Coordinating<span class="_ _7"> </span>Planning<span class="_ _3a"> </span>. . . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>231</div><div class="t m0 x1 h3 y76 ff1 fs1 fc0 sc0 ls2 ws3">15.6<span class="_ _e"> </span>Joint<span class="_ _7"> </span>Action<span class="_ _3c"> </span>in<span class="_ _7"> </span>the<span class="_ _7"> </span>First<span class="_ _7"> </span>Y<span class="_ _a"></span>ears<span class="_ _7"> </span>of<span class="_ _7"> </span>Life<span class="_ _20"> </span>. . . . . . . . . . . . .<span class="_ _1a"> </span>235</div><div class="t m0 x1 h3 y77 ff1 fs1 fc0 sc0 ls2 ws3">15.7<span class="_ _e"> </span>Collective<span class="_ _7"> </span>Goals<span class="_ _7"> </span>vs<span class="_ _7"> </span>Shared<span class="_ _7"> </span>Intentions<span class="_ _27"> </span>. . . . . . . . . . . . .<span class="_ _2f"> </span>239</div><div class="t m0 x1 h3 y78 ff1 fs1 fc0 sc0 ls2 ws3">15.8<span class="_ _e"> </span>Expectations<span class="_ _7"> </span>ab<span class="_ _11"></span>out<span class="_ _7"> </span>Collective<span class="_ _7"> </span>Goals<span class="_ _33"> </span>. . . . . . . . . . . . . .<span class="_ _1a"> </span>242</div><div class="t m0 x1 h3 y79 ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>5<span class="_ _1"></span>.<span class="_ _1"></span>9 C<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _1"></span>c<span class="_ _1"></span>l<span class="_ _1"></span>u<span class="_ _1"></span>s<span class="_ _1"></span>i<span class="_ _1"></span>o<span class="_ _1"></span>n<span class="_ _d"></span>............................<span class="_ _17"> </span>2<span class="_ _1"></span>4<span class="_ _1"></span>5<span class="_ _1"></span></div><div class="t m0 x0 h2 y7a ff2 fs1 fc0 sc0 ls2 ws5">16<span class="_ _33"> </span>Conclusion to Part II<span class="_ _3e"> </span>249</div><div class="t m0 x1 h3 y7b ff1 fs1 fc0 sc0 ls2 ws3">16.1<span class="_ _e"> </span>Dual<span class="_ _7"> </span>Process<span class="_ _7"> </span>Theories<span class="_ _1b"> </span>. . . . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>250</div><div class="t m0 x1 h3 y7c ff1 fs1 fc0 sc0 ls2 ws3">16.2<span class="_ _e"> </span>Pluralism<span class="_ _7"> </span>about<span class="_ _7"> </span>Mo<span class="_ _11"></span>dels<span class="_ _33"> </span>. . . . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>251</div><div class="t m0 x1 h3 y7d ff1 fs1 fc0 sc0 ls2 ws3">16.3<span class="_ _e"> </span>Goal<span class="_ _7"> </span>T<span class="_ _d"></span>racking<span class="_ _7"> </span>Is<span class="_ _7"> </span>the<span class="_ _7"> </span>Foundation . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>252</div><div class="t m0 x1 h3 y7e ff1 fs1 fc0 sc0 ls2 ws3">16.4<span class="_ _e"> </span>When<span class="_ _7"> </span>Joint<span class="_ _7"> </span>Action<span class="_ _3c"> </span>Enables<span class="_ _7"> </span>Goal<span class="_ _7"> </span>Tracking<span class="_ _2f"> </span>. . . . . . . . . .<span class="_ _2f"> </span>253</div><div class="t m0 x1 h3 y7f ff1 fs1 fc0 sc0 ls2 ws5">16.5<span class="_ _e"> </span>Joint Action and the De<span class="_ _d"></span>velopmental Emergence of Knowledge 255</div><div class="t m0 x0 h4 y80 ff2 fs2 fc0 sc0 ls2 ws10">Conclusion 259</div><div class="t m0 x0 h2 y81 ff2 fs1 fc0 sc0 ls2 wsd">17 Conclusion<span class="_ _3f"> </span>259</div><div class="t m0 x1 h3 y82 ff1 fs1 fc0 sc0 ls2 ws3">17.1<span class="_ _e"> </span>Infants<span class="_ _7"> </span>Rely<span class="_ _7"> </span>on<span class="_ _7"> </span>Minimal<span class="_ _7"> </span>Models<span class="_ _7"> </span>…<span class="_ _34"> </span>. . . . . . . . . . . . . . .<span class="_ _2f"> </span>260</div><div class="t m0 x1 h3 y83 ff1 fs1 fc0 sc0 ls2 ws3">17.2<span class="_ _e"> </span>…<span class="_ _7"> </span>As<span class="_ _3c"> </span>Do<span class="_ _7"> </span>Adults,<span class="_ _7"> </span>Sometimes<span class="_ _35"> </span>. . . . . . . . . . . . . . . . . .<span class="_ _35"> </span>261</div><div class="t m0 x1 h3 y84 ff1 fs1 fc0 sc0 ls0 wse">1<span class="_ _1"></span>7<span class="_ _1"></span>.<span class="_ _1"></span>3 P<span class="_ _1"></span>u<span class="_ _1"></span>z<span class="_ _1"></span>z<span class="_ _1"></span>l<span class="_ _1"></span>e<span class="_ _1"></span>s<span class="_ _3"></span>M<span class="_ _1"></span>a<span class="_ _1"></span>t<span class="_ _1"></span>t<span class="_ _1"></span>e<span class="_ _1"></span>r..........................<span class="_ _26"> </span>2<span class="_ _1"></span>6<span class="_ _1"></span>2<span class="_ _1"></span></div><div class="t m0 x1 h3 y85 ff1 fs1 fc0 sc0 ls2 ws3">17.4<span class="_ _e"> </span>Linking<span class="_ _7"> </span>Problems<span class="_ _3c"> </span>Ab<span class="_ _11"></span>ound<span class="_ _16"> </span>. . . . . . . . . . . . . . . . . . .<span class="_ _1a"> </span>263</div><div class="t m0 x1 h3 y86 ff1 fs1 fc0 sc0 ls2 ws3">17.5<span class="_ _e"> </span>Core<span class="_ _3c"> </span>Knowledge<span class="_ _7"> </span>Isn’t<span class="_ _7"> </span>What<span class="_ _7"> </span>Y<span class="_ _a"></span>ou<span class="_ _7"> </span>Think<span class="_ _7"> </span>It<span class="_ _7"> </span>Is<span class="_ _17"> </span>. . . . . . . . . .<span class="_ _35"> </span>264</div><div class="t m0 x1 h3 y87 ff1 fs1 fc0 sc0 ls2 ws3">17.6<span class="_ _e"> </span>How<span class="_ _3c"> </span>to<span class="_ _7"> </span>Solve<span class="_ _7"> </span>Linking<span class="_ _7"> </span>Problems<span class="_ _3a"> </span>. . . . . . . . . . . . . . . .<span class="_ _1a"> </span>265</div><div class="t m0 x1 h3 y42 ff1 fs1 fc0 sc0 ls2 ws3">17.7<span class="_ _e"> </span>Representation:<span class="_ _40"> </span>Handle<span class="_ _7"> </span>with<span class="_ _7"> </span>Care<span class="_ _15"> </span>. . . . . . . . . . . . . . .<span class="_ _1a"> </span>266</div><div class="t m0 x5 h5 y1c ff1 fs3 fc0 sc0 ls2">viii</div><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:743.720000px;width:115.048000px;height:10.630000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:726.292000px;width:213.551000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:711.483000px;width:218.298000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:696.674000px;width:221.047000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:681.865000px;width:165.767000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:669.710000px;width:222.673000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:654.901000px;width:177.387000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:637.438000px;width:188.338000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:622.629000px;width:231.879000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:607.820000px;width:213.719000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:593.011000px;width:145.012000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:578.202000px;width:205.015000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:563.393000px;width:243.806000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:536.901000px;width:85.690000px;height:12.220000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:521.578000px;width:291.236000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:509.423000px;width:111.155000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:494.614000px;width:171.744000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:479.805000px;width:135.950000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:462.342000px;width:141.282000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:448.268000px;width:208.064000px;height:12.376000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:435.378000px;width:211.698000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:417.915000px;width:205.171000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:405.760000px;width:84.747000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:378.831000px;width:133.104000px;height:10.517000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:363.944000px;width:138.246000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:349.135000px;width:144.977000px;height:10.457000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:331.672000px;width:187.477000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:316.863000px;width:234.473000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:302.054000px;width:332.828000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:262.823000px;width:76.133000px;height:12.221000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:235.716000px;width:81.709000px;height:10.630000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:218.289000px;width:198.093000px;height:13.111000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:204.681000px;width:165.504000px;height:11.910000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:191.325000px;width:101.436000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:173.862000px;width:157.888000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:159.053000px;width:240.845000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:144.244000px;width:184.213000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:129.435000px;width:195.770000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
          <div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><div class="t m0 x1 h3 y1d ff1 fs1 fc0 sc0 ls2 ws3">17.8<span class="_ _e"> </span>Inferential<span class="_ _3c"> </span>and<span class="_ _7"> </span>Intentional<span class="_ _7"> </span>Isolation<span class="_ _27"> </span>. . . . . . . . . . . . . .<span class="_ _35"> </span>267</div><div class="t m0 x1 h3 y88 ff1 fs1 fc0 sc0 ls2 ws3">17.9<span class="_ _e"> </span>Rediscovery<span class="_ _7"> </span>Is<span class="_ _7"> </span>Joint<span class="_ _7"> </span>Action<span class="_ _2c"> </span>. . . . . . . . . . . . . . . . . . .<span class="_ _2f"> </span>268</div><div class="t m0 x0 h2 y89 ff2 fs1 fc0 sc0 ls2 ws11">Glossary 271</div><div class="t m0 x3 h5 y1c ff1 fs3 fc0 sc0 ls2">ix</div><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:743.756000px;width:203.497000px;height:10.456000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" '><div class="d m1" style="border-style:none;position:absolute;left:130.322000px;bottom:726.656000px;width:162.276000px;height:13.110000px;background-color:rgba(255,255,255,0.000001);"></div></span ><span class="l" ><div class="d m1" style="border-style:none;position:absolute;left:112.390000px;bottom:700.320000px;width:49.442000px;height:13.183000px;background-color:rgba(255,255,255,0.000001);"></div></span ></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
        </div>
      </div>
    </div>
  </body>
</html>


---

Title: Are There Signature Limits in Early Theory of Mind?
Authors: Ella Fizke, Stephen A. Butterfill, Lea van de Loo, Eva Reindl, and Rakoczy, Hannes
Year: 2017
Journal: Journal of Experimental Child Psychology
Type: Publication

## Abstract

Current theory-of-mind research faces the challenge of reconciling two sets of seemingly incompatible findings: Whereas children come to solve explicit verbal false belief (FB) tasks from around 4 years of age, recent studies with various less explicit measures such as looking time, anticipatory looking, and spontaneous behavior suggest that even infants can succeed on some FB tasks. In response to this tension, two-systems theories propose to distinguish between an early-developing system, tracking simple forms of mental states, and a later-developing system, based on fully developed concepts of belief and other propositional attitudes. One prediction of such theories is that the early-developing system has signature limits concerning aspectuality. We tested this prediction in two experiments. The first experiment showed (in line with previous findings) that 2- and 3-year-olds take into account a protagonist’s true or false belief about the location of an object in their active helping behavior. In contrast, toddlers’ helping behavior did not differentiate between true and false belief conditions when the protagonist’s belief essentially involved aspectuality. Experiment 2 replicated these findings with a more stringent method designed to rule out more parsimonious explanations. Taken together, the current findings are compatible with the possibility that early theory-of-mind reasoning is subject to signature limits as predicted by the two-systems account.




---

Title: Gaining Knowledge via Other Minds: Children's Flexible Trust in Others as Sources of Information
Authors: Elizabeth J. Robinson, Stephen A. Butterfill and Erika Nurmsoo
Year: 2011
Journal: British Journal of Developmental Psychology
Type: Publication

## Abstract

In five experiments, we examined 3- to 6-year-olds' understanding that they could gain knowledge indirectly from someone who had seen something they had not. Consistent with previous research, children judged that an informant, who had seen inside a box, knew its contents. Similarly, when an informant marked a picture to indicate her suggestion as to the content of the box, 3- to 4-year-olds trusted this more frequently when the informant had seen inside the box than when she had not. Going beyond previous research, 3- to 4-year-olds were also sensitive to informants' relevant experience when they had to look over a barrier to see the marked picture, or ask for the barrier to be raised. Yet when children had to elicit the informant's suggestion, rather than just consult a suggestion already present, even 4- to 5-year-olds were no more likely to do so when the informant had seen the box's content than when she had not, and no more likely to trust the well-informed suggestion than the uninformed one. We conclude that young children who can ask questions may not yet fully understand the process by which they can gain accurate information from someone who has the experience they lack.




---

Title: Goals and Targets: A Developmental Puzzle about Sensitivity to Others’ Actions
Authors: Stephen A. Butterfill
Year: 2021
Journal: Synthese
Type: Publication

## Abstract

Sensitivity to others’ actions is essential for social animals like humans and a fundamental requirement for any kind of social cognition. Unsurprisingly, it is present in humans from early in the first year of life. But what processes underpin infants’ sensitivity to others’ actions? Any attempt to answer this question must solve twin puzzles about the development of goal tracking. Why does some, but not all, of infants’ goal tracking appear to be limited by their abilities to represent the observed action motorically at the time it occurs? And why does their sensitivity to action sometimes manifest itself differently in dishabituation, pupil dilation and anticipatory looking? Solving these twin puzzles is critical for understanding humans’ earliest sensitivity to others’ actions. After introducing the puzzles, this paper argues that solving them may require identifying multiple, distinct processes for tracking the targets and goals of actions.




---

Title: Infants' Representations of Causation (Commentary on Susan Carey, The Origin of Concepts)
Authors: Stephen A. Butterfill
Year: 2011
Journal: Behavioral and Brain Sciences
Type: Publication

## Abstract

It is consistent with the evidence in The Origin of Concepts to conjecture that infants' causal representations, like their numerical representations, are not continuous with adults', so that bootstrapping is needed in both cases.



---

Title: Intention and Motor Representation in Purposive Action
Authors: Stephen A. Butterfill and Corrado Sinigaglia
Year: 2014
Journal: Philosophy and Phenomenological Research
Type: Publication

## Abstract

Are there distinct roles for intention and motor representation in explaining the purposiveness of action? Standard accounts of action assign a role to intention but are silent on motor representation. The temptation is to suppose that nothing need be said here because motor representation is either only an enabling condition for purposive action or else merely a variety of intention. This paper provides reasons for resisting that temptation. Some motor representations, like intentions, coordinate actions in virtue of representing outcomes; but, unlike intentions, motor representations cannot feature as premises or conclusions in practical reasoning. This implies that motor representation has a distinctive role in explaining the purposiveness of action. It also gives rise to a problem: were the roles of intention and motor representation entirely independent, this would impair effective action. It is therefore necessary to explain how intentions interlock with motor representations. The solution, we argue, is to recognise that the contents of intentions can be partially determined by the contents of motor representations. Understanding this content-determining relation enables better understanding how intentions relate to actions.




---

Title: Interacting Mindreaders
Authors: Stephen A. Butterfill
Year: 2012
Journal: Philosophical Studies
Type: Publication

## Abstract

Could interacting mindreaders be in a position to know things which they would be unable to know if they were manifestly passive observers? This paper argues that they could. Mindreading is sometimes reciprocal: the mindreader's target reciprocates by taking the mindreader as a target for mindreading. The paper explains how such reciprocity can significantly narrow the range of possible interpretations of behaviour where mindreaders are, or appear to be, in a position to interact. A consequence is that revisions and extensions are needed to standard theories of the evidential basis of mindreading. The view also has consequences for understanding how abilities to interact combined with comparatively simple forms of mindreading may explain the emergence, in evolution or development, of sophisticated forms of social cognition.




---

Title: Intuitions about Joint Commitment
Authors: John Michael and Stephen A. Butterfill
Year: 2022
Journal: Philosophical Psychology
Type: Publication

## Abstract

In what sense is commitment essential to joint action, and do the participants in a joint action themselves perceive commitment as essential? Attempts to answer this question have so far been hampered by clashes of intuition. Perhaps this is because the intuitions in question have mostly been investigated using informal methods only. To explore this possibility, we adopted a more formal approach to testing intuitions about joint action, sampling naïve participants’ intuitions about experimentally controlled scenarios. This approach did reveal patterns in participants’ responses which may hint at potential conceptual links between commitment and joint action. It did not however provide evidence to support the view that commitment is essential to joint action, at least not from the agents’ own perspective. We conclude that intuitions alone, even when drawn systematically from a large sample, may be a poor basis for theorizing about joint action.



Keywords: Joint action; commitment; shared intention; Margaret Gilbert; social obligation  

<div class="fulltext">

<h1 id="introduction">1. Introduction</h1>
<p>In recent decades, philosophers have devoted considerable effort to
investigating the phenomenon (or phenomena) of joint action.<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> Despite this, significant
disagreement on the basic features of joint action remains: for
instance, on whether joint action essentially involves an irreducibly
joint commitment (for example, Gilbert 2013 versus Bratman 2014); on
whether joint action essentially involves common knowledge (for example,
Bratman 2014 versus Blomberg 2016); on whether joint action essentially
involves a special kind of reasoning (Gold and Sugden 2007; Pacherie
2012), a special kind of mental state (Searle 1990; Gallotti 2011;
Gallotti and Frith 2013); or a special kind of subject (Helm 2008) as
opposed to mental states with plural subjects (Schmid 2009). Here we
focus on the issue about commitment. Our aim is to identify obstacles to
adjudicating among competing theoretical positions and to explore the
prospects for one way of overcoming the obstacles.</p>
<p>What kinds of commitment might be essential to joint action? One kind
of commitment is associated with ordinary individual intention: to
intend to do something arguably involves being committed to doing it.
Whatever kind of commitment is involved here can only be a commitment of
the subject of intention to herself; or at least, it cannot be a
commitment of anyone but the subject and it cannot be a commitment to
anyone other than the subject. One of Gilbert’s groundbreaking
contributions was to focus on a different kind of commitment she labels
‘joint commitment’. This is a commitment whereby ‘each is obligated to
all the others for performance’ (1990, p.8; cf also Gomez-Lavin &amp;
Rachar, 2019, 2021; Roth, 2004; Löhr, 2022). The question we focus on
here is whether joint action essentially involves joint commitment.</p>
<p>Clashing intuitions appear to inform disagreement on this question.
For instance, Gilbert reasons that if joint action essentially involves
joint commitment, then when agents performing joint actions are doing so
in virtue of intentions, these intentions cannot be unilaterally
rescinded. (Several routes to this view are available; see Gilbert 2009;
2013.) To illustrate, Gilbert describes a case:</p>
<p>‘The parties are Ned and Olive, and Olive is speaking: “Our plan was
to hike to the top of the hill. We arrived at the hill and started up.
As he told me later, Ned realized early on that it would be too much for
him to go all the way to the top, and decided that he would only go half
way. Though he no longer had any intention of hiking to the top of the
hill, he had as yet said nothing about this to me, thinking it best to
wait until we were at least half way up before doing so. Before then we
encountered Pam, who asked me how far we intended to go. I said that our
intention was to hike to the top of the hill, as indeed it was”’
(Gilbert 2013, p. 8).</p>
<p>Gilbert reasons that the intuitive correctness of Pam’s statement
supports the view that Ned could not unilaterally rescind their
intention, and that this in turn supports the view that joint action
essentially involves joint commitment. Elaborating on this, Gilbert
further specifies that joint commitments entail obligations; as she puts
it in her seminal (1990) paper: ‘As long as people are out on a walk
together, they will understand that each has an obligation to do what he
or she can to achieve the relevant goal’ (p.6). And more recently:
‘obligations and entitlements—not necessarily moral obligations and
rights—are inherent in acting together’<a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>
(2013, p. 53).</p>
<p>How compelling is Gilbert’s line of thought? Bratman’s reply is
blunt:</p>
<p>‘As I see it, once Ned has changed his mind they no longer have a
shared intention to climb to the top’ (Bratman 2014, p. 117).</p>
<p>How can we account for such stark clashes of intuition? Gilbert is
explicit that her views, like those of many philosophers, are based on
‘informal observation including self-observation’ and her ‘own sense of
the matter’ (Gilbert 2013, pp. 24, 358). It is no surprise that such
methods have not reliably led philosophers with different theoretical
positions (and potentially also different experiences and backgrounds)
to adopt compatible views.</p>
<p>In light of this, it appears that the method of relying on one’s
intuitions presents two obstacles to adjudicating among competing
theoretical positions. First, different researchers may have conflicting
intuitions (as Bratman and Gilbert appear to), or they may have no
stable intuitions at all (as is the case for the current authors). And
second, we cannot be confident that there are no extraneous personal or
cultural factors which are serving as crucial inputs to the procedures.
And yet, before writing off attempts to draw conclusions from intuitions
altogether, we should give arguments from intuitions the best chance of
success. To this end, we can follow the ground-breaking work of
Tollefsen et al (2014) and Gomez-Lavin and Rachar (2019) in moving from
informal observation to a more formal approach, and in considering the
views of a more diverse group of people than the professional
philosophers whose theories are at stake. Gomez-Lavin and Rachar (2019)
offer evidence against the existence of intuitions which, they suggest,
have been used to support Bratman’s view. As they note (p. 117), their
findings do not directly provide support for Gilbert’s view. In a
follow-up study, Gomez-Lavin and Rachar (2021) go further. Their results
suggested that participants in a joint action may feel obliged to notify
joint action partners that they are unilaterally ending participation
but not – pace Gilbert (1990; 2013) – to ask for permission to do so.
However the cogency of this interpretation of their results has been
questioned by Löhr (2022) on methodological grounds. Briefly, Löhr notes
that in asking their participants about a putative obligation to request
permission to disengage, Gomez-Lavin and Rachar ask whether they ‘have
to’ do so; by contrast, in asking about a putative obligation to notify
another of their disengagement, the experiments ask whether they
‘should’ do so (pp. 759-60). Plausibly, this difference in wording could
at least partially explain the differences in responses to those two
questions. For, as Löhr (2022, p. 759) reminds us, it is coherent to
think there are things we should do (voting in a local election,
perhaps) that we do not strictly have to do. It remains an open
question, therefore, whether Gilbert’s intuitions are widely shared
among non-philosophers.</p>
<p>In three pre-registered experiments, we set out to discover how naive
subjects categorise behaviours as involving shared intentions,
commitments and obligations. Would they follow Gilbert in identifying
cases in which there is a joint plan, but individual intentions not to
fulfil the plan, as being like cases in which there is uncontroversially
a shared intention as far as the shared intention, commitment and
obligations go (Experiments 1, 2, &amp; 3)? Or would they diverge from
Gilbert in identifying such cases as more like cases in which there is
uncontroversially no joint plan at all (Experiments 1 &amp; 2)? To test
this, we implemented scenarios spelled out by Gilbert in arguing for her
view, and stuck as closely as possible to Gilbert’s wording in
formulating our questions. By asking participants whether they agreed
with Gilbert that the agents in our test conditions had shared
intentions, commitments and obligations, we were also able to probe
whether participants’ intuitions about the relationships among these
three concepts match Gilbert’s. On Gilbert’s analysis, shared intentions
entail joint commitments as well as obligations, so responses to
questions about these should be highly correlated. On other views, in
contrast, this may not be the case – Bratman (1997; 2014), for example,
denies that shared intentions entail joint commitments or obligations,
though he does acknowledge that they may be commonly associated with
commitments and obligations to others. On other views, in contrast, this
may not be the case – Bratman (1997; 2014), for example, denies that
shared intentions entail commitments or obligations, though he does
acknowledge that they often involve commitments and obligations. It is
arguably also coherent to hold, contrary to both Gilbert and Bratman,
that shared intentions entail commitments but not obligations. This is
why we asked participants about shared intentions, commitments and
obligations.</p>
<p>In sticking as closely as possible to Gilbert’s formulations in
designing our experiments we faced a problem. The formulations are
longer and more complex than would be ideal for a psychological study in
which great weight is placed on ensuring as narrow a focus as possible
on the question of interest while minimising extraneous features,
cognitive demands and possible sources of confusion. For our purposes,
however, it would not have been appropriate to substantially alter
Gilbert’s formulations, given that this would require taking a view on
which features are extraneous, which would likely be controversial. More
importantly, our goal was to test whether the scenarios Gilbert used to
generate intuitions actually do generate the specified intuitions. Of
course if Gilbert’s scenarios do yield replicable effects it would be
important to further support the conclusions drawn with more targeted
stimuli and measures.</p>
<p>A second problem that arises from sticking to Gilbert’s formulations
is that it is possible to interpret her use of terms like ‘intention’,
‘commitment’ and ‘obligation’ as having a specialized technical use. (We
thank an anonymous reviewer for this observation.) It is possible that
non-specialists will understand these terms in a way quite different
from what Gilbert intends. We acknowledge this potential limitation (and
will return to it in the discussion). To partially address this while
avoiding the pitfalls of deviating from Gilbert’s formulations, we
substituted a more colloquial formulation (i.e. ‘We will walk to the top
of the hill.’) in Experiment 2 to replace Gilbert’s technical term
‘intention’.</p>
<p>The question of what people think about joint action has special
significance for Gilbert’s view. It is not simply that support for
Gilbert’s view might be strengthened if non-philosophers turn out to
share her intuitions about joint action. Rather, Gilbert claims that the
agents of a joint action regard themselves as committed and obligated in
virtue of being such: ‘I take it as read here that the account [of joint
action] should be such that the parties to the shared intention will
understand that they have the stated obligations, and that they
understand that this is so as a matter of what a shared intention is’
(2009, p. 175). This means that Gilbert’s theory, as formulated, entails
that ordinary people connect shared intention, commitment and obligation
in the way that she does.</p>
<p>All three experiments were approved by the (EPKEB) United Ethical
Review Board for Research in Psychology, and carried out in accordance
with the Declaration of Helsinki. Participants were recruited from
Prolific Academic. There were no geographical restrictions; the
experiment was open to all prolific users over the age of 18. Each
participant received 60 pence for their participation. The
pre-registered study information can be found here:</p>
<ul>
<li><p><a
href="https://aspredicted.org/blind.php?x=dv67ap"><u>https://aspredicted.org/blind.php?x=dv67ap</u></a></p></li>
<li><p><a
href="https://aspredicted.org/blind.php?x=ix7qf9"><u>https://aspredicted.org/blind.php?x=ix7qf9</u></a></p></li>
<li><p><a
href="https://aspredicted.org/blind.php?x=dx3ss3"><u>https://aspredicted.org/blind.php?x=dx3ss3</u></a></p></li>
</ul>
<h1 id="experiment-1">2. Experiment 1</h1>
<p>In Experiment 1, we manipulated whether participants were considering
a description of joint intention with no complications (Baseline
Condition), a description of joint intention where the participants had
unilaterally and secretly decided they would abort the activity (Test
Condition), or a description involving individual, not joint, intention
(Parallel Condition). We presented three groups of participants
(<em>N</em> = 92; 35 female, 28 male, 29 unspecified<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>;
Mean age = 28.8, <em>SD</em> = 9.6) with the following three
vignettes:</p>
<p>Baseline Condition: Ned and Olive’s plan was to hike to the top of
the hill. They arrived at the hill and started up.  On the way, they
encountered Pam, who asked how far they intended to go. Olive said, ‘Our
intention is to hike to the top of the hill.’</p>
<p>Test Condition: Ned and Olive’s plan was to hike to the top of the
hill. They arrived at the hill and started up. As he told Olive later,
Ned realized early on that it would be too much for him to go all the
way to the top, and decided that he would only go half way. Though he
no longer had any intention of hiking to the top of the hill, he had as
yet said nothing about this to Olive, thinking it best to wait until he
and Olive were at least half way up before doing so. As it happens,
Olive was in the same position as Ned: she’d also decided that she would
not go all the way to the top of the hill, though she hadn’t yet
broached the subject with Ned. Before either of them got around to
raising this issue, they encountered Pam, who asked Olive how far they
intended to go. Olive said, ‘Our intention is to hike to the top of the
hill.’</p>
<p>Parallel Condition: Olive's plan was to hike to the top of the hill.
She arrived at the hill and started up. As she did so, she saw Ned ahead
of her on the path also hiking towards the top of the hill. At some
point along the way, she realized that it would be too much for her to
go all the way to the top, and decided that she would only go half way.
Along the way she ran into Ned sitting down and taking a break. Just
then Pam also appeared, who asked how far we intended to go. Olive said,
‘Our intention is to hike to the top of the hill.’</p>
<p>All participants were then presented with the following three
questions, each couched in Gilbert’s own terms in order to test her view
as directly as possible:</p>
<p>Shared Intention Question: “To what extent would you agree that
Olive’s statement to Pam at the end was accurate (i.e., ‘Our intention
is to hike to the top of the hill’)?”</p>
<p>Answers were given on a 5-point scale ranging from ‘Strongly
disagree’ to ‘Strongly agree’.</p>
<p>Commitment Question: “To what extent do you think that Ned and Olive
have a commitment to walk to the top of the hill?”</p>
<p>Answers were given on a 5-point scale ranging from ‘Strongly
disagree’ to ‘Strongly agree’.</p>
<p>Obligation Question: “To what extent do you think that Ned and Olive
have an obligation to walk to the top of the hill?”</p>
<p>Answers were given on a 5-point scale ranging from ‘Strongly agree’
to ‘Strongly disagree’.</p>
<p>We take Gilbert’s position to predict that, on each question, answers
in the baseline and test conditions should not differ, but that the test
and parallel conditions should differ; in particular, participants’
answers should be closer to ‘Strongly Agree’ in the test than in the
parallel condition.<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a> This is because, as mentioned above,
Gilbert holds that shared intentions entail both joint commitments and
obligations, so that both joint commitments and obligations are
established at the start of the scenario in the Baseline and Test
Conditions (but not the Parallel Condition); and also that shared
intentions, joint commitments and obligations cannot be unilaterally
rescinded.</p>
<p><em>Results</em></p>
<p>For the shared intention question, we performed a three-way Anova,
which revealed a significant effect of condition, <em>F</em> (2,87) =
25.1, <em>p</em> &lt; .001, ges= .37. We then performed post-hoc
pairwise comparisons using a Bonferroni correction (alpha = .017), which
revealed that responses in the test condition (<em>M</em>= 2.43) were
significantly lower than in the baseline condition (<em>M</em> = 4.56),
<em>t</em>(40.49) = 7.65, <em>p</em> &lt; .001, <em>d</em> = 1.94, and
also significantly lower than in the parallel condition (<em>M</em> =
2.86), <em>t</em>(50.89)=7 , <em>p</em> &lt;.001, <em>d</em> = 0.32.
This is diametrically opposed to the pattern which Gilbert’s position
would predict.</p>
<p>For the commitment question, we performed a three-way Anova, which
revealed a significant effect of condition, <em>F</em> (2,87) = 14.00,
<em>p</em> &lt; .001, ges = .24. We then performed post-hoc pairwise
comparisons using a Bonferroni correction (alpha = .017), which revealed
that responses in the test condition (<em>M</em> = 2.43) were
significantly lower than in the baseline condition (<em>M</em> = 4.08),
<em>t</em> (53) = 5.13, <em>p</em> &lt; .001, <em>d</em> = 1.36, but did
not differ significantly from the parallel condition (<em>M</em> =
2.89), <em>t</em> (57.98)= 1.49 , <em>p</em> =.14, <em>d</em> = 0.37.
This pattern is inconsistent with Gilbert’s analysis.</p>
<p>For the obligation question, we performed a three-way Anova, which
did not reveal a significant effect of condition, <em>F</em> (2,87) =
.31, <em>p</em> = .73. We may speculate that many participants found the
term ‘obligation’ to be too strong for such a casual instance of joint
action. One possibility is that, unlike Gilbert, they may not recognize
a role for a non-moral notion of obligation in joint action. Another
possibility is that participants do recognise a non-moral notion of
obligation but, again unlike Gilbert, would not use the term
‘obligation’ to express it.</p>
<p>Figure 1. Mean responses for all three test questions in Experiments
1-3. The error bars represent standard errors.</p>
<p><img
src="/public/img/articles/intuitions_about_joint_commitment/94ae8b6563c512628655f4a7d65d0087fcfe329bb8a003d4d5c818aeba326f78.jpg" /></p>
<p>Next, we performed a battery of simple linear regressions to predict
responses to the shared intention question based on responses to the
commitment question, to predict responses to the shared intention
question based on responses to the obligation question, and to predict
responses to the commitment question based on responses to the
obligation question. The rationale for this was that, on Gilbert’s
analysis, shared intentions entail commitments (joint commitments more
specifically) as well as obligations, so responses to these three test
questions should be highly correlated. TThese analyses are important
insofar as they provide a further opportunity to find support for
Gilbert’s view, one that does not depend on participants finding the
scenarios we used particularly compelling. To illustrate, if
participants agree that shared intentions entail commitments then we
would expect that their answers to the question about intention predict
their answers to the question about commitment. Even if participants
were confused by the scenarios or interpret them in some unintended way,
Gilbert’s view in any case leads us to predict significant regression
equations in all three cases. The results (for all three experiments),
are summarized in Table 1.</p>
<p>Table 1. Linear Regressions</p>
<p>Experiment 1</p>
<table style="width:98%;">
<colgroup>
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 15%" />
<col style="width: 9%" />
<col style="width: 14%" />
</colgroup>
<tbody>
<tr>
<td></td>
<td></td>
<td style="text-align: center;">Significant regression found?</td>
<td style="text-align: center;">Does Gilbert's analysis predict a
significant regression?</td>
<td style="text-align: left;"><em>F</em></td>
<td style="text-align: right;"><em>p</em></td>
<td style="text-align: right;"><em>r</em>-squared</td>
</tr>
<tr>
<td>Predictor response</td>
<td>Response predicted</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: left;"></td>
<td style="text-align: right;"></td>
<td style="text-align: right;"></td>
</tr>
<tr>
<td>commitment</td>
<td>shared intention</td>
<td style="text-align: center;">Y</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (88,1)=27.37</td>
<td style="text-align: right;">&lt;.001</td>
<td style="text-align: right;">.23</td>
</tr>
<tr>
<td>obligation</td>
<td>commitment</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (88,1)=0.28</td>
<td style="text-align: right;">.6</td>
<td style="text-align: right;">.003</td>
</tr>
<tr>
<td>obligation</td>
<td>shared intention</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (88,1)=0.10</td>
<td style="text-align: right;">.756</td>
<td style="text-align: right;">.001</td>
</tr>
</tbody>
</table>
<p>Experiment 2</p>
<table style="width:98%;">
<colgroup>
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 15%" />
<col style="width: 9%" />
<col style="width: 14%" />
</colgroup>
<tbody>
<tr>
<td></td>
<td></td>
<td style="text-align: center;">Significant regression found?</td>
<td style="text-align: center;">Does Gilbert's analysis predict a
significant regression?</td>
<td style="text-align: left;"><em>F</em></td>
<td style="text-align: left;"><em>p</em></td>
<td style="text-align: left;"><em>r</em>-squared</td>
</tr>
<tr>
<td>Predictor response</td>
<td>Response predicted</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td>commitment</td>
<td>shared intention</td>
<td style="text-align: center;">Y</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (89,1)=25.39</td>
<td style="text-align: left;">&lt;.001</td>
<td style="text-align: left;">.22</td>
</tr>
<tr>
<td>obligation</td>
<td>commitment</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (89,1)=0.2</td>
<td style="text-align: left;">.66</td>
<td style="text-align: left;">.002</td>
</tr>
<tr>
<td>obligation</td>
<td>shared intention</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (89,1)=0.80</td>
<td style="text-align: left;">.372</td>
<td style="text-align: left;">.008</td>
</tr>
</tbody>
</table>
<p>Experiment 3</p>
<table style="width:98%;">
<colgroup>
<col style="width: 14%" />
<col style="width: 14%" />
<col style="width: 15%" />
<col style="width: 15%" />
<col style="width: 16%" />
<col style="width: 7%" />
<col style="width: 15%" />
</colgroup>
<tbody>
<tr>
<td></td>
<td></td>
<td style="text-align: center;">Significant regression found?</td>
<td style="text-align: center;">Does Gilbert's analysis predict a
significant regression?</td>
<td style="text-align: left;"><em>F</em></td>
<td style="text-align: left;"><em>p</em></td>
<td style="text-align: left;"><em>r</em>-squared</td>
</tr>
<tr>
<td>Predictor response</td>
<td>Response predicted</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td>commitment</td>
<td>shared intention</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (61,1)=2.57</td>
<td style="text-align: left;">.114</td>
<td style="text-align: left;">.024</td>
</tr>
<tr>
<td>obligation</td>
<td>commitment</td>
<td style="text-align: center;">Y</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (61,1)=10.49</td>
<td style="text-align: left;">.002</td>
<td style="text-align: left;">.13</td>
</tr>
<tr>
<td>obligation</td>
<td>shared intention</td>
<td style="text-align: center;">N</td>
<td style="text-align: center;">Y</td>
<td style="text-align: left;"><em>F</em> (61,1)=0.39</td>
<td style="text-align: left;">.536</td>
<td style="text-align: left;">.001</td>
</tr>
</tbody>
</table>
<h1 id="experiment-2">3. Experiment 2</h1>
<p>In Experiment 2, we changed only the wording of the decisive
statement in the vignette ‘Our intention is to hike to the top of the
hill’, replacing it with ‘We will walk to the top of the hill.’ The
reason for this was that talk about intention is relatively uncommon and
may have made the task unnecessarily difficult for our participants. To
illustrate this possibility, we consulted a large collection of English
language corpora (https://www.english-corpora.org/iweb/). The phrase ‘we
will’ occurs roughly 220 times more frequently than ‘our intention’.
While not decisive, this led us to suspect that the more colloquial ‘we
will’ phrasing might reduce any variance due to participants’
uncertainty about intention. This change does not alter the predictions
which derive from Gilbert’s position.</p>
<p>The sample was made up of 91 participants (23 female, 39 male, 29
unspecified; Mean age = 25.1, <em>SD</em> = 8.1).</p>
<p><em>Results</em></p>
<p>For the shared intention question, we performed a three-way Anova,
which revealed a significant effect of condition, <em>F</em> (2,88) =
39.03, <em>p</em> &lt; .001, ges= .47. We then performed post-hoc
pairwise comparisons using a Bonferroni correction (alpha = .017), which
revealed that the test condition (<em>M</em>= 2.44) differed
significantly from the baseline condition (<em>M</em>= 4.50), <em>t</em>
(42.1) = 42.06, <em>p</em>&lt; .001, <em>d</em>= 2.11, but not from the
parallel condition (<em>M</em>= 2.71), <em>t</em>(52.5)=0.96 ,
<em>p</em>=.39, <em>d</em>= 0.23. This is opposite to the pattern which
Gilbert’s view predicts.</p>
<p>For the commitment question, we performed a three-way Anova, which
revealed a significant effect of condition, <em>F</em> (2,88) = 15.88,
<em>p</em> &lt; .001, ges= .27. We then performed post-hoc pairwise
comparisons using a Bonferroni correction (alpha = .017), which revealed
that responses in the test condition (<em>M</em>= 2.93) differed
significantly from the baseline condition (<em>M</em>= 4.19), <em>t</em>
(39.3) = 4.87, <em>p</em>&lt; .001, <em>d</em>= 1.33, but did not differ
significantly from the parallel condition (<em>M</em>= 3.00),
t<em>(</em>52.7)=0.23, <em>p</em>=.82, <em>d</em>= 0.62. Again, this is
opposite to the pattern which Gilbert’s view predicts.</p>
<p>For the obligation question, we performed a three-way Anova, which
did not reveal a significant effect of condition, <em>F</em> (2,88) =
0.06, <em>p</em> = .94. As noted above, we may speculate that many
participants found the term ‘obligation’ to be too strong for such a
casual instance of joint action.</p>
<p>As for Experiment 1, we performed a battery of simple linear
regressions to predict responses to the shared intention question based
on responses to the commitment question, to predict responses to the
shared intention question based on responses to the obligation question,
and to predict responses to the commitment question based on responses
to the obligation question (See Table 1).</p>
<h1 id="experiment-3">4. Experiment 3</h1>
<p>In order to probe the robustness of our findings, we conducted
Experiment 3 with new vignettes describing a different scenario (adapted
from Gilbert, 2014). We were concerned that in the hill walking scenario
implemented in Experiments 1 and 2, participants may have felt that
either agent could walk on alone, so that commitment was not critical.
The new scenario in Experiment 3 involved a higher degree of
interdependence.</p>
<p>The two groups of participants (<em>N</em> = 63; 23 female, 26 male,
14 unspecified; Mean age = 28.1, <em>SD</em> = 12.3) were presented with
the following vignettes:</p>
<p>Baseline Condition: Roz and Dan have decided to play a 5-set tennis
match on Tuesday morning. During the second set, their friend Phil
arrives and approaches the court to greet them. Roz tells him, ‘We are
playing a 5-set match.’</p>
<p>Test Condition: Roz and Dan have decided to play a 5-set tennis match
on Tuesday morning. Midway through the second set, Roz decides that she
has had enough tennis and is going to stop after the second set. As it
happens, Dan has the very same thought, but neither of them says
anything just yet. During the second set, their friend Phil arrives and
approaches the court to greet them. Roz tells him, ‘We are playing a
5-set match.’</p>
<p>In view of the higher degree of interdependence in this scenario, we
elected not to include a parallel condition.</p>
<p>We take Gilbert’s position to predict that the baseline and test
conditions should not differ. Any evidence that they do differ would
therefore present a challenge to her theory.</p>
<p><em>Results</em></p>
<p>We first performed a t-test for the shared intention question, which
revealed that the test condition (<em>M</em>= 3.47) did not differ
significantly from the baseline condition (<em>M</em>= 3.88), <em>t</em>
(52) = 1.30, <em>p</em> = .199, <em>d</em>= 0.33. This is consistent
with Gilbert’s view.</p>
<p>We then performed a t-test for the commitment question, which
revealed that responses in the test condition (<em>M</em>= 2.83) were
significantly lower than in the baseline condition (<em>M</em>= 3.70),
<em>t</em> (60) = 2.99, <em>p</em> = .004, <em>d</em>=0.73. Gilbert’s
view provides no reason to expect this.</p>
<p>Next, we performed a t-test for the obligation question, which
revealed that the test condition (M= 2.81) did not differ significantly
from the baseline condition (<em>M</em>= 2.70), <em>t</em> (57) = 0.30,
<em>p</em>= .767, <em>d</em>= 0.08. As noted above, we may speculate
that many participants found the term ‘obligation’ to be too strong for
such a casual instance of joint action.</p>
<p>As for Experiments 1 and 2, we performed a battery of simple linear
regressions to predict responses to the shared intention question based
on responses to the commitment question, to predict responses to the
shared intention question based on responses to the obligation question,
and to predict responses to the commitment question based on responses
to the obligation question (See Table 1).</p>
<h1 id="discussion">5. Discussion</h1>
<p>Attempts to establish which, if any, forms of commitment are
essential to, rather than merely commonly associated with, joint action
have so far been hampered by clashes of intuition. This may be due in
part to the way in which intuitions have been investigated—usually
through informal, unrepeatable observations. To improve the chance that
progress in adjudicating theories can be made by reflection on
intuitions, we adopted the more systematic approach of sampling
theoretically neutral, naive participants’ intuitions about
experimentally controlled scenarios. Indeed, this approach did reveal
significant patterns in participants’ responses. Some of these patterns
were consistent with predictions of Gilbert’s view about the role of
joint commitment in joint action. In line with her view, the results of
Experiments 1 and 2 revealed that participants’ judgements about
commitment predicted their judgements about expressions of intention,
although this was not the case for Experiment 3.</p>
<p>However, other key predictions we derived from Gilbert’s view were
unsupported and, in some cases, even falsified. In particular,
participants’ judgments about obligations did not predict their
judgments about commitment in Experiments 1 and 2; although they did in
Experiment 3. Further, for the three questions in Experiments 1 and 2,
Gilbert’s view provides a reason to predict a difference between cases
in which there is a joint plan, but individual intentions not to fulfil
the plan (test condition), and cases in which there is uncontroversially
no joint plan at all (parallel condition). But we did not find any such
difference. Relatedly, for the three questions in all experiments,
Gilbert’s view provides a reason to predict no difference between cases
in which there is a joint plan but individual intentions not to fulfil
the plan (test condition), and cases in which there is uncontroversially
a shared intention. Yet we did observe very large significant
differences for the shared intention question in Experiments 1 and 2,
and for the commitment question in all three experiments. Overall, these
results indicate that a less informal approach to sampling naive
participants’ intuitions about examples does not support Gilbert’s view
on commitment and joint action.</p>
<p>Moreover, it is worth highlighting once more that our findings are
problematic for Gilbert not only because they reveal that the intuitions
on which she bases her theory are not widely shared. If this were the
case, it would be possible to dismiss the results on the grounds that
naïve participants’ intuitions are irrelevant to a philosophical
analysis. But, as we mentioned earlier, there is an additional problem:
Gilbert’s theory positively stipulates that people do understand the
relationship between shared intention, commitment and obligation in the
way she has spelled out, and that their having this understanding is
part of their capacity to have shared intentions (2009, p. 175). Of
course this problem could be avoided by revising Gilbert’s view in such
a way as to eliminate this requirement.</p>
<p>Should we therefore reject Gilbert’s view? We believe that it would
be premature to draw any firm conclusions. For one thing, we must be
cautious in drawing inferences from a narrow range of scenarios. While
it is significant that the scenarios Gilbert herself introduces to
support her view do not appear to generate the intuitions she predicts,
it remains possible that other scenarios could generate different
intuitions. In this vein, Löhr (2022) has suggested that cross-cultural
research could be helpful in teasing apart subtle differences in
people’s attitudes towards obligations.</p>
<p>But even assuming, in line with our findings, that the agents of a
joint action do not explicitly link shared intention, commitment and
obligation in the way Gilbert suggests, there are at least three
possibilities which our findings cannot rule out. One is that the
concepts are linked despite lay people’s failure to appreciate the links
without philosophical training. Another, perhaps related possibility is
that there are implicit connections among intention, commitment and
obligation; if so, implicit measures could yield a different picture
(Bonalumi et al, 2019; 2022).<a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a> Finally, we must
acknowledge that aspects of Gilbert’s view may survive even if some
details are wrong. For instance, in our experiments both parties to the
joint action unilaterally rescinded. Gilbert may be wrong that this is
impossible but still correct that just one of the parties cannot
unilaterally rescind.</p>
<p>To conclude with a methodological point, the current study
complements recent research suggesting that intuitions alone, even when
drawn systematically from a large sample, fail to adjudicate between
competing views about the role of commitment in joint action
(Gomez-Lavin and Rachar 2019; 2021).<a href="#fn6" class="footnote-ref"
id="fnref6" role="doc-noteref"><sup>6</sup></a> Looking more broadly,
there is also reason to doubt that intuitions alone can settle questions
about the nature of knowledge (e.g. Starmans and Friedman 2012; 2013).
Overall, our complex pattern of findings indicates that intuitions are
no better as a basis for theorising about joint action.</p>


<h1>References</h1>
<p>Baier, Annette C. 1997. “Doing Things with Others: The Mental
Commons.” In <em>Commonality and Particularity in Ethics</em>, edited by
Lilli Alanen, Sarah Heinamaa, and Thomas Wallgren, 15–44. Palgrave
Macmillan. <a
href="https://doi.org/10.1007/978-1-349-25602-0_2"><u>https://doi.org/10.1007/978-1-349-25602-0_2</u></a>.</p>
<p>Blomberg, Olle. 2016. “Common Knowledge and Reductionism About Shared
Agency.” <em>Australasian Journal of Philosophy</em> 94 (2): 315–26. <a
href="https://doi.org/10.1080/00048402.2015.1055581"><u>https://doi.org/10.1080/00048402.2015.1055581</u></a>.</p>
<table style="width:97%;">
<colgroup>
<col style="width: 97%" />
</colgroup>
<tbody>
<tr>
<td style="text-align: left;">Bonalumi, Francesca, Margherita Isella,
and John Michael. "Cueing implicit commitment." <em>Review of Philosophy
and Psychology</em> 10.4 (2019): 669-688.</td>
</tr>
</tbody>
</table>
<p>Bonalumi, Francesca, John Michael, and Christophe Heintz. "Perceiving
commitments: When we both know that you are counting on me." <em>Mind
&amp; Language</em> 37.4 (2022): 502-524.</p>
<p>Bratman, Michael E. 1997. “I Intend That We J.” In <em>Contemporary
Action Theory, Volume 2: Social Action</em>, edited by Raimo Tuomela and
Ghita Holmstrom-Hintikka. Dordrecht: Kluwer.</p>
<p>———. 2014. <em>Shared Agency: A Planning Theory of Acting
Together</em>. Oxford: Oxford University Press. <a
href="http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199897933.001.0001"><u>http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199897933.001.0001</u></a>.</p>
<p>Brooks, D. H. M. 1981. “Joint Action.” <em>Mind</em>, New series, 90
(357): 113–19. <a
href="http://www.jstor.org/stable/2253670"><u>http://www.jstor.org/stable/2253670</u></a>.</p>
<p>Brownell, Celia A. 2011. “Early Developments in Joint Action.”
<em>Review of Philosophy and Psychology</em> 2: 193–211.<a
href="https://doi.org/10.1007/s13164-011-0056-1"><u>https://doi.org/10.1007/s13164-011-0056-1</u></a>.</p>
<p>Carpenter, Malinda. 2009. “Just How Joint Is Joint Action in
Infancy?” <em>Topics in Cognitive Science</em> 1 (2): 380–92.</p>
<p>Gallotti, Mattia. 2011. “A Naturalistic Argument for the
Irreducibility of Collective Intentionality.” <em>Philosophy of the
Social Sciences</em> 20 (10): 3–30. <a
href="https://doi.org/10.1177/0048393111426864"><u>https://doi.org/10.1177/0048393111426864</u></a>.</p>
<p>Gallotti, Mattia, and Chris D. Frith. 2013. “Social Cognition in the
We-Mode.” <em>Trends in Cognitive Sciences</em> 17 (4): 160–65. <a
href="https://doi.org/10.1016/j.tics.2013.02.002"><u>https://doi.org/10.1016/j.tics.2013.02.002</u></a>.</p>
<p>Gilbert, M. 1990. Walking together: A paradigmatic social
phenomenon. <em>MidWest studies in philosophy</em>, <em>15</em>,
1-14.</p>
<p>———. 2009. “Shared Intention and Personal Intentions.”
<em>Philosophical Studies</em> 144 (1): 167–87.<a
href="https://doi.org/10.1007/s11098-009-9372-z"><u>https://doi.org/10.1007/s11098-009-9372-z</u></a>.</p>
<p>———. 2010. “Collective Action.” In <em>A Companion to the Philosophy
of Action</em>, edited by Timothy O’Connor and Constantine Sandis,
67–73. Oxford: Blackwell.</p>
<p>———. 2013. <em>Joint Commitment: How We Make the Social World</em>.
Oxford: Oxford University Press. <a
href="http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199970148.001.0001"><u>http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199970148.001.0001</u></a>.</p>
<p>Gold, Natalie, and Robert Sugden. 2007. “Collective Intentions and
Team Agency.” <em>Journal of Philosophy</em> 104 (3): 109–37.</p>
<p>Gomez‐Lavin, Javier, and Matthew Rachar. "Normativity in joint
action." <em>Mind &amp; Language</em> 34.1 (2019): 97-120.</p>
<p>Gomez-Lavin, Javier, and Matthew Rachar. "Why we need a new
normativism about collective action." <em>The Philosophical
Quarterly</em>72.2 (2022): 478-507.</p>
<p>Helm, Bennett W. 2008. “Plural Agents.” <em>Nous</em> 42 (1): 17–49.
<a
href="https://doi.org/10.1111/j.1468-0068.2007.00672.x"><u>https://doi.org/10.1111/j.1468-0068.2007.00672.x</u></a>.</p>
<p>Knoblich, Günther, Stephen A. Butterfill, and Natalie Sebanz. 2011.
“Psychological Research on Joint Action: Theory and Data.” In
<em>Psychology of Learning and Motivation</em>, edited by</p>
<p>Brian Ross, 51:59–101. San Diego, CA: Academic Press.</p>
<p>Löhr, G. “Recent Experimental Philosophy on Joint Action: Do We Need
a New Normativism About Collective Action?”, <em>The Philosophical
Quarterly</em>, Volume 72, Issue 3, July 2022, 754–762. <a
href="https://doi.org/10.1093/pq/pqab070"
class="uri">https://doi.org/10.1093/pq/pqab070</a></p>
<p>Longworth, Guy. 2019. “Sharing Non-Observational Knowledge.”
<em>Inquiry</em> 0 (0): 1–21.<a
href="https://doi.org/10.1080/0020174X.2019.1680430"><u>https://doi.org/10.1080/0020174X.2019.1680430</u></a>.</p>
<p>Ludwig, Kirk. 2016. <em>From Individual to Plural Agency: Collective
Action</em>. Oxford University Press.</p>
<p>Meyer, Marlene, Robrecht P. R. D. van der Wel, and Sabine Hunnius.
2016. “Planning My Actions to Accommodate Yours: Joint Action
Development During Early Childhood.” <em>Phil. Trans. R. Soc. B</em> 371
(1693): 20150371.<a
href="https://doi.org/10.1098/rstb.2015.0371"><u>https://doi.org/10.1098/rstb.2015.0371</u></a>.</p>
<p>Michael, J., Sebanz, N., &amp; Knoblich, G. (2016). Observing joint
action: Coordination creates
commitment. <em>Cognition</em>, <em>157</em>, 106-113.</p>
<p>Pacherie, Elisabeth. 2010. “The Phenomenology of Joint Action:
Self-Agency Vs. Joint-Agency.” In <em>Joint Action</em>, edited by Axel
Seemann. MIT Press.</p>
<p>———. 2012. “Intentional Joint Agency: Shared Intention Lite.”
<em>Synthese</em> forthcoming.</p>
<p>———. 2013. “Intentional Joint Agency: Shared Intention Lite.”
<em>Synthese</em> 190 (10): 1817–39.<a
href="https://doi.org/10.1007/s11229-013-0263-7"><u>https://doi.org/10.1007/s11229-013-0263-7</u></a>.</p>
<p>Pettit, Philip, and David Schweikard. 2006. “Joint Actions and Group
Agents.” <em>Philosophy of the Social Sciences</em> 36 (1): 18–39. <a
href="https://doi.org/10.1177/0048393105284169"><u>https://doi.org/10.1177/0048393105284169</u></a>.</p>
<p>Roth A (2004) Shared agency and contralateral commitments. Philos Rev
113(3):359–410</p>
<p>Sacheli, Lucia Maria, Elisa Arcangeli, and Eraldo Paulesu. 2018.
“Evidence for a Dyadic Motor Plan in Joint Action.” <em>Scientific
Reports</em> 8 (1): 5027. <a
href="https://doi.org/10.1038/s41598-018-23275-9"><u>https://doi.org/10.1038/s41598-018-23275-9</u></a>.</p>
<p>Schmid, Hans Bernhard. 2008. “Plural Action.” <em>Philosophy of the
Social Sciences</em> 38 (1): 25–54.<a
href="https://doi.org/10.1177/0048393107310877"><u>https://doi.org/10.1177/0048393107310877</u></a>.</p>
<p>———. 2009. <em>Plural Action: Essays in Philosophy and Social
Science</em>. Vol. 58. Dordrecht: Springer.</p>
<p>Searle, John R. 1990. “Collective Intentions and Actions.” In
<em>Intentions in Communication</em>, edited by P. Cohen, J. Morgan, and
M. E. Pollack, 90–105. Cambridge: Cambridge University Press.</p>
<p>Sebanz, Natalie, Harold Bekkering, and Günther Knoblich. 2006. “Joint
Action: Bodies and Mind Moving Together.” <em>Trends in Cognitive
Sciences</em> 10 (2): 70–76.</p>
<p>Starmans, Christina, and Ori Friedman. 2012. “The Folk Conception of
Knowledge.” <em>Cognition</em> 124 (3): 272–83.<a
href="https://doi.org/10.1016/j.cognition.2012.05.017"><u>https://doi.org/10.1016/j.cognition.2012.05.017</u></a>.</p>
<p>———. 2013. “Taking ‘Know’ for an Answer: A Reply to Nagel, San Juan,
and Mar.” <em>Cognition</em> 129 (3): 662–65.<a
href="https://doi.org/10.1016/j.cognition.2013.05.009"><u>https://doi.org/10.1016/j.cognition.2013.05.009</u></a>.</p>
<p>Tollefsen, Deborah. 2005. “Let’s Pretend: Children and Joint Action.”
<em>Philosophy of the Social Sciences</em> 35 (75): 74–97.</p>
<p>Tollefsen, D., Kreuz, R., and Dale, R. (2014). Flavors of
“Togetherness”. In Lombrozo, T., Knobe, J., and Nichols, S., editors,
<em>Oxford Studies in Experimental Philosophy</em>, volume 1, pages 232–
252. Oxford: OUP.</p>
<p>Tuomela, R. 2000. <em>Cooperation: A Philosophical Study</em>.
Amsterdam: Springer Science &amp; Business Media.</p>
<p>Tuomela, Raimo, and Kaarlo Miller. 1985. “We-Intentions and Social
Action.” <em>Analyse &amp; Kritik</em> 7 (1): 26–43. <a
href="https://doi.org/10.1515/auk-1985-0102"><u>https://doi.org/10.1515/auk-1985-0102</u></a>.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>A variety of labels have been used for what we are
calling ‘joint action’. These include ‘joint action’ (Brooks 1981;
Sebanz, Bekkering, and Knoblich 2006; Knoblich, Butterfill, and Sebanz
2011; Tollefsen 2005; Pettit and Schweikard 2006; Carpenter 2009;
Pacherie 2010; Brownell 2011; Sacheli, Arcangeli, and Paulesu 2018;
Meyer, Wel, and Hunnius 2016), ‘social action’ (Tuomela and Miller
1985), ‘collective action’ (Searle 1990; Gilbert 2010), ‘joint activity’
(Baier 1997), ‘acting together’ (Tuomela 2000), ‘shared intentional
activity’ (Bratman 1997), ‘plural action’ (Schmid 2008), an exercise of
‘joint agency’ (Pacherie 2013) or of ‘small scale shared agency’
(Bratman 2014), ‘intentional joint action’ (Blomberg 2016), ‘collective
intentional behavior’ (which is an exercise of ‘plural agency’) (Ludwig
2016), and ‘collective activity’ (Longworth 2019). We leave open whether
these are all labels for a single thing or whether different researchers
are targeting different things. We use the term ‘joint action’ for the
targets of Gilbert's analysis. We avoid potentially controversial
assumptions about exactly what these targets are because we have
implemented joint action scenarios devised by Gilbert to illustrate her
view.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Note that Gilbert is careful to acknowledge that the
obligations in question may not be of a moral nature, and that they may
be outweighed by moral obligations.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>This high number of unspecified responses was due to
experimenter error – i.e. this question was not administered to these 27
participants.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>We note that the views of opponents of Gilbert, such as
Bratman, do not generate relevant predictions which are distinct from
these. This is because they may allow that commitments are commonly
associated with joint action even though not essential (see Bratman
2014, pp. 110–1 for discussion) and because our Commitment Question is
formulated in a broad way and does not specify an irreducibly joint
commitment. Despite this, we chose to not formulate the Commitment
Question in terms of an irreducibly joint commitment because we were
concerned that doing so would require terminology that may be unfamiliar
to our participants. Thus the weaker formulation gives us the best
chance of confirming the predictions derived from Gilbert’s position
while admittedly limiting the strength of the conclusions we could draw
from their confirmation.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>It is worth noting that Michael et al (2016) found a
dissociation between perceived commitment and obligation using implicit
measures. However they did not explicitly contrast parallel with joint
action.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Although these authors endorse a stronger conclusion on
the basis of their findings (compare Gomez-Lavin and Rachar 2019,
p. 119: ‘our common intuitions are in line with a general form of the
normativist thesis …’), we are more cautious: first, because their
indicators of normativity appear as strongly present in cases of minimal
interaction as in paradigm joint actions (contra to what we suppose
either Bratman or Gilbert might predict); and second, because their
experiments are not designed to distinguish the normativist thesis from
Bratman’s competing view that norms are merely contingently associated
with acting together.<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</div>

---

Title: Joint Action and Development
Authors: Stephen A. Butterfill
Year: 2011
Journal: Philosophical Quarterly
Type: Publication

## Abstract

Given the premise that joint action plays some role in explaining how humans come to understand minds, what could joint action be? Not what a leading account, Michael Bratman&#39;s, says it is. For on that account engaging in joint action involves sharing intentions and sharing intentions requires much of the understanding of minds whose development is supposed to be explained by appeal to joint action. This paper therefore offers an account of a different kind of joint action, an account compatible with the premise about development. The new account is no replacement for the leading account; rather the accounts characterise two kinds of joint action. Where the kind of joint characterised by the leading account involves shared intentions, the new account characterises a kind of joint action involving shared goals.

<h3 class="likesectionHead"><a id="x1-1000" name="x1-1000"></a>Contents</h3>

      <div class="tableofcontents">
        <span class="sectionToc">1 <a href="#x1-20001" id="QQ2-1-2" name="QQ2-1-2">The
        Question</a></span><br />
        <span class="sectionToc">2 <a href="#x1-30002" id="QQ2-1-3" name="QQ2-1-3">What
        is joint action? The leading account</a></span><br />
        <span class="sectionToc">3 <a href="#x1-40003" id="QQ2-1-4" name="QQ2-1-4">Why
        shared intentional activity could not significantly foster an understanding of
        minds</a></span><br />
        <span class="sectionToc">4 <a href="#x1-50004" id="QQ2-1-5" name=
        "QQ2-1-5">Joint action, shared intention and coordinated
        planning</a></span><br />
        <span class="sectionToc">5 <a href="#x1-60005" id="QQ2-1-6" name=
        "QQ2-1-6">Plural activities</a></span><br />
        <span class="sectionToc">6 <a href="#x1-70006" id="QQ2-1-7" name="QQ2-1-7">What
        is the function of shared goals?</a></span><br />
        <span class="sectionToc">7 <a href="#x1-80007" id="QQ2-1-8" name=
        "QQ2-1-8">Which states could realise shared goals?</a></span><br />
        <span class="sectionToc">8 <a href="#x1-90008" id="QQ2-1-9" name=
        "QQ2-1-9">Shared goals characterise one form of joint action</a></span><br />
        <span class="sectionToc">9 <a href="#x1-100009" id="QQ2-1-10" name=
        "QQ2-1-10">Conclusion</a></span>
      </div><!--l. 49-->

      <p class="indent">&nbsp; <a id="x1-1001r1" name="x1-1001r1"></a></p>

      <h3 class="sectionHead"><span class="titlemark">1.</span> <a id="x1-20001" name=
      "x1-20001"></a>The Question</h3><!--l. 54-->

      <p class="noindent">On the assumption that joint action plays some role in
      explaining how humans develop an understanding of minds, what could joint action
      be? This question needs a little background. It is quite widely agreed that human
      adults reflections on thoughts and actions, their own and others, involve a range
      of commonsense psychological concepts including belief, desire, intention,
      knowledge and perception. Childrens abilities to deploy these concepts improve in
      fluency and sophistication over more than three years (e.g.&nbsp;<a href=
      "#Xen_610">Bartsch &amp; Wellman</a>&nbsp;<a href="#Xen_610">1995</a>). Several
      psychologists have claimed that children first engage in joint action from around
      their first birthday and that engaging in joint action facilitates these early
      improvements (<a href="#Xen_1198">Moll &amp; Tomasello</a>&nbsp;<a href=
      "#Xen_1198">2007</a>;&nbsp;<a href="#Xen_1421">Tomasello &amp;
      Carpenter</a>&nbsp;<a href="#Xen_1421">2007</a>;&nbsp;<a href=
      "#Xen_1090">Tomasello et&nbsp;al.</a>&nbsp;<a href=
      "#Xen_1090">2005</a>;&nbsp;<a href="#Xen_557">Tomasello &amp;
      Rakoczy</a>&nbsp;<a href="#Xen_557">2003</a>). Joint actions that young children
      engage in include tidying up the toys together (<a href="#Xen_1204">Behne
      et&nbsp;al.</a>&nbsp;<a href="#Xen_1204">2005</a>), cooperatively pulling handles
      in sequence to make a dog-puppet sing (<a href="#Xen_1679">Brownell
      et&nbsp;al.</a>&nbsp;<a href="#Xen_1679">2006</a>), bouncing a ball on a large
      trampoline together (<a href="#Xen_1421">Tomasello &amp;
      Carpenter</a>&nbsp;<a href="#Xen_1421">2007</a>) and pretending to row a boat
      together. The psychologists claim that engaging in joint actions like these plays
      some role in the early development of abilities to use concepts like belief,
      desire, intention, knowledge and perception, and in the development of higher
      forms of cognition more generally. My question is what joint action could be
      given that some version of this claim is true.</p><!--l. 56-->

      <p class="indent">The question arises because a leading account of joint action,
      Michael Bratman's, is incompatible with the premise. To anticipate what is
      explained in detail below, on the leading account engaging in joint action
      requires sharing intentions, and sharing intentions requires abilities to engage
      in reasoning about propositional attitudesreasoning of just the sort whose
      development was supposed to be explained by engaging in joint action. So if the
      leading account were the whole truth about joint action, engaging in joint action
      would presuppose, and therefore could not explain, much of the development of
      reasoning about others mental states. Given that the premise is true, the leading
      account cannot be the whole truth about joint action. We need a further account
      of joint action, one that is compatible with the premise that joint action plays
      a role in explaining how humans develop abilities to think about minds and
      actions. Sections 4 to 8 provide such an account. Before that, Section 2 outlines the
      leading account of joint action and Section 3 explains why this account is
      incompatible with the premise about development. <a id="x1-2001r2" name=
      "x1-2001r2"></a></p>

      <h3 class="sectionHead"><span class="titlemark">2.</span> <a id="x1-30002" name=
      "x1-30002"></a>What is joint action? The leading account</h3><!--l. 61-->

      <p class="noindent">Philosophers paradigm cases of joint action include painting
      the house together (Michael Bratman), lifting a heavy sofa together (David
      Velleman), preparing a hollandaise sauce together (John Searle), going to Chicago
      together (Christopher Kutz), and walking together (Margaret Gilbert). One aim of
      an account of joint action is to identify features of some or all of these cases
      in virtue of which they count as joint actions. In this paper I focus on Michael
      Bratman's account because, despite the clarity of its presentation, no decisive
      objection to the parts of his account outlined below has yet been published, and
      also because this account has been most influential in psychology.<span class=
      "footnote-mark"><a href="#fn1x0" id="fn1x0-bk" name="fn1x0-bk"><sup class=
      "textsuperscript">1</sup></a></span><a id="x1-3001f1" name="x1-3001f1"></a></p>
      <!--l. 71-->

      <p class="indent">Bratman characterises a kind of joint action he calls shared
      intentional activity, which is activity explainable by shared
      intention.<span class="footnote-mark"><a href="#fn2x0" id="fn2x0-bk" name=
      "fn2x0-bk"><sup class="textsuperscript">2</sup></a></span><a id="x1-3002f2" name=
      "x1-3002f2"></a> This immediately leads to the question of what shared intentions
      are. Bratman's answer has two parts, a specification of the functional role shared
      intentions play and a substantial account of what shared intentions could be. On
      the first part, Bratman stipulates that the functional role of shared intentions
      is to:</p>

      <div class="quote">
        <!--l. 74-->

        <p class="noindent">(i) coordinate activities; (ii) coordinate planning; and
        (iii) provide a framework to structure bargaining (<a href=
        "#Xen_1356">Bratman</a>&nbsp;<a href="#Xen_1356">1993</a>, p.&nbsp;99).</p>
      </div><!--l. 77-->

      <p class="noindent">To illustrate: if we share an intention that we cook dinner,
      this shared intention will (iii) structure bargaining insofar as we may need to
      decide what to cook or how to cook it on the assumption that we are cooking it
      together; the shared intention will also require us to (ii) coordinate our
      planning by each bringing complementary ingredients and tools, and to (i)
      coordinate our activities by preparing the ingredients in the right order.</p>
      <!--l. 79-->

      <p class="indent">Given this claim about what shared intentions are for, Bratman
      argues that the following three conditions are collectively
      sufficient<span class="footnote-mark"><a href="#fn3x0" id="fn3x0-bk" name=
      "fn3x0-bk"><sup class="textsuperscript">3</sup></a></span><a id="x1-3003f3" name=
      "x1-3003f3"></a> for you and I to have a shared intention that we J. This is his
      substantial account of what shared intentions could be:</p>

      <div class="quote">
        <!--l. 83-->

        <p class="noindent">1. (a) I intend that we J and (b) you intend that we J</p>
        <!--l. 85-->

        <p class="noindent">2. I intend that we J in accordance with and because of la,
        lb, and meshing subplans of la and lb; you intend that we J in accordance with
        and because of la, lb, and meshing subplans of la and lb</p><!--l. 87-->

        <p class="noindent">3. 1 and 2 are common knowledge between us (<a href=
        "#Xen_1356">Bratman</a>&nbsp;<a href="#Xen_1356">1993</a>, p.&nbsp;View 4)</p>
      </div><!--l. 90-->

      <p class="noindent">In arguing that these are collectively sufficient conditions
      for shared intention, Bratman combines two strategies. He argues that these
      conditions collectively suffice to rule out certain cases where, intuitively,
      there is no shared intention (such as the case where we each intend to paint the
      house, I yellow and you blue). And he argues that the attitudes specified in
      these conditions are collectively capable of playing the three roles shared
      intentions are supposed to play. <a id="x1-3004r3" name="x1-3004r3"></a></p>

      <h3 class="sectionHead"><span class="titlemark">3.</span> <a id="x1-40003" name=
      "x1-40003"></a>Why shared intentional activity could not significantly foster an
      understanding of minds</h3><!--l. 96-->

      <p class="noindent">Suppose that joint action plays a role in explaining the
      early development of childrens abilities to think about minds. Is Michael
      Bratman's shared intentional activity a notion of joint action which could play
      this role? Several psychologists have suggested that it is. Thus Moll and
      Tomasello explicate their hypothesis that the unique aspects of human cognition
      were driven by, or even constituted by social cooperation (<a href=
      "#Xen_1198">2007</a>, p.&nbsp;3) by appeal to a modified version of Bratman's
      (1992) definition of shared cooperative activities [on which] the participants in
      the cooperative activity share a joint goal (<a href="#Xen_1198">2007</a>,
      p.&nbsp;3); in this context share a joint goal means possess a shared intention.
      Similarly, Carpenter, in a discussion of joint action in infancy, writes:</p>

      <div class="quote">
        <!--l. 99-->

        <p class="noindent">I will adopt Bratman's (1992) influential formulation of
        joint action [F]or an activity to be considered shared or joint each partner
        needs to intend to perform the joint action together in accordance with and
        because of meshing subplans (p. 338) and this needs to be common knowledge
        between the participants. (<a href="#Xen_1682">Carpenter</a>&nbsp;<a href=
        "#Xen_1682">2009</a>, p.&nbsp;281)</p>
      </div><!--l. 102-->

      <p class="noindent">Others who appeal to Bratman's notion of shared intentional
      activity in characterising childrens first joint actions and their role in
      development include <a href="#Xen_1090">Tomasello et&nbsp;al.</a>&nbsp;(<a href=
      "#Xen_1090">2005</a>, p.&nbsp;680) and <a href=
      "#Xen_1365">Gr&acirc;&euro;&deg;fenhain et&nbsp;al.</a>&nbsp;(<a href=
      "#Xen_1365">2009</a>, p.&nbsp;1430).</p><!--l. 104-->

      <p class="indent">Recall that shared intentional activity requires shared
      intentions. On Bratman's substantial account, sharing intentions requires having
      intentions about intentions and even intentions about subplans of intentions (see
      Condition 2 in the quote on the preceding page). Bratman emphasises this feature
      of the account:</p>

      <div class="quote">
        <!--l. 107-->

        <p class="noindent">each agent does not just intend that the group perform the
        [] joint action. Rather, each agent intends as well that the group perform this
        joint action in accordance with subplans (of the intentions in favor of the
        joint action) that mesh (<a href="#Xen_1197">Bratman</a>&nbsp;<a href=
        "#Xen_1197">1992</a>, p.&nbsp;332).</p>
      </div><!--l. 110-->

      <p class="noindent">A natural thought at this point is that joint action might
      require only plans which <span class="cmti-12">in fact</span> mesh rather than
      <span class="cmti-12">intentions about</span> the meshing of plans. Bratman
      considers this option and explains why this weakening of his account is not
      coherent (<a href="#Xen_1197">Bratman</a>&nbsp;<a href="#Xen_1197">1992</a>,
      pp.&nbsp;331-3), so I shall not pursue this thought.</p><!--l. 112-->

      <p class="indent">The fact that shared intentions require intentions about
      intentions suggests a potential objection to the view that shared intentional
      activity explains early developments in childrens abilities to think about minds.
      For it seems unlikely that 2- and 3-year-olds, who according to many findings are
      years away from being able to ascribe any propositional attitudes at
      all,<span class="footnote-mark"><a href="#fn4x0" id="fn4x0-bk" name=
      "fn4x0-bk"><sup class="textsuperscript">4</sup></a></span><a id="x1-4001f4" name=
      "x1-4001f4"></a> can form intentions about others intentions.<span class=
      "footnote-mark"><a href="#fn5x0" id="fn5x0-bk" name="fn5x0-bk"><sup class=
      "textsuperscript">5</sup></a></span><a id="x1-4002f5" name="x1-4002f5"></a> This
      would mean they cannot meet the sufficient conditions Bratman lays out for
      sharing intentions.</p><!--l. 123-->

      <p class="indent">This potential objection is weak because it depends on
      controversial empirical claims about the absolute time in development at which
      abilities to ascribe, and to form intentions about, intentions might emerge. A
      more promising objection avoids this dependence. The ability to form intentions
      about intentions involves a sophisticated kind of propositional attitude
      ascription (as explained below). This ability is required for sharing intentions
      in accordance with Bratman's substantial account. So meeting the sufficient
      conditions for joint action given by this account could not significantly
      <span class="cmti-12">explain</span> the development of an understanding of minds
      because it already <span class="cmti-12">presupposes</span> too much
      sophistication in the use of psychological concepts.<span class=
      "footnote-mark"><a href="#fn6x0" id="fn6x0-bk" name="fn6x0-bk"><sup class=
      "textsuperscript">6</sup></a></span><a id="x1-4003f6" name="x1-4003f6"></a></p>
      <!--l. 125-->

      <p class="indent">Note that, as it stands, this objection does not establish
      much. It concerns conditions imposed by the substantial account of shared
      intention which are sufficient but not necessary conditions.<span class=
      "footnote-mark"><a href="#fn7x0" id="fn7x0-bk" name="fn7x0-bk"><sup class=
      "textsuperscript">7</sup></a></span><a id="x1-4004f7" name="x1-4004f7"></a> The
      substantial account is supposed to characterise oneperhaps one among manyways in
      which the functional role of shared intentions can be realised. So the objection
      serves only to raise a question. Are there in fact alternative sufficient
      conditions for shared intention, conditions that can be met without already
      having abilities to use psychological concepts whose development was supposed to
      be explained by joint action?</p><!--l. 131-->

      <p class="indent">The answer to this question is not entirely straightforward. We
      must begin with the functional roles of shared intention, for these provide
      necessary conditions. One of the roles of shared intentions is to coordinate
      planning. What does coordinating planning involve? Intuitively the idea is that
      just as individual intentions serve to coordinate an individuals planning over
      time, so shared intentions coordinate planning between agents. (I use the terms
      individual intention and individual goal to refer to intentions and goals
      explanatory of individual actions; an individual action is an action performed by
      just one agent such as that described by the sentence Ayesha repaired the
      puncture all by herself.) A second role for shared intentions is to structure
      bargaining concerning plans. To understand these roles it is essential to
      understand what planning means in this context. The term planning is sometimes
      used quite broadly to encompass processes involved in low-level control over the
      execution of sequences of movements, as is often required for manipulating
      objects manually (e.g.&nbsp;<a href="#Xen_1535">Haggard</a>&nbsp;<a href=
      "#Xen_1535">1998</a>), as well as processes controlling the movements of a limb
      on a single trajectory (e.g.&nbsp;<a href="#Xen_1681">Bizzu</a>&nbsp;<a href=
      "#Xen_1681">2001</a>). In Bratman's account and this paper, the term planning is
      used in a narrower sense. Planning in this narrow sense exists to coordinate an
      agents various activities over relatively long intervals of time; it involves
      practical reasoning and forming intentions which may themselves require further
      planning, generating a hierachy of plans and subplans. Paradigm cases include
      planning a birthday party or planning to move house.</p><!--l. 133-->

      <p class="indent">Given the functional roles of shared intention, when (if ever)
      must the states which realise shared intentions include intentions about others
      intentions? Coordinating plans with others does not seem always or in principle
      to require specific intentions about others intentions. It is plausible that in
      everyday life some of our plans are coordinated largely thanks to a background of
      shared preferences, habits and conventions. Consider, for example, people who
      often meet in a set place at a fixed time of day to discuss research over lunch.
      These people can coordinate their lunch plans merely by setting a date and
      following established routine; providing nothing unexpected happens, they seem
      not to need intentions about each others intentions. Within limits, then,
      coordinating plans may not always require intentions about intentions. The same
      may hold for structuring bargaining. But when the background of shared
      preferences, habits and conventions is not sufficient to ensure that our plans
      will be coordinated, it is necessary to monitor or manipulate others plans. And
      since intentions are the basic elements of plans (in the special sense of plan in
      terms of which Bratman defined shared intention), this means monitoring or
      manipulating others intentions. The background which makes for effortlessly
      coordinated planning is absent when our aims are sufficiently novel, when the
      circumstances sufficiently unusual (as in many emergencies), and when our
      co-actors are sufficiently unfamiliar. In all of these cases, coordinating plans
      and structuring bargaining will involve monitoring or manipulating others
      intentions. Now this does not necessarily involve forming intentions about their
      intentions because, in principle, monitoring and manipulating others intentions
      could (within limits) be achieved by representing states which serve as proxies
      for intentions rather than by representing intentions as such, much as one can
      (within limits) monitor and manipulate others visual perceptions by representing
      their lines of sight. But possession of general abilities to monitor and
      manipulate others intentions does require being able to form intentions about
      others intentions.</p><!--l. 135-->

      <p class="indent">The question was whether there are sufficient conditions for
      shared intention which do not presuppose abilities to use psychological concepts
      whose development is supposed to be explained by joint action. As promised, the
      answer is not straightforward. In a limited range of cases, coordinating plans
      and perhaps structuring bargaining does not appear to require insights into other
      minds. But in other cases, particularly cases involving novel aims or agents
      unfamiliar with each other, intentions about others intentions are generally
      required.</p><!--l. 137-->

      <p class="indent">The main question for this section was whether Bratman's account
      captures a notion of joint action suitable for explaining the early development
      of childrens abilities to think about minds. Some of the joint actions which
      young children engage in involve novel aims, and some involve unfamiliar
      partners. So if these joint actions did involve coordinating planning and
      structuring bargaining, they could not rest on a shared background but would
      require abilities to form intentions about others intentions. It follows that
      joint action would presuppose much of the sophistication in the use of
      psychological concepts whose development it was supposed to explain. So given the
      premise that joint action plays a role in explaining early developments in
      understanding minds, it cannot be the case that the joint actions children engage
      in as soon as they engage in any joint actions involve shared intentions as
      characterised by Bratman.</p><!--l. 139-->

      <p class="indent">This conclusion rests on the assumption that having intentions
      about intentions involves some of the psychological sophistication whose
      development is supposed to be explained by appeal to joint action. One might
      object that the ability for form intentions about intentions is somehow less
      sophisticated than abilities to form other kinds of representation of other kinds
      of mental states. To answer the objection it is sufficient to clarify what
      intention means in this context. For the term intention, like planning, is used
      to mean different things by different researchers. Sometimes intention and goal
      are used interchangeably in describing behaviour which is somewhat flexibly
      organised around some outcome (e.g.&nbsp;<a href=
      "#Xen_1433">Premack</a>&nbsp;<a href="#Xen_1433">1990</a>, p.&nbsp;14). But in
      this context we need a different notion of intention, one on which intentions are
      elements of plans. Such intentions play a role in coordinating an agents
      activities over time. Their role is characterised in part by normative
      constraints expressed in terms of the propositional contents of intentions. For
      instance, one norm characteristic of the role of intentions in plans requires an
      agent to avoid ways of realising one intention that will make it impossible for
      her to realise other intentions she has (all things being equal). This norm
      requires someone who intends both to visit an aunt and to buy some shoes in a
      single evening to limit time spent on each activity to allow for the other.
      Another norm characteristic of intention concerns the compatibility of having
      multiple intentions simultaneously: it is not rational to have multiple
      intentions unless it is rational to have a single intention agglomerating them
      all (<a href="#Xen_1543">Bratman</a>&nbsp;<a href="#Xen_1543">1987</a>). Norms
      such as these, together with the role of intentions in practical reasoning, are
      what characterise the role of intentions in planning. Given that intentions are
      characterised in this way as elements in plans, it seems necessary that
      understanding intentions will involve some grasp both of the role that intentions
      as propositional attitudes play in practical reasoning and also of the norms
      relating intentions to planning. Of course this does not mean that individuals
      who understand intentions as elements in plans can articulate or list the
      relevant roles or norms. But it does mean that they should sometimes be sensitive
      to some of the requirements these norms impose and also that they would be able
      to recognise some of the norms as correct in optimal conditions. This is why
      requiring intentions about intentions presupposes significant psychological
      sophistication.</p><!--l. 141-->

      <p class="indent">Given that joint action facilitates the development of mental
      understanding, and that (as just argued) Bratman's notion of shared intentional
      activity is not a kind of joint action which could play this role, does it follow
      that Bratman's account is incorrect?<span class="footnote-mark"><a href="#fn8x0"
      id="fn8x0-bk" name="fn8x0-bk"><sup class=
      "textsuperscript">8</sup></a></span><a id="x1-4005f8" name="x1-4005f8"></a>
      Drawing this conclusion would require the further assumption that there is just
      one kind of joint action. This is not obviously true. Compare individual action.
      It is sometimes accepted that there is a distinction between intentional action
      and other kinds of action such as response behaviours and merely purposive
      activities (<a href="#Xen_496">Dickinson &amp; Balleine</a>&nbsp;<a href=
      "#Xen_496">2000</a>;&nbsp;<a href="#Xen_194">Frankfurt</a>&nbsp;<a href=
      "#Xen_194">1971</a>). Because there may be an analogous distinction between kinds
      of joint action, the developmental considerations do not directly bear on the
      correctness of Bratman's account. Perhaps what we need is not a modified version
      of Bratman's account but an account of a different kind of joint action.</p>
      <!--l. 143-->

      <p class="indent">To sum up, Bratman's account does not characterise a kind of
      joint action which could play a role in explaining how children come to
      understand minds. In the next section I consider whether this undermines the
      claim that the interactions highlighted by developmental psychologists are really
      joint actions before offering a new account of joint action in the following
      sections. <a id="x1-4006r4" name="x1-4006r4"></a></p>

      <h3 class="sectionHead"><span class="titlemark">4.</span> <a id="x1-50004" name=
      "x1-50004"></a>Joint action, shared intention and coordinated planning</h3>
      <!--l. 149-->

      <p class="noindent">The argument of the previous section establishes that not all
      of the following claims are true:</p>

      <div class="quote">
        <!--l. 152-->

        <p class="noindent">(1) joint action fosters an understanding of minds;</p>
        <!--l. 154-->

        <p class="noindent">(2) all joint action involves shared intention; and</p>
        <!--l. 156-->

        <p class="noindent">(3) a function of shared intention is to coordinate two or
        more agents plans.</p>
      </div><!--l. 159-->

      <p class="noindent">These claims are inconsistent because if the second and third
      were both true, abilities to engage in joint action would presuppose, and so
      could not significantly foster, an understanding of minds. For all that has been
      said so far, any of these claims could be rejected. In what follows I
      characterise a form of joint action which involves what I call shared goals and
      no shared intentions. The aim is to show by construction that there are forms of
      joint action which require minimal cognitive sophistication. In doing this I
      shall provide grounds for rejecting the claim that joint action always involves
      shared intention, (2), strengthening the case for accepting the premise about
      development, (1), while remaining neutral on whether shared intentions function
      to coordinate planning, (3).</p><!--l. 161-->

      <p class="indent">Some researchers assert that all joint actions involve shared
      intentions. For instance, Tomasello writes that [t]he sine qua non of
      collaborative action is a joint goal and a joint commitment (<a href=
      "#Xen_1828">2008</a>, p.&nbsp;181). Here joint goal refers to shared intention in
      Bratman's sense and collaborative action includes joint actions early in
      development. Similarly, Gilbert writes I take collective action to involve a
      collective intention (<a href="#Xen_1287">2006</a>, p.&nbsp;5). Perhaps, then, a
      better strategy than the one I propose would be to reject the first claim, (1),
      above and conjecture that joint action cannot significantly foster an
      understanding of minds (although some lesser form of interaction may do so). But
      it is striking that none of the researchers who assert that all joint action
      involves shared intention provide an argument, and narrowly semantic
      considerations provide no support for this assertion (<a href=
      "#Xen_2394">Ludwig</a>&nbsp;<a href="#Xen_2394">2007</a>;&nbsp;<a href=
      "#Xen_2395">Smith</a>&nbsp;<a href="#Xen_2395">2011</a>, p.&nbsp;367). In fact
      other researchers have assumed without argument that not all joint actions
      involve shared intention (<a href="#Xen_1197">Bratman</a>&nbsp;<a href=
      "#Xen_1197">1992</a>, p.&nbsp;330; <a href="#Xen_1860">Schmidt
      et&nbsp;al.</a>&nbsp;<a href="#Xen_1860">2010</a>, p.&nbsp;2010; <a href=
      "#Xen_1778">Vesper et&nbsp;al.</a>&nbsp;<a href="#Xen_1778">2010</a>). On what
      grounds could we accept this assumption or its negation?</p><!--l. 165-->

      <p class="indent">Let us step back. What features other than shared intention
      indicate that the actions of two or more agents constitute a joint action as
      opposed to any other kind of interaction? Here are several indicators of joint
      action:</p>

      <div class="quote">
        <!--l. 168-->

        <p class="noindent">i. this case seems to fit with paradigm examples of joint
        action such as walking, cooking or playing the piano together (<a href=
        "#Xen_1861">Gilbert</a>&nbsp;<a href="#Xen_1861">1990</a>;&nbsp;<a href=
        "#Xen_2392">Goebl &amp; Palmer</a>&nbsp;<a href=
        "#Xen_2392">2009</a>;&nbsp;<a href="#Xen_25">Velleman</a>&nbsp;<a href=
        "#Xen_25">2000</a>);</p><!--l. 170-->

        <p class="noindent">ii. the candidate joint action differs from a case in which
        the agents perform the same type of activity (such as walking or cooking) in
        parallel rather than together (<a href="#Xen_1768">Bratman</a>&nbsp;<a href=
        "#Xen_1768">2009</a>;&nbsp;<a href="#Xen_1861">Gilbert</a>&nbsp;<a href=
        "#Xen_1861">1990</a>;&nbsp;<a href="#Xen_1365">Gr&acirc;&euro;&deg;fenhain
        et&nbsp;al.</a>&nbsp;<a href="#Xen_1365">2009</a>, p.&nbsp;150);</p>
        <!--l. 172-->

        <p class="noindent">iii. for each agent, acting together rather than
        individually is voluntary in this sense: in so far as they control which means
        they adopt in pursuing a goal, such as whether to move an object by lifting it
        or by dragging it, they can also control whether their actions are individual
        or joint;</p><!--l. 174-->

        <p class="noindent">iv. there is a sense in which all of the agents actions
        taken together are directed to a single goal, and this is not just a matter of
        each agents action being individually directed to that goal;</p><!--l. 176-->

        <p class="noindent">v. there is a description of the interaction with a plural
        subject and an action verb, such as they are bouncing the ball on the
        trampoline (<a href="#Xen_1290">Kutz</a>&nbsp;<a href="#Xen_1290">2000</a>
        emphasises this indicator);</p><!--l. 178-->

        <p class="noindent">vi. each agent is disposed to modify her actions in
        accordance with what is needed to achieve the goal given how the other agents
        actions are unfolding (<a href="#Xen_1197">Bratman</a>&nbsp;<a href=
        "#Xen_1197">1992</a>, p.&nbsp;328).</p>
      </div><!--l. 181-->

      <p class="noindent">I am not suggesting that any of these features is necessary
      for joint action, nor that they are collectively sufficient. My claim is just
      these features are relevant to deciding whether an interaction is a joint action,
      and that where an interaction has many or all of these features we have
      (defeasible) grounds to infer that it is a joint action. In short, I propose
      that, in the absence of a deeper analysis, we should take these features as a
      rough and provisional explication of one theoretically significant way of using
      the term joint action.<span class="footnote-mark"><a href="#fn9x0" id="fn9x0-bk"
      name="fn9x0-bk"><sup class="textsuperscript">9</sup></a></span><a id="x1-5001f9"
      name="x1-5001f9"></a></p><!--l. 183-->

      <p class="indent">So what about the objection that all joint action involves
      shared intention? The following will provide (defeasible) grounds for rejecting
      it. For I shall show that some interactions have the features listed above,
      (i)-(vi), but do not involve shared intention. <a id="x1-5002r5" name=
      "x1-5002r5"></a></p>

      <h3 class="sectionHead"><span class="titlemark">5.</span> <a id="x1-60005" name=
      "x1-60005"></a>Plural activities</h3><!--l. 189-->

      <p class="noindent">Our question is what joint action could be on the assumption
      that it fosters an understanding of minds. We have seen (in Section 3) that the
      answer cannot involve appeal to shared intention. Joint actions involving shared
      intention presuppose, and so cannot significantly foster the development of,
      sophisticated uses of psychological concepts. What we need, then, is to identify
      a form of joint action that requires as little psychological sophistication as
      possible; by presupposing less we make it possible to explain more.</p>
      <!--l. 191-->

      <p class="indent">I shall approach this task indirectly by first considering
      forms of action involving multiple agents more basic than any kind of joint
      action. Some ants harvest plant hair and fungus in order to build traps to
      capture large insects; once captured, many worker ants sting the large insects,
      transport them and carve them up (<a href="#Xen_1292">Dejean
      et&nbsp;al.</a>&nbsp;<a href="#Xen_1292">2005</a>). The ants behaviours have an
      interesting feature distinct from their being coordinated: each ants behaviours
      are individually organised around an outcomethe flys deathwhich occurs as a
      common effect of many ants behaviours. We can say that there is a single
      activitykilling a flywhich several ants performed. In general, a plural activity
      is one involving two or more agents. As I shall use the term plural activity, for
      agents to be engaged in a plural activity it is sufficient that each agents
      activities are individually organised around a single outcome which occurs as a
      common effect of all the agents activities.</p><!--l. 193-->

      <p class="indent">Note that nothing controversial is assumed in stating these
      sufficient conditions for plural activity. The first ingredient is the notion
      that an individuals behaviours can be organised around an outcome. This is
      shorthand for an open-ended disjunction of cases; it means that there is an
      intention, habit, biological function or other behaviour-organizing circumstance
      connecting the individuals behaviours to the outcome. The second ingredient is
      the notion of a common effect, which is not specific to action. The flys capture
      is a common effect of the ants individual behaviours in just the sense that the
      flys death is a common effect of the multiple doses of poison it received: none
      of the doses was individually deadly, each had its murderous effect only in
      concert with some of the others. As characterised here, the notion of a plural
      activity depends on nothing more controversial than the cogency of these two
      ingredients.</p><!--l. 195-->

      <p class="indent">My use of the term plural activity is different from other
      natural uses of this term and may be too broad to pick out an intuitive category.
      If Helen and Ayesha individually aim to smooth a section of pavement by shuffling
      their feet when they walk over it and if it does become smooth partly as a
      consequence of both their efforts, then they are engaged in the plural activity
      of smoothing the pavement. This is true even in the absence of any intention to
      act together. It is true even if their lives do not overlap at all, so that there
      may be no intuitive sense in which their smoothing the pavement is a joint
      action. Allowing this case to count as a plural activity does no harm for present
      purposes and makes it possible to characterise a useful notion of plural activity
      in uncontroversial terms.</p><!--l. 197-->

      <p class="indent">Another potentially unnatural feature of this definition of
      plural activity is that it requires success. By definition, where two or more
      agents actions constitute a plural activity the outcome to which they are
      directed must occur. This simplifies the definition in ways that will shortly be
      useful.</p><!--l. 199-->

      <p class="indent">Humans sometimes perform activities that are plural in the
      minimal sense that some ants behaviours are. In a particularly sulky mood Thomas
      pulls on one end of a large boat in order to move it; he does not realise that
      Illaria is pushing the other end and that without her contribution the boat would
      not move. He succeeds in moving the boat, as does Illaria. So there is a single
      activitymoving the boatwhich they both perform. Even though Thomas action is
      goal-directed (its goal is to move the boat to the sea), his activity is plural
      only in the minimal sense that the ants fly-trapping behaviour is: it is
      organised around an outcome which occurs as a common effect. The plural nature of
      such activities need not show up in intentions, desires or beliefs. That an
      activity is performed by two individuals does not require that they intend,
      believe or desire this to be so.</p><!--l. 201-->

      <p class="indent">What most philosophers mean by joint action is not, or not
      only, this minimal notion of plural activity. Certainly this minimal notion is
      inadequate for our present purpose, which is to understand what joint action
      could be on the assumption that it plays some role in explaining how children
      come to understand minds. Nevertheless, the notion of plural activity is a useful
      starting point for understanding a kind of joint action relevant to explaining
      development. <a id="x1-6001r6" name="x1-6001r6"></a></p>

      <h3 class="sectionHead"><span class="titlemark">6.</span> <a id="x1-70006" name=
      "x1-70006"></a>What is the function of shared goals?</h3><!--l. 206-->

      <p class="noindent">In giving an account of one kind of joint action I shall
      first identify something I call shared goals. Before starting it will be helpful
      to fix terminology. As I use the term goal it refers to an outcome, actual or
      possible, and not to a state. I make no direct use of the notion that agents can
      have goals (as in Sams goal was to topple the president) and focus on relations
      between goals and actions (as in the goal of Marvins action was to upset Ayesha).
      An action is <span class="cmti-12">goal-directed</span> where it makes sense to
      ask which of its possible and actual outcomes are goals to which the action was
      directed. One paradigm case of goal-directed action involves intention: where an
      agent acts on an intention, the intentions content specifies a goal to which her
      action is directed. In addition, an action can arguably be directed to a goal
      which is not specified in the content of any of the agents intentions (<a href=
      "#Xen_1359">Bratman</a>&nbsp;<a href="#Xen_1359">1984</a>). There may also be
      forms of action which are goal-directed but do not involve intention at
      all.<span class="footnote-mark"><a href="#fn10x0" id="fn10x0-bk" name=
      "fn10x0-bk"><sup class="textsuperscript">10</sup></a></span><a id="x1-7001f10"
      name="x1-7001f10"></a> Certainly there are ways of representing actions as
      goal-directed which do not involve representing intentions or any other
      propositional attitudes of agents.</p><!--l. 208-->

      <p class="indent">The term shared is used loosely. Just as, on most accounts,
      shared intentions are neither literally intentions nor literally shared (no
      single intention is mine and yours), so shared goals are not goals (they are
      complexes of states and relations) and do not by definition alone involve
      anything which is literally shared. I have used the otherwise infelicitous label
      shared goal in order to highlight the basic intuition behind the positive account
      of joint action I shall offer: some cases of joint action involve structures
      which bind not the agents intentions but the goals to which their activities are
      directed.<span class="footnote-mark"><a href="#fn11x0" id="fn11x0-bk" name=
      "fn11x0-bk"><sup class="textsuperscript">11</sup></a></span><a id="x1-7002f11"
      name="x1-7002f11"></a></p><!--l. 210-->

      <p class="indent">Having fixed terminology we can now turn to the primary issue,
      which is to identify shared goals. Following the model provided by Bratman's
      account of shared intentions, my account of shared goals has two parts: a
      specification of their function role and a substantial description of states that
      could realise them. This section is about the functional role of shared goals,
      the following section concerns their realisation. To emphasise, questions about
      the mental states involved in sharing goals will be deferred until the next
      section; in this section the question is only what shared goals are for.</p>
      <!--l. 212-->

      <p class="indent">Successful plural activity generally requires coordination. How
      is this coordination achieved? In the case of ants such coordination may be
      achieved hormonally. In humans, who can voluntarily engage in plural activities
      with novel outcomes, coordination can usually only be achieved psychologically.
      This is what shared goals are for. Shared goals coordinate multiple agents
      goal-directed activities around an outcome to be achieved as a common effect of
      their efforts. That is, their function is to coordinate plural activities.</p>
      <!--l. 214-->

      <p class="indent">An illustration may help to clarify what performing this
      function amounts to. There is a fallen tree lying across the road. Several people
      each want it moved, but none of them can move it by themselves and none of them
      can control the others actions. The trees movement can only be secured as common
      effect of several peoples actions. In this situation, there is a need for several
      people to coordinate their goal-directed activities. They need to lift in
      complementary directions and at suitably related times; and if lifting doesnt
      work, they need to change strategy and try pushing or something else that might
      achieve the outcome. The role of shared goals is to coordinate these
      goal-directed activities.</p><!--l. 216-->

      <p class="indent">In the above illustration, plural activity is necessary to
      achieve an outcome. Shared goals also play a role in situations where plural
      activity occurs even though it is not necessary. For instance, Amin and Bertram
      each individually aim to put a large barrel into a boat. Either of them could
      move the barrel into the boat alone or their doing this could be a plural
      activity; the choice is theirs. The sequence of activities Amin would need to
      perform to put the barrel in the boat differs depending on whether he is acting
      alone or with Bertram. Acting alone, Amin would position himself so that the
      barrel and boat are in front of him, throw his arms around the middle of barrel,
      raise it, tilt back and then push up and forwards. If he chose to act with
      Bertram, Amin would need to take an entirely different approach. It is this need
      that shared goals answer.</p><!--l. 218-->

      <p class="indent">The notion that a function of shared goals is to coordinate
      goal-directed activities needs qualifying because all action involves
      coordination at several levels. Any goal-directed action, individual or joint,
      will be realised by a collection of simple object-directed actions such as
      pushing, pulling and tearing; and these in turn will be realized by some kind of
      motor actions, and so on until at some point we reach continuous bodily
      movements. Plainly most tasks require coordination at several of these levels;
      for instance, passing an object from one hand to another requires precise timing
      of releases and grasps as well as appropriate positioning in space. At some
      levels, coordination is largely independent of which goals agents actions are
      directed to (for example, it can be hard to use ones hands in an uncoordinated
      way even when doing so would be advantageous). This is true even for coordination
      of multiple agents activities. We may coordinate with others without being aware
      of how we are coordinating or even that we are coordinating (<a href=
      "#Xen_1693">Richardson et&nbsp;al.</a>&nbsp;<a href="#Xen_1693">2009</a>). In
      fact there seem to be several forms of <span class="cmti-12">emergent
      coordination</span>, that is, coordination which is independent of the goals of
      an agents actions (<a href="#Xen_1812">Knoblich et&nbsp;al.</a>&nbsp;<a href=
      "#Xen_1812">2010</a>). Clearly, then, shared goals are not the only factor in
      coordinating plural activity. The role of shared goals is limited to coordinating
      goal-directed actions and not their non-purposive components, and it may be that
      shared goals can play this role only thanks to the existence of other mechanisms
      of emergent coordination.</p><!--l. 220-->

      <p class="indent">Shared goals resemble shared intentions insofar as both exist
      to coordinate activities. They differ in that structuring bargaining and
      coordinating planning are not functions of shared goals. On some views, the
      distinction I have drawn between shared intentions and shared goals parallels a
      distinction between individual intentions and more primitive states connecting
      individuals activities with the goals to which they are directed. For individual
      intentions are sometimes held to be intrinsically elements in agents plans and
      therefore absent from the lives of any agents incapable of planning (<a href=
      "#Xen_1694">Bratman</a>&nbsp;<a href="#Xen_1694">2007</a>). Such agents (if there
      are any) may need to act when faced with equally desirable alternatives and to
      coordinate their activities around goals despite fluctuations in desire. This
      need might be met by states which resemble intentions in that they exist in part
      to coordinate a single agents activities and in that they connect the agents
      activities to a goal, but differ from intentions in lacking planning functions.
      Given this distinction, shared intentions would stand to shared goals roughly as
      individual intentions stand to their more primitive counterparts.</p>
      <!--l. 222-->

      <p class="indent">The limited function of shared goals makes them better suited
      than shared intentions for characterising the cases studied in developmental
      research. Many, perhaps all, of these cases would not normally require
      coordinated planning. As mentioned above, these cases include tidying up the toys
      together and cooperatively pulling handles in sequence in order to make a puppet
      sing. As coordinated planning is not needed in such cases, nor are shared
      intentions. What is needed, though, is for the agents goal-directed actions to be
      coordinated. This is what shared goals are for. <a id="x1-7003r7" name=
      "x1-7003r7"></a></p>

      <h3 class="sectionHead"><span class="titlemark">7.</span> <a id="x1-80007" name=
      "x1-80007"></a>Which states could realise shared goals?</h3><!--l. 227-->

      <p class="noindent">In the previous section I identified shared goals in terms of
      their function, which is to coordinate plural activities. The next step is to
      characterise states capable of realising this function.</p><!--l. 229-->

      <p class="indent">To start with an illustration, suppose that a goal of Amins
      actions in the near future will be move a large barrel into a boat. Amin
      anticipates that some of Bertrams future actions will have the same goal, and
      Amin expects the barrels moving into the boat to occur as a common effect of his
      own goal-directed actions and Bertrams. For his part, moving the barrel into the
      boat will also be a goal of Bertrams actions and Bertram has expectations
      mirroring Amins. In favourable circumstances their goal-directed contributions to
      a plural activity of moving the barrel into the boat could be coordinated in
      virtue of this pattern of goal-relations and expectations. Accordingly, the
      existence of such goal-relations and expectations are sufficient for Amin and
      Bertram to share the goal of getting the barrel into the boat.</p><!--l. 231-->

      <p class="indent">Here are the key features of this case expressed in general
      terms:</p>

      <div class="quote">
        <!--l. 234-->

        <p class="noindent">(a) <span class="cmti-12">one goal, two or more
        agents</span></p><!--l. 236-->

        <p class="noindent">there is a single goal, G, to which each agents actions
        are, or will be, individually directed;</p><!--l. 238-->

        <p class="noindent">(b) <span class="cmti-12">identification</span></p>
        <!--l. 240-->

        <p class="noindent">each agent can identify each of the other agents in a way
        that doesnt depend on knowledge of the goal or actions directed to it;</p>
        <!--l. 242-->

        <p class="noindent">(c) <span class="cmti-12">expectations about goal-directed
        actions</span></p><!--l. 245-->

        <p class="noindent">on balance<span class="footnote-mark"><a href="#fn12x0" id=
        "fn12x0-bk" name="fn12x0-bk"><sup class=
        "textsuperscript">12</sup></a></span><a id="x1-8001f12" name="x1-8001f12"></a>
        each agent expects each of the other agents she can identify to perform an
        action directed to the goal; and</p><!--l. 247-->

        <p class="noindent">(d) <span class="cmti-12">expectations about a common
        effect</span></p><!--l. 250-->

        <p class="noindent">on balance each agent expects this goal to occur as a
        common effect of all of their actions directed to the goal, her own and the
        others.</p>
      </div><!--l. 253-->

      <p class="noindent">In favourable circumstances and in concert with emergent
      coordination, these goal-relations and expectations could serve to coordinate the
      goal-directed plural activities of two or more agents (I shall say which
      circumstances are favourable below). Since shared goal was defined in terms of
      this coordinating function, (a)-(d) are collectively sufficient for possessing a
      shared goal.</p><!--l. 255-->

      <p class="indent">Let us consider these four features in turn. The first feature,
      (a), is required just because we are concerned with plural activities; by
      definition, actions comprising a plural activity are directed to a single goal
      such as moving a particular barrel onto a certain boat (see Section 4). The
      second feature, (b), was not explicit in the description of Amin and Bertrams
      barrel moving. It excludes the following sort of case. Mia and Sobani are in a
      crowded space. Each intends to move a table and, thanks to her background
      knowledge, expects that exactly one other agent intends the same. But neither Mia
      nor Sobani can identify who else she expects to be involved in moving the table,
      except trivially as the other table-mover. In this case, the pattern of
      goal-relations and expectations in (a), (c) and (d) could have at most a limited
      effect on Mia and Sobanis ability to coordinate their efforts. So the
      identification requirement, (b), is included because the coordinating effect of
      (a), (c) and (d) seem to depend on it. Identification may not feature whenever
      agents have a shared goal; (a)-(d) collectively provide only sufficient
      conditions.</p><!--l. 257-->

      <p class="indent">The third and fourth features, (c) and (d), involve
      expectations. Knowledge states and beliefs both count as expectations but it is
      not necessary to have either. In developmental research, looking times and eye
      movements are regularly used as measures of infants expectations concerning goals
      (for example&nbsp;<a href="#Xen_1434">Csibra et&nbsp;al.</a>&nbsp;<a href=
      "#Xen_1434">2003</a>;&nbsp;<a href="#Xen_1436">Gergely &amp;
      Csibra</a>&nbsp;<a href="#Xen_1436">2003</a>;&nbsp;<a href="#Xen_1207">Gergely
      et&nbsp;al.</a>&nbsp;<a href="#Xen_1207">1995</a>;&nbsp;<a href="#Xen_1437">Luo
      &amp; Baillargeon</a>&nbsp;<a href="#Xen_1437">2005</a>;&nbsp;<a href=
      "#Xen_1439">Woodward &amp; Sommerville</a>&nbsp;<a href="#Xen_1439">2000</a>). It
      is an open question whether these sorts of expectations are beliefs. Where such
      expectations do not merely control looking times and eye movements but also
      inform a range of goal-directed actions in ways that are rational given their
      contents, then expectations of this type are sufficient for sharing goals whether
      or not they amount to beliefs. This marks one contrast between requirements on
      sharing goals and sharing intentions. Given that intentions function to
      coordinate planning in Bratman's intellectual sense of planning and given some
      plausible norms governing the rationality of planning (<a href=
      "#Xen_1774">Hawthorne</a>&nbsp;<a href="#Xen_1774">2004</a>, pp.&nbsp;29-31),
      sharing an intention will require knowledge of others intentions and their
      relations to ones own. By contrast, sharing a goal does not require knowledge.
      because several kinds of expectation which fall short of knowledge are sufficient
      for coordinating plural activities.</p><!--l. 259-->

      <p class="indent">The third feature, (c), concerns expectations about other
      agents goal-directed actions. This is a minimal counterpart of the requirement
      that agents who share an intention represent each others intentions. Possessing a
      shared goal requires representing only goal-directed actions. It is possible to
      represent an action as goal-directed without representing (or even being able to
      represent) intentions or any other propositional attitudes. For instance, an
      agent might represent goals as functions of actions.<span class=
      "footnote-mark"><a href="#fn13x0" id="fn13x0-bk" name="fn13x0-bk"><sup class=
      "textsuperscript">13</sup></a></span><a id="x1-8002f13" name="x1-8002f13"></a>
      There are strong theoretical and empirical grounds to hold that representing
      goal-directed actions requires less conceptual sophistication, and may be less
      cognitively demanding, than representing intentions as such.</p><!--l. 265-->

      <p class="indent">The fourth feature, (d), concerns the agents expectations that
      the goal to which their actions are directed will occur as a common effect of
      their efforts. This and the third feature are jointly equivalent to requiring
      that the each agent expects that she and the other agents are engaged in a plural
      activity with goal G. (The agents may not actually be engaged in a single plural
      activity because, as noted earlier, plural activities are by definition
      successful whereas it is possible to possesses a shared goal without succeeding.)
      The claim that features (a)-(d) are sufficient for agents to possess a shared
      goal is the claim that this combination of features could function to coordinate
      plural activities. In essence, the claim is this: an expectation, on the part of
      each agent concerned, that she is or will be involved in a plural activity with
      the others, will, in favourable circumstances and in concert with emergent
      coordination, normally enable them to coordinate their actions.</p><!--l. 267-->

      <p class="indent">Shared intention is sometimes thought to involve common
      knowledge in such a way that agents who share an intention can know that they
      share an intention.<span class="footnote-mark"><a href="#fn14x0" id="fn14x0-bk"
      name="fn14x0-bk"><sup class="textsuperscript">14</sup></a></span><a id=
      "x1-8003f14" name="x1-8003f14"></a> By contrast, it is possible to have a shared
      goal without knowing that one does. Agents can have, and act on (see Section 8
      below), a shared goal without understanding their actions as comprising anything
      more than a plural activity.</p><!--l. 273-->

      <p class="indent">The above pattern of goal-relations and expectations, (a)-(d),
      can play its coordinating role only in favourable circumstances. What makes
      circumstances <span class="cmti-12">un</span>favourable? One factor is a lack of
      freedom. To illustrate, suppose that Hendrik and Arch are instructed to tidy the
      toys away. Arch would not normally obey this instruction but Hendrik convincingly
      threatens reprisals unless Arch tidies all the toys away. For the goal of tidying
      the toys away, (a)-(d) above could all obtain in this case (Hendrik fulfils (a)
      by the act of threatening). But any coordinating effect this pattern of
      goal-relations and expectations might have had is trumped by Hendriks control
      over Archs actions. Archs lack of freedom is an unfavourable circumstance, that
      is, one in which the coordinating role of shared goals may be blocked. Another
      unfavourable circumstance is antagonism to plural activity. Suppose that Ella and
      Cohen have been tasked with wiping a table clean. Ella is desperate to clean the
      table without Cohen, and Cohen is desperate to clean it without Ella. Neither
      thinks this will be possible, and they satisfy (a)-(d) above. But because they
      are desperate to act alone, each tries to sabotage the others efforts. Any
      coordinating effect the shared goal might have had is overridden by the agents
      antagonism to plural activity. In short, then, favourable circumstances are those
      in which factors that would defeat the coordinating tendency of the pattern of
      goal-relations and expectations in (a)-(d) are absent; paradigm defeating factors
      are a lack of freedom and antagonism towards plural activity. <a id="x1-8004r8"
      name="x1-8004r8"></a></p>

      <h3 class="sectionHead"><span class="titlemark">8.</span> <a id="x1-90008" name=
      "x1-90008"></a>Shared goals characterise one form of joint action</h3>
      <!--l. 279-->

      <p class="noindent">So far I have stipulated that the function of shared goals is
      to coordinate plural activities and argued that this function could be realised
      by a certain pattern of goal-relations and expectations. Finally I shall use this
      to characterise a form of joint action which, lacking the cognitive and
      conceptual demands associated with shared intentional action, could be used to
      explicate the premise that engaging in joint action fosters an understanding of
      minds.</p><!--l. 281-->

      <p class="indent">Shared goals are characteristic of a form of joint action but
      the relation between possession of a shared goal and performing a joint action is
      not straightforward. Compare ordinary individual action. Acting intentionally is
      not just a matter of acting and simultaneously intending; nor is it even just a
      matter of being caused to act by an intention (<a href=
      "#Xen_1211">Searle</a>&nbsp;<a href="#Xen_1211">1983</a>, pp.&nbsp;136-7).
      Relatedly, we should not suppose that the mere presence, or even the mere
      efficacy, of a shared goal is sufficient for joint action. Take any collection of
      actions directed to a single goal, G, involving two or more agents. Let us say
      that these actions, taken collectively, are <span class="cmti-12">driven by a
      shared goal</span> when G is a shared goal of the agents, when, in performing
      actions directed to this goal, they are acting on the associated expectations and
      any other attitudes in ways that are rational, and when their so acting functions
      to coordinate their actions in a way that would normally facilitate the goals
      occurring as a common effect of all their efforts. (I assume that, although the
      expectations mentioned in Section 7 may not be necessary for possessing a shared
      goal, some such expectations are always involved.) I claim that actions driven by
      shared goals are joint actions.</p><!--l. 283-->

      <p class="indent">Why accept this? Recall the six indicators of joint action
      identified earlier (Section 4). Where these three conditions hold of an
      interaction, most of these indicators will be present. The interaction will be
      distinct from a case in which the agents pursue the goal in parallel and without
      a shared goal (this was the second indicator). The action will be voluntary with
      respect to its jointness insofar as jointness is partly due to agents acting on
      their expectations in ways that are rational, as contrasted with interactions
      where coordination involves only involuntary forms of emergent coordination
      (third indicator). If the goal occurs, this will normally be in part because of
      the coordination provided by the shared goal; in this sense, the coordination
      serves to direct the agents actions, taken together, to the goal and this amounts
      to more than each agents actions being individually directed to the goal (fourth
      indicator). Finally, the agents dispositions to adapt their actions to each
      others is built into the requirement that the shared goal function to coordinate
      their actions by means of their acting on the associated expectations (sixth
      indicator). In short, actions driven by shared goals have many features
      indicative of joint action. This is reason to hold that they are in fact joint
      actions.</p><!--l. 285-->

      <p class="indent">Not every case in which actions are driven by shared goals fits
      intuitively with paradigm examples of joint action. Consider two drivers on a
      collision course in a narrow street. Suppose (perhaps unrealistically) that each
      acts with the goal of avoiding a collision between their cars, expects the other
      to do the same and expects that they will avoid collision thanks to their
      combined efforts. This is sufficient for avoiding a collision to be a shared
      goal. (Note that specifying the goal requires care: the drivers actions would
      have different goals if, for instance, the only goal of each drivers action were
      to avoid hitting the other.) Suppose also that their actions are driven by a
      shared goal in the sense defined above. So, on the above account, their avoiding
      collision is a joint action. (Not all cases of avoiding a collision are joint
      actions, only those, if any, which are driven by shared goals.) But intuitively
      this case may not seem to fit with paradigms of joint action because the
      interaction is so minor. If this counts as joint action, then, given the right
      goal-relations and expectations, so could passing someone in a corridor. Should
      we modify the account of joint action in order to exclude this sort of case?
      There is an obstacle to doing that. We could elaborate a series of interactions
      driven by the shared goal of avoiding collision where each interaction is
      slightly less minor than its predecessor in the series. Whether or not intuitions
      support drawing a boundary, it seems that no such boundary is theoretically
      significant for understanding the role of joint action in development. Since our
      aim is to characterise joint action as it fosters development, we should risk
      deviating from intuition to avoid otherwise unnecessary complexity.</p>
      <!--l. 287-->

      <p class="indent">There is another sort of case in which actions driven by a
      shared goal may not intuitively fit with paradigm joint actions. Consider again
      the two drivers whose goal is to avoid collision. Now suppose, in addition, that
      the first driver hawkishly accelerates while covertly preparing to brake if
      necessary, causing the second driver to brake hard. Given the present account,
      their actions nevertheless constitute joint action. This may not fit intuitively
      with paradigm joint actions because the first driver dominates the second (and
      does so by means of deception).<span class="footnote-mark"><a href="#fn15x0" id=
      "fn15x0-bk" name="fn15x0-bk"><sup class=
      "textsuperscript">15</sup></a></span><a id="x1-9001f15" name="x1-9001f15"></a>
      Again it is possible to elaborate a series of cases involving gradually varying
      degrees of domination. While outright coercion is incompatible with joint action
      on the account I have offered (see Section 7 above), neither domination nor other
      failures to be cooperative are excluded. This may conflict with intuitions about
      joint action but reduces the complexity of the account. That the account is
      nevertheless an account of joint action is shown by the presence of the other
      indicators of joint action mentioned above.</p><!--l. 289-->

      <p class="indent">Accounts of joint action sometimes invoke special kinds of
      mental state (<a href="#Xen_1426">Gilbert</a>&nbsp;<a href=
      "#Xen_1426">1992</a>;&nbsp;<a href="#Xen_1369">Searle</a>&nbsp;<a href=
      "#Xen_1369">2002</a>), special kinds of reasoning (<a href="#Xen_1383">Gold &amp;
      Sugden</a>&nbsp;<a href="#Xen_1383">2007a</a>), special kinds of interdependence
      (<a href="#Xen_1356">Bratman</a>&nbsp;<a href="#Xen_1356">1993</a>;&nbsp;<a href=
      "#Xen_1827">Miller</a>&nbsp;<a href="#Xen_1827">2001</a>) or, apparently, special
      kinds of agent (<a href="#Xen_2391">Helm</a>&nbsp;<a href="#Xen_2391">2008</a>).
      The present account, if successful, shows that there is a simple kind of joint
      action characterising which requires no such special ingredients. The simple kind
      of joint action involves only ordinary individual goal directed-actions being
      coordinated in part by expectations about others goal-directed actions and their
      common effects.</p><!--l. 291-->

      <p class="indent">There are, of course, questions and puzzles about joint action
      which the simple account offered here does not address and which may call for
      greater complexity. These include issues about commitment (<a href=
      "#Xen_1287">Gilbert</a>&nbsp;<a href="#Xen_1287">2006</a>), the coordination of
      decisions to act jointly (<a href="#Xen_1297">Velleman</a>&nbsp;<a href=
      "#Xen_1297">1997</a>), the kind of reasoning needed for coordinating choices
      (<a href="#Xen_1373">Sugden</a>&nbsp;<a href="#Xen_1373">2000</a>), and the
      possibilities of intending others actions (<a href=
      "#Xen_1369">Searle</a>&nbsp;<a href="#Xen_1369">2002</a>,&nbsp;<a href=
      "#Xen_1692">1994</a>) and of acting on others intentions (<a href=
      "#Xen_1427">Roth</a>&nbsp;<a href="#Xen_1427">2004</a>). Failure to address these
      questions or tackle these puzzles might be an objection if the simple account
      were meant to be the whole story about joint action. In fact the simple account
      is not supposed to apply to every case of joint action. For instance, painting a
      house together will probably involve intentionally coordinating plans and so
      require sharing intentions rather than merely sharing goals. On the other hand,
      in some cases joint action does not require planning, commitment, coordinating
      decisions to act or special kinds of reasoning. Knoblich and Sebanz offer an
      example:</p>

      <div class="quote">
        <!--l. 294-->

        <p class="noindent">the way people lift a two-handled basket depends on whether
        they lift it alone or together. When alone, a person would normally grasp each
        handle with one hand. When together, one person would normally grasp the left
        handle with his/her right hand and the other person would grasp the right
        handle with his/her left hand. (<a href="#Xen_1429">Knoblich &amp;
        Sebanz</a>&nbsp;<a href="#Xen_1429">2008</a>, p.&nbsp;2026)</p>
      </div><!--l. 297-->

      <p class="noindent">Because handles provide an obvious way for two people to lift
      the basket (these authors even postulate a joint affordance) and people are often
      skilled at coordinated lifting, planning is typically unnecessary and it is
      plausible that shared goals are sufficient for joint actions of this
      sort.<span class="footnote-mark"><a href="#fn16x0" id="fn16x0-bk" name=
      "fn16x0-bk"><sup class="textsuperscript">16</sup></a></span><a id="x1-9002f16"
      name="x1-9002f16"></a> <a id="x1-9003r9" name="x1-9003r9"></a></p>

      <h3 class="sectionHead"><span class="titlemark">9.</span> <a id="x1-100009" name=
      "x1-100009"></a>Conclusion</h3><!--l. 303-->

      <p class="noindent">The question was this. Given the premise that joint action
      plays some role in explaining how children come to understand minds, what could
      joint action be? The negative point was that it couldnt involve sharing
      intentions for reasons connected to the fact that sharing intentions involves
      coordinating planning and so requires sophistication in ascribing propositional
      attitudes. The positive claim was that there is a simple account of joint action
      which is compatible with the developmental premise. On the simple account, joint
      action involves sharing goals and sharing goals requires only an understanding of
      goal-directed actions and their common effects.</p><!--l. 305-->

      <p class="indent">This simple account of joint action is not offered as a
      replacement for Bratman's account or any accounts competing with his. Bratman's
      account assumes that joint action involves shared intention where the functions
      of shared intention include coordinating paradigmatically long-term plans. Such
      an account may be required to characterise complex cases where success demands
      that agents plans mesh. But some cases of joint action (such as carrying a
      two-handled basket together) do not involve plans in the relevant sense of
      planning. The agents need to coordinate their activities but not their plans. The
      simple account applies only in such cases. In philosophical accounts of
      individual action, actions explainable by intending are sometimes distinguished
      from other kinds of individual action including response behaviours, arrational
      actions and merely purposive activities (<a href="#Xen_181">Dickinson &amp;
      Balleine</a>&nbsp;<a href="#Xen_181">1993</a>;&nbsp;<a href=
      "#Xen_1683">Hursthouse</a>&nbsp;<a href="#Xen_1683">1991</a>;&nbsp;<a href=
      "#Xen_25">Velleman</a>&nbsp;<a href="#Xen_25">2000</a>). Comparable distinctions
      are certain to be needed for understanding joint action; the differences between
      shared intentions and shared goals mark one such distinction between kinds of
      joint action.</p>

      <h3 class="likesectionHead"><a id="x1-110009" name="x1-110009"></a><span class=
      "cmr-10x-x-109">References</span></h3>

      <div class="thebibliography">
        <p class="bibitem"><span class="biblabel"><a id="Xen_1686" name=
        "Xen_1686"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Apperly,
        I.</span><span class="cmr-10x-x-109">&nbsp;A. &amp; Butterfill, S. (2009). Do
        humans have two systems to track beliefs</span> <span class="cmr-10x-x-109">and
        belief-like states?</span> <span class="cmti-10x-x-109">Psychological
        Review</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">2009</span><span class="cmr-10x-x-109">(116), 4.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_69" name=
        "Xen_69"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Astington, J. (1991). Intention in the child&rsquo;s theory of
        mind. In D.</span><span class="cmr-10x-x-109">&nbsp;Frye &amp;</span>
        <span class="cmr-10x-x-109">C.</span><span class="cmr-10x-x-109">&nbsp;Moore
        (Eds.),</span> <span class="cmti-10x-x-109">Children&rsquo;s Theories of Mind:
        mental states and social understanding</span> <span class=
        "cmr-10x-x-109">(pp.</span><span class="cmr-10x-x-109">&nbsp;157&ndash;172).
        Hove: Erlbaum.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_70" name=
        "Xen_70"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Astington, J. &amp; Gopnik, A. (1991). Developing understanding
        of desire and intention.</span> <span class="cmr-10x-x-109">In
        A.</span><span class="cmr-10x-x-109">&nbsp;Whiten (Ed.),</span> <span class=
        "cmti-10x-x-109">Natural Theories of the Mind: evolution, development
        and</span> <span class="cmti-10x-x-109">simulation of everyday
        mindreading</span> <span class="cmr-10x-x-109">(pp.</span><span class=
        "cmr-10x-x-109">&nbsp;39&ndash;50). Oxford: Blackwell.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1789" name=
        "Xen_1789"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Baillargeon, R., Scott, R.</span><span class=
        "cmr-10x-x-109">&nbsp;M., &amp; He, Z. (2010). False-belief understanding in
        infants.</span> <span class="cmti-10x-x-109">Trends in Cognitive
        Sciences</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">14</span><span class="cmr-10x-x-109">(3),
        110&ndash;118.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_610" name=
        "Xen_610"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bartsch,
        K. &amp; Wellman, H.</span><span class="cmr-10x-x-109">&nbsp;M. (1995).</span>
        <span class="cmti-10x-x-109">Children talk about the mind</span><span class=
        "cmr-10x-x-109">. New York ;</span> <span class="cmr-10x-x-109">Oxford: Oxford
        University Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1204" name=
        "Xen_1204"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Behne,
        T., Carpenter, M., &amp; Tomasello, M. (2005). One-year-olds comprehend
        the</span> <span class="cmr-10x-x-109">communicative intentions behind gestures
        in a hiding game.</span> <span class="cmti-10x-x-109">Developmental
        Science</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">8</span><span class="cmr-10x-x-109">(6),
        492&ndash;499.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1681" name=
        "Xen_1681"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bizzu,
        E. (2001). Motor control. In R.</span><span class="cmr-10x-x-109">&nbsp;A.
        Wilson &amp; F.</span><span class="cmr-10x-x-109">&nbsp;C. Keil (Eds.),</span>
        <span class="cmti-10x-x-109">The MIT</span> <span class=
        "cmti-10x-x-109">Encyclopedia of the Cognitive Sciences</span><span class=
        "cmr-10x-x-109">. Cambridge, Mass: MIT Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1359" name=
        "Xen_1359"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bratman,
        M. (1984). Two faces of intention.</span> <span class="cmti-10x-x-109">The
        Philosophical Review</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">93</span><span class="cmr-10x-x-109">(3),</span> <span class=
        "cmr-10x-x-109">375&ndash;405.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1543" name=
        "Xen_1543"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bratman,
        M. (1987).</span> <span class="cmti-10x-x-109">Intentions, Plans, and Practical
        Reasoning</span><span class="cmr-10x-x-109">. Cambridge MA:</span> <span class=
        "cmr-10x-x-109">Harvard University Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1197" name=
        "Xen_1197"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bratman,
        M. (1992). Shared cooperative activity.</span> <span class="cmti-10x-x-109">The
        Philosophical Review</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">101</span><span class="cmr-10x-x-109">(2),</span> <span class=
        "cmr-10x-x-109">327&ndash;341.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1356" name=
        "Xen_1356"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bratman,
        M. (1993). Shared intention.</span> <span class=
        "cmti-10x-x-109">Ethics</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">104</span><span class="cmr-10x-x-109">,
        97&ndash;113.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1357" name=
        "Xen_1357"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bratman,
        M. (1999 [1997]). I intend that we j. In</span> <span class=
        "cmti-10x-x-109">Faces of Intention</span><span class="cmr-10x-x-109">.
        Cambridge:</span> <span class="cmr-10x-x-109">Cambridge University
        Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1694" name=
        "Xen_1694"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bratman,
        M. (2007).</span> <span class="cmti-10x-x-109">Structures of
        Agency</span><span class="cmr-10x-x-109">. Oxford: Oxford University
        Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1768" name=
        "Xen_1768"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Bratman,
        M. (2009). Modest sociality and the distinctiveness of intention.</span>
        <span class="cmti-10x-x-109">Philosophical Studies</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">144</span><span class=
        "cmr-10x-x-109">(1), 149&ndash;165.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1679" name=
        "Xen_1679"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Brownell, C.</span><span class="cmr-10x-x-109">&nbsp;A.,
        Ramani, G.</span><span class="cmr-10x-x-109">&nbsp;B., &amp; Zerwas, S. (2006).
        Becoming a social partner</span> <span class="cmr-10x-x-109">with peers:
        cooperation and social understanding in one- and two-year-olds.</span>
        <span class="cmti-10x-x-109">Child</span> <span class=
        "cmti-10x-x-109">Development</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">77</span><span class="cmr-10x-x-109">(4),
        803&ndash;21.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1682" name=
        "Xen_1682"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Carpenter, M. (2009). Just how joint is joint action in
        infancy?</span> <span class="cmti-10x-x-109">Topics in Cognitive</span>
        <span class="cmti-10x-x-109">Science</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">1</span><span class="cmr-10x-x-109">(2),
        380&ndash;392.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1438" name=
        "Xen_1438"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Csibra,
        G. (2008). Goal attribution to inanimate agents by 6.5-month-old
        infants.</span> <span class="cmti-10x-x-109">Cognition</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">107</span><span class=
        "cmr-10x-x-109">(2), 705&ndash;717.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1434" name=
        "Xen_1434"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Csibra,
        G., B</span><span class="cmr-10x-x-109">&Atilde;&OElig;r</span><span class=
        "cmr-10x-x-109">&Atilde;&rsaquo;, S., Ko</span><span class=
        "cmr-10x-x-109">&Atilde;&rsaquo;s, O., &amp; Gergely, G. (2003). One-year-old
        infants use</span> <span class="cmr-10x-x-109">teleological representations of
        actions productively.</span> <span class="cmti-10x-x-109">Cognitive
        Science</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">27</span><span class="cmr-10x-x-109">(1),
        111&ndash;133.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1292" name=
        "Xen_1292"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Dejean,
        A., Solano, P.</span><span class="cmr-10x-x-109">&nbsp;J., Ayroles, J.,
        Corbara, B., &amp; Orivel, J. (2005). Insect</span> <span class=
        "cmr-10x-x-109">behaviour: Arboreal ants build traps to capture prey.</span>
        <span class="cmti-10x-x-109">Nature</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">434</span><span class="cmr-10x-x-109">,
        973.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_181" name=
        "Xen_181"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Dickinson, A. &amp; Balleine, B. (1993). Actions and responses:
        the dual psychology of</span> <span class="cmr-10x-x-109">behaviour. In
        N.</span><span class="cmr-10x-x-109">&nbsp;Eilan, R.</span><span class=
        "cmr-10x-x-109">&nbsp;McCarthy, &amp; B.</span><span class=
        "cmr-10x-x-109">&nbsp;Brewer (Eds.),</span> <span class=
        "cmti-10x-x-109">Spatial representation:</span> <span class=
        "cmti-10x-x-109">problems in philosophy and psychology</span> <span class=
        "cmr-10x-x-109">(pp.</span><span class="cmr-10x-x-109">&nbsp;277&ndash;293).
        Oxford: Oxford University</span> <span class="cmr-10x-x-109">Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_496" name=
        "Xen_496"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Dickinson, A. &amp; Balleine, B. (2000). Causal cognition and
        goal-directed action. In</span> <span class=
        "cmr-10x-x-109">C.</span><span class="cmr-10x-x-109">&nbsp;Heyes &amp;
        L.</span><span class="cmr-10x-x-109">&nbsp;Huber (Eds.),</span> <span class=
        "cmti-10x-x-109">The Evolution of Cognition</span><span class="cmr-10x-x-109">.
        Cambridge, Mass.: MIT</span> <span class="cmr-10x-x-109">Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_194" name=
        "Xen_194"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Frankfurt, H. (1971). Freedom of the will and the concept of a
        person.</span> <span class="cmti-10x-x-109">The Journal</span> <span class=
        "cmti-10x-x-109">of Philosophy</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">68</span><span class="cmr-10x-x-109">(1),
        5&ndash;20.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1436" name=
        "Xen_1436"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Gergely,
        G. &amp; Csibra, G. (2003). Teleological reasoning in infancy: the nave
        theory</span> <span class="cmr-10x-x-109">of rational action.</span>
        <span class="cmti-10x-x-109">Trends in Cognitive Sciences</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">7</span><span class=
        "cmr-10x-x-109">(7), 287&ndash;292.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1207" name=
        "Xen_1207"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Gergely,
        G., Nadasky, Z., Csibra, G., &amp; Biro, S. (1995). Taking the intentional
        stance</span> <span class="cmr-10x-x-109">at 12 months of age.</span>
        <span class="cmti-10x-x-109">Cognition</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">56</span><span class=
        "cmr-10x-x-109">, 165&ndash;193.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1861" name=
        "Xen_1861"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Gilbert,
        M. (1990). Walking together: A paradigmatic social phenomenon.</span>
        <span class="cmti-10x-x-109">Midwest</span> <span class=
        "cmti-10x-x-109">Studies in Philosophy</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">15</span><span class=
        "cmr-10x-x-109">, 14.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1426" name=
        "Xen_1426"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Gilbert,
        M. (1992).</span> <span class="cmti-10x-x-109">On Social
        Facts</span><span class="cmr-10x-x-109">. Princeton, NJ: Princeton University
        Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1287" name=
        "Xen_1287"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Gilbert,
        M. (2006). Rationality in collective action.</span> <span class=
        "cmti-10x-x-109">Philosophy of the Social Sciences</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">36</span><span class=
        "cmr-10x-x-109">(1), 3&ndash;17.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_2392" name=
        "Xen_2392"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Goebl,
        W. &amp; Palmer, C. (2009). Synchronization of timing and motion among</span>
        <span class="cmr-10x-x-109">performing musicians.</span> <span class=
        "cmti-10x-x-109">Music Perception: An Interdisciplinary
        Journal</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">26</span><span class="cmr-10x-x-109">(5),</span> <span class=
        "cmr-10x-x-109">427&ndash;438.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1383" name=
        "Xen_1383"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Gold, N.
        &amp; Sugden, R. (2007a). Collective intentions and team agency.</span>
        <span class="cmti-10x-x-109">Journal of</span> <span class=
        "cmti-10x-x-109">Philosophy</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">104</span><span class="cmr-10x-x-109">(3),
        109&ndash;137.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_2393" name=
        "Xen_2393"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Gold, N.
        &amp; Sugden, R. (2007b). Theories of team agency. In F.</span><span class=
        "cmr-10x-x-109">&nbsp;Peter &amp; H.</span><span class="cmr-10x-x-109">&nbsp;B.
        Schmid</span> <span class="cmr-10x-x-109">(Eds.),</span> <span class=
        "cmti-10x-x-109">Rationality and Commitment</span> <span class=
        "cmr-10x-x-109">(pp.</span><span class="cmr-10x-x-109">&nbsp;280&ndash;312).
        Oxford: Oxford University Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1365" name=
        "Xen_1365"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Gr</span><span class="cmr-10x-x-109">&acirc;&euro;&deg;fenhain,
        M., Behne, T., Carpenter, M., &amp; Tomasello, M. (2009). Young
        children&rsquo;s</span> <span class="cmr-10x-x-109">understanding of joint
        commitments.</span> <span class="cmti-10x-x-109">Developmental
        Psychology</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">45</span><span class="cmr-10x-x-109">(5),
        1430&ndash;1443.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1535" name=
        "Xen_1535"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Haggard,
        P. (1998). Planning of action sequences.</span> <span class=
        "cmti-10x-x-109">Acta Psychologica</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">99</span><span class="cmr-10x-x-109">(2),
        201&ndash;215.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1774" name=
        "Xen_1774"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Hawthorne, J.</span><span class="cmr-10x-x-109">&nbsp;O.
        (2004).</span> <span class="cmti-10x-x-109">Knowledge and
        Lotteries</span><span class="cmr-10x-x-109">. Oxford: Oxford University
        Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_2391" name=
        "Xen_2391"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Helm,
        B.</span><span class="cmr-10x-x-109">&nbsp;W. (2008). Plural agents.</span>
        <span class="cmti-10x-x-109">Nous</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">42</span><span class="cmr-10x-x-109">(1),
        17&ndash;49.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1300" name=
        "Xen_1300"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Hughes,
        C., Fujisawa, K.</span><span class="cmr-10x-x-109">&nbsp;K., Ensor, R., Lecce,
        S., &amp; Marfleet, R. (2006). Cooperation</span> <span class=
        "cmr-10x-x-109">and conversations about the mind: A study of individual
        differences in 2-year-olds and</span> <span class="cmr-10x-x-109">their
        siblings.</span> <span class="cmti-10x-x-109">British Journal of Developmental
        Psychology</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">24</span><span class="cmr-10x-x-109">(1),
        53&ndash;72.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1683" name=
        "Xen_1683"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Hursthouse, R. (1991). Arational actions.</span> <span class=
        "cmti-10x-x-109">The Journal of Philosophy</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">88</span><span class=
        "cmr-10x-x-109">(2), 57&ndash;68.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1812" name=
        "Xen_1812"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Knoblich, G., Butterfill, S., &amp; Sebanz, N. (2010).
        Psychological research on joint</span> <span class="cmr-10x-x-109">action:
        Theory and data. In B.</span><span class="cmr-10x-x-109">&nbsp;Ross
        (Ed.),</span> <span class="cmti-10x-x-109">Psychology of Learning and
        Motivation</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmr-10x-x-109">volume</span><span class="cmr-10x-x-109">&nbsp;51
        (pp.</span><span class="cmr-10x-x-109">&nbsp;59&ndash;101). Academic
        Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1429" name=
        "Xen_1429"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Knoblich, G. &amp; Sebanz, N. (2008). Evolving intentions for
        social interaction: from</span> <span class="cmr-10x-x-109">entrainment to
        joint action.</span> <span class="cmti-10x-x-109">Philosophical Transactions of
        the Royal Society B</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">363</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmr-10x-x-109">2021&ndash;2031.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1821" name=
        "Xen_1821"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Kov</span><span class="cmr-10x-x-109">&Acirc;&middot;cs,</span>
        <span class="cmr-10x-x-109">&Acirc;&iexcl;.</span><span class=
        "cmr-10x-x-109">&nbsp;M., T</span><span class=
        "cmr-10x-x-109">&Atilde;&circ;gl</span><span class=
        "cmr-10x-x-109">&Acirc;&middot;s, E., &amp; Endress, A.</span><span class=
        "cmr-10x-x-109">&nbsp;D. (2010). The social sense: Susceptibility</span>
        <span class="cmr-10x-x-109">to others&rsquo; beliefs in human infants and
        adults.</span> <span class="cmti-10x-x-109">Science</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">330</span><span class=
        "cmr-10x-x-109">(6012), 1830&ndash;1834.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1290" name=
        "Xen_1290"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Kutz, C.
        (2000). Acting together.</span> <span class="cmti-10x-x-109">Philosophy and
        Phenomenological Research</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">61</span><span class="cmr-10x-x-109">(1),</span>
        <span class="cmr-10x-x-109">1&ndash;31.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_2394" name=
        "Xen_2394"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Ludwig,
        K. (2007). Collective intentional behavior from the standpoint of
        semantics.</span> <span class="cmti-10x-x-109">Nous</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">41</span><span class=
        "cmr-10x-x-109">(3), 355&ndash;393.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1437" name=
        "Xen_1437"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Luo, Y.
        &amp; Baillargeon, R. (2005). Can a self-propelled box have a goal?</span>
        <span class="cmti-10x-x-109">Psychological</span> <span class=
        "cmti-10x-x-109">Science</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">16</span><span class="cmr-10x-x-109">(8),
        601&ndash;608.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1827" name=
        "Xen_1827"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Miller,
        S. (2001).</span> <span class="cmti-10x-x-109">Social Action: A Teleological
        Account</span><span class="cmr-10x-x-109">. Cambridge: Cambridge</span>
        <span class="cmr-10x-x-109">University Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1198" name=
        "Xen_1198"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Moll, H.
        &amp; Tomasello, M. (2007). Cooperation and human cognition: the
        vygotskian</span> <span class="cmr-10x-x-109">intelligence hypothesis.</span>
        <span class="cmti-10x-x-109">Philosophical Transactions of the Royal Society
        B</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">362</span><span class="cmr-10x-x-109">(1480),</span>
        <span class="cmr-10x-x-109">639&ndash;648.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1092" name=
        "Xen_1092"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Onishi,
        K.</span><span class="cmr-10x-x-109">&nbsp;H. &amp; Baillargeon, R. (2005). Do
        15-month-old infants understand false</span> <span class=
        "cmr-10x-x-109">beliefs?</span> <span class=
        "cmti-10x-x-109">Science</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">308</span><span class="cmr-10x-x-109">(8),
        255&ndash;258.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1433" name=
        "Xen_1433"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Premack,
        D. (1990). The infant&rsquo;s theory of self-propelled objects.</span>
        <span class="cmti-10x-x-109">Cognition</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">36</span><span class=
        "cmr-10x-x-109">(1),</span> <span class="cmr-10x-x-109">1&ndash;16.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_139" name=
        "Xen_139"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Price,
        C. (2001).</span> <span class="cmti-10x-x-109">Functions in
        Mind</span><span class="cmr-10x-x-109">. Oxford: Clarendon Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1693" name=
        "Xen_1693"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Richardson, M.</span><span class="cmr-10x-x-109">&nbsp;J.,
        Campbell, W.</span><span class="cmr-10x-x-109">&nbsp;L., &amp; Schmidt,
        R.</span><span class="cmr-10x-x-109">&nbsp;C. (2009). Movement</span>
        <span class="cmr-10x-x-109">interference during action observation as emergent
        coordination.</span> <span class="cmti-10x-x-109">Neuroscience
        Letters</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">449</span><span class="cmr-10x-x-109">(2),
        117&ndash;122.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1427" name=
        "Xen_1427"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Roth,
        A.</span><span class="cmr-10x-x-109">&nbsp;S. (2004). Shared agency and
        contralateral commitments.</span> <span class="cmti-10x-x-109">The</span>
        <span class="cmti-10x-x-109">Philosophical Review</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">113</span><span class=
        "cmr-10x-x-109">(3), 359&ndash;410.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1860" name=
        "Xen_1860"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Schmidt,
        R.</span><span class="cmr-10x-x-109">&nbsp;C., Fitzpatrick, P., Caron, R.,
        &amp; Mergeche, J. (2010). Understanding</span> <span class=
        "cmr-10x-x-109">social motor coordination.</span> <span class=
        "cmti-10x-x-109">Human Movement Science</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">In Press, Corrected
        Proof</span><span class="cmr-10x-x-109">.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1211" name=
        "Xen_1211"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Searle,
        J.</span><span class="cmr-10x-x-109">&nbsp;R. (1983).</span> <span class=
        "cmti-10x-x-109">Intentionality: An Essay in the Philosophy of
        Mind</span><span class="cmr-10x-x-109">. Cambridge:</span> <span class=
        "cmr-10x-x-109">Cambridge University Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1369" name=
        "Xen_1369"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Searle,
        J.</span><span class="cmr-10x-x-109">&nbsp;R. (1990 [2002]). Collective
        intentions and actions. In</span> <span class="cmti-10x-x-109">Consciousness
        and</span> <span class="cmti-10x-x-109">Language</span> <span class=
        "cmr-10x-x-109">(pp.</span><span class="cmr-10x-x-109">&nbsp;90&ndash;105).
        Cambridge: Cambridge University Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1692" name=
        "Xen_1692"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Searle,
        J.</span><span class="cmr-10x-x-109">&nbsp;R. (1994).</span> <span class=
        "cmti-10x-x-109">The Construction of Social Reality</span><span class=
        "cmr-10x-x-109">. New York: The Free Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_2395" name=
        "Xen_2395"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Smith,
        T.</span><span class="cmr-10x-x-109">&nbsp;H. (forthcoming 2011). Playing
        one&rsquo;s part.</span> <span class="cmti-10x-x-109">Review of Philosophy
        and</span> <span class="cmti-10x-x-109">Psychology</span><span class=
        "cmr-10x-x-109">.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1373" name=
        "Xen_1373"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Sugden,
        R. (2000). Team preferences.</span> <span class="cmti-10x-x-109">Economics and
        Philosophy</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">16</span><span class="cmr-10x-x-109">,
        175&ndash;204.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1261" name=
        "Xen_1261"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Surian,
        L., Caldi, S., &amp; Sperber, D. (2007). Attribution of beliefs by
        13-month-old</span> <span class="cmr-10x-x-109">infants.</span> <span class=
        "cmti-10x-x-109">Psychological Science</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">18</span><span class=
        "cmr-10x-x-109">(7), 580&ndash;586.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1358" name=
        "Xen_1358"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Tollefsen, D. (2005). Let&rsquo;s pretend: Children and joint
        action.</span> <span class="cmti-10x-x-109">Philosophy of the</span>
        <span class="cmti-10x-x-109">Social Sciences</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">35</span><span class=
        "cmr-10x-x-109">(75), 74&ndash;97.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1828" name=
        "Xen_1828"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Tomasello, M. (2008).</span> <span class=
        "cmti-10x-x-109">Origins of HUman Communication</span><span class=
        "cmr-10x-x-109">. Cambridge, Mass.: MIT</span> <span class=
        "cmr-10x-x-109">Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1421" name=
        "Xen_1421"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Tomasello, M. &amp; Carpenter, M. (2007). Shared
        intentionality.</span> <span class="cmti-10x-x-109">Developmental
        Science</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">10</span><span class="cmr-10x-x-109">(1),
        121&ndash;5.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1090" name=
        "Xen_1090"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Tomasello, M., Carpenter, M., Call, J., Behne, T., &amp; Moll,
        H. (2005). Understanding</span> <span class="cmr-10x-x-109">and sharing
        intentions: The origins of cultural cognition.</span> <span class=
        "cmti-10x-x-109">Behavioral and Brain</span> <span class=
        "cmti-10x-x-109">Sciences</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">28</span><span class="cmr-10x-x-109">,
        675&ndash;735.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_557" name=
        "Xen_557"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Tomasello, M. &amp; Rakoczy, H. (2003). What makes human
        cognition unique? from</span> <span class="cmr-10x-x-109">individual to shared
        to collective intentionality.</span> <span class="cmti-10x-x-109">Mind and
        Language</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">18</span><span class="cmr-10x-x-109">(2),
        121&ndash;147.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1403" name=
        "Xen_1403"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Tuomela,
        R. (1995).</span> <span class="cmti-10x-x-109">The Importance of Us: A
        Philosophical Study of Basic Social</span> <span class=
        "cmti-10x-x-109">Notions</span><span class="cmr-10x-x-109">. Stanford: Stanford
        University Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1297" name=
        "Xen_1297"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Velleman, D. (1997). How to share an intention.</span>
        <span class="cmti-10x-x-109">Philosophy and Phenomenological</span>
        <span class="cmti-10x-x-109">Research</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">57</span><span class=
        "cmr-10x-x-109">(1), 29&ndash;50.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_25" name=
        "Xen_25"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Velleman, D. (2000).</span> <span class="cmti-10x-x-109">The
        Possibility of Practical Reason</span><span class="cmr-10x-x-109">. Oxford:
        Oxford University</span> <span class="cmr-10x-x-109">Press.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1778" name=
        "Xen_1778"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Vesper,
        C., Butterfill, S., Knoblich, G., &amp; Sebanz, N. (2010). A minimal
        architecture</span> <span class="cmr-10x-x-109">for joint action.</span>
        <span class="cmti-10x-x-109">Neural Networks</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">23</span><span class=
        "cmr-10x-x-109">(8-9), 998&ndash;1003.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_87" name=
        "Xen_87"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Wellman,
        H., Cross, D., &amp; Watson, J. (2001). Meta-analysis of theory of mind</span>
        <span class="cmr-10x-x-109">development: The truth about false-belief.</span>
        <span class="cmti-10x-x-109">Child Development</span><span class=
        "cmr-10x-x-109">,</span> <span class="cmti-10x-x-109">72</span><span class=
        "cmr-10x-x-109">(3), 655&ndash;684.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_89" name=
        "Xen_89"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Wimmer,
        H. &amp; Perner, J. (1983). Beliefs about beliefs: Representation and</span>
        <span class="cmr-10x-x-109">constraining function of wrong beliefs in young
        children&rsquo;s understanding of deception.</span> <span class=
        "cmti-10x-x-109">Cognition</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">13</span><span class="cmr-10x-x-109">,
        103&ndash;128.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_717" name=
        "Xen_717"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Woodward, A.</span><span class="cmr-10x-x-109">&nbsp;L. (1998).
        Infants selectively encode the goal object of an actor&rsquo;s</span>
        <span class="cmr-10x-x-109">reach.</span> <span class=
        "cmti-10x-x-109">Cognition</span><span class="cmr-10x-x-109">,</span>
        <span class="cmti-10x-x-109">69</span><span class="cmr-10x-x-109">,
        1&ndash;34.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_1439" name=
        "Xen_1439"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class=
        "cmr-10x-x-109">Woodward, A.</span><span class="cmr-10x-x-109">&nbsp;L. &amp;
        Sommerville, J.</span><span class="cmr-10x-x-109">&nbsp;A. (2000).
        Twelve-month-old infants interpret</span> <span class="cmr-10x-x-109">action in
        context.</span> <span class="cmti-10x-x-109">Psychological
        Science</span><span class="cmr-10x-x-109">,</span> <span class=
        "cmti-10x-x-109">11</span><span class="cmr-10x-x-109">(1),
        73&ndash;77.</span></p>

        <p class="bibitem"><span class="biblabel"><a id="Xen_161" name=
        "Xen_161"></a><span class="bibsp"><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span><span class=
        "cmr-10x-x-109">&nbsp;</span></span></span><span class="cmr-10x-x-109">Wright,
        L. (1976).</span> <span class="cmti-10x-x-109">Teleological
        Explanations</span><span class="cmr-10x-x-109">. Berkeley: University of
        California Press.</span></p>
      </div>


      <div class="footnotes">
        <h3>Footnotes</h3>
        <!--l. 69-->

        <p class="indent"><span class="footnote-mark"><a href="#fn1x0-bk" id="fn1x0"
        name="fn1x0"><sup class="textsuperscript">1</sup></a></span><span class=
        "cmr-10">Other notable contributions not discussed in this paper due to lack of
        space include</span> <a href="#Xen_1369"><span class=
        "cmr-10">Searle</span></a><span class="cmr-10">&nbsp;(</span><a href=
        "#Xen_1369"><span class="cmr-10">2002</span></a><span class="cmr-10">),</span>
        <a href="#Xen_1287"><span class="cmr-10">Gilbert</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1287"><span class=
        "cmr-10">2006</span></a><span class="cmr-10">),</span> <a href=
        "#Xen_1403"><span class="cmr-10">Tuomela</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1403"><span class=
        "cmr-10">1995</span></a><span class="cmr-10">),</span> <a href=
        "#Xen_1373"><span class="cmr-10">Sugden</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1373"><span class=
        "cmr-10">2000</span></a><span class="cmr-10">),</span> <a href=
        "#Xen_1383"><span class="cmr-10">Gold &amp; Sugden</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1383"><span class=
        "cmr-10">2007a</span></a><span class="cmr-10">),</span> <a href=
        "#Xen_1290"><span class="cmr-10">Kutz</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1290"><span class=
        "cmr-10">2000</span></a><span class="cmr-10">) and</span> <a href=
        "#Xen_1427"><span class="cmr-10">Roth</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1427"><span class=
        "cmr-10">2004</span></a><span class="cmr-10">).</span></p><!--l. 71-->

        <p class="indent"><span class="footnote-mark"><a href="#fn2x0-bk" id="fn2x0"
        name="fn2x0"><sup class="textsuperscript">2</sup></a></span><a href=
        "#Xen_1357"><span class="cmr-10">Bratman</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1357"><span class=
        "cmr-10">1997</span></a><span class="cmr-10">, p.</span><span class=
        "cmr-10">&nbsp;142). See</span> <a href="#Xen_1197"><span class=
        "cmr-10">Bratman</span></a><span class="cmr-10">&nbsp;(</span><a href=
        "#Xen_1197"><span class="cmr-10">1992</span></a><span class="cmr-10">,
        pp.</span><span class="cmr-10">&nbsp;338-9) for further details on the
        relation</span> <span class="cmr-10">between shared intentions and shared
        intentional activities.</span></p><!--l. 79-->

        <p class="indent"><span class="footnote-mark"><a href="#fn3x0-bk" id="fn3x0"
        name="fn3x0"><sup class="textsuperscript">3</sup></a></span><span class=
        "cmr-10">In</span> <a href="#Xen_1356"><span class=
        "cmr-10">Bratman</span></a><span class="cmr-10">&nbsp;(</span><a href=
        "#Xen_1356"><span class="cmr-10">1993</span></a><span class="cmr-10">), the
        following were offered as jointly sufficient</span> <span class="cmti-10">and
        individually necessary</span> <span class="cmr-10">conditions; the retreat to
        sufficient conditions occurs in</span> <a href="#Xen_1357"><span class=
        "cmr-10">Bratman</span></a><span class="cmr-10">&nbsp;(</span><a href=
        "#Xen_1357"><span class="cmr-10">1997</span></a><span class="cmr-10">,
        pp.</span><span class="cmr-10">&nbsp;143-4) where he notes</span> <span class=
        "cmr-10">that for all that I have said, shared intention might be multiply
        realizable.</span></p><!--l. 115-->

        <p class="indent"><span class="footnote-mark"><a href="#fn4x0-bk" id="fn4x0"
        name="fn4x0"><sup class="textsuperscript">4</sup></a></span><span class=
        "cmr-10">The most widely discussed propositional attitude has been belief; see
        (</span><a href="#Xen_87"><span class="cmr-10">Wellman</span> <span class=
        "cmr-10">et</span><span class="cmr-10">&nbsp;al.</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_87"><span class=
        "cmr-10">2001</span></a><span class="cmr-10">;</span><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_89"><span class="cmr-10">Wimmer &amp;
        Perner</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_89"><span class="cmr-10">1983</span></a><span class="cmr-10">) but also
        (</span><a href="#Xen_1789"><span class="cmr-10">Baillargeon
        et</span><span class="cmr-10">&nbsp;al.</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1789"><span class=
        "cmr-10">2010</span></a><span class="cmr-10">;</span><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1821"><span class=
        "cmr-10">Kov</span><span class="cmr-10">&Acirc;&middot;cs</span> <span class=
        "cmr-10">et</span><span class="cmr-10">&nbsp;al.</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1821"><span class=
        "cmr-10">2010</span></a><span class="cmr-10">;</span><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1092"><span class="cmr-10">Onishi &amp;
        Baillargeon</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_1092"><span class="cmr-10">2005</span></a><span class=
        "cmr-10">;</span><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_1261"><span class="cmr-10">Surian et</span><span class=
        "cmr-10">&nbsp;al.</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_1261"><span class="cmr-10">2007</span></a><span class="cmr-10">). Apperly
        and Butterfill (</span><a href="#Xen_1686"><span class="cmr-10">Apperly
        &amp;</span> <span class="cmr-10">Butterfill</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1686"><span class=
        "cmr-10">2009</span></a><span class="cmr-10">) argue for the possibility that
        while children in their first and second year have</span> <span class=
        "cmr-10">abilities to track beliefs, they cannot ascribe beliefs or other
        propositional attitudes as</span> <span class="cmr-10">such.</span></p>
        <!--l. 120-->

        <p class="indent"><span class="footnote-mark"><a href="#fn5x0-bk" id="fn5x0"
        name="fn5x0"><sup class="textsuperscript">5</sup></a></span> <span class=
        "cmr-10">There is evidence that children of this age have difficulty
        understanding intentions</span> <span class="cmr-10">(</span><a href=
        "#Xen_69"><span class="cmr-10">Astington</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_69"><span class=
        "cmr-10">1991</span></a><span class="cmr-10">;</span><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_70"><span class="cmr-10">Astington &amp;
        Gopnik</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_70"><span class="cmr-10">1991</span></a><span class="cmr-10">). A range
        of researchers have argued</span> <span class="cmr-10">that infants form
        expectations about goal-directed activity (</span><a href=
        "#Xen_1438"><span class="cmr-10">Csibra</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1438"><span class=
        "cmr-10">2008</span></a><span class="cmr-10">;</span><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1207"><span class="cmr-10">Gergely</span>
        <span class="cmr-10">et</span><span class=
        "cmr-10">&nbsp;al.</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_1207"><span class="cmr-10">1995</span></a><span class=
        "cmr-10">;</span><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_717"><span class="cmr-10">Woodward</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_717"><span class=
        "cmr-10">1998</span></a><span class="cmr-10">;</span><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1439"><span class="cmr-10">Woodward &amp;
        Sommerville</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_1439"><span class="cmr-10">2000</span></a><span class="cmr-10">). It may
        be that the understanding</span> <span class="cmr-10">of goal-directed activity
        examined by these studies falls short of an understanding of</span>
        <span class="cmr-10">intention.</span></p><!--l. 123-->

        <p class="indent"><span class="footnote-mark"><a href="#fn6x0-bk" id="fn6x0"
        name="fn6x0"><sup class="textsuperscript">6</sup></a></span><span class=
        "cmr-10">A related objection may apply to Claire Hughes appeal to reciprocal
        exchanges.</span> <span class="cmr-10">She specifies that such exchanges depend
        on modelling the others intentions/desires</span> <span class="cmr-10">(i.e.
        reflecting on the others inner states) and monitoring the others understanding
        of</span> <span class="cmr-10">ones own intentions and desires (i.e. detecting
        mistaken beliefs about ones own inner</span> <span class="cmr-10">states)
        (</span><a href="#Xen_1300"><span class="cmr-10">Hughes et</span><span class=
        "cmr-10">&nbsp;al.</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_1300"><span class="cmr-10">2006</span></a><span class="cmr-10">,
        p.</span><span class="cmr-10">&nbsp;56). Thus engaging in reciprocal exchanges
        appears to</span> <span class="cmr-10">require fluid and sophisticated
        ascriptions of mental states. Accordingly, engaging in</span> <span class=
        "cmr-10">such exchanges cannot significantly explain how children develop
        abilities to think about</span> <span class="cmr-10">minds.</span></p>
        <!--l. 128-->

        <p class="indent"><span class="footnote-mark"><a href="#fn7x0-bk" id="fn7x0"
        name="fn7x0"><sup class="textsuperscript">7</sup></a></span><a href=
        "#Xen_1358"><span class="cmr-10">Tollefsen</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1358"><span class=
        "cmr-10">2005</span></a><span class="cmr-10">) objects to Bratman's account of
        shared intention on the grounds that it requires</span> <span class=
        "cmr-10">common knowledge. This objection also fails because common knowledge
        is explicitly required by</span> <span class="cmr-10">what I am calling
        Bratman's substantial account only, which gives sufficient but not
        necessary</span> <span class="cmr-10">conditions for shared intention. (A
        second potential problem for Tollefsens argument is that it</span> <span class=
        "cmr-10">requires the premise that young children engage in joint actions of
        the kind Bratman's account aims</span> <span class="cmr-10">to characterise, the
        kind whose paradigms involve coordinating potentially long-term</span>
        <span class="cmr-10">plans.)</span></p><!--l. 141-->

        <p class="indent"><span class="footnote-mark"><a href="#fn8x0-bk" id="fn8x0"
        name="fn8x0"><sup class="textsuperscript">8</sup></a></span><a href=
        "#Xen_1358"><span class="cmr-10">Tollefsen</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_1358"><span class=
        "cmr-10">2005</span></a><span class="cmr-10">) argues that Bratman's account of
        joint action is incorrect on the</span> <span class="cmr-10">grounds that
        children engage in joint action but not in shared intentional activity
        as</span> <span class="cmr-10">characterised by Bratman. The considerations
        below identify a missing premise in her</span> <span class=
        "cmr-10">argument.</span></p><!--l. 181-->

        <p class="indent"><span class="footnote-mark"><a href="#fn9x0-bk" id="fn9x0"
        name="fn9x0"><sup class="textsuperscript">9</sup></a></span><span class=
        "cmr-10">There may be other notions of joint action. For instance, Ludwig
        asserts that [t]he concept of a</span> <span class="cmr-10">joint action as
        such is just that of an event of which there are multiple agents
        (</span><a href="#Xen_2394"><span class="cmr-10">2007</span></a><span class=
        "cmr-10">, p.</span><span class="cmr-10">&nbsp;366). As he</span> <span class=
        "cmr-10">notes, it is a straightforward consequence of this view that if there
        are joint actions then there are</span> <span class="cmr-10">joint actions
        without shared intentions.</span></p><!--l. 206-->

        <p class="indent"><span class="footnote-mark"><a href="#fn10x0-bk" id="fn10x0"
        name="fn10x0"><sup class="textsuperscript">10</sup></a></span><span class=
        "cmr-10">This is suggested by Vellemans (</span><a href="#Xen_25"><span class=
        "cmr-10">2000</span></a><span class="cmr-10">, pp.</span><span class=
        "cmr-10">&nbsp;10-30) discussion of purposeful activity.</span></p>
        <!--l. 208-->

        <p class="indent"><span class="footnote-mark"><a href="#fn11x0-bk" id="fn11x0"
        name="fn11x0"><sup class="textsuperscript">11</sup></a></span><span class=
        "cmr-10">This intuition provides a loose connection between the notion of
        shared goals and Millers notion</span> <span class="cmr-10">of a collective end
        (</span><a href="#Xen_1827"><span class="cmr-10">Miller</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_1827"><span class=
        "cmr-10">2001</span></a><span class="cmr-10">). While it would be useful to
        discuss differences and similarities in</span> <span class="cmr-10">substance
        and motivation, there is no space to do that here.</span></p><!--l. 245-->

        <p class="noindent"><span class="footnote-mark"><a href="#fn12x0-bk" id=
        "fn12x0" name="fn12x0"><sup class=
        "textsuperscript">12</sup></a></span><span class="cmr-10">The on balance
        qualification in conditions (c) and (d) rules out cases where agents do have
        the</span> <span class="cmr-10">specified expectations about goals and outcomes
        but also have further, conflicting expectations</span> <span class=
        "cmr-10">which outweigh them.</span></p><!--l. 262-->

        <p class="indent"><span class="footnote-mark"><a href="#fn13x0-bk" id="fn13x0"
        name="fn13x0"><sup class="textsuperscript">13</sup></a></span><span class=
        "cmr-10">On goals as functions of actions see, for example, Wright
        (</span><a href="#Xen_161"><span class="cmr-10">Wright</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_161"><span class=
        "cmr-10">1976</span></a><span class="cmr-10">) and Price (</span><a href=
        "#Xen_139"><span class="cmr-10">Price</span></a><span class=
        "cmr-10">&nbsp;</span><a href="#Xen_139"><span class=
        "cmr-10">2001</span></a><span class="cmr-10">).</span> <span class="cmr-10">A
        variety of research supports the claim that young children, non-human primates
        and corvids track</span> <span class="cmr-10">the functions of things
        (including Rakoczy and Tomasello 2007; Casler and Kelemen 2007; Csibra</span>
        <span class="cmr-10">and Gergely 2007; Kelemen 1999; German and Defeyter 2000;
        Hauser 1997; Emery and</span> <span class="cmr-10">Clayton 2004). On the
        abilities of these groups to represent goals specifically, see further</span>
        <span class="cmr-10">footnote</span><span class="cmr-10">&nbsp;</span><a href=
        "#x1-4002f5"><span class="cmr-10">5</span>
        <!--tex4ht:ref: fn:goals --></a><span class="cmr-10">.</span></p><!--l. 270-->

        <p class="indent"><span class="footnote-mark"><a href="#fn14x0-bk" id="fn14x0"
        name="fn14x0"><sup class="textsuperscript">14</sup></a></span><span class=
        "cmr-10">This view is endorsed by</span> <a href="#Xen_1356"><span class=
        "cmr-10">Bratman</span></a><span class="cmr-10">&nbsp;(</span><a href=
        "#Xen_1356"><span class="cmr-10">1993</span></a><span class="cmr-10">,
        p.</span><span class="cmr-10">&nbsp;103) and rejected by</span> <a href=
        "#Xen_2394"><span class="cmr-10">Ludwig</span></a><span class=
        "cmr-10">&nbsp;(</span><a href="#Xen_2394"><span class=
        "cmr-10">2007</span></a><span class="cmr-10">,</span> <span class=
        "cmr-10">pp.</span><span class="cmr-10">&nbsp;387-8).</span></p><!--l. 287-->

        <p class="indent"><span class="footnote-mark"><a href="#fn15x0-bk" id="fn15x0"
        name="fn15x0"><sup class="textsuperscript">15</sup></a></span><span class=
        "cmr-10">This example is can be modelled as a Hawk-Dove game and is adapted
        from a discussion of Gold</span> <span class="cmr-10">and Sugden
        (</span><a href="#Xen_2393"><span class="cmr-10">Gold &amp;
        Sugden</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_2393"><span class="cmr-10">2007b</span></a><span class="cmr-10">,
        pp.</span><span class="cmr-10">&nbsp;304-8). As these authors note, the
        combination of actions is</span> <span class="cmr-10">not a rational
        consequence of team reasoning (</span><a href="#Xen_1373"><span class=
        "cmr-10">Sugden</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_1373"><span class="cmr-10">2000</span></a><span class="cmr-10">, on team
        reasoning see) and so does not</span> <span class="cmr-10">involve the
        associated notion of group agency (</span><a href="#Xen_1383"><span class=
        "cmr-10">Gold &amp; Sugden</span></a><span class="cmr-10">&nbsp;</span><a href=
        "#Xen_1383"><span class="cmr-10">2007a</span></a><span class=
        "cmr-10">).</span></p><!--l. 297-->

        <p class="indent"><span class="footnote-mark"><a href="#fn16x0-bk" id="fn16x0"
        name="fn16x0"><sup class="textsuperscript">16</sup></a></span><span class=
        "cmr-10">Knoblich and Sebanz claim that lifting the basket together requires
        joint intentionality which in</span> <span class="cmr-10">turn requires shared
        intentions in roughly Bratman's sense: [t]here needs to be an intentional</span>
        <span class="cmr-10">structure that allows an actor to relate his/her own
        intention and the others intention to an intention</span> <span class=
        "cmr-10">that drives the joint activity (</span><a href=
        "#Xen_1429"><span class="cmr-10">2008</span></a><span class="cmr-10">,
        p.</span><span class="cmr-10">&nbsp;2025). I reject this claim for the reasons
        given</span> <span class="cmr-10">above.</span></p>
      </div>


---

Title: Joint Action: A Minimalist Approach
Authors: Stephen A. Butterfill
Year: 2016
Type: Publication



---

Title: Joint Action: What Is Shared?
Authors: Stephen A. Butterfill and Natalie Sebanz (eds.)
Year: 2011
Journal: Review of Philosophy and Psychology
Type: Publication

<h3>Description</h3>
<p>A collection of papers by philosophers and cognitive scientists on joint action and shared intention.</p>
<h3>Contents</h3>
<ol>
  <li>Stephen A. Butterfill and Natalie Sebanz: Editorial: Joint Action: What Is Shared?</li>
  <li>Dorit Wenke, Silke Atmaca, Antje Holl&auml;nder: What is Shared in Joint Action? Issues of Co-representation, Response Conflict, and Agent Identification</li>
  <li>Elisabeth Pacherie: Framing Joint Action</li>
  <li>Celia A. Brownell: Early Developments in Joint Action</li>
  <li>Thomas H. Smith: Playing One's Part</li>
  <li>Jay R. Elliott: Stag Hunts and Committee Work: Cooperation and the Mutualistic Paradigm</li>
  <li>Christopher Woodard: Rationality and the Unit of Action</li>
  <li>Axel Seemann: Joint Motor Action and Cross-Creature Embodiment</li>
  <li>Giovanni Pezzulo: Shared Representations as Coordination Tools for Interaction</li>
  <li>Olle Blomberg: Socially Extended Intentions-in-Action</li>
  <li>John Michael: Shared Emotions and Joint Action</li>
</ol>

---

Title: Joint Action: What Is Shared?  Introduction to the special issue
Authors: Stephen A. Butterfill and Natalie Sebanz
Year: 2011
Journal: Review of Philosophy and Psychology
Type: Publication

## Abstract

Joint action raises a tangle of philosophical, developmental and cognitive questions. Many of these questions are naturally understood to be about sharing, about the sharing of intentions, emotions, task representations, and action plans. Of course it is not easy to explain what it means to share in this context. Few researchers hold that agents can literally share intentions, emotions or other states in the sense in which two siblings share a parent; and while it is uncontroversial that agents can share intentions, emotions and other states in the sense in which siblings share genes, on almost any account this kind of sharing is not sufficient for joint action. The overarching question in this special issue is which forms of sharing (if any) are needed to explain the development of joint action, to characterise the mechanisms which make effective joint action possible and to explain what joint action is. In this Introduction we will explain how the papers in this special issue contribute to answering this question and, in some cases, raise new puzzles.



---

Title: Direct and indirect measures of Level-2 perspective-taking in children and adults
Authors: Andrew Surtees, Stephen A. Butterfill and Ian Apperly
Year: 2012
Journal: British Journal of Developmental Psychology
Type: Publication

## Abstract

Studies with infants show divergence between performance on theory of mind tasks depending on whether direct or indirect measures are used. It has been suggested that direct measures assess a flexible but cognitively demanding ability to reason about the minds of others, whereas indirect measures assess distinct processes which afford more efficient but less flexible theory of mind abilities (Apperly & Butterfill, 2009). This leads to the prediction that performance on indirect measures should be subject to signature limits. The current study tested whether the Level-1/Level-2 distinction might constitute one such limit. The study adapted a task that has shown evidence of Level-1 perspective-taking on both direct and indirect measures (Samson, Apperly, Braithwaite, Andrews, & Bodley-Scott, 2010). The aim was to test Level-2 perspective-taking in a sample of 6- to 11-year-olds (N = 80) and adults (N = 20). Participants were able to make Level-2 judgements on the direct measure. In contrast with the findings from Level-1 perspective-taking, there was no evidence of automatic processing of Level-2 perspectives on the indirect measure. This finding is consistent with the view that theory of mind abilities assessed by indirect measures are subject to signature limits. The Level-1/Level-2 distinction, suitably refined, marks one way in which efficient but inflexible theory of mind abilities are limited.




---

Title: A view from mindreading on fast-and-slow thinking
Authors: Low, Jason and Butterfill, Stephen A. and Michael, John
Year: 2023
Journal: Behavioral and Brain Sciences
Type: Publication

# Abstract
De Neys’ incisive critique of empirical and theoretical research on the exclusivity feature underscores the depth of the challenge of explaining the interplay of fast and slow processes.  We argue that a closer look at research on mindreading reveals abundant evidence for the exclusivity feature—as well as methodological and theoretical perspectives that could inform research on fast and slow thinking. 


<p>&nbsp;</p>

<div class="fulltext">

<em>This is a response to Wim De Neys’</em> <a 
          href="https://doi.org/10.1017/S0140525X2200142X"
          target="_blank" 
          rel="noopener noreferrer"
          class="ml-2 font-medium hover:text-blue-600 dark:hover:text-blue-400"
        >
          Advancing theorizing about fast-and-slow thinking
          <svg xmlns="http://www.w3.org/2000/svg" class="inline-block w-4 h-4 ml-1" fill="none" viewBox="0 0 24 24" stroke="currentColor">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14" />
          </svg>
        </a>


De Neys opposes the ‘exclusivity feature’, on which fast and slow processes are ‘exclusively tied’ to particular responses. De Neys explains that ‘there is no solid empirical ground for the exclusivity assumption’—this is the ‘fundamental problem’ of the target article. However, with respect to empirical evidence, De Neys mentions mindreading only in passing.  Will a closer look at mindreading give him reason to reconsider the exclusivity assumption?

Methodologically, the studies De Neys relies on mostly involve observing direct, explicit choices, as is typically the case in research on reasoning. In mindreading research, by contrast, the norm is to observe both indirect implicit and direct explicit behaviours generated by a single scenario. These include anticipatory looking and verbal responses (Clements & Perner, 1994), early mediolateral motor activity and purposive action (Zani et al., 2020), response times and choices (Edwards & Low, 2017), or curvature and initiation time of computer-mouse movements (Van der Wel et al., 2014). In Clements and Perner’s seminal study, 3-year-olds correctly looked in anticipation of the belief-based action of an agent even though they gave incorrect explicit verbal predictions about where the agent will go to search for the object. The case for accepting that certain eye movements can index a fast mindreading process that is largely unchanging over development is strengthened by evidence that anticipatory looking in infants (Meristo et al., 2012) and younger and older adults (Grainger et al., 2018) show a similar pattern. Slow mindreading as indexed by verbal deliberations is scaffolded by culture, language and building of schemas and causal representations (Christiansen & Michael, 2016), and exhibits distinctive developmental trajectories. 

None of this directly undermines De Neys’ critique of the exclusivity feature. But a fruitful strand of developmental research relies on the method of signature limits (Carey, 2009). A signature limit of a process is a pattern of responses that the process generates which are incorrect or suboptimal (hence ‘limit’) and which no other process under consideration would generate (hence ‘signature’). Butterfill & Apperly (2013) argued on theoretical grounds that some fast processes for tracking others’ mental states are likely to generate incorrect predictions about beliefs involving mistakes about numerical identity. And in support of this, Low and Watts (2013) found that whilst 3-year-olds, 4-year-olds and adults show correct looking behaviour in an object-location false-belief task, the same participants showed incorrect looking behaviour in an object-identity false-belief task. The switch from processing a location false-belief task to a numerical-identity false-belief task did not influence the usual age-related improvements in participants’ explicit verbal judgements, as predicted. This is not just a hint that there is more than one process: seeing the same signature limit in adults as in infants (Edwards & Low, 2019; Fizke et al., 2017; Woo & Spelke, 2021), we infer that the fast process (and the conditions in which it occurs and the outputs it generates) does not completely overlap with the slow process (though not everyone would agree; Thompson, 2014).  You cannot reject the exclusivity feature and use the method of signature limits. The view from mindreading therefore indicates that the exclusivity assumption is solidly grounded after all.

Given that the empirical basis for rejecting the exclusivity assumption is tenuous – at least in the context of mindreading research – it is important to evaluate the theoretical considerations offered by De Neys. He argues that, given the plausibility of automatization, any conclusion arrived at by a slow process could, in principle at least, also be arrived at by a fast process. However, this theoretical argument is less challenging than it first appears. Automatization tells us that any conclusion arrived at by a slow process could be arrived at by some fast process but not which fast processes could arrive at that conclusion.

Here we face a problem. A model of the interplay of fast and slow processes is needed, as De Neys argues. But De Neys’ own elegant model is unavailable because it ‘forces us to get rid of exclusivity’ (p. 24). Further, developmental evidence speaks against it. On De Neys’ model, the slow process should only be triggered if fast processes generate conflicting responses, leading to uncertainty. But consider children’s responses to a mindreading context set up by Ruffman et al. (2001). The children watched Ed acquire a false belief. They were then invited to place bets on which of two slides Ed would come down. Their bets revealed they felt no uncertainty (younger children went all in on the wrong slide). But Ruffman et al. also measured children’s anticipatory looking as Ed was about to emerge, and this measure indicated a correct prediction. We take the betting to index a slow process and the looking to index a fast process. In this case we seem to have neither conflict among fast processes nor uncertainty (although of course we cannot entirely rule this out).

Is there an alternative to De Ney’s model? The key is to understand what other than conflict in fast processes might trigger (and halt) slow processes. One candidate is low cognitive fluency. In Ruffman et al.’s (2001) study, asking children to choose in which of two locations to place their bets interrupts their processing and so triggers deliberation; as they reason through the problem (Ed will go where his chocolate is), they regain cognitive fluency. Because this does not require that slow processes concerning a question are driven by fast processes generating responses to the same question, this proposal leaves room for discretion whereby individuals are free to make explicit judgements which conflict with implicit responses. Just as the developmental evidence indicates.

In sum, widening De Neys’ view to consider mindreading highlights the potential of more diverse methods than commonly employed in research on reasoning, and points toward empirical and theoretical obstacles to the proposed advance. Taking a step back, though, we find ourselves on common ground with De Neys: his critique shows both that more evidence is needed and that the interplay of fast and slow processes is truly a deep problem.


# References

Butterfill, S. A., & Apperly, I. A. (2013). How to construct a minimal theory of mind. Mind and Language, 28(5), 606–637. https://doi.org/10.1111/mila.12036

Carey, S. (2009). The origin of concepts. New York, NY: Oxford University Press. https://doi.org/10.1093/acprof:oso/9780195367638.001.0001
 
Christensen, W., & Michael, J. (2016). From two systems to a multi-systems architecture for mindreading. New Ideas in Psychology, 40(A), 48–64. https://doi.org/10.1016/j.newideapsych.2015.01.003
 
Clements, W. A., & Perner, J. (1994). Implicit understanding of belief. Cognitive Development, 9(4), 377–395. https://psycnet.apa.org/doi/10.1016/0885-2014(94)90012-4
 
Edwards, K., & Low, J. (2017) Reaction time profiles of adults’ action prediction reveal two mindreading systems. Cognition, 160, 1–16. https://doi.org/10.1016/j.cognition.2016.12.004

Edwards, K., & Low, J. (2019). Level 2 perspective-taking distinguishes automatic and non-automatic belief-tracking. Cognition, 193, 104017. https://doi.org/10.1016/j.cognition.2019.104017
 
Fizke, E., Butterfill, S. A., van de Loo, L., Reindl, E., & Rakoczy, H. (2017) Are there signature limits in early theory of mind? Journal of Experimental Child Psychology, 162, 209–224. https://doi.org/10.1016/j.jecp.2017.05.005
 
Grainger, S. A., Henry, J. D., Naughtin, C. K., Comino, M. S., & Dux, P. E. (2018). Implicit false belief tracking is preserved in late adulthood. Quarterly Journal of Experimental Psychology, 71(9), 1980–1987. https://doi.org/10.1177/1747021817734690
 
Low, J., & Watts, J. (2013). Attributing false beliefs about object identity reveals a signature blind spot in humans’ efficient mind-reading system. Psychological Science, 24(3), 305–311. https://doi.org/10.1177/0956797612451469
 
Meristo, M., Morgan, G., Geraci, A., Lozzi, L., Hjelmquist, E., Surian, L., & Siegal, M. (2012). Belief attribution in deaf and hearing infants. Developmental Science, 15(5), 633–640. https://doi.org/10.1111/j.1467-7687.2012.01155.x

Ruffman, T., Garnham, W., Import, A., & Connolly, D. (2001). Does eye gaze indicate knowledge of false belief: Charting transitions in knowledge. Journal of Experimental Child Psychology, 80(3), 201–224. https://doi.org/10.1006/jecp.2001.2633
 
Thompson, J. R. (2014). Signature limits in mindreading systems. Cognitive Science, 38(7), 1432–1455. https://doi.org/10.1111/cogs.12117
 
van der Wel, R. P., Sebanz, N., & Knoblich, G. (2014). Do people automatically track others’ beliefs? Evidence from a continuous measure. Cognition, 130(1), 128–133. https://doi.org/10.1016/j.cognition.2013.10.004
 
Woo, B., & Spelke, E. (2021). Limits to early mental state reasoning: Fourteen-to 15-month-old infants appreciate whether others can see objects, but not others’ experiences of objects. Proceedings of the Annual Meeting of the Cognitive Science Society, 43, 1914–1920. https://escholarship.org/uc/item/42n9x4n3
 
Zani, G., Butterfill, S. A., & Low, J. (2020). Mindreading in the balance: Adults' mediolateral leaning and anticipatory looking foretell others' action preparation in a false-belief interactive task. Royal Society Open Science, 7(1), 191167. https://doi.org/10.1098/rsos.191167

</div>

---

Title: Mindreading in the Balance: Adults’ Mediolateral Leaning and Anticipatory Looking Foretell Others’ Action Preparation in a False-Belief Interactive Task
Authors: Giovanni Zani, Stephen A. Butterfill and Jason Low
Year: 2020
Journal: Royal Society Open Science
Type: Publication

## Abstract

Anticipatory looking on mindreading tasks can indicate our expectation of an agent's action. The challenge is that social situations are often more complex, involving instances where we need to track an agent's false belief to successfully identify the outcome to which an action is directed. If motor processes can guide how action goals are understood, it is conceivable—where that kind of goal ascription occurs in false-belief tasks—for motor representations to account for someone's belief-like state. Testing adults (N = 42) in a real-time interactive helping scenario, we discovered that participants' early mediolateral motor activity (leftwards–rightwards leaning on balance board) foreshadowed the agent's belief-based action preparation. These results suggest fast belief-tracking can modulate motor representations generated in the course of one's interaction with an agent. While adults' leaning, and anticipatory looking, revealed the contribution of fast false-belief tracking, participants did not correct the agent's mistake in their final helping action. These discoveries suggest that adults may not necessarily use another's belief during overt social interaction or find reflecting on another's belief as being normatively relevant to one's own choice of action. Our interactive task design offers a promising way to investigate how motor and mindreading processes may be variously integrated.




---

Title: Introduction: Symposium on ‘How to Constuct a Minimal Theory of Mind’
Authors: Stephen A. Butterfill & Ian A. Apperly
Year: 2013
Type: Publication

<p>The target paper is here: <a href="/writing/minimal_theory_of_mind/">How to Construct a Minimal Theory of Mind</a></p>
<p>There are commentaries by <a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/rakoczy.pdf" target="_blank">Hannes Rakoczy [pdf]</a><span>, </span><a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/spaulding.pdf" target="_blank">Shannon Spaulding [pdf]</a><span> and </span><a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/zawidzki.pdf" target="_blank">Tadeusz Zawidzki [pdf]</a><span> and comments from many others on  </span><a href="http://philosophyofbrains.com/2013/11/11/symposium-on-butterfill-and-apperlys-how-to-construct-a-minimal-theory-of-mind-mind-language-28-5-606-63.aspx">Brains</a><span>.</span></p>
<p>We also wrote  <a href="/writing/minimal_brains_discussion_replies/">replies to the commentaries</a><span>.</span></p>

---

Title: Replies to Three Commentaries on ‘How to Construct a Minimal Theory of Mind’
Authors: Stephen A. Butterfill & Ian A. Apperly
Year: 2013
Type: Publication

## Abstract

We are grateful to Hannes Rakoczy, Shannon Spaulding and Tadeusz Zawidzki for three illuminating and very helpful critical commentaries. Here we report some of what we have learned from them and answer the objections.


<p>The target paper is here: <a href="/writing/minimal_theory_of_mind/">How to Construct a Minimal Theory of Mind</a></p>
<p>There are commentaries by <a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/rakoczy.pdf" target="_blank">Hannes Rakoczy [pdf]</a><span>, </span><a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/spaulding.pdf" target="_blank">Shannon Spaulding [pdf]</a><span> and </span><a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/zawidzki.pdf" target="_blank">Tadeusz Zawidzki [pdf]</a><span> and comments from many others on  </span><a href="http://philosophyofbrains.com/2013/11/11/symposium-on-butterfill-and-apperlys-how-to-construct-a-minimal-theory-of-mind-mind-language-28-5-606-63.aspx">Brains</a><span>.</span></p>

---

Title: How to Construct a Minimal Theory of Mind
Authors: Stephen A. Butterfill and Ian A. Apperly
Year: 2013
Journal: Mind and Language
Type: Publication

## Abstract

What could someone represent that would enable her to track, at least within limits, others' perceptions, knowledge states and beliefs including false beliefs?  An obvious possibility is that she might represent these very attitudes as such. It is sometimes tacitly or explicitly assumed that this is the only possible answer. However we argue that several recent discoveries in developmental, cognitive, and comparative psychology indicate the need for other, less obvious possibilities. Our aim is to meet this need by describing the construction of a minimal theory of mind.  Minimal theory of mind is rich enough to explain systematic success on tasks held to be acid tests for theory of mind cognition including many false belief tasks. Yet minimal theory of mind does not require representing propositional attitudes, or any other kind of representation, as such. Minimal theory of mind may be what enables those with limited cognitive resources or little conceptual sophistication, such as infants, chimpanzees, scrub-jays and human adults under load,  to track others' perceptions, knowledge states and beliefs.


<p> <a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/rakoczy.pdf" target="_blank">Hannes Rakoczy [pdf]</a><span>, </span><a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/spaulding.pdf" target="_blank">Shannon Spaulding [pdf]</a><span> and </span><a href="http://philosophyofbrains.com/wp-content/uploads/2013/11/zawidzki.pdf" target="_blank">Tadeusz Zawidzki [pdf]</a><span> have commentaries  on this paper in  a symposium in </span><a href="http://philosophyofbrains.com/2013/11/11/symposium-on-butterfill-and-apperlys-how-to-construct-a-minimal-theory-of-mind-mind-language-28-5-606-63.aspx">Brains</a><span>, which includes comments from many others.  </span><span>We also wrote  </span><a href="/writing/minimal_brains_discussion_replies/">replies to the commentaries</a><span>.</span></p>


---

Title: What are Modules and What Is Their Role in Development?
Authors: Stephen A. Butterfill
Year: 2007
Journal: Mind and Language
Type: Publication

## Abstract

Modules are widely held to play a central role in explaining mental development and in accounts of the mind generally. But there is much disagreement about what modules are, which shows that we do not adequately understand modularity. This paper outlines a Fodoresque approach to understanding one type of modularity. It suggests that we can distinguish modular from nonmodular cognition by reference to the kinds of process involved, and that modular cognition differs from nonmodular forms of cognition in being a special kind of computational process. The paper concludes by considering implications for the role of modules in explaining mental development.




---

Title: Motor Representation and Action Experience in Joint Action
Authors: Corrado Sinigaglia and Stephen A. Butterfill
Year: 2020
Type: Publication

## Abstract

Acting together with a purpose is a familiar feature of everyday life. We jump together, play music together and move tables together. But what do we experience of action in acting together? It is perhaps tempting to suppose that there is a special way in which we can experience our own actions, and that we cannot experience the actions of others in this way. This view would imply that in acting together, our own actions are experienced in a way that our partners’ actions are not. However recent research on motor representation suggests that, in observing another act, it may be possible to experience her actions in whatever sense we can experience our own actions. This makes it at least conceivable that in acting together we can experience the actions each of us performs in the same way. But the occurrence of a joint action involves more than merely the occurrences of two individual actions. Are there experiences of joint actions which involve more than merely two or more experiences of individual actions? In this chapter we defend a positive answer. In some cases, experiences associated with joint action are experiences of action in whatever sense experiences of acting alone are.




---

Title: Motor Representation in Goal Ascription
Authors: Corrado Sinigaglia and Stephen A. Butterfill
Year: 2016
Type: Publication

## Abstract

Goal ascription, the process of identifying outcomes to which purposive actions are directed, is indispensable for predicting others’ behaviours and understanding their minds.  
But which mechanisms underpin goal ascription?
This chapter examines several ways in which motor representations and processes are involved in different forms of goal ascription.
We argue that motor representations and processes matter for goal ascription in two ways.
They provide for capturing the directedness of an action to an outcome, and they shape the observers’ experiences of actions in such a way that these experiences reveal the goals of actions.
The occurrence of motor representations in action observation thereby makes available, independently of any prior knowledge of others’ mental states, a route to knowledge of the goals of their actions.




---

Title: Motor Representation and Knowledge of Skilled Action
Authors: Corrado Sinigaglia and Stephen A. Butterfill
Year: 2020
Type: Publication

## Abstract

If you are more skilled in performing certain actions, you are probably also better able to acquire knowledge when observing those actions. Why are performance skills so connected to observation skills? In this chapter, the authors defend a conjecture: it is because performing and observing actions involves a common element, namely motor representations of outcomes to which the actions are directed. This conjecture, which is supported by a significant body of evidence, implies that motor representations can have content-respecting influences on knowledge states. How is this possible? How do motor representations interface with knowledge states? Several distinct candidate answers have been proposed, but the evidence that would distinguish them is not yet available. There is, then, a major gap in our understanding of how expertise matters for gaining knowledge of observed actions. We know that motor representations do, in fact, facilitate the acquisition of observational knowledge, but no one can yet say how they do so.




---

Title: Visibly constraining an agent modulates observers’ automatic false-belief tracking
Authors: Jason Low, Katheryn Edwards & Stephen A. Butterfill
Year: 2020
Journal: Scientific Reports
Type: Publication

## Abstract

Our motor system can generate representations which carry information about the goals of another agent’s actions. However, it is not known whether motor representations play a deeper role in social understanding, and, in particular, whether they enable tracking others’ beliefs. Here we show that, for adult observers, reliably manifesting an ability to track another’s false belief critically depends on representing the agent’s potential actions motorically. One signature of motor representations is that they can be disrupted by constraints on an observed agent’s action capacities. We therefore used a ‘mummification’ technique to manipulate whether the agent in a visual ball-detection task was free to act or whether he was visibly constrained from acting. Adults’ reaction times reliably reflected the agent’s beliefs only when the agent was free to act on the ball and not when the agent was visibly constrained from acting. Furthermore, it was the agent’s constrained action capabilities, rather than any perceptual novelty, that determined whether adult observers’ reaction times reliably reflected the agent’s beliefs. These findings signal that our motor system may underpin more of social cognition than previously imagined, and, in particular, that motor representations may underpin automatic false-belief tracking.




---

Title: Principles of belief acquisition. How we read other minds
Authors: Pascarelli, M. T. and Quarona, D. and Barchiesi, G. and Riva, G. and Butterfill, S. A. and Sinigaglia, C.
Year: 2024
Journal: Consciousness and Cognition
Type: Publication

# Abstract

Reading other minds is a pervasive feature of human social life. A decade of research indicates that people can automatically track an agent’s beliefs regardless of whether this is required. But little is known about the principles t guide automatic belief tracking. In six experiments adapting a false belief task introduced by Kovacs et al. (2010), we tested whether belief tracking is interrupted by either an agent’s lack of perceptual access or else by an agent’s constrained action possibilities. We also tested whether such manipulations create interruptions when participants were instructed to track beliefs. Our main finding: the agent’s lack of perceptual access did not interrupt belief tracking when participants were not instructed to track beliefs. Overall, our findings raise a challenge: some of the phenomena that have been labelled mindreading are perhaps not mindreading at all, or—more likely—they are mindreading but not as we know it.  

Keywords: Social Cognition, Mindreading, Belief-tracking, Automatic processes

<div class="fulltext">

# 1. Introduction  

Reading other minds is a hallmark of human sociality. Successful interaction very often depends on our ability to know the minds of others and to identify which beliefs predict and explain their behaviour. A standard way of assessing this ability involves tasks requiring a disparity between the participant’s and target agent’s mental states. For instance, in a classic false belief task, participants see a character named Sally looking at an object (e.g., a ball) being placed in a box before Sally leaves the room. During Sally’s absence, another character, Anne, switches the ball to another box. When Sally comes back, participants are asked to indicate in which box they think she will search for the ball. Adults and children around four tend to correctly indicate the box Sally was looking at before leaving the room, and not the box containing the ball (Wimmer & Perner, 1983; Baron-Cohen et al., 1985).  

Strikingly, a decade of research indicates that some mindreading may be automatic in the sense that whether it occurs is relatively unaffected by participants tasks or intentions (Kovacs, Teglas, & Endress, 2010; Schneider, Bayliss, Becker, & Dux, 2012; Schneider, Slaughter, & Dux, 2017; van der Wel, Sebanz, & Knoblich, 2014). Indeed, in a seminal paper, Kovacs and colleagues (2010) adapted an object-location task by presenting adult participants with movies in which a character (a smurf) placed a ball on a table and looked at it rolling behind an occluder or away from it, just before leaving the scene. In the absence of the smurf, the ball could change its location. When the smurf came back, the occluder was removed. Participants were instructed to press a button as soon as they detected the ball’s presence on the removal of the occluder. As expected, they were faster when they believed the ball was behind the occluder (‘P+’ conditions) than when they believed it wasn’t there (‘P–’ conditions). Surprisingly, however, they turned out to be faster in pressing the button when the smurf supposedly believed that the ball was present (‘P–A+’ condition) compared to when both they and the smurf supposedly believed the ball was absent (‘P–A–’ condition); this is the critical ‘(P–A+)<(P–A–)’ finding. If some mindreading is automatic, this effect of smurf’s belief on responses may be a consequence of automatic mindreading.  

There is intense debate about this finding. An early view was that it may be an artefact of extraneous features of the stimuli used (Phillips et al., 2015). A direct test of that view did not support it, however (Al Kaddouri et al., 2020), and a number of successful replications with a variety of stimuli would make finding extraneous features challenging (Nijhof et al., 2016; Bardi et al., 2017a,b; Low et al., 2020). We, therefore, started by assuming that in Kovacs and colleagues' paradigm, it really is the agent's belief that influences participants’ responses.  

A question yet to be considered is which principles characterise automatic belief tracking. To illustrate, processes for tracking physical objects do not necessarily operate in accordance with all and only true physical principles, nor even in accordance with what we know to be the case. This is nicely illustrated by the tunnel effect, in which good continuity of trajectory requires us to see as one object what we actually know to be two (Scholl, 2007). Similarly, we reasoned that the principles which characterise automatic mindreading may not coincide with principles that do, or are widely held to, govern how beliefs are acquired in non-automatic mindreading. It would, therefore, be valuable to develop ways of testing which principles guide which mindreading processes. Doing so is crucial for understanding how people read other minds.  

One basic principle concerns perceptual access. A natural thought is that, in order to first acquire a belief about the location of a ball (say), an agent has to see or otherwise perceive the ball (unless, of course, they have other sources of knowledge). Certainly, in hundreds of false belief tasks the agent initially sees a target object and—so the story—thereby acquires a belief about it; a subsequent failure to see the target is what causes false belief. This is why it may seem bizarre, or even incoherent, to create a false belief task in which an agent was looking away and lacking any perceptual access to the object right from the start. Yet we know that, while adults can be sensitive to an agent’s visual access rather than their mere presence or orientation (e.g., Furlanetto et al., 2016), they also sometimes overestimate the informativeness of visual access (Wang et al., 2014) and are prone to neglect lack of visual access (Keysar et al., 2003). It is, therefore, coherent to ask, from the point of view of one or another mindreading process, whether, in the absence of other sources of knowledge, an agent’s failure to perceive an object’s movements affects what they believe about its location.  

The question we are concerned with can be made clearer by reflection on Trauble et al. $(2010)^{\prime}{\bf s}$ finding that infant mindreading does not appear to require visual access in all cases. In their paradigm, an agent who lacks visual access to a ball tilts a ramp to control its location. This is a wonderful way to test belief ascription when an agent has no visual access but does have another source of information about the ball’s location. By contrast, our question was whether complete failure of perceptual access, in the absence of any other source of information, would influence mindreading processes.  

![](/public/img/articles/pascarelli2024_principles/fef1033580057817e18acea843903893045ec60e82adda3670d566c7553b3ef6.jpg)  
Fig. 1. Structure of events in the movies used in Experiment 1. For the actual timing of events see Table S1. For an example of this series of video clips see Movie S1.  

Some readers may insist that, normatively, failure to perceive must affect what is believed (in the absence of other sources of knowledge). But even if they are right, it does not follow that all mindreading processes operate in accordance with that principle.  

Another potential principle concerns acting. Does an agent have to be in a position to act on the ball in order to acquire a belief about it? If you share our pre-theoretical intuitions, you will be tempted to deny this immediately and without reflection. Whether or not you can act should not generally affect your beliefs about clearly visible events around you. But if we are open to the idea that mindreading processes are not necessarily characterised by true principles, nor by widely agreed principles, then we might be curious to know whether one or another mindreading process will only track beliefs when agents are in a position to act. We were motivated to consider this possibility by evidence that automatically taking the perspective of another individual might depend on perceiving her as being able to act (Cardellicchio et al., 2013; Costantini et al., 2011). Further, automatic (but not non-automatic) mindreading appears to be associated with a superior parietal network, including the superior marginal gyrus, typically related to sensory-motor processes and representations (Grosse Wiesmann et al., 2020; but see Bardi et al., 2017a,b). Consistent with this, Zani et al. (2020) demonstrated that automatic mindreading can modulate how actions are motorically processed in social interaction; and Low et al. (2020) provided evidence that automatic mindreading enables people to track a belief except when the agent was visibly constrained from acting. It is. therefore, coherent to ask whether, from the point of view of one or another mindreading process, an agent’s having limited possi­ bilities to act on an object might affect what they believe about that object.  

In order to understand whether the principles which characterise automatic mindreading coincide with principles that do, or are widely held to, govern how beliefs are acquired in non-automatic mindreading, we ran three experiments where participants were never instructed to report beliefs and none of the experiments mentioned beliefs. In the first experiment, we implemented the same experimental setting and design as Kovacs et al. (2010). Participants were presented with different movies with four distinct scenes: (i) an agent (the smurf) placing a ball on a table in front of an occluder; (ii) the agent seeing the ball rolling behind the occluder and then staying there or moving away; (iii) the agent leaving the scene and the ball remaining in position or changing position by either moving away from or returning to behind, the occluder; and (iv) the agent coming back and the occluder lowering (Fig. 1). As in Kovacs et al. (2010), participants were asked to press a button as soon as they saw the ball behind the lowered occluder, with the ball being randomly present in half of the trials in all the conditions. Finding the critical effect, $(\mathrm{P–A}+)<(\mathrm{P–A}-);$ , in this experiment would indicate that our materials can be used to further corroborate Kovacs et al. (2010).  

![](/public/img/articles/pascarelli2024_principles/dbf8cedf9fdc893158da23f0547f77262282d83ccc8a1b37079ec2ac8b12a40f.jpg)  
Fig. 2. Structure of events in the movies used in Experiment 2. For the actual timing of events see Table S2. For an example of this series of video clips see Movie S2.  

In a second experiment, the agent’s (smurf’s) perceptual access was manipulated. We created a new series of movies differing from those used in the first experiment in the first two scenes only. These are the scenes where, supposedly, the agent acquires their belief about the location of the ball. In each movie in this new series, in the first two scenes the agent turned their back on the table thus ensuring they were unable to see the ball’s movements (Fig. 2). If the critical effect, $(\mathrm{P–A}+)<(\mathrm{P–A}-)_{}$ were found in this experiment, this would indicate that, from the perspective of automatic mindreading, an agent’s failure to perceive an object, even in the absence of any other sources of knowledge, does not affect what they believe about its location.  

In a third experiment, the agent’s (smurf’s) perceptual access was left unhindered while their action possibilities were constrained; this was achieved by encasing them in plexiglass. We created a third series of movies differing from those used in the earlier exper­ iments in the first two scenes only. In each movie in this third series, in the first two scenes the agent appeared immobilised in their plexiglass cage and saw the ball rolling behind the occluder, staying there or moving away (Fig. 3). If the critical effect, $(\mathsf{P{-}A+})<$ (P–A–), were found in this experiment, this would indicate that, from the perspective of automatic mindreading, an agent’s having limited possibilities to act on an object does not affect what they believe about its location.  

Motivated by the possibility of finding similarities and differences between automatic and non-automatic mindreading, we then switched our focus to non-automatic mindreading. We ran three further experiments with a modified design where participants were instructed to track the agent’s beliefs. Taking a cue from previous studies (Nijhof et al., 2016; Bardi et al., 2017a), the modified design required participants not only to press the button as soon as they saw the ball but also to answer questions about the agent’s belief about the ball’s location. These questions were randomly presented at the end of the movies in one-sixth of the trials. This modified design was used with each of the series of videos from Experiments 1–3 (in Experiments 4–6, respectively). We assumed that explicit answers to the questions would be dominated by non-automatic mindreading processes. We also regarded it as possible that being instructed to answer a question about belief would increase the influence of non-automatic mindreading processes on response times; although Nijhof et al. (2016, p. 9) found no trace of any such effect, intriguingly Bardi et al. (2017a, p. 395) observed smaller dif­ ferences in response time when participants were instructed about belief. The three new experiments thus allowed us to investigate whether, from the perspective of non-automatic mindreading, an agent’s failure to perceive affects what they believe and also whether an agent’s having limited action possibilities might affect what they believe.  

![](/public/img/articles/pascarelli2024_principles/4bcca4273177bf63e817e16e53094bdfeddeae3afb2a251d0e620bcda289ef2f.jpg)  
Fig. 3. Structure of events in the movie used in Experiment 3. For the actual time of events see Table S3. For an example of this series of video clips see Movie S3.  

# 2. Methods  

## 2.1. Sample size estimation  

In order to reach standardised effect size, a sample size of at least 31 participants was determined with $G^{*}$ Power software (input parameters: $\mathtt{q}=0.01$ , Power $(1-\upbeta\mathrm{err}\mathrm{prob})=0.8$ and effect size $\mathrm{d}\mathbf{z}=0.657.$ . Effect size dz was calculated from the difference of mean and SD of P–A– vs $\mathrm{P}\mathrm{-}\mathrm{A}+$ comparison (Free-Agent experiment) in Low et al. (2020). A total of 210 participants took part in this study and they were randomly allocated to exactly one of each six experiments. All the participants were right-handed, with normal or corrected-to-normal vision, and with no history of either psychiatric or neurological disorders. All research methods were approved by the Local Ethics Committee and were carried out in accordance with the principles of the revised Helsinki Declaration (World Medical Association General Assembly, 2008). Written informed consent was obtained from all the participants.  

3. Experiment 1 — Unistructed belief tracking, visual access, no plexiglass cage.  

## 3.1. Participants  

Thirty-five participants (19 females, age mean $\pm{\sf S E}=21.77\pm0.47$ years old) took part in this experiment 1.  

## 3.2. Stimuli  

The experimental stimuli consisted in 8 video clips ( $1920\times1080$ pixels,.mp4, 25 fps, 19 s) depicting a 3D room, with an agent (i.e., a smurf) taking a ball in his right hand, a red table, and a green occluder on the table (see ). All video clips started with the smurf placing the ball in front of the occluder and the ball rolling behind it (Phase I). After that, the video clips presented four different possible scenarios:  

1. The ball moved away from the occluder and returned behind it; then the smurf left the scene (Phase II). In absence of the smurf, the ball did not change its position (phase III).   
2. The ball moved away from the occluder, returned behind it, and finally moved away again, leaving the scene; then the smurf left the scene (phase II). In absence of the smurf, the ball did not change its position (Phase III);   
3. The ball moved away from the occluder and returned behind it; then the smurf left the scene (Phase II). In absence of the smurf, the ball changed its position, by moving away from the occluder (Phase III);   
4. The ball moved away from the occluder, returned behind it, and finally moved away again, leaving the scene; then the smurf left the scene (Phase II). In the absence of the smurf, the ball changed its position, by returning behind the occluder (Phase III).  

Finally, in all the video clips the smurf came back and the occluder was lowered (Phase IV). The ball was present behind the occluder in half of the video clips (for the timing of events in each kind of video see Table S1; for an example of these videos see Movie S1 in Supplementary Materials).  

We distinguished four different conditions. We adopted the same notation as Kovacs et al. (2010) to characterise the four conditions. “P” stands for Participant, “A” for Agent (i.e., the smurf), “ $^+$ ” means that they supposedly believe that the ball was behind the occluder, and “–” means that they supposedly believe that the ball was not there. The conditions were:  

  ‘P+A+’ : both the participant and the agent supposedly believe that the ball is behind the occluder; 
  
  ‘P–A–’: both supposedly believe that the ball was not behind the occluder; 
  
  ‘P–A+’ : the participant supposedly believes that the ball was not behind the occluder, while the agent supposedly believes that the ball was there; 
  
  ‘P+A–’ : the participant supposedly believes that the ball was behind the occluder, while the agent supposedly believes that the ball was not there.  

## 3.3. Procedure  

The experiment took place in a dimly lit room. Participants were instructed to observe a series of video clips on a monitor ( $\mathbf{1920~x}$ 1080 pixels, refresh rate $=60\mathrm{Hz}$ ). Each trial started with a fixation cross of $1000\mathrm{ms}$ , followed by one of the video clips. Each video clip was repeated 6 times in a random order for a total of 48 trials. Participants were instructed to observe the ball trajectory during each video clip and to press a button on a keyboard with their right index as soon as they detected the ball when the occluder was lowered. They were instructed not to respond when the ball was absent. The occluder fell down at ${18s}$ in each video clip, so they had 1 s to respond. Reaction times were collected. To make sure that participants paid attention to the entire video clip, they were also asked to press a button with their left index finger as soon as the smurf left the scene (catch trials). Before the task, participants completed 8 practice trials, one for each video clip. The stimuli, timing, and randomization procedure were controlled by E-Prime Software 3.0 (Psychology Software Tools).  

## 3.4. Data analysis  

In this and the following experiments, RTs deviating more than $\pm2.5$ s.d. at the subject level were considered outliers and were eliminated from the analysis. Participants having a number of outliers/missing in the task, average RTs in the task, or a number of outliers/missing in the catch trials deviating more than $\pm2.5$ s.d. at the group level were considered outliers and were eliminated from the analysis. In Experiment 1, two participants were eliminated from the analysis. After that, average RTs for each condition were computed. Finally, the data were transformed into a logarithmic scale. As in Kovacs et al. (2010), RTs were submitted to four preplanned comparisons: (P–A–) vs (P+A+) , (P–A–) vs (P–A+) , (P–A–) vs (P+A–) , (P+A+) vs (P+A–) . For all statistical tests, the alpha level of significance was set to 0.05, but corrected for multiple comparisons using Bonferroni’s method (alpha/ $'4=0.0125.$ . This correction is arguably too stringent as, despite our stated plans, it may be thought that just two comparisons are truly relevant, (P–A–) vs (P+A–) to show that the participant’s own belief matters and (P–A–) vs (P–A+) to test whether the agent’s belief matters. But, as it turns out, the less stringent correction (alpha/ $2=0.025$ ) would not alter the conclusions we draw (see Table S4). Further, we were also interested in the (P+A+) vs (P+A–) comparison, which is potentially also an indicator of whether the agent’s belief matters (even if this comparison did not yield significant results in published research to date). Traditional methods of data analysis (i.e. frequentist) were complemented by a Bayesian two-tailed $t$ -test for all comparisons using JASP 0.14.1 software, using default Cauchy priors of 0.707.  

# 4. Experiment 2 — Unistructed belief tracking, no visual access  

## 4.1. Participants  

Thirty-five participants (18 females, age mean $\pm{\sf S E}=22.17\pm0.56$ years old) took part in this experiment.  

## 4.2. Stimuli  

The experimental stimuli consisted of 8 new video clips. The clips differed from those used in Experiment 1 in that the agent’s (smurf’s) visual access to the ball was manipulated (see Fig. 2). In the new video clips, the smurf turned their back to the table after placing the ball in front of the occluder (phase I), which meant the smurf was manifestly unable to see all the ball’s movements (phase II). Phases III and IV were the same as in Experiment 1. For the timing of events in each kind of video see Table S2; for an example of these videos see Movie S2 in Supplementary Materials.  

## 4.3. Procedure  

As in Experiment 1, participants were instructed to observe the ball’s trajectory during each video clip and to press a button on a keyboard with their right index as soon as they detected the ball when the occluder was lowered. Reaction times were collected.  

## 4.4. Data analysis  

See Experiment 1. In Experiment 2, one participant was eliminated from the analysis.  

# 5. Experiment 3 — Uninstructed belief tracking, plexiglass cage  

## 5.1. Participants  

Thirty-five participants (17 females, age mean $\pm$ $\mathbf{-}\mathbf{S}\mathbf{E}=22.09\pm0.36$ years old) took part in this experiment.  

## 5.2. Stimuli  

The experimental stimuli consisted of 8 new video clips. The clips differed from those used in Experiment 1 in that the smurf was immobilised in a plexiglass cage and entered the scene from the left, with the ball entering the scene from the right (Fig. 3). Phases II-IV of the videos were the same as in Experiment 1 except that the smurf always appeared in the cage. For the timing of events in each kind of video see Table S3; for an example of these videos see Movie S3 in Supplementary Materials.  

## 5.3. Procedure  

Because of the Covid-19 pandemic, the experiment was run online with E-Prime-Go (E-Prime Software 3.0, Psychology Software Tools). Participants ran the experiment on their own computer in a dimly lit room and were instructed to observe the video clips on their screen (refresh rate $=60~\mathrm{Hz}$ ). The experimenter monitored the video rendering with E-Prime-Go. Participants whose videos involved four or more dropped frames were to be excluded. No participants were excluded on these grounds. The experimenter also checked the correctness of all procedures by asking participants to share their screen and observing them through their webcam.  

5.4. Data analysis  

See Experiment 1. In Experiment 3, one participant was eliminated from the analysis.  

6. Experiment 4 — Instructed belief tracking, visual access and no plexiglass cage  

6.1. Participants Thirty-five participants (18 females, age mean $\pm{\sf S E}=22.06\pm0.38$ years old) took part in the experiment.  

## 6.2. Stimuli  

Stimuli were the same as in Experiment 1.  

## 6.3. Procedure  

The procedure was almost the same as in Experiment 1. The only difference was that, following previous studies using an explicit version of Kovacs et al (2010)'s paradigm (Nijhof,et al., 2016; Bardi et al., 2017a), in 8 out of the 48 experimental trials, after the end of the video clip a question was displayed on a black screen: “Did the smurf think that the ball was behind the occluder?” Participants had to respond “yes” or “no” by pressing “c” with their left middle finger or “v” with their left index finger. In half of the trials, the word “yes” was displayed below the question on the right side of the screen, and the word “no” was displayed on the left side of the screen. In the other half of the trials, it was vice versa. Participants had a maximum of $3000\mathrm{ms}$ to respond. Accuracies were collected. Before the experiment, participants completed six practice trials, five without the question and one with the question.  

## 6.4. Data analysis  

Data analysis was as in Experiment 1. Further, the accuracy of the question task was calculated and submitted to a one-sample t-test against the chance level (i.e., 0.5).  

# 7. Experiment 5 — Instructed belief tracking, no visual access  

## 7.1. Participants  

Thirty-five participants (18 females, age mean $\pm\:{\mathsf{S E}}=22.03\pm0.48$ years old) took part in the experiment.  

## 7.2. Stimuli  

Stimuli were the same as in Experiment 2.  

## 7.3. Procedure  

The procedure was almost the same as in Experiment 2. The only difference was the addition of the question task from Experiment 4.  

7.4. Data analysis  

See Experiment 4.  

8. Experiment 6 — Instructed belief tracking, plexiglass cage  

8.1. Participants Thirty-five participants (19 females, age mean $\pm\:{\mathsf{S E}}=23.34\pm0.62$ years old) took part in the experiment.  

8.2. Stimuli Stimuli were the same as in Experiment 3.  

## 8.3. Procedure  

The procedure was almost the same as in Experiment 3 with the addition of the question task like in Experiment 4 and 5. Because of the Covid-19 pandemic, the experiment was run online with E-Prime-Go (E-Prime Software 3.0, Psychology Software Tools). Par­ ticipants ran the experiment on their own computer in a dimly lit room and were instructed to observe the video clips on their screen (refresh rate $=60\mathrm{Hz}$ ). The experimenter monitored the video rendering with E-Prime-Go. Participants whose videos involved four or more dropped frames were to be excluded. No participants were excluded on these grounds. The experimenter also checked the correctness of all procedures by asking participants to share their screens and observing them through their webcam.  

## 8.4. Data analysis  

See Experiment 4. In Experiment 6, one participant was eliminated from the analysis.  

# 9. Results  

9.1. Experiment 1 — Uninstructed belief tracking, visual access and no plexiglass cage.  

The (P–A–) vs (P+A+) comparison revealed a significant difference $(\mathbf{t}_{(34)}=3.032$ , $P=0.005$ , Cohen’s $\mathrm{d}=0.513.$ ). Indeed, par­ ticipants were significantly faster at detecting the ball in the (P+A+) condition than in the (P–A–) condition (Log10 RTs mean dif­ ference $\pm{\sf S E}=0.021\pm0.007\mathrm{m}s)$ . The same held for the (P–A–) vs (P+A–) comparison, which revealed a significant difference (t(34) $=4.540$ , $P<0.001$ , Cohen’s $\mathrm{d}=0.767)$ , with participants being significantly faster at detecting the ball in the (P+A–) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\sf S E}=0.034\pm0.008\mathrm{ms})$ . The (P–A–) vs (P–A+) comparison, which has been held to be critical for testing automatic mindreading, revealed a significant difference $(\mathrm{t}_{(34)}=3.800$ , $P<0.001$ , Cohen’s $\mathrm{d}=0.642)$ , with participants being significantly faster at detecting the ball in the (P–A+) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\sf S E}=0.027\pm0.007\mathrm{ms})$ . Finally, the $\left(\mathbf{P}+\mathbf{A}+\right)$ vs (P+A–) comparison revealed no significant difference $(\mathrm{t}_{(34)}=1.645$ , $P=$ 0.109) (see Fig. 4A; see also Table S4).  

To complement traditional methods of data analysis (i.e., frequentist) and quantify the relative strength of our empirical data we ran Bayesian two-tailed t-test for all comparisons using JASP 0.14.1 software, using default Cauchy priors of 0.707. There was very strong evidence for the $(\mathbf{P}{-}\mathbf{A}{+}){<}(\mathbf{P}{-}\mathbf{A}{-})$ effect $(\mathrm{BF}_{10}=52.168)$ (see Fig. 4D). The other comparisons and the $\%$ error of the BF are shown in Table S5. All the row and processed data are uploaded to the repository of Open Science at the following link https://osf.io/ 7zvhy/?view_only $=$ 3e5d8212afbb40ceb9cfc7b8170be55f.  

## 9.2. Experiment 2 — Uninstructed belief tracking, no visual access.  

The (P–A–) vs (P+A+) comparison revealed a significant difference $(\mathrm{t}_{(33)}=3.929$ , $P<0.001$ , Cohen’s $\mathrm{d}=0.674)$ . As expected, participants were faster at detecting the ball in the (P+A+) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\tt S E}=$ $0.028\pm0.007\mathrm{m}s)$ . The same was held for the (P–A–) vs (P+A–) comparison, which revealed a significant difference $(\mathrm{t}_{(33)}=4.180,P<$ 0.001, Cohen’s $\mathrm{d}=0.717;$ . Participants were significantly faster at detecting the ball in the (P+A–) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\sf S E}=0.048\pm0.011\mathrm{ms})$ . Strikingly, the (P–A–) vs $\left(\mathsf{P{-}A+}\right)$ ) comparison, which has been held to be critical for testing automatic mindreading, revealed a significant difference $(\mathrm{t}_{(33)}=4.262$ , $P<0.001$ , Cohen’s $\mathrm{d}=0.731_{.}$ ). Par­ ticipants were significantly faster at detecting the ball in the $(\mathsf{P{-}A+})$ condition than in the (P–A–) condition (Log10 RTs mean dif­ ference $\pm{\sf S E}=0.044\pm0.010\mathrm{ms})$ . Finally, the (P+A+) vs (P+A–) comparison did not reveal significant difference $(\mathrm{t}_{(33)}=2.150$ , $P=$ 0.039). (see Fig. 4B; see also Table S4).  

The Bayesian two-tailed $t$ -test comparisons revealed very strong evidence for the $(\mathrm{P–A}+){<}(\mathrm{P–A}-)$ effect $(\mathrm{BF}_{10}=166.228)$ (see Fig. 4E). The other comparisons and the $\%$ error of the BF are shown in Table S5. All the row and processed data are uploaded to the repository of Open Science at the following link https://osf.io/7zvhy/?view_only $=$ 3e5d8212afbb40ceb9cfc7b8170be55f.  

## 9.3. Experiment 3 — Uninstructed belief tracking, plexiglass cage.  

The (P–A–) vs (P+A+) comparison revealed a significant difference $(\mathrm{t}_{(33)}=2.862$ , $P=0.007$ , Cohen’s $\mathrm{d}=0.491\$ ). As expected, participants were significantly faster at detecting the ball in the (P+A+) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm~\mathsf{S E}=0.023\pm0.008~\mathrm{ms})$ . The same results were obtained with the (P–A–) vs (P+A–) comparison, which revealed a significant difference $(\mathrm{t}(33)=6.211$ , $\mathbf{P}<0.001$ , Cohen’s $\mathrm{d}=1.065\$ . Participants were significantly faster at detecting the ball in the (P+A–) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm~{\sf S E}=0.056\pm0.009~{\mathrm{ms}})$ . The (P–A–) vs (P–A+) comparison, which has been held to be critical for testing mindreading, also revealed a significant difference $(\mathrm{t}_{(33)}=3.413$ , $P=0.002$ , Cohen’s $\mathrm{d}=0.585;$ ). Participants were significantly faster in detecting the ball in the (P–A+) condition compared to the (P–A–) condition (Log10 RTs mean difference $\pm{\sf S E}=0.027\pm0.008~\mathrm{ms})$ . Finally, the (P+A+) vs (P+A–) comparison revealed a significant difference $(\mathrm{t}_{(33)}=3.410$ , $P=0.002$ , Cohen’s $\mathrm{d}=0.585^{\circ}.$ . Participants were significantly faster at detecting the ball in the (P+A–) condition than in the (P+A+) condition (Log10 RTs mean difference $\pm{\sf S E}=0.033\pm0.010\mathrm{ms})$ (see Fig. 4C; see also Table S4).  

The Bayesian two-tailed t-test comparisons revealed strong evidence for the $\mathbf{\partial}^{\prime}\mathbf{P}{-}\mathbf{A}{+}\mathbf{\partial}){<}(\mathbf{P}{-}\mathbf{A}{-})$ effect $(\mathrm{BF}_{10}=19.884)$ (see Fig. 4F). The other comparisons and the $\%$ error of the BF are shown in Table S5. All the row and processed data are uploaded to the repository of Open Science at the following link https://osf.io/7zvhy/?view_only $=$ 3e5d8212afbb40ceb9cfc7b8170be55f.  

![](/public/img/articles/pascarelli2024_principles/3a598ebf3b61c0102759e0b3f43828ec590049f63146848f58494ddbd8d21fe7.jpg)  
Fig. 4. Results of the Experiments 1–3. Upper panels Planned comparison of ball detection latencies (Reaction Times, or RTs) in Experiment 1 (A), Experiment 2 (B), and Experiment 3 (C). Bars represent the Log10 transformed of mean RTs in milliseconds, and error bars represent standard errors. \* represents a p-value lower than 0.0125 (Bonferroni’s correction is applied) of the planned comparisons. For a systematic overview of the pairwise comparisons in each condition of all the Experiments see Table S4. Lower panels Sequential analysis plots of the Bayes factor for the critical comparison (P–A– vs $\mathbf{P}{-}\mathbf{A}{+},$ in Experiments 1 (D), Experiment 2 (E), and Experiment 3 (F).  

## 9.4. Experiment 4 — Instructed belief tracking, visual access and no plexiglass cage.  

The (P–A–) vs (P+A+) comparison revealed a significant difference $(\mathrm{t}_{(34)}=3.319$ , $P=0.002$ , Cohen’s $\mathrm{d}=0.561^{\'}$ ). Participants were significantly faster at detecting the ball in the (P+A+) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\mathrm{SE}}=$ $0.036\pm0.011\mathrm{ms}$ ). The (P–A–) vs (P+A–) comparison revealed a significant difference $(\mathrm{t}_{(34)}=5.630$ , $P<0.001$ , Cohen’s $\mathrm{d}=0.952;$ . Participants were significantly faster at detecting the ball in the (P+A–) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{}\mathsf{S E}=0.046\pm0.008\mathrm{~ms})$ . Further, the (P–A–) vs (P–A+) comparison, which has been held to be critical for testing mindreading, revealed a significant difference $(\mathrm{t}_{(34)}=2.848$ , $P=0.007$ , Cohen’s $\mathrm{d}=0.481^{\cdot}$ ). Participants were significantly faster at detecting the ball in the (P–A+) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\sf S E}=0.035\pm0.012\mathrm{ms})$ . Finally, the (P+A+) vs (P+A–) comparison revealed no significant difference $(\mathrm{t}_{(34)}=1.558$ , $P=0.128)$ (see Fig. 5A; see also Table S4). Participants completed the question task with an accuracy higher than 0.5 (mean $\pm{\sf S E}=0.76\pm0.03$ , $\mathrm{t}_{(34)}=7.163$ , $P<0.001\$ .  

The Bayesian two-tailed t-test comparisons revealed moderate evidence for the $(\mathrm{P–A}+)<\left(\mathrm{P–A}-\right)$ effect $(\mathrm{BF}_{10}=5.517)$ (see Fig. 5D). The other comparisons and the $\%$ error of the BF are shown in Table S5. All the row and processed data are uploaded to the repository of Open Science at the following link https://osf.io/7zvhy/?view_only $=$ 3e5d8212afbb40ceb9cfc7b8170be55f.  

## 9.5. Experiment 5 — Instructed belief tracking, no visual access.  

The (P–A–) vs (P+A+) comparison revealed a significant difference $(\mathrm{t}_{(34)}=4.176,P<0.001$ , Cohen’s $\mathrm{d}=0.706)$ . Participants were faster at detecting the ball in the (P+A+) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\sf S E}=0.031\pm0.007$ ms). The (P–A–) vs (P+A–) comparison revealed a significant difference $(\mathrm{t}_{(34)}=4.640$ , $P<0.001$ , Cohen’s $\mathrm{d}=0.784)$ . Participants were significantly faster at detecting the ball in the (P+A–) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\tt S E}=$ $0.050\pm0.011\mathrm{m}s)$ . The (P–A–) vs (P–A+) comparison, which has been held to be critical for testing mindreading, did not reveal a significant difference $(\mathrm{t}_{(34)}=2.084$ , $P=0.045^{\cdot}$ ). Finally, also the (P+A+) vs (P+A–) comparison revealed no significant difference $(\mathbf{t}_{(34)}=1.973,\mathbf{P}=0.057)$ (see Fig. 5B; see also Table S4). Participants completed the question task with an accuracy higher than chance $(\mathrm{mean}\pm\mathrm{SE}=0.61\pm0.06$ , $\mathbf{t}_{(34)}=3.060$ , $P=0.004_{.}$ .  

The Bayesian two-tailed $t$ -test comparisons revealed anecdotal evidence for the $(\mathbf{P}{-}\mathbf{A}{+}){<}(\mathbf{P}{-}\mathbf{A}{-})$ effect $(\mathrm{BF}_{10}=1.232)$ (see Fig. 5E). The other comparisons and the $\%$ error of the BF are shown in Table S5. All the row and processed data are uploaded to the repository of Open Science at the following link https://osf.io/7zvhy/?view_only $=$ 3e5d8212afbb40ceb9cfc7b8170be55f.  

![](/public/img/articles/pascarelli2024_principles/c10190642bf68c8ea43d0f3d026756b77cfdb666ee53b0fc9210ff6f6f841384.jpg)  
Fig. 5. Results of the Experiments 4–6. Upper panels Planned comparison of ball detection latencies (Reaction Times, or RTs) in Experiment 4 (A), Experiment 5 (B), and Experiment 6 (C). Bars represent the Log10 transformed of mean RTs in milliseconds, and error bars represent standard errors. \* represents a p-value lower than 0.0125 (Bonferroni’s correction is applied) of the planned comparisons. For a systematic overview of the pairwise comparisons in each condition of all the Experiments see Table S4. Lower panels Sequential analysis plots of the Bayes factor for the critical comparison (P–A– vs $\mathbf{P}{\mathrm{-}}\mathbf{A}{+}.$ ) in the Experiments 4 (D), Experiment 5 (E), and Experiment 6 (F).  

## 9.6. Experiment 6 — Instructed belief tracking, plexiglass cage.  

The (P–A–) vs (P+A+) comparison revealed a significant difference $(\mathrm{t}_{(33)}=4.409$ , $P<0.001$ , Cohen’s $\mathrm{d}=0.756)$ . Participants were significantly faster at detecting the ball in the (P+A+) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm~{\tt S E}=$ $0.038\pm0.009\mathrm{ms}$ ). The (P–A–) vs (P+A–) comparison revealed a significant difference $(\mathrm{t}_{(33)}=5.577$ , $P<0.001$ , Cohen’s $\mathrm{d}=0.956;$ . Participants were significantly faster at detecting the ball in the (P+A–) condition compared to the (P–A–) condition (Log10 RTs mean difference $\pm{\sf S E}=0.066\pm0.012\mathrm{ms})$ . The (P–A–) vs (P–A+) comparison revealed a significant difference $(\mathrm{t}_{(33)}=2.730$ , $P=0.010$ , Cohen’s $\mathrm{d}=0.468)$ . Participants were significantly faster at detecting the ball in the (P–A+) condition than in the (P–A–) condition (Log10 RTs mean difference $\pm{\sf S E}=0.024\pm0.009\mathrm{ms})$ . Finally, the (P+A+) vs (P+A–) comparison revealed a significant difference $(\mathbf{t}_{(33)}=2.893$ , $P=0.007$ , Cohen’s $\mathrm{d}=0.496)$ . Participants were significantly faster at detecting the ball in the (P+A–) condition than in the (P+A+) condition (Log10 RTs mean difference $\pm{\sf S E}=0.029\pm0.010\mathrm{ms})$ . (see Fig. 5C; see also Table S4). Participants completed the question task with an accuracy higher than 0.5 $\operatorname{mean}\pm\mathrm{SE}=0.74\pm0.05$ , $\mathrm{t}_{(33)}=5.145$ , $P<0.001\$ .  

The Bayesian two-tailed $t$ -test comparisons revealed moderate evidence for the $(\mathrm{P}-\mathrm{A}+)<\left(\mathrm{P}-\mathrm{A}-\right)$ effect $(\mathrm{BF}_{10}=4.283)$ (see Fig. 5F). The other comparisons and the $\%$ error of the BF are shown in Table S5. All the row and processed data are uploaded to the repository of Open Science at the following link https://osf.io/7zvhy/?view_only $=$ 3e5d8212afbb40ceb9cfc7b8170be55f.  

# 10. Discussion  

The main aim of the present study was to understand the principles on which automatic and non-automatic mindreading operate in tracking the initial acquisition of a belief. From the point of view of automatic mindreading, or of non-automatic mindreading (or both), does an agent’s failure to perceive an object’s movements affect what they believe about its location? And, from the same points of view, does an agent’s inability to act on an object affect what they believe about its location?  

There are two main findings and an interesting anomaly. First, in Experiment 1, we successfully replicated the key finding of Kovacs et al., 2010. This adds to a now growing body of successful replications of that discovery (Nijhof,et al., 2016; Bardi et al., 2017a.b; Al Kaddouri et al., 2020; Low et al., 2020; but see also Phillips et al.,2015).  

A second main finding concerns Experiment 2, where the agent does not perceive the ball and has no other source of information about its location. Participants’ responses followed the same pattern as would be expected if their automatic mindreading processes were attributing false beliefs to the agent (that is, $\mathrm{P–A}\mathrm{+}\mathrm{<P–A-}$ ). This suggests that from the point of view of automatic mindreading, failure to perceive does not prevent believing, even in the absence of any compensating information.  

This suggestion presents a challenge to accounts of automatic mindreading processes which take for granted that belief tracking is influenced by lack of perceptual access. For instance, Butterfill & Apperly (2013) assume that registration (roughly belief) depends on encountering (roughly, perceptual access). While the theory does allow for exceptions (an agent’s successful action is also permitted as a cue to what the agent has encountered), none of those can explain the pattern of findings we observed in Experiment 2. It seems we may therefore need alternative principles to characterise automatic mindreading. An alternative response might be to abandon the idea that the automatic processes responsible for the $\mathrm{P–A}+<\mathrm{P–A}-$ effect are genuinely mindreading processes. But any verdict on whether these responses are correct should also take into account our third main finding.  

This third main finding comes from Experiment 5. In this experiment, the agent once again fails to perceive the ball, but participants knew they could be asked to answer questions about belief explicitly. Participants’ answers revealed that they were generally attributing beliefs without regard to the agent’s failure to perceive. Indeed, accuracy in answering the question about the agent’s belief was significantly higher than chance. (By ‘accurate’, we mean an answer that attributes beliefs as if the agent were not looking away.) We do not infer, of course, that participants’ non-automatic mindreading never takes failures to perceive into account when attributing beliefs. A more plausible possibility is that in mindreading, some of the details about what is perceived are sometimes ignored (as others also suggest; compare Keysar et al., 2003). For comparison with another domain: although adults can track physical objects’ trajectories through momentary occlusion in simple cases, when tracking multiple objects simultaneously they disregard trajectory information and fall back to relying on a simple proximity heuristic (Franconeri et al., 2012). Similarly, although adults can track perceptual access in situations involving a static display (Furlanetto et al., 2016), when processing a more complex, changing scene their mindreading may fall back to relying on simpler heuristics. In the case of Experiment 5, it is possible that participants may have used simple heuristics such as people near an event often have correct beliefs about its most basic features.1 Although researchers generally associate such heuristics with automatic mindreading, and with infants’ or nonhumans’ behavioural predictions, one might speculate that heuristics play a role when adult humans are answering explicit questions about belief.  

There is a complication with Experiment 5, however. In contrast to Experiment 2, participants’ response times in Experiment 5 provided no evidence that the participants’ mindreading violated the idea that the agent’s failure to perceive affects what they can believe in their response times (see Fig. 5B). We suggest that the lack of evidence should probably not carry any weight. Bardi et al. (2017a, p. 395) report smaller differences in response time when participants were instructed about belief than when uninstructed. Further, the Bayesian analysis provides anecdotal evidence for non-automatic mindreading in Experiment 5.  

We note an interesting anomaly concerning results from Experiments 3 and 6, where the agent was encased in plexiglass. Par­ ticipants’ response times and their answers to questions about beliefs (in Experiment 6 only), both followed the pattern we would expect if their mindreading processes were attributing false beliefs to the agent. This appears to indicate that, from the point of view of those mindreading processes, an agent’s having limited action possibilities does not affect what they believe; and, therefore, seems to conflict with Low et al. (2020)’s evidence that automatic mindreading was impaired when the agent was unable to act. However, we also note that when our participants believed the ball was present, they were significantly slower to detect the ball when the agent believed it was present than when the agent believed it was absent. So when participants themselves believe the ball is absent, they appear to be mindreading (that is, $\mathrm{P}\mathrm{-}\mathrm{A}\mathrm{+}<\mathrm{P}\mathrm{-}\mathrm{A}\mathrm{-})$ ; when participants themselves believe the ball is present, they appear to be doing the inverse of mindreading (that is, $\mathrm{P}\mathrm{+}\mathrm{A}\mathrm{-}<\mathrm{P}\mathrm{+}\mathrm{A}\mathrm{+}$ . This ‘inverse mindreading’ effect is in contrast to other studies in which either no significant differences are found when participants believe the ball to be present (for example, Kovacs et al., 2010) or else significant differences in the opposite, expected direction are found (for example, Low et al., 2020). Indeed, others propose that these previous mixed results arise because an agent’s belief is likely less impactful when participants have a true belief (Al Kaddouri et al., 2020, p. 1755). However, that explanation cannot account for a significant effect in the opposite direction. We, therefore, interpret this ‘inverse mindreading’ effect as removing, for now, any justification for concluding that the results of Experiments 3 and 6 provide evidence of mindreading. Of course, caution is needed because future discoveries may shed light on when and why ‘inverse mindreading’ is expected.  

We have been assuming that, in our paradigm, it really is the agent’s belief that explains the differences in participants’ responses. Perhaps this is wrong. As we noted in the Introduction, some researchers have held that differences in participants’ responses are an artefact of one or another extraneous feature of the stimuli (Phillips et al., 2015; Heyes, 2014a,b). The difficulty for such views until now is that a direct test failed to support one leading contender (Al Kaddouri et al., 2020); and, as we noted above, a number of successful replications with a variety of stimuli make finding extraneous features challenging (Nijhof et al., 2016; Bardi et al., 2017a, b), particularly as some of these find significant effects of the agent’s belief on participants’ responses even when participants believe the ball to be present (for example, Low et al., 2020). However, our findings may give new hope to anyone aiming to identify extraneous factors. After all, observing a mindreading effect even in the absence of perceptual access (in Experiments 2 and 5) may suggest to some that this is not, after all, a mindreading effect. This perspective is not without problems. The fact that explicit responses to a question show the same pattern (in Experiment 5) is tricky to explain from this perspective and may require further investigation. On the other hand, the anomaly between the way the agent’s belief affects participants’ responses when they themselves believe the ball absent compared to when they themselves believe the ball present in Experiments 3 and 6 (discussed above) is consistent with the focus on finding an extraneous factor affecting only conditions where the participants believe the ball absent (Heyes, 2014a,b). One route to making convincing an ‘extraneous factor’ view would be to successfully explain and predict the mixed pattern of discrepancies between conditions where participants themselves believe the ball present and where they themselves believe it absent.  

To understand mindreading we must know which principles govern it. To date, researchers have mostly assumed that the principles are known a priori. We have taken a step forward by treating the principles as hypotheses and developing ways to test whether one or another mindreading process accords with the principles or not. Overall, our findings motivate considering whether principles of belief acquisition that researchers are used to taking for granted really do characterise how people actually read minds. If phenomena that have been labelled automatic mindreading are mindreading at all, they are perhaps unlikely to be mindreading as we know it.  

# CRediT authorship contribution statement  

M.T. Pascarelli: Conceptualization, Data curation, Formal analysis, Writing – original draft, Writing – review & editing. D. Quarona: Conceptualization, Data curation, Formal analysis. G. Barchiesi: Formal analysis, Methodology, Writing – review & editing. G. Riva: Conceptualization, Funding acquisition, Resources, Supervision. S. Butterfill: Conceptualization, Supervision, Writing – original draft, Writing – review & editing. C. Sinigaglia: Conceptualization, Funding acquisition, Resources, Supervision, Writing – original draft, Writing – review & editing.  

# Declaration of competing interest  

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.  

# Data availability  

All the row and processed data are uploaded to the repository of Open Science at the following link https://osf.io/7zvhy/?view_ only $^{\prime}=$ 3e5d8212afbb40ceb9cfc7b8170be55f.  

# Acknowledgements  

This article was supported by the Department of Philosophy ‘Piero Martinetti’ of the University of Milan with the Project “De­ partments of Excellence 2018-2022” awarded by the Italian Ministry of Education, University and Research (MIUR) (to MTP, DQ, and CS) and by the PRIN 2017 project “The cognitive neuroscience of interpersonal coordination and cooperation: a motor approach in humans and non-human primates” (Cod. Prog. 201794KEER; to CS). It has also been supported by the UCSC D3.2 2020 project "Behavioural change: prospettive per la stabilizzazione di comportamenti virtuosi verso la sostenibilita" (to GR). We are grateful to Roberto Ranon for his critical contribution in making the different series of video clips.  

# Appendix A. Supplementary data  

Supplementary data to this article can be found online at https://doi.org/10.1016/j.concog.2023.103625.  

# References  

Al Kaddouri, R., Bardi, L., De Bremaeker, D., Brass, M., & Wiersema, J. R. (2020). Measuring spontaneous mentalizing with a ball detection task: Putting the attentioncheck hypothesis by Phillips and colleagues (2015) to the test. Psychological Research, 84, 1749–1757.   
Bardi, L., Desmet, C., Nijhof, A., Wiersema, J. R., & Brass, M. (2017a). Brain activation for spontaneous and explicit false belief tasks overlaps: New fMRI evidence on belief processing and violation of expectation. Social Cognitive and Affective Neuroscience, 1(12), 391–400.   
Bardi, L., Six, P., & Brass, M. (2017b). Repetitive TMS of the temporo-parietal junction disrupts participant’s expectations in a spontaneous Theory of Mind task. Social Cognitive and Affective Neuroscience, 1(12), 1775–1782.   
Baron-Cohen, S., Leslie, A. M., & Frith, U. (1985). Does the autistic child have a “theory of mind”? Cognition, 21, 37–46.   
Butterfill, S. A., & Apperly, I. (2013). How to construct a minimal theory of mind. Mind & Language, 28, 606–637.   
Cardellicchio, P., Sinigaglia, C., & Costantini, M. (2013). Grasping affordances with the other’s hand: A TMS study. Social Cognitive and Affective Neuroscience, 8, 455–459.   
Costantini, M., Committeri, G., & Sinigaglia, C. (2011). Ready both to your and to my hands: Mapping the action space of others. PLoS One, 4(6), e17923.   
Franconeri, S. L., Pylyshyn, Z. W., & Scholl, B. J. (2012). A simple proximity heuristic allows tracking of multiple objects through occlusion. Attention, Perception, & Psychophysics, 74(4), 691–702.   
Furlanetto, T., Becchio, C., Samson, D., & Apperly, I. (2016). Altercentric interference in level 1 visual perspective taking reflects the ascription of mental states, not submentalizing. Journal of Experimental Psychology. Human Perception and Performance, 42, 2, 158–163.   
Grosse Wiesmann, C., Friederici, A. D., Singer, T., & Steinbeis, N. (2020). Two systems for thinking about others’ thoughts in the developing brain. Proceedings of the National Academy of Science USA, 24(117), 6928–6935.   
Heyes, C. (2014a). Submentalizing: I am not really reading your mind. Perspective on Psychological Science, 9, 131–143.   
Heyes, C. (2014b). False Belief in Infancy: A Fresh Look. Developmental Science, 17(5), 647–659.   
Keysar, B., Lin, S., & Barr, D. J. (2003). Limits on theory of mind use in adults. Cognition, 89(1), 25–41.   
Low, J., Edwards, K., & Butterfill, S. A. (2020). Visibly constraining an agent modulates observers’ automatic false-belief tracking. Scientific Report, 10, 11311.   
Nijhof, A. D., Brass, M., Bardi, L., & Wiersema, J. R. (2016). Measuring mentalizing ability: A within- subject comparison between an explicit and implicit version of a ball detection task. PLoS ONE, 11, e016437.   
Schneider, D., Bayliss, A. P., Becker, S. I., & Dux, P. E. (2012). Eye movements reveal sustained implicit processing of others’ mental states. Journal of Experimental Psychology General, 141, 433–438.   
Schneider, D., Slaughter, V. P., & Dux, P. E. (2017). Current evidence for automatic Theory of Mind processing in adults. Cognition, 162, 27–31.   
Scholl, B. J. (2007). Object Persistence in Philosophy and Psychology. Mind & Language, 22(5), 563–591.   
van der Wel, R. P. R. D., Sebanz, N., & Knoblich, G. (2014). Do people automatically track others’ beliefs? Evidence from a continuous measure. Cognition, 130, 128–133.   
Wang, J. J., Miletich, D. D., Ramsey, R., & Samson, D. (2014). Adults see vision to be more informative than it is. Quarterly Journal of Experimental Psychology, 67(12), 2279–2292.   
Wimmer, H., & Perner, J. (1983). Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children’s understanding of deception. Cognition, 13(1), 103–128.   
Zani, G., Butterfill, S. A., & Low, J. (2020). Mindreading in the balance: Adults’ mediolateral leaning and anticipatory looking foretell others’ action preparation in a false-belief interactive task. Royal Society Open Science, 7(1), Article 191167.  

</div>

---

Title: Perceiving Expressions of Emotion: What evidence could bear on questions about perceptual experience of mental states?
Authors: Stephen A. Butterfill
Year: 2015
Journal: Consciousness and Cognition
Type: Publication

## Abstract

What evidence could bear on questions about whether humans ever perceptually experience any of another’s mental states, and how might those questions be made precise enough to test experimentally? This paper focusses on emotions and their expression. It is proposed that research on perceptual experiences of physical properties provides one model for thinking about what evidence concerning expressions of emotion might reveal about perceptual experiences of others’ mental states. This proposal motivates consideration of the hypothesis that categorical perception of expressions of emotion occurs, can be facilitated by information about agents’ emotions, and gives rise to phenomenal expectations. It is argued that the truth of this hypothesis would support a modest version of the claim that humans sometimes perceptually experience some of another’s mental states. Much available evidence is consistent with, but insufficient to establish, the truth of the hypothesis. We are probably not yet in a position to know whether humans ever perceptually experience others’ mental states.




---

Title: Planning for Collective Agency
Authors: Stephen A. Butterfill
Year: 2016
Type: Publication

## Abstract

Which planning mechanisms enable agents to coordinate their actions, and what if anything do these tell us about the nature of collective agency?  On the leading, best developed account, Michael Bratman's, collective agency  is explained in terms of interconnected planning.  For our plans to be interconnected is for them to concern not just facts about our environment and goals but also facts about each others' plans.  This chapter contrasts interconnected with parallel planning.  In parallel planning, we each individually plan all of our actions and so are in a position to conceive of our own and each other's actions as parts of a single plan or exercises of a single ability.  (The very idea of parallel planning may initially seem incoherent; the chapter examines this issue.)  Could parallel rather than interconnected planning underpin intentional collective agency?  Some considerations in favour of a positive answer are provided by appeal to recent evidence on the role of motor representation in coordinating exercises of collective agency.




---

Title: From foraging to autonoetic consciousness: The primal self as a consequence of embodied prospective foraging
Authors: Thomas T. Hills and Stephen A. Butterfill
Year: 2015
Journal: Current Zoology
Type: Publication

## Abstract

The capacity to adapt to resource distributions by modulating the frequency of exploratory and exploitative behaviors is common across metazoans and is arguably a principal selective force in the evolution of cognition. Here we (1) review recent work investigating behavioral and biological commonalities between external foraging in space and internal foraging over environments specified by cognitive representations, and (2) explore the implications of these commonalities for understanding the origins of the self. Behavioural commonalities include the capacity for what is known as area-restricted search in the ecological literature: this is search focussed around locations where resources have been found in the past, but moving away from locations where few resources are found, and capable of producing movement patterns mimicking Lévy flights. Area-restricted search shares a neural basis across metazoans, and these biological commonalities in vertebrates suggest an evolutionary homology between external and internal foraging. Internal foraging, and in particular a form we call embodied prospective foraging, makes available additional capacities for prediction based on search through a cognitive representation of the external environment, and allows predictions about outcomes of possible future actions. We demonstrate that cognitive systems that use embodied prospective foraging require a primitive sense of self, needed to distinguish actual from simulated action. This relationship has implications for understanding the evolution of autonoetic consciousness and self-awareness.




---

Title: Psychological Research on Joint Action: Theory and Data
Authors: Guenther Knoblich, Stephen A. Butterfill and Natalie Sebanz
Year: 2011
Type: Publication

## Abstract

When two or more people coordinate their actions in space and time to produce a joint outcome, they perform a joint action. The perceptual, cognitive, and motor processes that enable individuals to coordinate their actions with others have been receiving increasing attention during the last decade, complement- ing earlier work on shared intentionality and discourse. This chapter reviews current theoretical concepts and empirical findings in order to provide a structured overview of the state of the art in joint action research. We distin- guish between planned and emergent coordination. In planned coordination, agents' behavior is driven by representations that specify the desired outcomes of joint action and the agent's own part in achieving these outcomes. In emergent coordination, coordinated behavior occurs due to perception-action couplings that make multiple individuals act in similar ways, independently of joint plans. We review evidence for the two types of coordination and discuss potential synergies between them.




---

Title: On a Puzzle about Relations between Thought, Experience and the Motoric
Authors: Corrado Sinigaglia and Stephen A. Butterfill
Year: 2015
Journal: Synthese
Type: Publication

## Abstract

Motor representations live a kind of double life. Although paradigmatically involved in performing actions, they also occur when merely observing others act and sometimes influence thoughts about the goals of observed actions. Further, these influences are content-respecting: what you think about an action sometimes depends in part on how that action is represented motorically in you.  The existence of such content-respecting influences is puzzling. After all, motor representations do not feature alongside beliefs or intentions  in reasoning about action; indeed, thoughts are inferentially isolated from motor representations. So how could motor representations have content-respecting influences on thoughts? Our aim is to solve this puzzle.  In so doing, we shall provide the basis for an account of how experience links the motoric with thought. Such an account matters for understanding how humans think about action: in some cases, we have reasons for thoughts about actions that we would not have if we were unable to represent those actions motorically.




---

Title: Review of Consciousness: New Philosophical Perspectives. Edited by Quentin Smith and Aleksander Jokic
Authors: Stephen A. Butterfill
Year: 2005
Journal: Philosophical Quarterly
Type: Publication



---

Title: Review of Joint Commitment: How We Make the Social World by Margaret Gilbert
Authors: Stephen A. Butterfill
Year: 2017
Journal: Journal of Moral Philosophy
Type: Publication



---

Title: Review of Self-Knowing Agents by Lucy O'Brien
Authors: Stephen A. Butterfill
Year: 2009
Journal: Philosophical Review
Type: Publication

<p>The first-person is "expressive of self-consciousness" (64).  Someone who uses the first-person, for example in saying or thinking "Where am I?",  not only succeeds in referring to herself but also knows that she refers to herself.  In Self-Knowing Agents, O'Brien's primary aim is to explain how it is that using the first-person guarantees this knowledge-that is, to explain "how it is that 'I' expresses self-consciousness" (57).</p>
<p>The explanation hinges on agent's awareness, the awareness an agent has of an action by virtue of controlling it.  Control consists in this: the agent evaluates possibilities for action which she is aware of as possibilities; then she selects, endorses or accepts one (116-7, 183).  The possibilities in question are basic actions, that is, actions the subject can carry out without having to do anything else (163-5).  The process of evaluation and selection immediately determines how the agent will act.  For this reason, an agent who knows that some action resulted from her evaluation and selection is in a position to know which basic action resulted (165).  Further, nobody else's actions can be immediately determined by her process of evaluation and selection, only the agent's (184).  For this reason, if an agent knows that some action occurred as an immediate consequence of her process of evaluation and selection, then she is able to know that the action is her action (119).  The general idea, then, is that agent's awareness does not involve first-person reference but does enable agents to know with respect to their own actions both who is acting and what the action is (123).</p>
<p>The explanation of how 'I' expresses self-consciousness is now straightforward.  O'Brien holds that there are mental actions and that judging, wondering and supposing are all actions (89).  Using the first-person in thought or talk is a basic action (or perhaps a component of one) and so can be done with agent's awareness.  Where the first-person is used with agent's awareness, the agent can know that her action is one of using the first-person and that she is the agent of this action.  Now users of the first-person also know that the first-person is governed by the rule that it refers to the subject who produced it (77).  Knowledge of this rule in combination with agent's awareness enables subjects who use the first-person to judge that they have referred to themselves.  </p>
<p>In short, given some general knowledge about the term 'I', what enables us to know who we are referring to when using 'I' is the act of using 'I' itself.  </p>
<p>The book also explores a set of related claims about self-knowledge.  These centre on the question, How do we know which bodily action we are performing and, in the case of mental action, which thought we are thinking?  As sketched above, agent's awareness provides an answer.  When an action results from evaluating and selecting possibilities that we are aware of as possibilities, the agent can know what she is thinking or doing because she selected it.  So it is the fact of acting with agent's awareness and not any perception or representation of our actions that enables us to know what we are thinking and doing.</p>
<p>The positive claims of Self-Knowing Agents are supported by critical discussion of alternative positions.  One type of alternative is to reject the datum O'Brien sets out to explain, that the first-person is expressive of self-consciousness.  This might be rejected either on the grounds that 'I' does not refer (Anscombe) or the grounds that using the first-person need not involve knowing that one refers to oneself (Mellor).   Both views are countered in detail (Chapter 2 and 59-65).  Perceptual accounts are another type of alternative to O'Brien's position.  In Chapter 3, O'Brien discusses the view that self-conscious self-reference might be grounded in bodily awareness and Gareth Evans' view that self-conscious self-reference depends on being able to use perceptual information to track one's own location.  Both views imply that perception, or at least memory based on perception, is necessary for self-conscious self-reference (47-8).  O'Brien objects that we could use the first-person self-consciously while suffering complete memory loss and full sensory deprivation (4-5, 34, 46).</p>
<p>Is it true, as O'Brien and others claim, that agents would know who their own uses of 'I' referred to even if deprived of memory and perception?  Although this claim carries much weight in Self-Knowing Agents, it is not defended.  Unless this claim is obviously true, there is a gap in the main argument against perceptual accounts.</p>
<p>O'Brien interprets others' views in the most charitable way possible and faces objections to her own squarely.  She also identifies a counterexample to her own position.  Recall that agent's awareness was characterised in terms of control over action.  This control takes the form of evaluating possibilities for action and selecting one.  When the action is judging, O'Brien illustrates the general idea by suggesting that we "accept or endorse a given thought in the light of our awareness of the possible judgements we could make, and the reasons in favour of one over another" (116).  But consider being suddenly struck by the thought, "I am supposed to be outside the school gates right now" (90).  Thinking this thought seems to involve self-reference as expressive of self-consciousness as any other use of the first-person.  But being struck by a thought involves no process of evaluating possible thoughts and so does not involve agent's awareness.  On the face of it, then, O'Brien's account cannot explain self-conscious uses of the first-person in all cases.</p>
<p>The problem also affects O'Brien's account of self-knowledge.  Many of our actions, including our judgements, are triggered by things others say or do, and by changes in our situation.  The rude remark provokes a swift retort, the infant's smile induces a hug.  Agents don't generally evaluate and select possibilities in such cases, but they do exercise control to the extent that they can inhibit their actions.  Control by inhibition cannot explain self-knowledge; indeed, inhibition sometimes requires awareness of which action one is inhibiting.  So agent's awareness construed as evaluation and selection cannot explain an agent's knowledge of which action she is performing in these cases.</p>
<p>O'Brien's main response to these counterexamples is to suggest that they are derivative in the sense that self-knowledge in cases lacking agent's awareness depends on the existence of other cases in which there is agent's awareness (90-2).  This suggestion is hard to evaluate without an account of how the dependence works.  When an infant's smile induces hugging (say), how does the agent's knowledge of who is acting now depend on her knowledge of who acted on other occasions?  O'Brien's core idea is that the fact of acting enables an agent to know who is acting.  This seems equally plausible in cases where action is not the outcome of a process evaluation and selection.  Perhaps, then, the substantive account of agent's awareness needs modification.  As it stands, O'Brien's account makes no appeal to connections among a subject's thoughts and actions.  The account works as well for an agent who acts just once as it does for an agent who enjoys a long and eventful life.  If the lives of self-consciousness agents necessarily form more than a series of isolated actions, one way to modify the account of agent's awareness would be to appeal to how an agent's judgements fit with her other thoughts and how her bodily actions affect her plans.  </p>
<p>Self-Knowing Agents is a deep and ambitious book which develops and defends a new thesis about the role of agency in self-reference and self-knowledge.  Readers will be grateful that O'Brien sets the scene for her account with sympathetic and rigorous discussion of competing and connected positions.  And there is a richness to the book which this review entirely fails capture, for O'Brien deftly weaves the main arguments into larger-scale views about the nature of action, bodily awareness and agency.</p>

---

Title: Review of The Rational Imagination by Ruth Byrne
Authors: Stephen A. Butterfill
Year: 2008
Journal: Mind
Type: Publication

## Abstract

This book develops a mental models approach to counterfactual thinking. It brings together a large body of empirical research by the author and collaborators, and interprets the findings in the light of some novel views about meaning.  In this review, I argue that unless indicative conditional, counterfactual, and causal assertions really do all mean the same thing, the mental models discussed in <i>The Rational Imagination</i>  are not adequate for explaining counterfactual and causal reasoning.



---

Title: Review of Thinking without Words by Jose Luis Bermudez
Authors: Stephen A. Butterfill
Year: 2004
Journal: Mind
Type: Publication

<p>That some animals, early hominids and infants think (or did so once) is increasingly hard to doubt.  Our evidence includes everything from the manufacture and use of tools (55, 127), to the ways infants react when shown apparently impossible physical events (81).  Berm&uacute;dez' project is to explain the nature of this thinking.  How can we know what an infant, ape or early hominid thinks?  What determines the contents of their thoughts?  Are they thinkers in just the sense that you and I are, or do we humans become fundamentally different types of thinker with our own distinctive cognitive abilities after infancy?  Thinking without Words offers answers to these questions, mixing philosophical argument with accounts of empirical research.</p>
<p>The notion that there is such a thing as 'thinking without words' is doubly controversial.  First, some philosophers hold that creatures incapable of communication by language are also  incapable of thought.  Berm&uacute;dez counters this view in Chapter 3, where he argues at length that some non- and pre-linguistic creatures are capable of real thinking-that is, their decision-making involves both structured representations and instrumental reasoning about the consequences of actions (51).  Second, the notion of 'thinking without words' is controversial because, assuming that nonlinguistic creatures can think, it is not obvious that their thinking differs in kind from ours.  And even supposing their thinking does differ in kind from ours, it is not obvious that this has anything to do with language.  However, as I will shortly explain, Berm&uacute;dez argues that languageless creatures' thinking is more limited than ours and that 'an important class of thoughts ... is in principle unavailable to nonlinguistic creatures' (150).  Not only does their thinking exclude inference (111) and practical reasoning (131-2); they are also unable to think thoughts involving logical constants such as NOT and quantifiers such as EVERY (Chapters 8-9).  If Berm&uacute;dez is right that languageless creatures don't infer or quantify, what could their thinking be like?  Come to think of it, how could they be thinking at all?</p>
<p>Berm&uacute;dez adopts a nice strategy for answering these questions.  Take a theory about some aspect of thinking, a theory which is coherent but doesn't quite work because it lacks the resources to capture our ordinary ways of thinking.  Then see whether that theory might work for a creature whose thinking is more limited than ours.  Recycling theories in this way makes a virtue of their limitations, provided the theories are limited in just the ways that the target creatures' thinking is limited.  Take NOT, a concept which apes are supposed to lack on account of their languageless state (as I'll soon explain).  Some philosophers have held that NOT modifies predicates rather than whole sentences.  While that probably isn't how our concept NOT works, there could be an element of ape thinking-'protonegation'-that does work this way (142-5).  So it is that Berm&uacute;dez attempts to characterise nonlinguistic thinking by recycling a failed theory of negation.  The same strategy is used to explain what determines the contents of nonlinguistic creatures' thoughts.  Take 'success semantics', a theory according to which 'the content of a belief is given by ... the condition that would have to obtain for the various desires associated with it to be satisfied' (65).  While success semantics probably isn't right for our thoughts (66-8), Berm&uacute;dez suggests, it's the sort of theory we need for nonlinguistic thought.</p>
<p>Why is nonlinguistic thinking supposed to be limited?  In Chapters 8 and 9, Berm&uacute;dez argues like this:</p>
<ol>
  <li>Thinking thoughts containing NOT requires the ability to think 'about how the truth-value of one thought might be related to the truth-value of another thought' (178); this is 'intentional ascent'.</li>
  <li>Intentional ascent requires 'semantic ascent', which is the ability to think about sentences.</li>
</ol>
<p>Therefore:</p>
<ol start="3">
  <li>Using NOT requires the ability to communicate by language.</li>
</ol>
<p>In addition to NOT, this argument is supposed to work for any truth-functional connective, quantifier, tense operator or modal operator.</p>
<p>The first premise, [1], is merely stated.  Although quite widely held, it is not obvious how this premise could be true.  Is Berm&uacute;dez' position that the ability to think about the truth values of thoughts is always, or even just sometimes, actually exercised in thinking thoughts containing NOT?  If it is, then we need to know how this ability is exercised.  As he notes, thinking THE CAT IS NOT HERE doesn't involve thinking about the truth values of thoughts in anything like the sense in which it involves thinking about cats (178).  If, on the other hand, Berm&uacute;dez' position is that thinking thoughts containing NOT never involves exercising an ability to think about the truth values of thoughts, then he needs to explain how merely having this ability could be a necessary condition for thinking thoughts containing NOT.  Either way, it is unclear how, if at all, an ability to think about the truth values of thoughts is involved in thinking NOT-thoughts.</p>
<p>The second premise, [2], is argued for.  First, assume Dummett's view that thinking about thoughts requires thinking about their vehicles.  Then, since intentional ascent involves 'conscious cognitive access to the target thoughts', it follows that the vehicles of these thoughts must be accessible to consciousness (159).  Finally, Berm&uacute;dez argues that 'public language sentences are the only possible ... vehicles for thoughts that are to be the objects of reflexive thinking', and he does this by eliminating rival candidates (160).  One problem with this argument is that since, as Berm&uacute;dez says, 'we have little idea of what the vehicle of nonlinguistic thought might be' (192), he can hardly have eliminated this particular vehicle or have shown that a thought's having this vehicle would not permit it to be an object of reflexive thinking.  Another problem with arguing by elimination is that it sheds no light on why the conclusion is true.  If we really can think about a thought only when we have somehow expressed it in a sentence that we use to communicate with, I'd like to know why.  An argument from elimination leaves it mysterious why there should be a link between sentences we use for communication and thoughts we can think about.  In short, then, much more needs to be said to explicate and defend the two premises of Berm&uacute;dez' main argument relating thought and language.</p>
<p>The project of understanding early hominid, infant and animal thought is surely interesting and important, but I don't yet see what their lack of language has to do with it.  A second way of relating thought and language is implicit in Thinking without Words.  Berm&uacute;dez remarks that '[w]e have no theoretical framework for understanding the content and nature of nonlinguistic thought' (vii).  Does this mean that we do have a theoretical framework for understanding language-users' thoughts?  In Chapter 2, Berm&uacute;dez gives the impression that we do, and that Gotlob Frege and Michael Dummett have together succeeded in providing it.  The key to their theory is the claim that to grasp a thought is to understand a sentence which expresses it.  This theory doesn't work for the languageless, Berm&uacute;dez claims, because 'no account has yet been given of what it might be to grasp a thought independently of understanding a sentence' (19).  I read Berm&uacute;dez as implying that thinking without words is especially problematic because we have an adequate conception of thinking which applies only to language-users.  But do we?  Let's concede that grasping a thought is understanding a sentence which expresses it.  Now we need to know what constitutes understanding a sentence.  And of course no one has got very far with explaining this-or, at least, no one has got further with this than they have with explaining what it is to grasp a thought.  Why not?  Probably because understanding a sentence involves grasping the thought it expresses.  An animal's having a language would make it easier to understand the nature of its thinking only if we knew what it is to understand a sentence; but the problem of understanding sentences turns out to be no easier than the problem of grasping thoughts.  In this respect, language-using animals' thinking is no better understood than languageless animals'.  </p>
<p>The arguments relating thought and language are quite a small part of this book.  The main part, Chapters 3-7, is a systematic attempt to describe a kind of thought and an associated kind of thinking, and to relate this theoretical description to a wide variety of experimental research.  Even if Berm&uacute;dez hasn't fully explained what this kind of thinking has to do with language, the more important question is surely whether he's right about how any of his subjects-animals, infants and early hominids-think.  On this point the book offers many valuable insights.  I'm about to recommend it to you as a tremendous resource which takes in an enormous range of experimental work and is full of ideas about the nature of thought.  But first I want to raise another objection.</p>
<p>Berm&uacute;dez describes his book as a first step towards providing 'a conceptual foundation for the various disciplines that are committed to giving psychological explanations of the behavior of nonlinguistic creatures' (193).  Talk of foundations is misleading because Berm&uacute;dez' position is in part an error theory.  You wouldn't know it from reading this book, but an important cluster of theories in developmental psychology are deeply committed to the hypothesis that infants think and reason in just the ways that adults do.  Take Ren&eacute;e Baillargeon's research on infants' understanding of how objects behave.  The presentation of her research in Thinking without Words is selective; Berm&uacute;dez says only that Baillargeon has shown that infants are 'sensitive' to certain higher-order principles about the ways objects behave (54, 78).  But Baillargeon, like other researchers, is not content to describe infant cognition using uninformative notions like 'sensitivity'.  She aims for a deeper understanding of what happens when infants perceive objects.  Her experiments are designed to show that 'infants, like older learners, formulate rules or hypotheses about physical events and revise and elaborate these hypotheses in light of additional input' (Aguiar and Baillargeon, 'Developments in Young Infants' Reasoning About Occluded Objects', Cognitive Psychology, 2002, 45:267-336, p. 329).  According to Berm&uacute;dez, however, infants are incapable of testing or revising hypotheses; at best they are capable of 'protoinference', which is not how older learners reason.  So, far from constituting a foundation for Baillargeon's psychological explanations, Berm&uacute;dez' views are incompatible with them.  </p>
<p>Berm&uacute;dez engages with scientists' views about thought in other work (for example, in The Paradox of Self-Consciousness, Cambridge, MA: MIT Press, 1998, pp. 62-76); a deeper level of engagement would also have benefited this book.  Take infants' perceptions of objects again.  Whether and how infants think about objects is currently much debated within psychology.  There are several versions of the view that infants discover the properties of objects by formulating and testing hypotheses; there are also psychologists who deny that infants think about (as opposed to perceive) objects at all; and there are those who, like Berm&uacute;dez, hold that infants do think about objects but not in the same way that older people do.  The fact that his view conflicts with other researchers' views is part of what makes it worth studying.  </p>
<p>Thinking without Words is an accessible and fascinating book; it develops a theory of how animals, early hominids and infants think, which is supported by reference to many different areas of research as well as by philosophical arguments.  Anyone who cares about any kind of thinking should enjoy reading it.</p>

---

Title: Seeing Causes and Hearing Gestures
Authors: Stephen A. Butterfill
Year: 2009
Journal: Philosophical Quarterly
Type: Publication

## Abstract

Can humans see causal interactions? Evidence on the visual perception of causal interactions, from Michotte to contemporary work, is best interpreted as showing that we can see some causal interactions in the same sense as that in which we can hear speech. Causal perception, like speech perception, is a form of categorical perception.




---

Title: Seeing It Both Ways: Using a Double-Cuing Task to Investigate the Role of Spatial Cuing in Level-1 Visual Perspective-Taking
Authors: John Michael, Thomas Wolf, Clément Letesson, Stephen A. Butterfill, Joshua Skewes Jakob Hohwy
Year: 2018
Journal: Journal of Experimental Psychology: Human Perception and Performance
Type: Publication

## Abstract

Previous research using the dot-perspective task has produced evidence that humans may be equipped with a mechanism that spontaneously tracks others’ gaze direction and thereby acquires information about what they can see. Other findings, however, support the alternative hypothesis that a spatial-cuing mechanism underpins the effect observed in the dot-perspective task. To adjudicate between these hypotheses, we developed a double-cuing version of Posner’s (1980) spatial-cuing paradigm to be implemented in the dot-perspective task, and conducted 3 experiments in which we manipulated stimulus-onset asynchrony, as well as secondary task demands. Crucially, the 2 conflicting hypotheses generated divergent patterns of predictions across these experimental conditions. Our results support the hypothesis of an automatic perspective-taking mechanism.




---

Title: Motor Representation in Acting Together
Authors: Corrado Sinigaglia and Stephen A. Butterfill
Year: 2022
Journal: Synthese
Type: Publication

<div class='fulltext'>

<h1 id="sec:abstract">Abstract</h1>

<div class='abstract'>
People walk, build, paint and otherwise act together with a purpose in myriad ways. What is the relation between the actions people perform in acting together with a purpose and the outcome, or outcomes, to which their actions are directed? We argue that fully characterising this relation will require appeal not only to intention, knowledge and other familiar philosophical paraphernalia but also to another kind of representation involved in preparing and executing actions, namely motor representation. If we are right, motor representation plays a central role in the story of acting together.
</div>

<h1 id="sec:new_introduction">A Question about Acting Together</h1>
<p>People walk, build, paint and otherwise act together with a purpose
in myriad ways. Minimally, our acting together with a purpose requires
that there be some sense in which we are acting together, and also an
outcome to which our actions are directed. But this is not quite enough
to capture what we want. To see why not, consider a contrast involving a
long drain which is blocked:</p>
<blockquote>
<p>CASE 1: Ayesha and Beatrice live at different ends of the drain. By
chance, they are simultaneously attempting to unblock it with drain
rods. Although neither’s efforts would have been sufficient, the common
effect of their actions is sufficient vibration and disturbance to clear
the blockage.</p>
<p>CASE 2: … is exactly like CASE 1 except that it is not by chance but
by agreement that Ayesha and Beatrice are simultaneously attempting to
unblock the drain; moreover, they expect that blockage to be removed as
a common effect of their actions.</p>
</blockquote>
<p>In both cases we can say that Ayesha and Beatrice unblocked the drain
together—after all, neither of them alone was doing quite enough to move
the blockage.<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> Further, there is a single outcome,
the unblocking, to which each of their actions are directed. Yet we aim
to exclude the first case and include the second only. This can be done
by imposing a further requirement: where we act together with a purpose,
there must be an outcome to which our actions are directed and this
cannot be, or cannot only be, a matter of each action being directed to
it. To save words, we stipulate that in such cases our actions are
<em>collectively directed</em> to the outcome.</p>
<p>These minimal requirements on acting together with a purpose are
weaker than those commonly assumed in discussions of acting together for
they involve neither psychological mechanisms such as shared intentions
(contrast <span class="citation" data-cites="Bratman:1992mi">(Bratman
1992)</span>) nor normative structures (contrast <span class="citation"
data-cites="gilbert:2014_book">(Gilbert 2013)</span>); nor do they
invoke any novel kind of reasoning (<span class="citation"
data-cites="Gold:2007zd">(Gold and Sugden 2007)</span>) or subject
(<span class="citation" data-cites="helm_plural_2008">(Helm
2008)</span>). <a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a> Despite this, there is at least one
question which can be brought into view without relying on anything more
than the minimal requirements.</p>
<p>To see this question, recall the contrast above. Given that actions
are events, there is no special mystery about how the actions we perform
can collectively have effects such as unblocking a drain: this is just a
matter of events having common effects. By contrast, it is less obvious
how our actions could be directed to unblocking the drain without this
being merely a matter of each action being individually directed to that
outcome. When we act together with a purpose, in virtue of what are the
actions we perform collectively directed to outcomes?</p>
<p>This question is parallel to one about ordinary individual actions
and the outcomes to which they are directed. Some have argued that the
directedness of ordinary, individual actions to outcomes depends not
only on intention or knowledge or other familiar philosophical
paraphernalia but also other kinds of representations which are involved
in preparing and executing actions; in particular, something called
<em>motor representations</em> (see section <a href="#sec:acting_alone"
data-reference-type="ref" data-reference="sec:acting_alone">2</a>).
Inspired by these arguments, and taking the correctness of their
conclusion as a premise, we shall consider whether they can be
generalised to acting together with a purpose. This will involve four
steps. The first step is to examine the possibility that, when people
act together with a purpose, the outcomes to which their actions are
collectively directed are sometimes represented motorically. Recent
discoveries suggest that this is indeed the case (see section <a
href="#sec:collective_goals_are_represented" data-reference-type="ref"
data-reference="sec:collective_goals_are_represented">3</a>). The second
step is to propose a conjecture: motor representations of outcomes can
be components of certain interagential structures, and these structures
can facilitate interpersonal coordination of actions around the
represented outcomes (see section <a href="#sec:coordination"
data-reference-type="ref" data-reference="sec:coordination">4</a> where
we first specify the interagential structure). The third step is to show
that the conjecture is theoretically coherent and empirically motivated
(see section <a href="#sec:two_objections" data-reference-type="ref"
data-reference="sec:two_objections">5</a>). The fourth step is to
observe that the conjecture implies an answer to our overall question:
Sometimes when people act together with a purpose, it is a certain
interagential structure of motor representations in virtue of which
their actions are collective directed to outcomes (see section <a
href="#sec:collective_goals_motor_representations"
data-reference-type="ref"
data-reference="sec:collective_goals_motor_representations">6</a>).</p>
<p>Our focus may seem unusual. There are rich discussions of commitment
<span class="citation"
data-cites="Roth:2004ki gilbert:2014_book michael:2022_book">(Roth 2004;
Gilbert 2013; Michael 2022)</span>, of shared intention <span
class="citation"
data-cites="bratman:2014_book Searle:1990em ludwig:2016_individual">(Bratman
2014; Searle 1990; Ludwig 2016)</span>, of knowledge <span
class="citation"
data-cites="blomberg:2015_common rodl:2018_joint roessler:2020_plural satne:2020_practical">(Blomberg
2016; Rödl 2018; Roessler 2024; Satne 2020)</span>, of norms <span
class="citation" data-cites="bicchieri:2016_norms">(Bicchieri
2016)</span>, of awareness <span class="citation"
data-cites="Schmid:2013_self">(Schmid 2013)</span>, of temporal
coordination <span class="citation"
data-cites="issartel:2007_unintended oullier:2008_social">(Issartel,
Marin, and Cadopi 2007; Oullier et al. 2008)</span>, of reasoning <span
class="citation"
data-cites="Gold:2007zd Sugden:2000mw pacherie:2013_lite">(Gold and
Sugden 2007; Sugden 2000; Pacherie 2013)</span>, and of agents <span
class="citation" data-cites="helm_plural_2008">(Helm 2008)</span>. By
contrast, despite a groundbreaking proposal <span class="citation"
data-cites="Pacherie:2006dl">(Pacherie and Dokic 2006)</span>, motor
representation has been widely ignored in philosophical discussions in
this area. This may be because philosophers assume motor representations
play at most an enabling role by coordinating actions. Our aim is to
identify a more central role for them in the story of acting
together.</p>
<h1 id="sec:acting_alone">Motor Representation in Acting Alone with a
Purpose</h1>
<p>The aim of this paper is to argue that when acting together with a
purpose, the actions performed are sometimes collectively directed to an
outcome in virtue of a certain structure of motor representations. As a
starting point, let us outline, in barest detail, an established view
about motor representation in acting alone with a purpose. We shall
later argue that this view can be generalised to acting together.</p>
<p>Consider very small scale actions, such as playing a chord, dipping a
brush into a can of paint, placing a book on a shelf or cracking an egg.
<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a> Often enough, the early part of such
an action carries information about how the action will unfold. For
example, in grasping a book (or tall cylinder) you would probably hold
its middle, which makes lifting it less effortful. But if you are about
to place the book on a high shelf, you are more likely to grasp the book
at one end, which makes lifting it more awkward now but will later make
placing it easier <span class="citation"
data-cites="cohen:2004_wherea meyer:2013_higher-order">(Cohen and
Rosenbaum 2004; Meyer, Wel, and Hunnius 2013)</span>. For another
illustration, imagine you are a cook who needs to take an egg from its
box, crack it and put it (except for the shell) into a bowl ready for
beating into a carbonara sauce. How tightly you now need to grip the egg
depends, among other things, on the forces to which you will later
subject the egg in lifting it. It turns out that people reliably grip
objects such as eggs just tightly enough across a range of conditions in
which the optimal tightness of grip varies. How tightly you initially
grip the egg indicates your anticipated future hand and arm movements
(compare <span class="citation"
data-cites="kawato:1999_internal">Kawato 1999</span>).</p>
<p>This anticipatory control of grasp, like several other features of
action performance (<span class="citation"
data-cites="rosenbaum:2010_human">(see Rosenbaum 2009, chap. 1)</span>
for more examples), is not plausibly a consequence of mindless
physiology. It indicates that control of action involves representations
concerning how actions will unfold in the future. These and other
representations which characteristically play a role in coordinating
very small scale actions are labelled ‘motor representations’. <a
href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></p>
<p>What do motor representations represent? An initially tempting view
would be that they represent sequences of bodily configurations and
joint displacements only. However there is a significant body of
evidence for the opposing view that some motor representations represent
outcomes to which purposive actions are directed, such as the placing of
a book or the breaking of an egg. These are outcomes which might, on
different occasions, involve very different bodily configurations and
joint displacements (see <span class="citation"
data-cites="rizzolatti_functional_2010">(Rizzolatti and Sinigaglia
2010)</span> for a selective review). The experiments providing such
evidence typically involve a marker—such as a pattern of neuronal
firings, a motor evoked potential or a behavioural performance
profile—which allows sameness or difference of motor representation to
be distinguished. Such markers can be exploited to show that the
sameness and difference of motor representations is linked to the
sameness and difference of outcomes such as the grasping of a particular
object. This supports the view that some motor representations represent
outcomes other than sequences of bodily configurations and joint
displacements. <a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p>
<p>If some motor representations do indeed represent such outcomes, why
consider them to be motoric at all? Part of the answer concerns their
role in preparing and performing actions. <a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>
Motor representations can trigger processes which are like planning in
some respects. These processes are planning-like in that they involve
starting with representations of relatively distal outcomes and
gradually filling in details, resulting in motor representations whose
contents can be hierarchically arranged by the means–end relation <span
class="citation" data-cites="grafton:2007_evidence">(Grafton and
Hamilton 2007)</span>. Some processes triggered by motor representations
are also planning-like in that they involve meeting constraints on the
selection of means by which to bring about one outcome that arise from
the need to select means by which, later, to bring about another outcome
<span class="citation" data-cites="rosenbaum:2012_cognition">(Rosenbaum
et al. 2012)</span>. So motor processes are planning-like both in that
they involve computation of means–ends relations and in that they
involve satisfying relational constraints on the selection of means.</p>
<p>Motor representations can be distinguished from intentions.
Future-directed intentions set problems for practical reasoning and are
subject to norms such as agglomeration. (In short, the norm of
agglomeration says it is a mistake to knowingly have several intentions
if it would be a mistake to knowingly have one large intention
agglomerating the several intentions; see <span class="citation"
data-cites="Bratman:1987xw">(Bratman 1987)</span>). While there may be
kinds of intention which are unlike future-directed intentions,
intentions of any kind are inferentially and normatively integrated with
future-directed intentions (compare <span class="citation"
data-cites="Bratman:1984jr">(Bratman 1984, 379)</span>; <span
class="citation" data-cites="pacherie:2000_content">(Pacherie 2000,
403)</span>). By contrast, motor representations are inferentially and
normatively isolated from future-directed intentions. To illustrate,
consider again the cook who is reaching for an egg to grasp and
transport it. Her actions are subject to two kinds of constraint. One
kind is associated with motor processes and representations, and is
manifest in things such as the end-state comfort effect (which concerns
avoiding extreme joint angles; <span class="citation"
data-cites="rosenbaum:2012_cognition">(Rosenbaum et al. 2012,
926)</span>) and Fitt’s law (which links speed and accuracy). Another
kind of constraint arises from her intentions and beliefs, which in this
case mean she needs to break the egg into the sauce and not the
similar-sized, conveniently positioned fruit bowl. If motor
representations and intentions were inferentially integrated, we would
expect a single process of practical reasoning to enable agents to meet
both kinds of constraint. But in fact practical reasoning rarely if ever
enables agents to meet constraints associated with motor processes and
representations <span class="citation"
data-cites="Searle:1983tx">(compare Searle 1983, 151)</span>. This
suggests that motor representations are interestingly distinct from
intentions, at least as intentions are standardly conceived. <a
href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p>
<p>These reflections indicate that actions are sometimes directed to an
outcome in virtue of motor representations. For we have just seen that,
when you break an egg (for example), there may be a motor representation
in you of this outcome, the breaking of the egg, and that this motor
representation can trigger planning-like processes which coordinate your
actions and do so in such a way that, normally, such coordination would
facilitate the occurrence of the outcome represented. This ensures that
your actions are directed to the breaking of the egg. Motor
representations and processes are therefore sufficient for actions to be
directed to outcomes. <a href="#fn8" class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a></p>
<p>To summarise, motor representations characteristically play a role in
the coordination of very small scale actions. Some represent outcomes
such as the placing of a book or the breaking of an egg. They trigger
planning-like processes which ensure that sequences of very small scale
actions are coordinated around the outcomes represented motorically. And
despite resembling intentions in some ways, motor representations and
the processes in which they feature are distinct from intentions and
practical reasoning. All of this indicates that in some cases where
someone acts alone with a purpose, it is motor representations that link
her actions to outcomes. In what follows we aim to generalise this claim
to acting together with a purpose.</p>
<h1 id="sec:collective_goals_are_represented">Motor Representation in
Acting Together with a Purpose</h1>
<p>The first step is to examine the possibility that when people act
together with a purpose, outcomes to which their actions are
collectively directed are sometimes represented motorically. A variety
of findings jointly indicate that this is indeed the case.</p>
<p>Using simultaneous EEG measurements from a pair of interacting agents
performing complementary actions, <span class="citation"
data-cites="Menoret:2013fk">Ménoret et al. (2014)</span> provided
evidence that motor representations in one agent may be affected by
facts about another’s actions or the outcomes to which they are
directed, even when these have no significant effect on the kinematics
of the agent’s own actions. While this doesn’t quite show that an
outcome to which both agents’ actions are directed is represented
motorically (as <span class="citation"
data-cites="Menoret:2013fk">Ménoret et al. (2014)</span> themselves note
on p. 95), the finding does indicate that some or other aspects of
another’s actions can be represented motorically when interacting with
them.</p>
<p>To take a step further, consider pianists who produce a chord in
playing a duet. There is evidence that, sometimes, in a pianist playing
a duet, monitoring and control of action involves representations not
only of the pianist’s and her partner’s individual contributions but
also of the chord that she and her partner are supposed to produce
together <span class="citation"
data-cites="loehr:2013_monitoring">(Janeen D. Loehr et al. 2013)</span>.
This indicates that, in some cases, where some agents’ actions are
collectively directed to an outcome, this outcome is represented
motorically.</p>
<p>Further evidence for this view comes from a study exploiting the fact
that imitation facilitates motor responses <span class="citation"
data-cites="tsai:2011_groop_effect">(Tsai, Sebanz, and Knoblich
2011)</span>. Subjects were required to imitate single key-presses
performed by a counterpart. Each subject sat next to a confederate who
also had a counterpart and who, on critical trials, either imitated her
counterpart or, in another condition, performed an action complementary
to her counterpart’s. The experimenters asked whether subjects
represented motorically only the outcomes to which their own actions
were individually directed, or whether they also represented motorically
outcomes to which their actions and those of the confederate were, or
could have been, collectively directed. Where the former occurs, facts
about the confederate’s task should not directly affect the subjects’
actions: imitation should facilitate performance in every case. By
contrast, where the latter occurs, subjects will only be imitating in
conditions in which the confederate’s task is to do what her counterpart
does. So performance should vary systematically depending on which
outcomes the subject’s and confederate’s actions could be collectively
directed to. And this is what the findings revealed <span
class="citation" data-cites="ramenzoni:2014_scaling">(related evidence
is provided by Ramenzoni, Sebanz, and Knoblich 2014)</span>.</p>
<p>While any of these studies can be interpreted in various ways, taken
together they provide at least enough evidence to justify treating as a
working hypothesis the view that there are motor representations of
outcomes to which the actions people perform in acting together with a
purpose could be collectively directed. <a href="#fn9"
class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> But
taking this hypothesis seriously invites a question. What are those
motor representations doing there?</p>
<h1 id="sec:coordination">Coordination in Acting Together: A
Conjecture</h1>
<p>We conjecture that motor representations of outcomes to which actions
are collectively directed can enable interpersonal coordination. More
specifically, we conjecture that there are certain interagential
structures (specified below) which include these motor representations
and that, where some actions are collectively directed to these
outcomes, the structures can facilitate interpersonal coordination of
the actions around the outcomes. <a href="#fn10" class="footnote-ref"
id="fnref10" role="doc-noteref"><sup>10</sup></a> The next step in our
overall argument is to explain how this conjecture could be true.</p>
<p>Consider what is involved when, in acting alone, you move a mug from
one place to another, passing it between your hands half-way. In this
action there is a need to coordinate the exchange between your two
hands. If your action is fluid, you may proactively prepare to release
the mug from your left hand moments in advance of the mug’s being
secured by your right hand <span class="citation"
data-cites="diedrichsen:2003_anticipatory">(compare Diedrichsen et al.
2003)</span>. How is such tight coordination achieved? A full answer
cannot be given by appeal to physiology alone <span class="citation"
data-cites="jackson:2002_functional piedimonte:2015_invisible">(Jackson,
German, and Peacock 2002; Piedimonte et al. 2015)</span>. Instead, part
of the answer involves the fact that there is a motor representation for
the whole action which triggers planning-like motor processes, so that
the motor representations and processes concerning the actions involving
each hand are not entirely independent of each other (compare <span
class="citation" data-cites="kelso:1979_coordination">(Kelso, Southard,
and Goodman 1979)</span> and <span class="citation"
data-cites="rosenbaum:2010_human">(Rosenbaum 2009, 244–48)</span>). As
we have seen (in section <a href="#sec:acting_alone"
data-reference-type="ref" data-reference="sec:acting_alone">2</a>), such
planning-like processes result in motor representations concerning
different parts of the action which can be hierarchically arranged by
the means-ends relation and ensure that relational constraints on
components of the action are satisfied. So when you move a mug from one
place to another, passing it between your hands half-way, and when this
action and its components are represented motorically in a plan-like
hierarchy, it is this plan-like hierarchy which ensures the movements of
one hand constrain and are constrained by the movements of the other
hand.</p>
<p>Compare this individual action with a similar moving of the mug
performed by two agents acting together. One agent takes the mug and
passes it to the other, who then places it. This event is like the
individual action in two respects. There is a similar coordination
problem—the agents’ two hands have to meet; and the outcome to which
their actions are collectively directed is the same, namely to move the
mug from here to there. Our working hypothesis is that, sometimes, when
acting together, this outcome, the movement of the mug from one place to
another, is represented in each agent motorically. Such motor
representations can trigger planning-like processes, so that in each
agent there will be motor representations somewhat like those that would
occur were she performing the whole action alone (compare <span
class="citation"
data-cites="kourtis:2012_predictive kourtis:2014_attention meyer:2011_joint meyer:2013_higher-order">(Kourtis,
Sebanz, and Knoblich 2013; Kourtis et al. 2014; Meyer et al. 2011;
Meyer, Wel, and Hunnius 2013)</span>).</p>
<p>But why should this support, rather than hinder, coordination?
Suppose that the agents’ planning-like motor processes are sufficiently
similar that, in this context at least, they will nonaccidentally
produce matching plan-like hierarchies of motor representations in each
agent. For a plan-like hierarchy in an agent, let the <em>self part</em>
be those motor representations concerning the agent’s own actions and
let the <em>other part</em> be the other motor representations. <a
href="#fn11" class="footnote-ref" id="fnref11"
role="doc-noteref"><sup>11</sup></a> Then, just as in the case where one
agent moves the mug all by herself, the self part of each agent’s
plan-like hierarchy (grasping and giving the mug with the left hand,
say) will be directly constrained by the other part of her plan-like
hierarchy (taking and placing the mug with the right hand, say). But
matching implies that the other part of her plan-like hierarchy matches
the self part of the other’s plan-like hierarchy. This ensures that the
self part of her plan-like hierarchy will be indirectly constrained by
the self part of the other agent’s plan-like hierarchy. Thus, much as
motor representations of outcomes can enable intrapersonal coordination
in acting alone, so also can matching structures of motor
representations enable interpersonal coordination when acting together.
Or so we conjecture.</p>
<p>The case just offered for this conjecture relies on an as yet
unspecified notion of <em>matching</em>. In the simplest case, plan-like
hierarchies of motor representations match if they are identical. But
matching does not require identity. It is sufficient that the
differences between two (or more) plan-like hierarchies of motor
representations don’t matter in the following sense. First consider what
would happen if, for a particular agent, the other part of her plan-like
hierarchy were as nearly identical to the self part (or parts) of the
other’s plan-like hierarchy (or others’ plan-like hierarchies) as
psychologically possible. Would the agent’s self part be different? If
not, let us say that any differences between her plan-like hierarchy and
the other’s (or others’) are <em>not relevant</em> for her. Finally, if
for some agents’ plan-like hierarchies of motor representations the
differences between them are not relevant for any of the agents, then
let us say that the differences <em>don’t matter</em>. Consider the
condition that the differences between plan-like hierarchies of motor
representations in two agents don’t matter. Meeting this condition is
sufficient to support our proposed explanation of how motor
representations could enable interpersonal coordination. So even without
fully specifying how plan-like hierarchies in two (or more) agents must
be related if motor representations are to explain interpersonal
coordination, we can be sure that there are sufficient conditions for
such matching.</p>
<p>We can now describe an interagential structure of motor
representations capable of facilitating interpersonal coordination. This
involves four conditions. First, there must be an outcome to which the
actions are, or could be, collectively directed, and in each agent there
must be a motor representation of this outcome. Second, these motor
representations must trigger planning-like processes which result in
plan-like hierarchies of motor representations in each agent. Third, the
plan-like hierarchy in each agent must involve motor representations
concerning not only actions she will eventually perform but also actions
another will eventually perform. Fourth, the plan-like hierarchies of
motor representations in the agents must non-accidentally match. When
all four conditions are met, the result is an interagential structure of
motor representations.</p>
<p>As we have just seen, instances of this interagential structure could
coordinate actions performed by people acting together with a purpose in
something like the way that ordinary, individual hierarchies of motor
representations can coordinate actions performed by a person acting
alone with a purpose.</p>
<p>It is no part of our view that the need for interpersonal
coordination can always be met by this interagential structure of motor
representations. People acting together with a purpose may successfully
coordinate their actions around outcomes which are not represented
motorically. Suppose that Hannah puts slugs in Sara’s shoes and Lucas
puts worms in her hat, where their actions are collectively directed to
freaking Sara out. (As they each know, Sara is so robust that finding
only slugs or only worms in her clothing would barely perturb her.) Now
let us suppose, for the sake of argument, that freaking Sara out isn’t
an outcome that is represented motorically on this occasion. So Hannah’s
and Lucas’ actions could not be coordinated around this outcome by
virtue of motor representations of it. However, their acting together
may well involve them passing objects between them, reaching in a
coordinated way, and one holding the hat while the other drops worms
into it. Such very small scale actions are the sort most plausibly
coordinated by the interagential structure of motor representations we
have identified.</p>
<p>Is there any empirical motivation for our conjecture that certain
interagential structures of motor representations can enable
interpersonal coordination? Contrast acting together with a purpose and
acting in parallel but merely alone. Even where these two require the
same joint displacements and bodily configurations, the conjecture we
have just introduced implies that they can differ motorically: acting
together with a purpose, unlike acting in parallel, provides reason to
expect that there will be motor representations concerning another’s
action in each agent. <span class="citation"
data-cites="dellagatta:2017_drawn">della Gatta et al. (2017)</span> set
out to test just this prediction and found some evidence for it (as we
discuss in <span class="citation"
data-cites="sinigaglia:2020_motor_joint_experience">(Sinigaglia and
Butterfill 2020, 189)</span>). A further test of the prediction is
provided by <span class="citation" data-cites="clarke:2019_joint">Clarke
et al. (2019)</span>, who use an entirely different paradigm. And
although they do not frame it in our terms, the results of <span
class="citation" data-cites="sacheli:2018_evidence">Sacheli, Arcangeli,
and Paulesu (2018)</span> can also be interpreted as supporting the
conjecture. Further, less direct evidence for the conjecture is provided
by some earlier studies including <span class="citation"
data-cites="kourtis:2012_predictive kourtis:2014_attention meyer:2011_joint">Kourtis,
Sebanz, and Knoblich (2013; Kourtis et al. 2014; Meyer et al.
2011)</span>.</p>
<p>While more evidence would be needed for us to know that the
conjecture is true, it is clearly precise enough to generate readily
testable (and actually tested) predictions and there is already enough
evidence to motivate considering it as a candidate for truth. But there
are also theoretical objections to the conjecture.</p>
<h1 id="sec:two_objections">Two Objections</h1>
<p>The conjecture we have just provided evidence for is that motor
representations can enable interpersonal coordination. Or, more
accurately: motor representations of outcomes can be components of
certain interagential structures (specified in section <a
href="#sec:coordination" data-reference-type="ref"
data-reference="sec:coordination">4</a>), and, where some actions are
collectively directed to these outcomes, the structures can facilitate
interpersonal coordination of the actions around the outcomes.</p>
<p>In this section we reply to two objections to our conjecture’s
theoretical coherence. The first objection concerns what is represented
motorically, whereas the second hinges on considerations about the
direction of fit of motor representation.</p>
<p>There are limits on which outcomes can be represented motorically.
Some such limits are linked to peculiarities of the agent in which the
motor representation occurs, and, in particular, to the range of actions
she can perform. For example, whether the grasping of a particular
object can be represented motorically may depend in part on whether the
agent can reach it <span class="citation"
data-cites="costantini:2010_where costantini:2011_tool">(Costantini et
al. 2010, 2011)</span>. Doesn’t this make it incoherent for us to
conjecture that, without any relevant ignorance or irrationality, there
are motor representations concerning actions another will perform? After
all, no agent can perform another’s actions—at least not in the cases we
are primarily concerned with. <a href="#fn12" class="footnote-ref"
id="fnref12" role="doc-noteref"><sup>12</sup></a></p>
<p>In replying to this first objection it is helpful to invoke the
notion of agent-neutrality. By saying that a representation is
<em>agent-neutral</em>, we mean that its content does not specify any
particular agent or agents. It is plausible that some motor processes
involve agent-neutral representations of outcomes <span class="citation"
data-cites="ramsey:2010_understanding">(Ramsey and Hamilton
2010)</span>. Indeed, that some motor representations are agent-neutral
is implied by Jeannerod’s argument for the view that motor
representations concerning your own actions are ‘entangled’ with motor
representations concerning others’ actions in such a way that knowing
which actions are yours requires the two to be disentangled. <a
href="#fn13" class="footnote-ref" id="fnref13"
role="doc-noteref"><sup>13</sup></a></p>
<p>The agent-neutrality of some motor representations allows us to
clarify what is involved in one agent having motor representations
concerning another’s actions. The first agent does represent outcomes to
which the other’s actions are, or will be, directed; and, normally,
these representations occur in part because the other’s actions are, or
will be, directed to these outcomes. But the contents of these
representations, which are agent-neutral, do not specify the other (or
the self) as the agent. It follows that an action’s having someone other
than you as its agent is not necessarily a barrier to the occurrence in
you of motor representations concerning that action.</p>
<p>The first objection concerned content. A second objection concerns
direction of fit. It may seem that our conjecture entails that there is
a single kind of representation, motor representation, different
instances of which have different directions of fit. Apparently, some
are world-to-mind insofar as they are supposed to lead to performing
actions, while others are mind-to-world insofar as they are supposed to
enable predictions of others’ actions.</p>
<p>This objection arises because of a point of contrast between
intention and motor representation. On some accounts (<span
class="citation" data-cites="bratman:2014_book">(Bratman 2014)</span>’s,
for instance), two agents’ having a shared intention involves each of
them having knowledge of the other’s intentions. They do not, of course,
intend actions the other will perform (at least not on many accounts;
but see <span class="citation" data-cites="Roth:2004ki">(Roth
2004)</span>). By contrast, where motor representations are involved in
enabling interpersonal coordination, the conjecture under consideration
is that in each agent there are motor representations concerning actions
that she will eventually perform and also motor representations—not
knowledge of motor representations but actual motor
representations—concerning actions that another will eventually perform.
So because our conjecture involves saying that there is just one kind of
representation here, it appears to entail that different instances of a
single attitude can have different directions of fit: some are
world-to-mind, others are mind-to-world. But this is arguably
incoherent. <a href="#fn14" class="footnote-ref" id="fnref14"
role="doc-noteref"><sup>14</sup></a> So the second objection. <a
href="#fn15" class="footnote-ref" id="fnref15"
role="doc-noteref"><sup>15</sup></a></p>
<p>As a preliminary to replying to the second objection, consider an
analogy. There is a rotary dial on your oven which enables you to
initiate and control the oven’s activity. We might think of the dial as
having an oven-to-instrument direction of fit: the oven temperature is
supposed to adjust to the setting on the dial. But now suppose, further,
that there is an indicator light on your oven which is illuminated
unless the oven has reached the temperature specified by the dial. This
enables you to use the dial to discover the temperature of the oven: if
the light is on, you turn the dial down until just the point where the
light goes off. Now the setting on the dial tells you the temperature of
the oven. So we might think of the dial as having an instrument-to-oven
direction of fit.</p>
<p>This analogy will guide our response to the second objection. The key
point can be put like this. There is a core system featuring the dial,
thermostat, heating element and oven. Relative to this core system, the
dial always has an oven-to-instrument direction of fit. However, there
is a larger system which embeds the core system and exploits it for
novel ends. This larger system includes you and your capacity to
temporarily prevent significant changes in the temperature of the oven
(perhaps by moving the dial between settings too quickly for the heating
element to respond). Relative to this larger system the dial has an
instrument-to-oven direction of fit. So to understand the dial’s
functions, we do need two directions of fit, oven-to-instrument and
instrument-to-oven. But this is not quite to say that the dial has both
directions of fit. For something has a direction of fit only relative to
a particular system. Which direction of fit we see depends on which
system we are considering. Understanding the dial does not require
supposing that anything has two directions of fit relative to a single
system.</p>
<p>Our response to the second objection is similar. If we consider
planning-like motor processes only (the core system), then each motor
representation’s function is linked to initiating and controlling
action. From this perspective, only a world-to-mind direction of fit is
in view. But these planning-like motor processes can occur in the
context of a larger system, one which involves something that somehow
prevents performance of action. The functions of this larger system
concern predicting which outcomes actions will be directed to. If we
consider this larger system, it is natural to describe the motor
representations as having a mind-to-world direction of fit. So, as in
our analogy, which direction of fit we see depends on which system we
are considering. Our reply to the second objection, then, is that our
conjecture involves no incoherence when properly understood.</p>
<h1 id="sec:collective_goals_motor_representations">How Are Actions
Linked to Outcomes when Acting Together?</h1>
<p>Our discussion so far has concerned the coordination of actions
people perform when acting together with a purpose. How is this relevant
to our opening question, which is about understanding in virtue of what
actions performed in acting together with a purpose can be collectively
directed to outcomes?</p>
<p>The interagential structure of motor representations we identified
can be used in linking actions to outcomes. For some (but not all) cases
in which people act together with a purpose, we can explain in virtue of
what their actions are collectively directed to an outcome by invoking
this interagential structure of motor representations. To see how this
works, consider first how accounts of shared intention suggest a way of
linking actions to outcomes. On at least some accounts of shared
intention, <a href="#fn16" class="footnote-ref" id="fnref16"
role="doc-noteref"><sup>16</sup></a> shared intentions relate things we
do together to actual or possible outcomes. Suppose we have a shared
intention that we move the piano. Then, on these accounts, our having a
shared intention consists in part in each of us intending that we, you
and I, move the piano, or in each of us being in some other state which
specifies this outcome. The shared intention also provides for the
coordination of our actions (so that, for example, you don’t attempt to
take one route while I pursue another). And coordination of this type
would normally facilitate occurrences of the type of outcome intended.
When people act together with a purpose, this is one way of explicating
what it is for their actions to be collectively directed to an outcome.
But the interagential structure of motor representations we identified
can be used in giving an alternative, structurally parallel explication.
For, as we specified in section <a href="#sec:coordination"
data-reference-type="ref" data-reference="sec:coordination">4</a>, this
interagential structure involves there being a single outcome such that
there is a representation in each agent of this outcome, and these
representations provide for coordination of the agents’ actions where
coordination of this type would normally facilitate occurrences of
outcomes of this type. It is therefore possible to link actions to
outcomes by appeal to this interagential structure of motor
representations.</p>
<p>The result of our investigation implies that this is not merely
possible: sometimes it is actually in virtue of a certain interagential
structure of motor representation that two or more agents’ actions are
collectively directed to an outcome.</p>
<p>Some may attempt to resist this conclusion on the grounds that the
interagential structure of motor representations identified in section
<a href="#sec:coordination" data-reference-type="ref"
data-reference="sec:coordination">4</a> is not something other than
shared intention, but simply one kind of shared intention. To see that
this is false, consider that shared intentions, whatever exactly they
turn out to be, are inferentially and normatively integrated with
ordinary, individual intentions. To illustrate, tonight there is a party
and a ceremony. It is impossible for anyone to attend both, and this is
common knowledge among Lily and Isabel. They have a shared intention
that they attend the ceremony together. But while having this shared
intention, Isabel also intends to go to the party. Given their common
knowledge, this combination of shared and individual intentions is
irrational. Its irrationality is related to that which might be involved
in Isabel individually intending to attend the ceremony while also
individually intending to go to the party. By contrast, as already
mentioned (see section <a href="#sec:acting_alone"
data-reference-type="ref" data-reference="sec:acting_alone">2</a>),
motor representations are not inferentially or normatively integrated
with intentions: they do not feature in practical reasoning, nor in any
inferences in which intentions also feature; and if there are any
normative requirements linking the contents of intentions with the
contents of motor representations at all, these are distinct from those
governing intentions. So even where the actions of agents who are acting
together are collectively directed to outcomes in virtue of an
interagential structure of motor representations, the occurrence of this
structure in the agents does not amount to their having a shared
intention.</p>
<p>A basic requirement on any account of acting together with a purpose
is that it explain in virtue of what actions performed in acting
together are collectively directed to outcomes. The interagential
structure of motor representation we have identified is needed to
explain this. Motor representation must therefore feature in any
adequate account of acting together with a purpose. <a href="#fn17"
class="footnote-ref" id="fnref17"
role="doc-noteref"><sup>17</sup></a></p>
<h1 id="conclusion">Conclusion</h1>
<p>We started by asking, When people act together with a purpose, in
virtue of what are their actions collectively directed to an outcome?
Our answer is that this is sometimes a matter of a certain interagential
structure of motor representations being realised and playing a role in
coordinating the actions (see section <a
href="#sec:collective_goals_motor_representations"
data-reference-type="ref"
data-reference="sec:collective_goals_motor_representations">6</a> for
the conjecture; the interagential structure is specified in section <a
href="#sec:coordination" data-reference-type="ref"
data-reference="sec:coordination">4</a>). How did we arrive at this
answer? We first identified evidence supporting the hypothesis that when
people act together with a purpose, outcomes to which their actions are
collectively directed are sometimes represented motorically (see section
<a href="#sec:collective_goals_are_represented"
data-reference-type="ref"
data-reference="sec:collective_goals_are_represented">3</a>). This
allowed us to make a conjecture about how motor representations of such
outcomes facilitate interpersonal coordination (see section <a
href="#sec:coordination" data-reference-type="ref"
data-reference="sec:coordination">4</a>). Sometimes these motor
representations trigger processes in each agent which result in matching
plan-like hierarchies concerning not only actions to be performed by the
agent herself but also actions that another will eventually perform.
These matching hierarchies realise an interagential structure that could
facilitate coordination of the actions performed by people acting
together with a purpose. This conjecture is theoretically coherent and
empirically motivated (see section <a href="#sec:two_objections"
data-reference-type="ref" data-reference="sec:two_objections">5</a>). It
suggests a way of generalising a view about acting alone with a purpose
to cases of acting together with a purpose. When an agent acts alone
with a purpose, sometimes it is motor representations that ground the
directedness of her actions to an outcome. Similarly, we argued (in
section <a href="#sec:collective_goals_motor_representations"
data-reference-type="ref"
data-reference="sec:collective_goals_motor_representations">6</a>), when
agents act together with a purpose, their actions are sometimes
collectively directed to an outcome in virtue of an interagential
structure of motor representations.</p>
<div id="refs" class="references csl-bib-body hanging-indent"
data-entry-spacing="0" role="list">
<div id="ref-alonso_shared_2009" class="csl-entry" role="listitem">
Alonso, Facundo M. 2009. <span>“Shared Intention, Reliance, and
Interpersonal Obligations.”</span> <em>Ethics</em> 119 (3): 444–75. <a
href="https://doi.org/10.1086/599984">https://doi.org/10.1086/599984</a>.
</div>
<div id="ref-bach:1978_representational" class="csl-entry"
role="listitem">
Bach, Kent. 1978. <span>“A Representational Theory of Action.”</span>
<em>Philosophical Studies</em> 34 (4): 361–79. <a
href="https://doi.org/10.1007/BF00364703">https://doi.org/10.1007/BF00364703</a>.
</div>
<div id="ref-bicchieri:2016_norms" class="csl-entry" role="listitem">
Bicchieri, Cristina. 2016. <em>Norms in the Wild: How to Diagnose,
Measure, and Change Social Norms</em>. Oxford: Oxford University Press.
</div>
<div id="ref-blomberg:2015_common" class="csl-entry" role="listitem">
Blomberg, Olle. 2016. <span>“Common <span>Knowledge</span> and
<span>Reductionism</span> about <span>Shared Agency</span>.”</span>
<em>Australasian Journal of Philosophy</em> 94 (2): 315–26. <a
href="https://doi.org/10.1080/00048402.2015.1055581">https://doi.org/10.1080/00048402.2015.1055581</a>.
</div>
<div id="ref-Bratman:1984jr" class="csl-entry" role="listitem">
Bratman, Michael E. 1984. <span>“Two Faces of Intention.”</span> <em>The
Philosophical Review</em> 93 (3): 375–405.
</div>
<div id="ref-Bratman:1987xw" class="csl-entry" role="listitem">
———. 1987. <em>Intentions, Plans, and Practical Reasoning</em>.
Cambridge, MA: Harvard University Press.
</div>
<div id="ref-Bratman:1992mi" class="csl-entry" role="listitem">
———. 1992. <span>“Shared Cooperative Activity.”</span> <em>The
Philosophical Review</em> 101 (2): 327–41.
</div>
<div id="ref-Bratman:1993je" class="csl-entry" role="listitem">
———. 1993. <span>“Shared Intention.”</span> <em>Ethics</em> 104: 97–113.
</div>
<div id="ref-bratman:2014_book" class="csl-entry" role="listitem">
———. 2014. <em>Shared Agency: A Planning Theory of Acting Together</em>.
Oxford: Oxford University Press. <a
href="http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199897933.001.0001">http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199897933.001.0001</a>.
</div>
<div id="ref-butterfill:2012_intention" class="csl-entry"
role="listitem">
Butterfill, Stephen A., and Corrado Sinigaglia. 2014. <span>“Intention
and Motor Representation in Purposive Action.”</span> <em>Philosophy and
Phenomenological Research</em> 88 (1): 119–45. <a
href="https://doi.org/10.1111/j.1933-1592.2012.00604.x">https://doi.org/10.1111/j.1933-1592.2012.00604.x</a>.
</div>
<div id="ref-clarke:2019_joint" class="csl-entry" role="listitem">
Clarke, Sam, Luke McEllin, Anna Francová, Marcell Székely, Stephen A.
Butterfill, and John Michael. 2019. <span>“Joint Action Goals Reduce
Visuomotor Interference Effects from a Partner’s Incongruent
Actions.”</span> <em>Scientific Reports</em> 9 (1): 1–9. <a
href="https://doi.org/10.1038/s41598-019-52124-6">https://doi.org/10.1038/s41598-019-52124-6</a>.
</div>
<div id="ref-cohen:2004_wherea" class="csl-entry" role="listitem">
Cohen, Rajal G., and David A. Rosenbaum. 2004. <span>“Where Grasps Are
Made Reveals How Grasps Are Planned: Generation and Recall of Motor
Plans.”</span> <em>Experimental Brain Research</em> 157 (4): 486–95. <a
href="https://doi.org/10.1007/s00221-004-1862-9">https://doi.org/10.1007/s00221-004-1862-9</a>.
</div>
<div id="ref-costantini:2011_tool" class="csl-entry" role="listitem">
Costantini, Marcello, Ettore Ambrosini, Corrado Sinigaglia, and Vittorio
Gallese. 2011. <span>“Tool-Use Observation Makes Far Objects
Ready-to-Hand.”</span> <em>Neuropsychologia</em> 49 (9): 2658–63. <a
href="https://doi.org/10.1016/j.neuropsychologia.2011.05.013">https://doi.org/10.1016/j.neuropsychologia.2011.05.013</a>.
</div>
<div id="ref-costantini:2010_where" class="csl-entry" role="listitem">
Costantini, Marcello, Ettore Ambrosini, Gaetano Tieri, Corrado
Sinigaglia, and Giorgia Committeri. 2010. <span>“Where Does an Object
Trigger an Action? An Investigation about Affordances in Space.”</span>
<em>Experimental Brain Research</em> 207 (1-2): 95–103. <a
href="https://doi.org/10.1007/s00221-010-2435-8">https://doi.org/10.1007/s00221-010-2435-8</a>.
</div>
<div id="ref-dellagatta:2017_drawn" class="csl-entry" role="listitem">
della Gatta, Francesco, Francesca Garbarini, Marco Rabuffetti, Luca
Viganò, Stephen A. Butterfill, and Corrado Sinigaglia. 2017.
<span>“Drawn Together: <span>When</span> Motor Representations Ground
Joint Actions.”</span> <em>Cognition</em> 165: 53–60. <a
href="https://doi.org/10.1016/j.cognition.2017.04.008">https://doi.org/10.1016/j.cognition.2017.04.008</a>.
</div>
<div id="ref-diedrichsen:2003_anticipatory" class="csl-entry"
role="listitem">
Diedrichsen, Jörn, Timothy Verstynen, Andrew Hon, Steven L. Lehman, and
Richard B. Ivry. 2003. <span>“Anticipatory Adjustments in the Unloading
Task: Is an Efference Copy Necessary for Learning?”</span>
<em>Experimental Brain Research</em> 148 (2): 272–76. <a
href="https://doi.org/10.1007/s00221-002-1318-z">https://doi.org/10.1007/s00221-002-1318-z</a>.
</div>
<div id="ref-gallese:2001_shared" class="csl-entry" role="listitem">
Gallese, V. 2001. <span>“The ’Shared Manifold’ Hypothesis. From Mirror
Neurons to Empathy.”</span> <em>Journal of Consciousness Studies</em> 8
(5-6): 33–50.
</div>
<div id="ref-gilbert_walking_1990" class="csl-entry" role="listitem">
Gilbert, Margaret P. 1990. <span>“Walking Together: A Paradigmatic
Social Phenomenon.”</span> <em>Midwest Studies in Philosophy</em> 15:
1–14.
</div>
<div id="ref-gilbert:2014_book" class="csl-entry" role="listitem">
———. 2013. <em>Joint Commitment: How We Make the Social World</em>.
Oxford: Oxford University Press. <a
href="http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199970148.001.0001">http://0-dx.doi.org.pugwash.lib.warwick.ac.uk/10.1093/acprof:oso/9780199970148.001.0001</a>.
</div>
<div id="ref-Gold:2007zd" class="csl-entry" role="listitem">
Gold, Natalie, and Robert Sugden. 2007. <span>“Collective Intentions and
Team Agency.”</span> <em>Journal of Philosophy</em> 104 (3): 109–37.
</div>
<div id="ref-grafton:2007_evidence" class="csl-entry" role="listitem">
Grafton, Scott T., and Antonia F. de C. Hamilton. 2007. <span>“Evidence
for a Distributed Hierarchy of Action Representation in the
Brain.”</span> <em>Human Movement Science</em> 26 (4): 590–616. <a
href="https://doi.org/10.1016/j.humov.2007.05.009">https://doi.org/10.1016/j.humov.2007.05.009</a>.
</div>
<div id="ref-helm_plural_2008" class="csl-entry" role="listitem">
Helm, Bennett W. 2008. <span>“Plural Agents.”</span> <em>Nous</em> 42
(1): 17–49. <a
href="https://doi.org/10.1111/j.1468-0068.2007.00672.x">https://doi.org/10.1111/j.1468-0068.2007.00672.x</a>.
</div>
<div id="ref-issartel:2007_unintended" class="csl-entry"
role="listitem">
Issartel, Johann, Ludovic Marin, and Marielle Cadopi. 2007.
<span>“Unintended Interpersonal Co-Ordination: <span>‘Can We March to
the Beat of Our Own Drum?’</span>”</span> <em>Neuroscience Letters</em>
411 (3): 174–79. <a
href="https://doi.org/10.1016/j.neulet.2006.09.086">https://doi.org/10.1016/j.neulet.2006.09.086</a>.
</div>
<div id="ref-jackson:2002_functional" class="csl-entry" role="listitem">
Jackson, G. M, K German, and K Peacock. 2002. <span>“Functional Coupling
Between the Limbs During Bimanual Reach-to-Grasp Movements.”</span>
<em>Human Movement Science</em> 21 (3): 5–21. <a
href="https://doi.org/10.1016/S0167-9457(02)00118-5">https://doi.org/10.1016/S0167-9457(02)00118-5</a>.
</div>
<div id="ref-jeannerod:1988_neural" class="csl-entry" role="listitem">
Jeannerod, Marc. 1988. <em>The Neural and Behavioural Organization of
Goal-Directed Movements</em>. <span>New York</span>: <span>Oxford
University Press</span>.
</div>
<div id="ref-jeannerod:2003_mechanism" class="csl-entry"
role="listitem">
———. 2003. <span>“The Mechanism of Self-Recognition in Humans.”</span>
<em>Behavioural Brain Research</em> 142 (1-2): 1–15. <a
href="https://doi.org/10.1016/S0166-4328(02)00384-4">https://doi.org/10.1016/S0166-4328(02)00384-4</a>.
</div>
<div id="ref-kawato:1999_internal" class="csl-entry" role="listitem">
Kawato, Mitsuo. 1999. <span>“Internal Models for Motor Control and
Trajectory Planning.”</span> <em>Current Opinion in Neurobiology</em> 9
(6): 718–27. <a
href="https://doi.org/10.1016/S0959-4388(99)00028-8">https://doi.org/10.1016/S0959-4388(99)00028-8</a>.
</div>
<div id="ref-kelso:1979_coordination" class="csl-entry" role="listitem">
Kelso, J., Dan Southard, and David Goodman. 1979. <span>“<a
href="https://www.ncbi.nlm.nih.gov/pubmed/528935">On the Coordination of
Two-Handed Movements</a>.”</span> <em>Journal of Experimental
Psychology: Human Perception and Performance</em> 5 (2): 229–38.
</div>
<div id="ref-kourtis:2014_attention" class="csl-entry" role="listitem">
Kourtis, Dimitrios, Günther Knoblich, Mateusz Woźniak, and Natalie
Sebanz. 2014. <span>“<span class="nocase">Attention Allocation and Task
Representation during Joint Action Planning</span>.”</span>
<em><span>Journal of Cognitive Neuroscience</span></em> 26 (10):
2275–86. <a
href="https://doi.org/10.1162/jocn_a_00634">https://doi.org/10.1162/jocn_a_00634</a>.
</div>
<div id="ref-kourtis:2012_predictive" class="csl-entry" role="listitem">
Kourtis, Dimitrios, Natalie Sebanz, and Günther Knoblich. 2013.
<span>“Predictive Representation of Other People’s Actions in Joint
Action Planning: An <span>EEG</span> Study.”</span> <em>Social
Neuroscience</em> 8 (1): 31–42. <a
href="https://doi.org/10.1080/17470919.2012.694823">https://doi.org/10.1080/17470919.2012.694823</a>.
</div>
<div id="ref-Kutz:2000si" class="csl-entry" role="listitem">
Kutz, Christopher. 2000. <span>“Acting Together.”</span> <em>Philosophy
and Phenomenological Research</em> 61 (1): 1–31.
</div>
<div id="ref-loehr:2013_monitoring" class="csl-entry" role="listitem">
Loehr, Janeen D, Dimitrios Kourtis, Cordula Vesper, Natalie Sebanz, and
Günther Knoblich. 2013. <span>“Monitoring Individual and Joint Action
Outcomes in Duet Music Performance.”</span> <em>Journal of Cognitive
Neuroscience</em> 25 (7): 1049–61.
</div>
<div id="ref-loehr:2015_sound" class="csl-entry" role="listitem">
Loehr, Janeen D., and Cordula Vesper. 2015. <span>“The Sound of You and
Me: Novices Represent Shared Goals in Joint Action.”</span> <em>The
Quarterly Journal of Experimental Psychology</em> 0 (ja): 1–30. <a
href="https://doi.org/10.1080/17470218.2015.1061029">https://doi.org/10.1080/17470218.2015.1061029</a>.
</div>
<div id="ref-ludwig:2016_individual" class="csl-entry" role="listitem">
Ludwig, Kirk. 2016. <em>From <span>Individual</span> to <span>Plural
Agency</span>: <span>Collective Action</span></em>. <span>Oxford
University Press</span>.
</div>
<div id="ref-Menoret:2013fk" class="csl-entry" role="listitem">
Ménoret, Mathilde, L. Varnet, R. Fargier, A. Cheylus, A. Curie, V. des
Portes, T. A. Nazir, and Y. Paulignan. 2014. <span>“Neural Correlates of
Non-Verbal Social Interactions: A Dual-EEG Study.”</span>
<em>Neuropsychologia</em> 55: 75–97.
</div>
<div id="ref-meyer:2011_joint" class="csl-entry" role="listitem">
Meyer, Marlene, Sabine Hunnius, Michiel van Elk, Freek van Ede, and
Harold Bekkering. 2011. <span>“Joint Action Modulates Motor System
Involvement During Action Observation in 3-Year-Olds.”</span>
<em>Experimental Brain Research</em> 211 (3-4): 581–92. <a
href="https://doi.org/10.1007/s00221-011-2658-3">https://doi.org/10.1007/s00221-011-2658-3</a>.
</div>
<div id="ref-meyer:2013_higher-order" class="csl-entry" role="listitem">
Meyer, Marlene, Robrecht P. R. D. van der Wel, and Sabine Hunnius. 2013.
<span>“Higher-Order Action Planning for Individual and Joint Object
Manipulations.”</span> <em>Experimental Brain Research</em> 225 (4):
579–88. <a
href="https://doi.org/10.1007/s00221-012-3398-8">https://doi.org/10.1007/s00221-012-3398-8</a>.
</div>
<div id="ref-michael:2022_book" class="csl-entry" role="listitem">
Michael, John. 2022. <em>The Philosophy and Psychology of
Commitment</em>. London: Routledge.
</div>
<div id="ref-millikan:1995_pushmi-pullyu" class="csl-entry"
role="listitem">
Millikan, Ruth Garrett. 1995. <span>“Pushmi-Pullyu
Representations.”</span> <em>Philosophical Perspectives</em> 9: 185–200.
<a
href="https://doi.org/10.2307/2214217">https://doi.org/10.2307/2214217</a>.
</div>
<div id="ref-novembre:2013_motor" class="csl-entry" role="listitem">
Novembre, G., L. F. Ticini, S. Schutz-Bosbach, and P. E. Keller. 2014.
<span>“Motor Simulation and the Coordination of Self and Other in
Real-Time Joint Action.”</span> <em>Social Cognitive and Affective
Neuroscience</em> 9 (8): 1062–68. <a
href="https://doi.org/10.1093/scan/nst086">https://doi.org/10.1093/scan/nst086</a>.
</div>
<div id="ref-oullier:2008_social" class="csl-entry" role="listitem">
Oullier, Olivier, Gonzalo C. de Guzman, Kelly J. Jantzen, Julien
Lagarde, and J. A. Scott Kelso. 2008. <span>“Social Coordination
Dynamics: Measuring Human Bonding.”</span> <em>Social Neuroscience</em>
3 (2): 178. <a
href="https://doi.org/10.1080/17470910701563392">https://doi.org/10.1080/17470910701563392</a>.
</div>
<div id="ref-pacherie:2000_content" class="csl-entry" role="listitem">
Pacherie, Elisabeth. 2000. <span>“The Content of Intentions.”</span>
<em>Mind and Language</em> 15 (4): 400–432. <a
href="https://doi.org/10.1111/1468-0017.00142">https://doi.org/10.1111/1468-0017.00142</a>.
</div>
<div id="ref-pacherie:2008_action" class="csl-entry" role="listitem">
———. 2008. <span>“The Phenomenology of Action: A Conceptual
Framework.”</span> <em>Cognition</em> 107 (1): 179–217. <a
href="https://doi.org/10.1016/j.cognition.2007.09.003">https://doi.org/10.1016/j.cognition.2007.09.003</a>.
</div>
<div id="ref-pacherie:2011_nonconceptual" class="csl-entry"
role="listitem">
———. 2011. <span>“Nonconceptual <span>Representations</span> for
<span>Action</span> and the <span>Limits</span> of <span>Intentional
Control</span>.”</span> <em>Social Psychology</em> 42 (1): 67–73. <a
href="https://doi.org/10.1027/1864-9335/a000044">https://doi.org/10.1027/1864-9335/a000044</a>.
</div>
<div id="ref-pacherie:2013_lite" class="csl-entry" role="listitem">
———. 2013. <span>“Intentional Joint Agency: Shared Intention
Lite.”</span> <em>Synthese</em> 190 (10): 1817–39. <a
href="https://doi.org/10.1007/s11229-013-0263-7">https://doi.org/10.1007/s11229-013-0263-7</a>.
</div>
<div id="ref-Pacherie:2006dl" class="csl-entry" role="listitem">
Pacherie, Elisabeth, and Jérôme Dokic. 2006. <span>“From Mirror Neurons
to Joint Actions.”</span> <em>Cognitive Systems Research</em> 7 (2-3):
101–12.
</div>
<div id="ref-piedimonte:2015_invisible" class="csl-entry"
role="listitem">
Piedimonte, Alessandro, Francesca Garbarini, Marco Rabuffetti, Lorenzo
Pia, Angelo Montesano, Maurizio Ferrarin, and Anna Berti. 2015.
<span>“Invisible <span>Grasps</span>: <span>Grip Interference</span> in
<span>Anosognosia</span> for <span>Hemiplegia</span>.”</span>
<em>Neuropsychology</em> 29 (5): 776–81. <a
href="https://doi.org/10.1037/neu0000182">https://doi.org/10.1037/neu0000182</a>.
</div>
<div id="ref-prinz:1990_cc" class="csl-entry" role="listitem">
Prinz, Wolfgang. 1990. <span>“A Common Coding Approach to Perception and
Action.”</span> In <em>Relationships Between Perception and Action</em>,
edited by Odmar Neumann and Wolfgang Prinz, 167–201. Berlin: Springer.
</div>
<div id="ref-prinz:1997_perception" class="csl-entry" role="listitem">
———. 1997. <span>“Perception and Action Planning.”</span> <em>European
Journal of Cognitive Psychology</em> 9 (2): 129–54. <a
href="https://doi.org/10.1080/713752551">https://doi.org/10.1080/713752551</a>.
</div>
<div id="ref-ramenzoni:2014_scaling" class="csl-entry" role="listitem">
Ramenzoni, Verónica C., Natalie Sebanz, and Günther Knoblich. 2014.
<span>“Scaling up Perception<span></span>action Links: Evidence from
Synchronization with Individual and Joint Action.”</span> <em>Journal of
Experimental Psychology: Human Perception and Performance</em> 40 (4):
1551–65. <a
href="https://doi.org/10.1037/a0036925">https://doi.org/10.1037/a0036925</a>.
</div>
<div id="ref-ramsey:2010_understanding" class="csl-entry"
role="listitem">
Ramsey, Richard, and Antonia F. de C. Hamilton. 2010.
<span>“Understanding Actors and Object-Goals in the Human Brain.”</span>
<em>Neuroimage</em> 50 (3): 1142–47.
</div>
<div id="ref-rizzolatti_mirrors_2008" class="csl-entry" role="listitem">
Rizzolatti, Giacomo, and Corrado Sinigaglia. 2008. <em>Mirrors in the
Brain: How Our Minds Share Actions, Emotions</em>. Oxford: Oxford
University Press.
</div>
<div id="ref-rizzolatti_functional_2010" class="csl-entry"
role="listitem">
———. 2010. <span>“The Functional Role of the Parieto-Frontal Mirror
Circuit: Interpretations and Misinterpretations.”</span> <em>Nature
Reviews: Neuroscience</em> 11 (4): 264–74. <a
href="https://doi.org/10.1038/nrn2805">https://doi.org/10.1038/nrn2805</a>.
</div>
<div id="ref-rodl:2018_joint" class="csl-entry" role="listitem">
Rödl, Sebastian. 2018. <span>“Joint <span>Action</span> and <span>Plural
Self</span>-<span>Consciousness</span>.”</span> <em>Journal of Social
Philosophy</em> 49 (1): 124–36. <a
href="https://doi.org/10.1111/josp.12226">https://doi.org/10.1111/josp.12226</a>.
</div>
<div id="ref-roessler:2020_plural" class="csl-entry" role="listitem">
Roessler, Johannes. 2024. <span>“Plural Practical Knowledge.”</span>
<em>Inquiry</em> 67 (4): 1–20. <a
href="https://doi.org/10.1080/0020174X.2020.1787221">https://doi.org/10.1080/0020174X.2020.1787221</a>.
</div>
<div id="ref-rosenbaum:2010_human" class="csl-entry" role="listitem">
Rosenbaum, David A. 2009. <em>Human Motor Control</em>. 2nd ed. San
Diego, <span>CA</span>, <span>US</span>: Academic Press.
</div>
<div id="ref-rosenbaum:2012_cognition" class="csl-entry"
role="listitem">
Rosenbaum, David A., Kate M. Chapman, Matthias Weigelt, Daniel J. Weiss,
and Robrecht P. R. D. van der Wel. 2012. <span>“Cognition, Action, and
Object Manipulation.”</span> <em>Psychological Bulletin</em> 138 (5):
924–46. <a
href="https://doi.org/10.1037/a0027839">https://doi.org/10.1037/a0027839</a>.
</div>
<div id="ref-Roth:2004ki" class="csl-entry" role="listitem">
Roth, Abraham Sesshu. 2004. <span>“Shared Agency and Contralateral
Commitments.”</span> <em>The Philosophical Review</em> 113 (3): 359–410.
</div>
<div id="ref-sacheli:2018_evidence" class="csl-entry" role="listitem">
Sacheli, Lucia Maria, Elisa Arcangeli, and Eraldo Paulesu. 2018.
<span>“Evidence for a Dyadic Motor Plan in Joint Action.”</span>
<em>Scientific Reports</em> 8 (1): 5027. <a
href="https://doi.org/10.1038/s41598-018-23275-9">https://doi.org/10.1038/s41598-018-23275-9</a>.
</div>
<div id="ref-santello:2002_patterns" class="csl-entry" role="listitem">
Santello, Marco, Martha Flanders, and John F. Soechting. 2002.
<span>“Patterns of Hand Motion During Grasping and the Influence of
Sensory Guidance.”</span> <em>The Journal of Neuroscience</em> 22 (4):
1426–35. <a
href="http://www.jneurosci.org/content/22/4/1426.abstract">http://www.jneurosci.org/content/22/4/1426.abstract</a>.
</div>
<div id="ref-satne:2020_practical" class="csl-entry" role="listitem">
Satne, Glenda Lucila. 2020. <span>“Practical Knowledge and Shared
Agency: Pluralizing the <span>Anscombean</span> View.”</span>
<em>Inquiry</em> forthcoming: 1–28. <a
href="https://doi.org/10.1080/0020174X.2020.1837236">https://doi.org/10.1080/0020174X.2020.1837236</a>.
</div>
<div id="ref-Schmid:2013_self" class="csl-entry" role="listitem">
Schmid, Hans Bernhard. 2013. <span>“Plural Self-Awareness.”</span>
<em><span>Phenomenology and the Cognitive Sciences</span></em> 13 (1):
1–18. <a
href="https://doi.org/10.1007/s11097-013-9317-z">https://doi.org/10.1007/s11097-013-9317-z</a>.
</div>
<div id="ref-Searle:1983tx" class="csl-entry" role="listitem">
Searle, John R. 1983. <em>Intentionality: An Essay in the Philosophy of
Mind</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Searle:1990em" class="csl-entry" role="listitem">
———. 1990. <span>“Collective Intentions and Actions.”</span> In
<em>Intentions in Communication</em>, edited by P. Cohen, J. Morgan, and
M. E. Pollack, 90–105. Cambridge: Cambridge University Press.
</div>
<div id="ref-shepherd:2015_conscious" class="csl-entry" role="listitem">
Shepherd, Joshua. 2015. <span>“Conscious <span>Control</span> over
<span>Action</span>.”</span> <em>Mind &amp; Language</em> 30 (3):
320–44. <a
href="https://doi.org/10.1111/mila.12082">https://doi.org/10.1111/mila.12082</a>.
</div>
<div id="ref-sinigaglia:2020_motor_joint_experience" class="csl-entry"
role="listitem">
Sinigaglia, Corrado, and Stephen A. Butterfill. 2020. <span>“Motor
Representation and Action Experience in Joint Action.”</span> In
<em>Minimal Cooperation and Shared Agency</em>, edited by Anika Fiebich,
181–94. Studies in the <span>Philosophy</span> of
<span>Sociality</span>. <span>Springer International Publishing</span>.
<a
href="https://doi.org/10.1007/978-3-030-29783-1">https://doi.org/10.1007/978-3-030-29783-1</a>.
</div>
<div id="ref-Sugden:2000mw" class="csl-entry" role="listitem">
Sugden, Robert. 2000. <span>“Team Preferences.”</span> <em>Economics and
Philosophy</em> 16: 175–204.
</div>
<div id="ref-tessitore:2013_hierarchical" class="csl-entry"
role="listitem">
Tessitore, G., Corrado Sinigaglia, and R. Prevete. 2013.
<span>“Hierarchical and Multiple Hand Action Representation Using
Temporal Postural Synergies.”</span> <em>Experimental Brain
Research</em> 225 (1): 11–36. <a
href="https://doi.org/10.1007/s00221-012-3344-9">https://doi.org/10.1007/s00221-012-3344-9</a>.
</div>
<div id="ref-tsai:2011_groop_effect" class="csl-entry" role="listitem">
Tsai, Jessica Chia-Chin, Natalie Sebanz, and Günther Knoblich. 2011.
<span>“The <span>GROOP</span> Effect: Groups Mimic Group
Actions.”</span> <em>Cognition</em> 118 (1): 135–40. <a
href="https://doi.org/10.1016/j.cognition.2010.10.007">https://doi.org/10.1016/j.cognition.2010.10.007</a>.
</div>
<div id="ref-tuomela:2000_cooperation" class="csl-entry"
role="listitem">
Tuomela, Raimo. 2000. <em>Cooperation: <span>A Philosophical
Study</span></em>. Dordrecht: Springer.
</div>
<div id="ref-wolpert:1995internal" class="csl-entry" role="listitem">
Wolpert, Daniel M., Z Ghahramani, and Mi Jordan. 1995. <span>“An
Internal Model for Sensorimotor Integration.”</span> <em>Science</em>
269 (5232): 1880–82. <a
href="https://doi.org/10.1126/science.7569931">https://doi.org/10.1126/science.7569931</a>.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Gilbert and Tuomela each use the term ‘acting together’
as if it applied far more narrowly (compare <span class="citation"
data-cites="tuomela:2000_cooperation">Tuomela (2000, 7)</span>: ‘Acting
together involves sociality in the relatively strong sense that such
action must be based on joint intention or shared collective goal.’). We
take this to be a terminological issue. Just as it is coherent to say
that the three legs of a tripod support a flask together, so it seems to
us coherent to say that people vibrating and disturbing a fatberg are
unblocking the drain together.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Endorsing these minimal requirements does not imply that
they are sufficient. Accordingly, we are neutral on whether any of the
researchers just cited may be sources of further necessary
requirements.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>In general, a <em>very small scale action</em> is one
that is typically distantly related as a descendent by the means-ends
relation to the actions which are sometimes described as ‘small scale’
actions, such as playing a sonata, cooking a meal or painting a house
(e.g. <span class="citation" data-cites="bratman:2014_book">(Bratman
2014, 8)</span>; <span class="citation"
data-cites="gilbert_walking_1990">(Gilbert 1990, 178)</span>). It is
sometimes suggested that standard accounts of acting together are
ill-suited to characterising large-scale interactions <span
class="citation" data-cites="Kutz:2000si">(e.g. Kutz 2000)</span>. They
may also fail to characterise very small-scale interactions.<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Much more could be said about what motor representations
are and why they are necessary; key sources include <span
class="citation" data-cites="rosenbaum:2010_human">Rosenbaum
(2009)</span>, <span class="citation" data-cites="prinz:1990_cc">Prinz
(1990)</span>, <span class="citation"
data-cites="wolpert:1995internal">Wolpert, Ghahramani, and Jordan
(1995)</span>, <span class="citation"
data-cites="jeannerod:1988_neural">Jeannerod (1988)</span> and <span
class="citation" data-cites="rizzolatti_mirrors_2008">Rizzolatti and
Sinigaglia (2008)</span>. Related theoretical considerations have also
been identified by philosophers, notably by <span class="citation"
data-cites="bach:1978_representational">Bach (1978)</span> on ‘executive
representations’.<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>For further supporting considerations, see <span
class="citation" data-cites="prinz:1997_perception">Prinz (1997,
143–46)</span>, <span class="citation"
data-cites="pacherie:2008_action">Pacherie (2008)</span> and <span
class="citation" data-cites="butterfill:2012_intention">Butterfill and
Sinigaglia (2014, 121–24)</span>.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Another part of the answer concerns the role of motor
representation of outcomes in reducing the number of kinematic
parameters to be computed, which facilitates planning and control of
action (see, for example, <span class="citation"
data-cites="santello:2002_patterns">(Santello, Flanders, and Soechting
2002)</span>; <span class="citation"
data-cites="tessitore:2013_hierarchical">(Tessitore, Sinigaglia, and
Prevete 2013)</span>).<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>Full discussion of the distinction between intention and
motor representation is beyond the scope of this paper. <span
class="citation" data-cites="butterfill:2012_intention">Butterfill and
Sinigaglia (2014, 124–30)</span> offer some further considerations. See
further <span class="citation"
data-cites="pacherie:2000_content pacherie:2011_nonconceptual shepherd:2015_conscious">Pacherie
(2000, 2011; Shepherd 2015)</span>.<a href="#fnref7"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Note that this conclusion is neutral on whether all
actions involve intentions. After all, a single action may involve both
intention and motor representation <span class="citation"
data-cites="butterfill:2012_intention">(Butterfill and Sinigaglia
2014)</span>.<a href="#fnref8" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Further relevant findings include <span class="citation"
data-cites="loehr:2015_sound novembre:2013_motor">Janeen D. Loehr and
Vesper (2015; Novembre et al. 2014)</span>.<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Far from being entirely novel, this conjecture is a
version of <span class="citation" data-cites="Pacherie:2006dl">Pacherie
and Dokic (2006, 111)</span>’s view that in ‘joint action control […]
each agent adjusts his own actions as a function of the common goal and
of the predicted consequences of the actions of other participants.’
Related ideas can also be found in <span class="citation"
data-cites="dellagatta:2017_drawn sacheli:2018_evidence clarke:2019_joint">della
Gatta et al. (2017; Sacheli, Arcangeli, and Paulesu 2018; Clarke et al.
2019)</span>.<a href="#fnref10" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>This should not be taken to imply that the motor
representations themselves specify self or other (see further section <a
href="#sec:two_objections" data-reference-type="ref"
data-reference="sec:two_objections">5</a>).<a href="#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>A version of this objection is due to Wolfgang Prinz
(personal communication).<a href="#fnref12" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>See <span class="citation"
data-cites="jeannerod:2003_mechanism">Jeannerod (2003)</span>. For
arguments for the agent-neutrality of some motor representations, see
also <span class="citation" data-cites="gallese:2001_shared">Gallese
(2001)</span> and <span class="citation"
data-cites="Pacherie:2006dl">Pacherie and Dokic (2006)</span>.<a
href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>Not everyone appears to find this incoherent <span
class="citation" data-cites="millikan:1995_pushmi-pullyu">(Millikan
1995, 191)</span>; but we shall concede that it is incoherent for the
sake of argument.<a href="#fnref14" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>This objection is due to Michael Bratman (personal
communication).<a href="#fnref15" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>The following is true on accounts offered by <span
class="citation" data-cites="Bratman:1993je">Bratman (1993)</span>,
<span class="citation" data-cites="alonso_shared_2009">Alonso
(2009)</span> and <span class="citation"
data-cites="pacherie:2013_lite">Pacherie (2013)</span>; and it is
consistent with <span class="citation" data-cites="Searle:1990em">Searle
(1990)</span> and <span class="citation" data-cites="Kutz:2000si">Kutz
(2000)</span> among others.<a href="#fnref16" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>Note that this claim is consistent with (and neutral
on) the view that shared intention is involved in every case of acting
together with a purpose. Our aim is to argue that an interagential
structure of motor representation is needed rather than that shared
intention is not needed.</p>
<p><span class="citation"
data-cites="sinigaglia:2020_motor_joint_experience">Sinigaglia and
Butterfill (2020)</span> propose a further, independent reason for
thinking that motor representation matters: it may ground experiences of
acting together with a purpose which are not merely experiences of
individual actions.<a href="#fnref17" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</div>

---

Title: Effort-based decision making in joint action: Evidence of a sense of fairness
Authors: Székely, Marcell and Butterfill, Stephen A. and Michael, John
Year: 2024
Journal: Journal of Experimental Social Psychology
Type: Publication

# Abstract


As humans, we are unique with respect to the flexibility and scope of our cooperative behavior. In recent years, considerable research has been devoted to investigating the psychological mechanisms which support this. One key finding is that people frequently calibrate their effort level to match a cooperation partner’s effort costs - although little is known about exactly why they do so. We hypothesized that people calibrate with the ultimate goal of attracting and keeping good collaboration partners, with the proximal psychological motive being a preference for fairness. Across four lab-based, pre-registered experiments $(N=142)$ , we found support for these hypotheses, and distinguished them from plausible alternative explanations, such as the conjecture that people may use their partner’s effort costs as information to infer the value of opportunities afforded by their envi­ ronment, and the conjecture that people may calibrate their effort investment in order to appear competent. Statement of relevance: As humans, we have unique skills and motivations for acting together. Crucially, acting together requires effort and a growing body of empirical work on cooperation and joint action suggests that people calibrate their effort level to match that of a partner’s effort costs - although little is known about the mechanisms leading them to do so. Our findings show that people calibrate their effort investment in joint action with the ultimate goal of attracting and keeping good collaboration partners and that the psychological mech­ anism that drives them to do so is a preference for fairness. These findings provide a valuable addition to existing research on the sense of fairness, providing evidence that the sense of fairness leads people not only to distribute resources according to individual effort costs but to distribute effort costs according to the expected reward distribution as well.  

Keywords: Cooperation, Joint action, Effort, Partner choice, Fairness, Naïve utility calculus  

<div class="fulltext">

# Introduction

As humans, we have unique skills and motivations for acting together (Nowak, 2006; Sebanz et al., 2006; Tomasello et al., 2012). Crucially, acting together requires effort - and recent empirical research on joint action has begun focusing on how people negotiate economies of effort. In one line of research (Chennells & Michael, 2018; Székely & Michael, 2018), it has been found that people make use of perceptual cues to infer a partner’s investment of effort and aim to calibrate their effort level to match that of their partner’s effort costs - however, these studies do not resolve the question as to why, or under what circumstances, people do so.  

Research on the evolution of cooperation provides a tentative explanation. In particular, recent research on strategies for cooperation in biological markets suggests that when individuals can choose partners, this can lead to selection pressure favoring psychological ad­ aptations for choosing, attracting and maintaining good collaboration partners (Barclay, 2013; Barclay & Willer, 2007). Building on this, one may speculate that people calibrate their effort investment in joint ac­ tion with the ultimate goal of attracting and retaining good collabora­ tion partners (The relationship-directed effort calibration hypothesis).  

If it is true that people tend to calibrate their effort investment in joint action with this ultimate goal, what proximal psychological mo­ tives drive them to do so? One possibility is linked to fairness. A growing body of theoretical and empirical work suggests that our sense of fair­ ness evolved over the course of human evolution through bargaining over opportunity costs in the context of partner selection, and that our sense of fairness involves a preference for divisions of rewards that are proportional to contributions (André & Baumard, 2011; Baumard et al., 2013; Debove et al., 2017; Frohlich, Oppenheimer, & Kurki, 2004; Hamann et al., 2014; Kanngiesser & Warneken, 2012). This research has established that people are highly sensitive to the distribution of effort costs, and that reward distribution is governed by a sense of fairness which takes effort investments into account. Extending these results, Szekely & Michael (2023) recently provided evidence that the sense of fairness leads people to distribute effort costs according to the expected reward distribution. This ability is important because in many contexts the success of joint action is uncertain and/or the reward is indivisible. For example, hunting and foraging in ancestral environments were un­ certain endeavors, and sometimes did not yield any reward to distribute. In such instances, it would have been important to exhibit a sense of fairness by investing effort equally. This line of reasoning leads us to the following hypothesis: when people expect to share the reward of the joint task equally, we should expect them to ensure fairness by cali­ brating their effort investment such as to reduce inequity with respect to joint action partners’ effort investment (The equity through effort cali­ bration hypothesis).  

The current study was designed to test the hypothesis that people calibrate their effort investment in joint action with the ultimate goal of attracting and retaining good collaboration partners, and that the proximal psychological motive that drives them to do so is a preference for fairness. In doing so, it is crucially important to distinguish an alternative explanation arising from the fact that sometimes the value of opportunities afforded by the environment is uncertain. In such cir­ cumstances, one may use others’ investment of effort to infer the reward value they anticipate from an action. For example, if the partner is pursuing a high-cost plan of action, one can infer that the partner ex­ pects a high reward. Accordingly, people may use their partner’s effort costs as information to infer the value of opportunities afforded by their environment, which may lead them to adjust their effort investment as a function of the inferred value (The environment-directed effort calibration hypothesis).  

While we believe that there are compelling theoretical reasons to expect that both types of effort calibration (environment-directed and relationship-directed effort calibration) are present in most participants and mutually compatible in most situations, we aimed to create sce­ narios in which the two motives (and thus the two hypotheses) would not be confounded, but would instead be pitted against each other. Theoretically, we remain neutral as to whether one of the two motives for effort calibration may dominate over the other, whether they cancel each other out, or even whether different participants may be more strongly motivated by one or the other.  

In the experiments, we implemented a social effort lottery task with an unknown reward (1 or 5 points). In Experiment 1, the rewards were sometimes the same (Congruent) and sometimes the opposite (Incon­ gruent) for the participant and the partner, and we also manipulated the partner’s effort level (High and Low). We reasoned that if participants use the perception of their partner’s effort investment as an input to infer the reward value of a trial, then in the Congruent condition (same reward value) we should expect participants to invest more effort in the High Partner Effort condition than in the Low Partner Effort condition, while in the Incongruent condition (opposite reward value), they should invest more effort in the Low Partner Effort condition than in the High Partner Effort condition. In contrast, if participants use the perception of their partner’s effort investment to ensure fairness by calibrating their effort investment such as to reduce inequity with respect to joint action partners’ effort investment, then we should expect participants to invest more effort in the High Partner Effort condition than in the Low Partner Effort condition regardless of Congruence. It is important to emphasize a crucial aspect of the experimental design: in the Incongruent condition, the optimal strategy to maximize subjective utility in the context of the task is to engage in inverse effort matching (“when my partner invests low effort, I invest high effort, and vice-versa”). Consequently, if par­ ticipants match their partner’s effort in the Incongruent condition, they would incur a cost not just to themselves but also to their partner.  

The second and third experiments were designed to rule out an alternative explanation which may equally explain effort calibration in joint action with the ultimate goal of attracting and retaining good collaboration partners. People may be motivated to appear competent and efficient as a means of increasing their value as collaborative part­ ners. Therefore, people may calibrate their effort investment to their partner’s belief about the potential reward value of their action (The appearance of being competent hypothesis).  

In Experiment 2, we again manipulated 1) participants’ beliefs about the reward structure of the task (Congruent and Incongruent), and 2) partner’s effort (High and Low). But in Experiment 2, unlike Experiment 1, participants were informed that their partner always believed that they were in the Congruent reward structure. This made it possible to control for an alternative explanation for Experiment 1, namely that different subsets of participants may have drawn different inferences about whether their partner was aware that the reward structures were opposite in the Incongruent condition, and accordingly have felt the need either to match their partner’s effort level or to do the opposite in order to appear as competent collaboration partners (The appearance of being competent hypothesis).  

In Experiment 3, we again manipulated 1) partner’s effort (High and Low). Moreover, instead of manipulating the Congruence of reward structure, participants were tested in an uncertain reward structure – that is, participants did not know whether they were in a Congruent or Incongruent condition. In addition, in Experiment 3 participants were informed that their partner always believed that they were in an incongruent reward structure. This design enabled us to distinguish the equity through effort calibration hypothesis from the appearance of being competent hypothesis while ensuring that environment-directed calibration would not play a role in their decision-making. While the equity through effort calibration hypothesis predicts that participants should match their partner’s effort more in the High Partner Effort condition than in the Low Partner Effort condition in order to appear as fair collaboration partners, the appearance of being competent hy­ pothesis generates the opposite prediction.  

The fourth experiment was designed to test to what extent people’s tendency to achieve equity through effort calibration depends on their belief that their reputation is exposed in the cooperation partner market. To this end, we manipulated 1) partner’s effort (High and Low) and 2) participants’ belief about the identity of their partner (Human partner and Computer partner). Our rationale for this was that, insofar as par­ ticipants were motivated to appear fair and thus to retain a good repu­ tation as a cooperation partner, their tendency to match their a partner’s effort investment should decrease when they are informed that the partner is a computer. Moreover, instead of manipulating the Congru­ ence of reward structure, participants were tested in an incongruent reward structure – that is, participants were led to correctly believe that when their partner could earn a high reward for a trial, then they could earn a low reward, and when their partner could earn a low reward for a trial, then they could earn a high reward. Participants were informed that their partner always believed that they were in a congruent reward structure. We predicted that those participants who matched their partner’s effort, that is, who invested more effort in the High Partner Effort condition than in the Low Partner Effort condition within the context of a human partner (RDC group), would not do so within the context of a computer partner. Moreover, we predicted that those par­ ticipants who invested effort efficiently, that is, who invested more effort in the Low Partner Effort condition than in the High Partner Effort condition within the context of a human partner (EDC group), would behave similarly within the context of a computer partner.  

In addition, in Experiment 4, we also measured participants’ explicit judgments about fairness using two hypothetical scenarios, in which we manipulated whether a joint action partner prefers equity in terms of effort and gains over utility maximization for the team, or vice-versa. This enabled us to investigate to what extent people’s tendency to match their partner’s effort or to invest effort efficiently is reflected in people’s explicit beliefs about fairness. We predicted that those partic­ ipants who matched their partner’s effort on the primary behavioral task would judge a course of action that involves equity as more fair than a course of action that involves utility maximization for the team. In contrast, we predicted that those participants who engaged in environment-directed effort calibration on the primary behavioral task would judge a course of action that involves utility maximization for the team as more fair than a course of action that involves equity. Furthermore, we also measured participants on Singelis’ Self-Construal Scale. This enabled us to investigate to what extent people’s tendency to match their partner’s effort or to invest effort efficiently is also reflected in their self-construal (independent/interdependent). Here, we did not have clear predictions. On the one hand, one may reasont that those who invest effort efficiently place less value on the joint outcome than on their own outcome, and that those who match effort care more about equity than about the sheer quantity of rewards or efficiency. On this interpretation, one should expect that the effort matchers would be more interdependent than those who invested effort efficiently. On a second interpretation, however, one may speculate that those who match their partner’s effort are willing to incur costs to the dyad for their own reputational gain. On this interpretation, one should expect the effort matchers to be more independent than those who invest effort efficiently and increase their partner’s payoff the most.  

# 1. Experiment 1  

# 1.1. Method  

We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study.  

# 1.1.1. Participants  

Using $G^{*}$ power (Faul et al., 2009), we determined that a sample size of 40 participants provides $80\%$ power to detect an effect size of $\mathbf{f}=$ 0.1876 or greater in a repeated measures ANOVA with a $5\%$ falsepositive rate. During the data collection process, we excluded one pair whose members knew each other prior to participation. The sample includes twenty pairs of individuals (29 female, $\mathbf{M}_{\mathrm{age}}=24.37$ years, $\mathrm{SD}_{\mathrm{age}}=3.32$ years). We did not exclude any data point from the anal­ ysis. Participants carried out the experiment in pairs; members in each pair did not know each other prior to participation. Participants were recruited through (removed for double-blind review), were naïve to the purpose of the study, and reported normal or corrected to normal vision. All participants gave their informed written consent prior to the experiment and received gift vouchers for their participation. The experiment was conducted in accordance with the Declaration of Hel­ sinki and was approved by (removed for double-blind review).  

# 1.1.2. Apparatus and stimuli  

The experiment was displayed on a 13-in. computer screen (resolu­ tion: $2560~\times~1600$ pixels, refresh rate: $60~\mathrm{Hz}$ ). The program for the experiment was written in Python (Peirce, 2007).  

# 1.1.3. Procedure  

Participants were first introduced to another participant in the waiting area, whom they were told would be their partner for the experiment, and who would be playing in the adjacent room (in fact, both of them were playing with a virtual partner controlled by the computer, so that maximum experimental control could be maintained). They were informed that their task was to collect points together with their partner and each point increased the probability of getting a bonus at the end of the experiment. Crucially, they were informed that the bonus would be evenly divided between them.  

On the effort lottery task, participants had to repeatedly press a button to reach a target in order to obtain an unknown reward (1 or 5 points). When they reached or surpassed the target, they received points. Critically, the target was invisible, so participants could not know whether or not they had reached it when deciding how long to persist before quitting. On quitting, participants received feedback about how many points they earned, but they never learned about the location of the invisible target. Before their turn, they observed as their partner performed the same task in order to obtain some reward (1 or 5 points). Importantly, at the beginning of each trial, the reward value of the trial was only revealed to their partners and their partners invested effort rationally: when they (i.e., partners) had high reward (5 points), they invested a high level of effort (High Partner Effort condition); when they had low reward (1 point), then they invested a low level of effort (Low Partner Effort condition) (see Fig. 1).  

The experiment was preceded by four tutorials. The first tutorial introduced participants to the effort lottery task with visible targets; they learned that they had to repeatedly press a button to reach the target and then they had to quit the effort lottery task by pressing another button. The second tutorial introduced participants to the effort lottery task with invisible targets: they had to decide when to quit without knowing whether they had reached the target. The partner’s component was introduced in the third tutorial; in four trials, the part­ ner invested 60, 25, 30 and 85 keypresses before quitting.  

# 1.1.4. Design  

In a within-subject design experiment, we manipulated participants’ beliefs about the reward structure of the task: in one block, they were led to correctly believe that when their partner had high reward for a trial, then they had high reward too, and when their partner had low reward for a trial, then they had low reward as well (Congruent condition); while in another block, they were led to correctly believe that when their partner had high reward for a trial, then they had low reward, and when their partner had low reward for a trial, then they had high reward (Incongruent condition). Furthermore, sometimes their partners inves­ ted a high level of effort (High Partner Effort condition), and sometimes they invested a low level of effort (Low Partner Effort condition). In each condition, there were 5 trials and we measured participants’ number of keypresses before quitting.  

# 1.1.5. Data preparation and analysis  

See the reproducible scientific report and SOM for details.  

# 1.2. Results  

To examine the effect of Partner’s Effort and Congruence on partic­ ipants’ effort investment in the form of keypresses, we planned to perform a repeated measures ANOVA and a Bayesian analysis, and preregistered them as the planned analyses. Prior to conducting this anal­ ysis, we performed a Shapiro-Wilk test on all four conditions and three of them showed evidence of non-normality (High Congruent $(M=280$ , $M d n=272$ , $S D=99.8)$ , $\mathbf{W}=0.908$ , $p=0.00323$ ; Low Congruent $(M=$ 159, $M d n=150$ , $S D=85.9\$ , $\mathrm{\DeltaW}=0.896$ , $p=0.00147$ ; High Incongruent $(M=232$ , $M d n=234$ , $S D=108\stackrel{\cdot}{_{.}}$ , $\mathrm{~W~}=0.952$ , $p=0.0886)$ ; Low Incongruent $\left(M=229\right.$ , $M d n=223$ , $S D=116\$ ), $\mathsf{W}=0.931$ , $p=0.0170\$ ) (see Fig. 2). Because the assumption of normality was not met, we could not perform a repeated measures ANOVA as we had pre-registered. We analyzed the data with Bayesian methods with the pre-registered model. We used a generalized linear mixed model, in which the predicted value is described as negative binomial distributed around a linear combina­ tion of categorical predictors (Partner’s Effort, Congruence, random effect of participant and random slopes of condition nested within participant) mapped to the central tendency of the predicted value via the exponential function. The results revealed a main effect of Partner Effort, no main effect of Congruence, and an interaction. Moreover, the results revealed a simple effect of Partner Effort in the Congruent con­ dition, that is, participants invested more effort in the High Partner Effort condition than in the Low Partner Effort condition, and no simple effect of Partner Effort in the Incongruent condition. The results also revealed a simple effect of Congruence in the High Partner Effort con­ dition, that is, participants invested more effort in the Congruent con­ dition than in the Incongruent condition, and a simple effect of Congruence in the Low Partner Effort condition, that is, participants invested more effort in the Incongruent condition than in the Congruent condition.  

![](/public/img/articles/szekely2024_effortbased/54c696d01190e729b35c4ee6c036244b8bc6a92f6213e9d8dafc1b860db7cbe7.jpg)  
Fig. 1. Trial structure. On each trial, participants observed their (virtual) partner performing the effort lottery task before their own turn on the same task for some reward value.  

![](/public/img/articles/szekely2024_effortbased/1d3d83c23ac9df44ef1b3a762295e8168a96c7357a803667fd9b31cf524e8ce0.jpg)  
Fig. 2. Participants’ effort investment in the form of keypresses across conditions. Each black dot represents one participant’s effort investment in the respective condition and the gray line connects one’s effort investment in the High and Low Partner’s Effort conditions within the respective Congruence condition. In each boxplot, horizontal lines indicate medians, and red circles indicate means. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)  

Although in the Incongruent condition we did not find any difference between the High and Low Partner’s Effort conditions at the group level, participants’ effort investments in the Incongruent condition suggested that there is a difference at the individual level. Specifically, there ap­ pears to be a subset of participants who invested more effort in the Low Partner Effort condition than in the High Partner Effort condition (Environment-directed effort calibration group) - that is, there appears to be a subset of participants who pursued rewards in the current task optimally, while there appears to be a distinct subset of participants who invested more effort in the High Partner Effort condition than in the Low Partner Effort condition (Relationship-directed effort calibration group) - that is, there appears to be a subset of participants who incurred costs to match their partner’s effort (see Fig. 3).  

To probe this, as an exploratory analysis, we analyzed the data of both subsets of participants separately by applying the same preregistered Bayesian model. The results of the Environment-directed effort calibration group revealed a main effect of Partner Effort, a main effect of Congruence, and an interaction. Moreover, the results revealed a simple effect of Partner Effort in the Congruent condition, that is, participants invested more effort in the High Partner Effort condition than in the Low Partner Effort condition, and a simple effect of Partner Effort in the Incongruent condition, that is, participants invested more effort in the Low Partner Effort condition than in the High Partner Effort condition. The results also revealed a simple effect of Congruence in the High Partner Effort condition, that is, participants invested more effort in the Congruent condition than in the Incongruent condition, and a simple effect of Congruence in the Low Partner Effort condition, that is, participants invested more effort in the Incongruent condition than in the Congruent condition. The results of the Relationship-directed effort calibration group revealed a main effect of Partner Effort, no main effect of Congruence, and no interaction.  

To further probe the conjecture that the behavior of the two groups was produced by different processes, as an exploratory analysis, we examined whether the distribution of the difference of participants’ effort investment between the High and Low Partner effort condition reflected a unimodal or bimodal distribution. While a unimodal distri­ bution would suggest that participants’ behavior is produced by the same process, a bimodal distribution would suggest that participants’ behavior is produced by different processes. The results revealed a bimodal distribution (see Fig. 4). To test whether the central tendency of the two subsets credibly differed from zero - meaning that the behavior of both subsets was influenced by their partner’s effort, we conducted a Bayesian analysis. This revealed that the difference of the effort in­ vestment between the High and Low Partner effort conditions credibly differed from zero for each subset. These results provide support that participants’ behavior reflect the operation of two distinct processes: while a subset of participants pursued rewards in the current task optimally, another subset of participants incurred costs to match their partner’s effort.  

# 2. Experiment 2  

We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study.  

![](/public/img/articles/szekely2024_effortbased/46006cf432b0c1f285e698b8aa77fa691c4c68ba684673a55640aef7b2a2e343.jpg)  
Fig. 3. Participants’ effort investment in the form of keypresses across conditions, split into two groups. The environment-directed effort calibration group (EDC) exhibits a change from effort matching to inverse effort matching when the reward structure is incongruent rather than congruent. The relationship-directed effort calibration group (RDC) exhibits no such change. Each black dot represents one participant’s effort investment in the respective condition, and the gray line connects each participant’s effort investment in the High and Low Partner’s Effort conditions within the respective Congruence of reward structure condition. In each boxplot, horizontal lines indicate medians, and red circles indicate means. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)  

![](/public/img/articles/szekely2024_effortbased/88fb958abf76b717136f92d2d10ae40e31e600134df73d6c7e95ab88e6fb1538.jpg)  
Fig. 4. Distribution of the difference of participants’ effort investment between the High and Low Partner effort condition within the context of the incongruent condition depicted on a density plot. The environment-directed effort calibra­ tion group (EDC, depicted in blue) is below zero because they invested more effort in the Low Partner Effort condition than in the High Partner Effort con­ dition. The relationship-directed effort calibration group (RDC, depicted in orange) is above zero because they invested more effort in the High Partner Effort condition than in the Low Partner Effort condition. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)  

# 2.1. Method  

# 2.1.1. Participants  

Using $G^{*}$ power (Faul et al., 2009), we determined that a sample size of 40 participants provides $80\%$ power to detect an effect size of $\mathbf{f}=$ 0.1876 or greater in a repeated measures ANOVA with a $5\%$ falsepositive rate. We followed the pre-registered exclusion criteria: accordingly, we excluded 20 participants who failed the belief manip­ ulation check at the end of the experiment (2 participants said that „My partner thought that the available reward value was always the opposite for them and for me.”; 15 participants said that „My partner thought that the available reward value was in one block the same, in another block the opposite for them and for me.”; 3 participants said that „I don’t remember what my partner thought about the available reward value.”) and we excluded 2 participants who were accidentally disturbed during the experiment by another participant. The sample includes forty in­ dividuals (25 female, $\mathbf{M}_{\mathrm{age}}=26.45$ years, $\mathrm{SD}_{\mathrm{age}}=7.11$ years). We did not exclude any data point from the analysis. Participants carried out the experiment in pairs; members in each pair did not know each other prior to participation. Participants were recruited through (removed for double-blind review), were naïve to the purpose of the study, and re­ ported normal or corrected to normal vision. All participants gave their informed written consent prior to the experiment and received gift vouchers for their participation. The experiment was conducted in accordance with the Declaration of Helsinki and was approved by (removed for double-blind review).  

# 2.1.2. Apparatus and stimuli  

The apparatus and stimuli were identical to that of Experiment 1.  

# 2.1.3. Procedure  

The procedure was identical to that of Experiment 1 except that at the end of the experiment, participants had to answer belief manipula­ tion check questions regarding their partner’s belief about the congru­ ence of reward structure.  

# 2.1.4. Design  

The design was identical to that of Experiment 1 except that par­ ticipants believed that their (virtual) partner always believed that they  

were in a congruent reward structure. The dependent measure was identical to that of Experiment 1.  

# 2.1.5. Data preparation and analysis  

See the reproducible scientific report and SOM for details.  

# 2.2. Results  

To examine the effect of Partner’s Effort and Congruence on partic­ ipants’ effort investment in the form of keypresses, we planned to perform a repeated measures ANOVA and a Bayesian analysis, and preregistered them as the planned analyses. Prior to conducting this anal­ ysis, we performed a Shapiro-Wilk test on all four conditions and two of them showed evidence of non-normality (High Congruent $(M=309$ , $M d n=287$ , $S D=101\$ ), $\mathrm{\Delta}W=0.858$ , $p=0.000139$ ; Low Congruent $\left(M=\begin{array}{r l}\end{array}\right)$ 167, $M d n=158$ , $S D=76.8\$ , $\mathrm{\DeltaW=0.961}$ , $p=0.184$ ; High Incongruent $(M=241$ , $M d n=242$ , $S D=96.1\$ ), $\mathsf{W}=0.921$ , $p=0.00836)$ ; Low Incongruent $\mathbf{\nabla}M=243$ , $M d n=240$ , $S D=82.2\$ ), $\mathsf{W}=0.972$ , $p=0.429)$ (see Fig. 5). Because the assumption of normality was not met, we could not perform a repeated measures ANOVA as we had pre-registered. We analyzed the data with Bayesian methods with the pre-registered model. We used a generalized linear mixed model, in which the predicted value is described as negative binomial distributed around a linear combina­ tion of categorical predictors (Partner’s Effort, Congruence, random effect of participant and random slopes of condition nested within participant) mapped to the central tendency of the predicted value via the exponential function. The results revealed a main effect of Partner Effort, a main effect of Congruence, and an interaction. Moreover, the results revealed a simple effect of Partner Effort in the Congruent con­ dition, that is, participants invested more effort in the High Partner Effort condition than in the Low Partner Effort condition, and no simple effect of Partner Effort in the Incongruent condition. The results also revealed a simple effect of Congruence in the High Partner Effort con­ dition, that is, participants invested more effort in the Congruent con­ dition than in the Incongruent condition, and a simple effect of Congruence in the Low Partner Effort condition, that is, participants invested more effort in the Incongruent condition than in the Congruent condition.  

Although in the Incongruent condition we did not find any difference between the High and Low Partner’s Effort conditions at the group level, participants’ effort investments in the Incongruent condition suggested that there is a difference at the individual level. Specifically, there ap­ pears to be a subset of participants who invested more effort in the Low Partner Effort condition than in the High Partner Effort condition (Environment-directed effort calibration group) - that is, there appears to be a subset of participants who pursued rewards in the current task optimally, while there appears to be a distinct subset of participants who invested more effort in the High Partner Effort condition than in the Low Partner Effort condition (Relationship-directed effort calibration group) - that is, there appears to be a subset of participants who incurred costs to match their partner’s effort (see Fig. 6).  

To probe this, as an exploratory analysis, we analyzed the data of both subsets of participants separately by applying the same preregistered Bayesian model. The results of the Environment-directed effort calibration group revealed a main effect of Partner Effort, no main effect of Congruence, and an interaction. Moreover, the results revealed a simple effect of Partner Effort in the Congruent condition, that is, participants invested more effort in the High Partner Effort condition than in the Low Partner Effort condition, and a simple effect of Partner Effort in the Incongruent condition, that is, participants invested more effort in the Low Partner Effort condition than in the High Partner Effort condition. The results also revealed a simple effect of Congruence in the High Partner Effort condition, that is, participants invested more effort in the Congruent condition than in the Incongruent condition, and a simple effect of Congruence in the Low Partner Effort condition, that is, participants invested more effort in the Incongruent condition than in the Congruent condition. The results of the Relationship-directed effort calibration group revealed a main effect of Partner Effort, a main effect of Congruence, and an interaction. Moreover, the results revealed a simple effect of Partner Effort in the Congruent condition, that is, par­ ticipants invested more effort in the High Partner Effort condition than in the Low Partner Effort condition, and a simple effect of Partner Effort in the Incongruent condition, that is, participants invested more effort in the High Partner Effort condition than in the Low Partner Effort condi­ tion. The results also revealed no simple effect of Congruence in the High Partner Effort condition, and a simple effect of Congruence in the Low Partner Effort condition, that is, participants invested more effort in the Incongruent condition than in the Congruent condition.  

![](/public/img/articles/szekely2024_effortbased/d1dbe6b1cc26eeb00e6e1953fcf0a236645fdc638e556935e8fb020978e9d337.jpg)  
Fig. 5. Participants’ effort investment in the form of keypresses across conditions. Each black dot represents one participant’s effort investment in the respective condition and the gray line connects one’s effort investment in the High and Low Partner’s Effort conditions within the respective Congruence condition. In each boxplot, horizontal lines indicate medians, and red circles indicate means.  

To further probe the conjecture that the behavior of the two groups was produced by different processes, as an exploratory analysis, we examined whether the distribution of the difference of participants’ effort investment between the High and Low Partner effort condition reflected a unimodal or bimodal distribution. While a unimodal distri­ bution would suggest that participants’ behavior is produced by the same process, a bimodal distribution would suggest that participants’ behavior is produced by different processes. The results revealed a bimodal distribution (see Fig. 7). To test whether the central tendency of the two subsets credibly differed from zero - meaning that the behavior of both subsets was influenced by their partner’s effort, we conducted a Bayesian analysis. This revealed that the difference of the effort in­ vestment between the High and Low Partner effort conditions credibly differed from zero for each subset. These results provide support that participants’ behavior reflect the operation of two distinct processes: while a subset of participants pursued rewards in the current task optimally, another subset of participants incurred costs to match their partner’s effort.  

# 3. Experiment 3  

We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study.  

# 3.1. Method  

# 3.1.1. Participants  

Using $G^{*}$ power (Faul et al., 2009), we determined that a sample size of 20 participants provides $80\%$ power to detect an effect size of $\mathrm{d}=0.66$ or greater in a paired-sample t-test with a $5\%$ false-positive rate. We followed the pre-registered exclusion criteria: accordingly, we excluded 9 participants who failed the belief manipulation check at the end of the experiment (2 participants said that „My partner thought that the available reward value was always the same for them and for me.”; 5 participants said that „My partner thought that the available reward value was in one block the same, in another block the opposite for them and for me.”; 2 participants said that „I don’t remember what my partner thought about the available reward value.”) and we excluded 1 partic­ ipant because we reached the target sample size of 20. The sample in­ cludes twenty individuals (14 female, $\mathbf{M}_{\mathbf{age}}=26.5$ years, $\mathrm{SD}_{\mathrm{age}}=3.713$ years). We did not exclude any data point from the analysis. Participants carried out the experiment in pairs; members in each pair did not know each other prior to participation. Participants were recruited through (removed for double-blind review), were naïve to the purpose of the study, and reported normal or corrected to normal vision. All partici­ pants gave their informed written consent prior to the experiment and received gift vouchers for their participation. The experiment was con­ ducted in accordance with the Declaration of Helsinki and was approved by (removed for double-blind review).  

# 3.1.2. Apparatus and stimuli  

The apparatus and stimuli were identical to that of Experiment 1.  

![](/public/img/articles/szekely2024_effortbased/c3e97e3258f05d063be14b5673b8de335727d8442cece84901a659bd340f8d06.jpg)  
Fig. 6. Participants’ effort investment in the form of keypresses across conditions, split into two groups. The environment-directed effort calibration group (EDC) exhibits a change from effort matching to inverse effort matching when the reward structure is incongruent rather than congruent. The relationship-directed effort calibration group (RDC) exhibits no such change. Each black dot represents one participant’s effort investment in the respective condition, and the gray line connects each participant’s effort investment in the High and Low Partner’s Effort conditions within the respective Congruence of reward structure condition. In each boxplot, horizontal lines indicate medians, and red circles indicate means. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)  

![](/public/img/articles/szekely2024_effortbased/22cc4b9b0c5a220403bd28771e01ffbe74635da8568899151c945a96f1fb25e9.jpg)  
Fig. 7. Distribution of the difference of participants’ effort investment between the High and Low Partner effort condition within the context of the incongruent condition depicted on a density plot. The environment-directed effort calibra­ tion group (EDC, depicted in blue) is below zero because they invested more effort in the Low Partner Effort condition than in the High Partner Effort con­ dition. The relationship-directed effort calibration group (RDC, depicted in orange) is above zero because they invested more effort in the High Partner Effort condition than in the Low Partner Effort condition. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)  

# 3.1.3. Procedure  

The procedure was identical to that of Experiment 1 except for two modifications. After the tutorials, participants had a familiarization phase with 4 trials in the Congruent condition and 4 trials in the Incongruent condition (they were counterbalanced and identical to the conditions of the Congruence manipulation of Experiment 1). Then, in the test phase, participants had 10 trials in the Uncertain condition.  

# 3.1.4. Design  

In a within-subject design experiment, participants were informed that their partner always believed that they were in an incongruent reward structure and that the partner believed that the participants had the same belief as them (i.e., partner). Moreover, participants were informed that, in fact, they would never know whether they were in a Congruent or Incongruent condition (Uncertain condition). We manip­ ulated the virtual partner’s effort investment: sometimes their partners invested a high level of effort (High Partner Effort condition), and sometimes they invested a low level of effort (Low Partner Effort con­ dition). The dependent measure was identical to that of Experiment 1.  

# 3.1.5. Data preparation and analysis  

See the reproducible scientific report and SOM for details.  

# 3.2. Results  

To examine the effect of Partner’s Effort on participants’ effort in­ vestment in the form of keypresses, we planned to perform a pairedsample $t$ -test and a Bayesian analysis, and pre-registered them as the planned analyses. Prior to conducting this analysis, we performed a Shapiro-Wilk test on the difference of participants’ effort investment between the conditions and it did not show evidence of non-normality (High Partner Effort $\zeta M=308$ , $M d n=305$ , $S D=109\$ ; Low Partner Effort $M=260$ , $M d n=264$ , $S D=125\$ ); $\mathsf{W}=0.922$ , $p=0.108.$ (see Fig. 8). Because the assumption of normality was met, we could perform a paired-sample t-test as we had pre-registered. The results revealed a significant effect of Partner Effort, $\mathrm{t}(19)=3.27$ , $p<0.00407$ , $\mathrm{d}=0.73$ . We also analyzed the data with Bayesian methods with the preregistered model. We used a generalized linear mixed model, in which the predicted value is described as negative binomial distributed around a linear combination of categorical predictors (Partner’s Effort, random effect of participant and random slopes of condition nested within participant) mapped to the central tendency of the predicted value via the exponential function. The results revealed an effect of Partner Effort.  

![](/public/img/articles/szekely2024_effortbased/efcb52a7473a25f2cfde11b9ddacad3fbb53ee3d9c94beca832aa68c7f3e1ad5.jpg)  
Fig. 8. Participants’ effort investment in the form of keypresses across conditions. Each black dot represents one participant’s effort investment in the respective condition and the gray line connects one’s effort investment in the High and Low Partner’s Effort conditions. In each boxplot, horizontal lines indicate medians, and red circles indicate means.  

# 4. Experiment 4  

We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study.  

# 4.1. Method  

# 4.1.1. Participants  

Using $G^{*}$ power (Faul et al., 2009), we determined that a sample size of 40 participants provides $90\%$ power to detect an effect size of $\mathbf{f}=0.2$ or greater in a repeated measures ANOVA with a $5\%$ false-positive rate. Eventually we tested 48 participants. We followed the pre-registered exclusion criteria: accordingly, we excluded 6 participants who failed the belief manipulation check at the end of the experiment (4 partici­ pants said that „My partner thought that the available reward value was always the opposite for them and for me.”; 1 participant said that „My partner thought that the available reward value was in one block the same, in another block the opposite for them and for me.”; 1 participant said that „I don’t remember what my partner thought about the avail­ able reward value.”). The sample includes twenty-one pairs of in­ dividuals (31 female, $\mathbf{M}_{\mathrm{age}}=24.57$ years, $\mathrm{SD}_{\mathrm{age}}=3.4$ years). We did not exclude any data point from the analysis. Participants carried out the experiment in pairs; members in each pair did not know each other prior to participation. Participants were recruited through (removed for double-blind review), were naïve to the purpose of the study, and re­ ported normal or corrected to normal vision. All participants gave their informed written consent prior to the experiment and received gift vouchers for their participation. The experiment was conducted in accordance with the Declaration of Helsinki and was approved by (removed for double-blind review).  

# 4.1.2. Apparatus and stimuli  

The apparatus and stimuli were identical to that of Experiment 1  

# 4.1.3. Procedure  

The procedure was identical to that of Experiment 2 except that at the end of the experiment, participants were measured on two secondary tasks: 1) we measured participants’ explicit judgment on fairness using two hypothetical scenarios in which we manipulated whether a joint action partner prefers equity in terms of effort and gains over utility maximization for the team or vice-versa; 2) and we measured partici­ pants on a 10-item version of Singelis’ Self-Construal Scale $\mathrm{^D}$ amico & Scrima, 2016), in which participants rated statements on a 5-point Likert scale from 1 (strongly disagree) to 5 (strongly agree). See SOM for de­ tails on the secondary tasks.  

# 4.1.4. Design  

In a within-subject design experiment, we manipulated 1) partner’s effort (High and Low) and 2) participants’ belief about the identity of the partner (Human partner and Computer partner). Moreover, instead of manipulating the Congruence of reward structure, participants were tested in an incongruent reward structure –that is, participants were led to correctly believe that when their partner has high reward for a trial, then they have low reward, and when their partner has low reward for a trial, then they have high reward. Moreover, participants were informed that their partner always believed that they were in a congruent reward structure. In each condition, there were 5 trials and we measured par­ ticipants’ number of keypresses before quitting.  

# 4.1.5. Data preparation and analysis  

See the reproducible scientific report and SOM for details.  

# 4.2. Results  

We were interested in investigating how people’s tendency to invest effort changes depending on whether they interact with a human partner or a computer. To examine the effect of Partner’s Effort and Partner identity on participants’ effort investment in the form of keypresses, we planned to perform a repeated measures ANOVA and a Bayesian anal­ ysis, and pre-registered them as the planned analyses. Prior to con­ ducting this analysis, we performed a Shapiro-Wilk test on all four conditions and one of them showed evidence of non-normality (High  

![](/public/img/articles/szekely2024_effortbased/c581fe9538cfc7c38f4cc37bace3fcd4e0ffcaae23209ae18aeab020b7c2eadf.jpg)  
Fig. 9. Participants’ effort investment in the form of keypresses across conditions. Each black dot represents one participant’s effort investment in the respective condition and the gray line connects one’s effort investment in the High and Low Partner’s Effort conditions within the respective Partner identity condition. In each boxplot, horizontal lines indicate medians, and red circles indicate means.  

![](/public/img/articles/szekely2024_effortbased/bad908ae9e7ed1cccc46ec2f3d2b4f456f1ea85db11aad8dae2249f193a85bc3.jpg)  
Fig. 10. Participants’ effort investment in the form of keypresses across conditions, split into two groups. Both the relationship-directed effort calibration group (RDC) and the environment-directed effort calibration group (EDC) exhibit a change of behavior when the partner is believed to be a computer algorithm rather than a human partner. Each black dot represents one participant’s effort investment in the respective condition, and the gray line connects each participant’s effort investment in the High and Low Partner’s Effort conditions within the respective Partner identity condition. In each boxplot, horizontal lines indicate medians, and red circles indicate means. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)  

Human partner $(M=233,M d n=240,S D=86.3),W=0.981,p=0.691$ ; Low Human partner $\left(M=249\right.$ , $M d n=257$ , $S D=101$ ), $\mathsf{W}=0.902$ , $p=$ 0.00163; High Computer partner $(M=237$ , $M d n=224$ , $S D=84.5\$ ), W $=0.977$ , $p=0.542)$ ); Low Computer partner $M=245$ , $M d n=249$ , $S D=$ 78.5), $\mathrm{\DeltaW}=0.983$ , $p=0.776)$ (see Fig. 9). Because the assumption of normality was not met, we could not perform a repeated measures ANOVA as we had pre-registered. We analyzed the data with Bayesian methods with the pre-registered model. We used a generalized linear mixed model, in which the predicted value is described as negative binomial distributed around a linear combination of categorical pre­ dictors (Partner’s Effort, Partner identity, random effect of participant and random slopes of condition nested within participant) mapped to the central tendency of the predicted value via the exponential function. The results revealed no main effect of Partner Effort, no main effect of Partner identity, and no interaction.  

Although we did not find any difference between the High and Low Partner’s Effort conditions at the group level, participants’ effort in­ vestments suggested that there is a difference at the individual level. Specifically, there appears to be a subset of participants who invested more effort in the Low Partner Effort condition than in the High Partner Effort condition (Environment-directed effort calibration group) - that is, there appears to be a subset of participants who pursued rewards in the current task optimally, while there appears to be a distinct subset of participants who invested more effort in the High Partner Effort condi­ tion than in the Low Partner Effort condition (Relationship-directed effort calibration group) - that is, there appears to be a subset of par­ ticipants who incurred costs to match their partner’s effort (see Fig. 10).  

To probe the conjecture that the behavior of the two groups was produced by different processes, we examined whether the distribution of the difference of participants’ effort investment between the High and Low Partner effort condition within the context of a human partner re­ flected a unimodal or bimodal distribution. While a unimodal distribu­ tion would suggest that participants’ behavior is produced by the same process, a bimodal distribution would suggest that participants’ behavior is produced by different processes. The results revealed a bimodal distribution (see Fig. 11). To test whether the central tendency of the two subsets credibly differed from zero - meaning that the behavior of both subsets was influenced by their partner’s effort, we conducted a Bayesian analysis. This revealed that the difference of the effort investment between the High and Low Partner effort conditions credibly differed from zero for each subset. These results provide sup­ port that participants’ behavior reflect the operation of two distinct processes: while a subset of participants pursued rewards in the current task optimally, another subset of participants incurred costs to match their partner’s effort.  

![](/public/img/articles/szekely2024_effortbased/cc0deb3c1ba54d4b4f496d19884b1df35cd4341a3b4d27b4189adcb461f6290b.jpg)  
Fig. 11. Distribution of the difference of participants’ effort investment be­ tween the High and Low Partner effort condition within the context of the Human partner condition depicted on a density plot. The environment-directed effort calibration group (EDC, depicted in blue) is below zero because they invested more effort in the Low Partner Effort condition than in the High Partner Effort condition. The relationship-directed effort calibration group (RDC, depicted in orange) is above zero because they invested more effort in the High Partner Effort condition than in the Low Partner Effort condition. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)  

To probe whether the behavior of the two groups changes differently depending on whether they interact with a human partner or a com­ puter, we analyzed the data of both subsets of participants separately by applying the same pre-registered Bayesian model. The results of the Environment-directed effort calibration group revealed a main effect of Partner Effort, no main effect of Partner identity, and an interaction. Moreover, the results revealed a simple effect of Partner Effort in the Human partner condition, that is, participants invested more effort in the Low Partner Effort condition than in the High Partner Effort condi­ tion, and a simple effect of Partner Effort in the Computer partner condition, that is, participants invested more effort in the Low Partner Effort condition than in the High Partner Effort condition. The results also revealed a simple effect of Partner identity in the Low Partner Effort condition, that is, participants invested more effort in the Human part­ ner condition than in the Computer partner condition, and a simple ef­ fect of Partner identity in the High Partner Effort condition, that is, participants invested more effort in the Computer partner condition than in the Human partner condition. The results of the Relationship-directed effort calibration group revealed a main effect of Partner Effort, no main effect of Partner identity, and an interaction. Moreover, the results revealed a simple effect of Partner Effort in the Human partner condi­ tion, that is participants invested more effort in the High Partner Effort condition than in the Low Partner Effort condition, and no simple effect of Partner Effort in the Computer partner condition. The results also revealed a simple effect of Partner identity in the Low Partner Effort condition, that is, participants invested more effort in the Computer partner condition than in the Human partner condition, and no simple effect of Partner identity in the High Partner Effort condition.  

To address to what extent people’s tendency to match their partner’s effort or to invest effort efficiently is reflected in people’s explicit beliefs about fairness, we examined how participants rated others’ behavior in the scenarios as a function of Group (RDC/EDC) and Vignette (utility maximization for the team/effort matching) with Bayesian methods with the pre-registered model (see Fig. 12 and Table 1). We used a generalized linear model, in which the predicted value is described as categorical distributed around a linear combination of nominal pre­ dictors (Group, Vignette, random effect of participant) mapped to a probability value via a thresholded cumulative normal function.  

Statement 1: The actor’s choice was fair. The results revealed no main effect of Group, no main effect of Vignette, and no interaction.  

Statement 2: The actor made the right choice. The results revealed no main effect of Group, a main effect of Vignette, and no interaction.  

Statement 3: In the actor’s position I would have made the same choice. The results revealed no main effect of Group, a main effect of Vignette, and no interaction.  

To address whether people’s tendency to match their partner’s effort or to invest effort efficiently is reflected in people’s self-construal, we examined how participants rated their feelings of connectedness to and separateness from social situations on Singelis’ Self-Construal Scale as a function of Group (RDC/EDC) and Subscale (independent/interdepen­ dent) with Bayesian methods with the pre-registered model (see Fig. 13 and Table 2). We used a generalized linear model, in which the pre­ dicted value is described as negative binomial distributed around a linear combination of categorical predictors mapped to the central tendency of the predicted value via the exponential function. Accord­ ingly, a linear combination of categorical predictors (Group, Subscale, Subjects) mapped to the central tendency parameter via the exponential function. The results revealed a main effect of Group, no main effect of Subscale, and no interaction.  

M. Szekely et al.  

The actor's choice was fair.  

The actor made the right choice.  

In the actor's position I would have made the same choice.  

![](/public/img/articles/szekely2024_effortbased/d48d41254efece429718e1d5b4e532bf724043e673236e89656a01bdcf355395.jpg)  
Fig. 12. We depicted how participants from the two groups (RDC/EDC) rated their agreement with statements related to the two hypothetical scenarios, in which an actor prefers equity in terms of effort and gains over utility maximization for the team, or vice-versa, on a Likert scale (1–5) (where 1 means “strongly disagree” and 5 means “strongly agree”).  

# 5. General discussion  

A growing body of empirical work suggests that the perception or anticipation of a partner’s effort modulates effort-based decision-mak­ ing in the context of joint action (Chennells & Michael, 2018; Jackson & 2019). In the current study, we investigated the hypothesis that people calibrate their effort investment in joint action with the ultimate goal of attracting and keeping good collaboration partners (The relationshipdirected effort calibration hypothesis) and that the proximal psychologi­ cal motive that drives them to do so is a preference for fairness (The equity through effort calibration hypothesis). Across four experiments, we tested these hypotheses and differentiated them from alternative explanations of why people match their partners’ effort. Specifically, in Experiments 1 and 2, we differentiated the relationship-directed effort calibration hypothesis from the hypothesis that people may use their partner’s effort costs as information to infer the value of opportunities afforded by their environment, which may lead them to adjust their effort investment as a function of the inferred value (The environmentdirected effort calibration hypothesis). In Experiment 1, we found that while one subset of participants pursued rewards in the current task optimally, another subset of participants incurred costs to match their partner’s effort. While the former provides support for the environmentdirected hypothesis, the latter provides support for the relationshipdirected hypothesis. However, with respect to each of these subsets, there is an alternative explanation which we did not control for: namely, that participants within the different subsets exhibited the observed patterns in order to appear competent (The appearance of competence hypothesis). Experiment 2 was designed to control for this alternative explanation of the subset that exhibited environment-directed effort calibration – i.e., this subset of participants may have inferred that their partner was aware that the reward structures were incongruent in the Incongruent condition, and may accordingly have invested greater effort in the Low Partner Effort condition and less effort in the High Partner Effort condition in order to demonstrate competence and efficiency to their partner. To address this, in Experiment 2, participants were informed that their partner always believed that they were in a congruent reward structure, and we found clear support for both the relationship-directed and the environment-directed hypotheses. Having found evidence for the relationship-directed hypothesis in Experiments 1 and 2, we next turned our attention to the proximal psychological motives underpinning these effects, and specifically to testing the hy­ pothesis that when people expect to share the reward of the joint task equally, people ensure fairness by calibrating their effort investment such as to reduce inequity with respect to joint action partners’ effort investment (The equity through effort calibration hypothesis). Experi­ ments 1 and 2 do not directly support this hypothesis because they were not designed to rule out the appearance of competence hypothesis. To address this, Experiment 3 provided further evidence of relationshipdirected effort calibration, but in a context in which it could uniquely be explained by the equity through effort calibration hypothesis – i.e. in which the appearance of competence hypothesis could be ruled out.  

Table 1 Median and IQR for the ordinal ratings at each level of the factors for all three statements.   


<html><body><table><tr><td colspan="4">The actor's choice was fair.</td></tr><tr><td>Vignette</td><td>Group</td><td></td><td></td></tr><tr><td></td><td></td><td>EDC</td><td>RDC</td></tr><tr><td>Equity in terms of effort and gains Utility maximization for the team</td><td>3 (2)</td><td>4 (1.75)</td><td>4 (3) 4 (1.25)</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4">The actor made the right choice.</td></tr><tr><td>Vignette</td><td>Group</td><td></td><td></td></tr><tr><td>Equity in terms of effort and gains</td><td>EDC</td><td></td><td>RDC</td></tr><tr><td>Utilitymaximizationfortheteam</td><td>2 (1.75) 4 (1)</td><td></td><td>2 (1.25) 4 (2)</td></tr><tr><td></td><td></td><td></td><td></td></tr><tr><td colspan="4">In the actor's position I would have made the same choice.</td></tr><tr><td>Vignette</td><td>Group</td><td></td><td></td></tr><tr><td></td><td>EDC</td><td></td><td>RDC</td></tr><tr><td>Equity in terms of effort and gains</td><td>2 (1.75)</td><td></td><td>2 (1.5)</td></tr><tr><td>Utilitymaximizationfortheteam</td><td>4 (2.5)</td><td></td><td>4 (1.25)</td></tr></table></body></html>  

Experiment 4 was designed to test the link between one’s tendency to match a partner’s effort and one’s exposure on the cooperation partner market. We hypothesized that if people match their partner’s effort with the ultimate goal of attracting and keeping good collaboration partners, then people should match their partner’s effort when they interact with a human partner, but that they should not do so when they interact with a computer. To address this, participants were led to believe that they played with two separate partners (a Human partner and a Computer partner) in an incongruent reward structure, and they were informed that both of their partners believed that they were in a congruent reward structure. We predicted that those participants who matched a human partner’s effort would not do so within the context of an interaction with a computer partner. Moreover, we predicted that those participants who pursued rewards in the current task optimally – that is, who invested more effort in the Low Partner Effort condition than in the High Partner Effort condition within the context of an interaction with a human partner – would invest effort similarly within the context of an inter­ action with a computer partner. This is because the optimal level of effort investment is not altered if one’s partner is a computer. We found clear support for both predictions - further corroborating the relationship-directed effort calibration hypothesis.  

Table 2 Median and IQR for the ordinal ratings at each level of the factors.   


<html><body><table><tr><td>Subscale</td><td colspan="2">Group</td></tr><tr><td></td><td>EDC</td><td>RDC</td></tr><tr><td>Independent</td><td>10 (5.25)</td><td>10 (5)</td></tr><tr><td>Interdependent</td><td>11 (2.75)</td><td>9 (5.5)</td></tr></table></body></html>  

![](/public/img/articles/szekely2024_effortbased/877b1a212427c95cf4eadf9527c4974643f23c310df1d32c42dae17c40f0f17f.jpg)  
Fig. 13. We depicted how participants rated their agreement with statements expressing independence or interdependence with respect to others on a Likert scale (1–5) (where 1 means “strongly disagree” and 5 means “strongly agree”).  

In addition, in Experiment 4, we also investigated to what extent people’s tendency to match their partner’s effort or to invest effort efficiently is reflected in people’s explicit beliefs about fairness. To address this, we measured participants’ explicit judgments about fair­ ness using two hypothetical scenarios. In the scenarios, we manipulated whether a joint action partner preferred equity (in terms of effort and gains) over utility maximization for the team, or vice-versa. We pre­ dicted that those participants who matched their partner’s effort on the primary task of Experiment 4 would judge an agent who acted in accordance with equity as more fair than an agent who acted in accor­ dance with utility maximization for the team. In contrast, we predicted that those participants who invested effort efficiently on the primary task would make the opposite judgment.  

The results showed no evidence that people’s tendency to match their partner’s effort or to invest effort efficiently is reflected in their explicit beliefs about fairness. Neither group of participants exhibited a substantial difference with respect to their judgments about the fairness of agents who acted equitably (in terms of effort and gains) and agents who maximized utility for the team. Interestingly, however, both groups of participants stated that they themselves would maximize utility rather than acting equitably (in terms of effort and gains) in a similar situation, and that doing so would be the right course of action. This is surprising: although previous research (Batson, Kobrynowicz, Dinner­ 2014) has shown that people sometimes endorse more altruistic fairness preferences when their own payoff is not at stake than when it is, the current research is the first, to our knowledge, to provide evidence that people sometimes act more equitably than they explicitly endorse – and that they may not even be aware of doing so. One possible interpretation is that people’s spontaneous actions reflect a basic sense of fairness with respect to effort investment which diverges from their explicit judg­ ments about fairness. A second possible interpretation (compatible with the first) is that participants who matched their partner’s efforts were more strongly motivated by equity in the primary task because they perceived it as a situation in which their actions might influence their value as cooperation partners, whereas their judgments about the vi­ gnettes were performed from a detached, hypothetical perspective. Future research may further explore the spontaneous sense of fairness expressed in people’s behavior, and its relation to explicit beliefs about fairness.  

To address whether people’s tendency to match their partner’s effort or to invest effort efficiently is reflected in people’s self-construal, we examined how participants rated their feelings of connectedness to and separateness from social situations on Singelis’ Self-Construal Scale. Here, we did not have clear predictions. On the one hand, one could speculate that those who invest effort efficiently care less about the joint outcome than about their own gains, whereas those who match a part­ ner’s effort care more about equity than about the sheer quantity of rewards or efficiency. On this interpretation, one should expect that the effort matchers would be more interdependent in their self-construal than those who invest effort efficiently. According to a second inter­ pretation, in contrast, one could speculate that within the context of the task, those who match their partner’s effort are willing to incur costs to themselves and to the dyad as well. In other words, they are willing to reduce their partner’s payoff for individual reputational gain. On this interpretation, one should expect the effort matchers to be more inde­ pendent in their self-construal than those who invest effort efficiently and increase their partner’s payoff the most. Both of these in­ terpretations remain speculative, however, given that our results do not provide evidence for either of them.  

This research offers evidence for functional explanations of why the perception of a partner’s effort modulates effort-based decision-making in joint action and thereby contributes to attaining a fuller under­ standing of the role of effort and effort perception in human cooperative interactions. First, our findings provide evidence that people have a tendency to achieve equity through effort calibration even at a cost to themselves and their partner. Moreover, our findings also provide a valuable addition to existing research on how people prioritize overall efficiency versus considerations of fairness. For example, Strachan and Torok (2020) found evidence that people prioritize joint efficiency over fairness in joint action. However, in their experiments the effort costs were small for participants, and the authors identified the possibility that fairness may affect decision-making more when there are substan­ tial action costs. The current research supports this conjecture by providing evidence that when the costs are higher, some participants are more strongly motivated by fairness than by efficiency considerations. Moreover, by identifying distinct subgroups that appear to be more strongly motivated by the one than the other, they raise the intriguing possibility that there may be substantial individual differences with respect to the relative strength of these motives. Further research is needed in order to catalogue and to explain these individual differences.  

Second, our findings provide evidence that people use others’ in­ vestment of effort to infer the value of opportunities afforded by their environment, and that they adjust their effort accordingly. These find­ ings are consistent with a large body of work on naïve utility calculus suggesting that human beings from early infancy assume that other agents act to maximize subjective utility (Jara-Ettinger et al., 2016).  

It is important to acknowledge several limitations of the current study. First, only Experiment 4 directly addresses the link between the tendency to match a partner’s effort and partner selection, and the re­ sults raise interesting questions for future research. On the one hand, we found that participants who matched their human partner’s effort were less inclined to match a computer partner’s effort – as one would expect if their tendency to match a partner’s effort was motivated by a concern about maintaining their value as cooperation partners. On the other hand, we show that some participants matched a computer partner’s effort. While this latter finding may be surprising, we believe that it is in fact consistent with Baumard et al. (2013)’s account of the evolution of fairness. In their account, competition among cooperative partners leads people to strategically share the costs and rewards of cooperation equally. With time, this eventually leads to the selection of a disposition to be intrinsically motivated to cooperate fairly. This is so because, at the psychological level, it may be a more cost-effective way of securing a good collaborative reputation than constantly engaging in the costbenefit analyses of the implications of various sharing behaviors. Therefore, if the tendency to achieve equity through effort calibration is indeed an evolved mechanism of partner choice, then people may have an intrinsic preference to match their partner’s effort. If so, then changes in partner market conditions may not lead to substantial short-term changes in people’s tendency to match their partner’s effort. That said, the link between one’s tendency to match their partner’s effort and partner selection should be further investigated.  

Second, the task itself did not implement a real partner market: participants could not choose their partners or leave their partners and do the task with someone else. In a way, this makes our results even more striking: although there was no partner to attract and no need to actively maintain one’s partner, one subset of participants matched their partner’s effort even when they incurred a cost in doing so. This is consistent with the hypothesis that the preference for equity through effort calibration may be intrinsic and not necessarily strategic. How­ ever, it must be noted that the experimental situation itself was embedded in a real partner market: participants were first introduced to another participant in the waiting area, whom they were told would be their partner for the experiment, and they were informed that their jointly earned rewards would be evenly divided between them and this partner. Participants could defect by going through the trials with no effort investment or by quitting the experiment.  

Third, we focused on the amount of effort people invest in joint ac­ tion. However, the amount of effort is just one aspect of how an agent contributes to a joint action. For example, agents may vary in the quality of their efforts –that is, in their level of competence. Moreover, agents’ contribution itself may vary in their pivotality – that is, with respect to the contribution’s importance in terms of the final outcome. Future research should investigate whether and how equity through effort calibration may be sensitive to specific features of cooperation partners such as their level of competence or the pivotality of contributions.  

# Open practices  

This project was pre-registered prior to data collection [Experiment 1: https://osf.io/up2sw/?view_only=1ac485fbb976436fad28c1a40b3d2a95; Experiment 2: https://osf.io/zt5d3/?view_only=b49366807cb94be 7a786b8e7b9847941; Experiment 3: https://osf.io/rptw9/?vie w_only $^{\prime}=$ c1540add34744cd285e251ee6c47600f; Experiment 4: htt ps://osf.io/avmcw/?view_only d4c7d84966d5464f9d8de277c 1ed035a]. The reproducible scientific reports (data and analysis code) are available in an online repository here [https://osf.io/cj64t/? view_only $^{r}=$ a3697e5d4a1847ea92095af20e40cc59].  

# Funding  

This research has received funding from the European Research Council (ERC) under the European Union’s Seventh Framework Pro­ gramme (FP7/2007-2013) under grant agreement No 679092 - SENSE OF COMMITMENT and the Department of Philosophy "Piero Martinetti" of the University of Milan under the Project "Departments of Excellence 2023-2027" awarded by the Ministry of University and Research (MUR).  

# CRediT authorship contribution statement  

Marcell Szekely: Conceptualization, Data curation, Formal analysis Methodology, Project administration, Software, Visualization, Writing – original draft. Stephen Butterfill: Conceptualization, Writing – review & editing. John Michael: Conceptualization, Funding acquisition, Investigation, Methodology, Resources, Supervision, Validation, Writing – original draft, Writing – review & editing.  

# Declaration of competing interest  

The authors declared that they had no conflicts of interest with respect to their authorship or the publication of this article.  

# Data availability  

The reproducible scientific reports (data and analysis code) are available in an online repository here [https://osf.io/cj64t/?view_­ only $=$ a3697e5d4a1847ea92095af20e40cc59 ].  

# Appendix A. Supplementary data  

Supplementary data to this article can be found online at https://doi. org/10.1016/j.jesp.2024.104601.  

# References  

Journal of Theoretical Biology, 289, 128–135.   
Barclay, P. (2013). Strategies for cooperation in biological markets, especially for humans. Evolution and Human Behavior, 34(3), 164–175.   
Barclay, P., & Willer, R. (2007). Partner choice creates competitive altruism in humans. Proceedings of the Royal Society B: Biological Sciences, 274(1610), 749–753.   
Batson, C. D., Kobrynowicz, D., Dinnerstein, J. L., Kampf, H. C., & Wilson, A. D. (1997). In a very different voice: Unmasking moral hypocrisy. Journal of Personality and Social Psychology, 72(6), 1335. evolution of fairness by partner choice. Behavioral and Brain Sciences, 36(1), 59–78.   
Chennells, M., & Michael, J. (2018). Effort and performance in a cooperative activity are boosted by perception of a partner’s effort. Scientific Reports, 8(1), 1–9.   
D’amico, A., & Scrima, F. (2016). The Italian validation of Singelis’s Self-Construal Scale (SCS): A short 10-item version shows improved psychometric properties. Current Psychology, 35, 159–168. PLoS One, 12(3), Article e0173636.   
Faul, F., Erdfelder, E., Buchner, A., & Lang, A. G. (2009). Statistical power analyses using ${\bf G}^{*}$ Power 3.1: Tests for correlation and regression analyses. Behavior Research Methods, 41(4), 1149–1160.   
Frohlich, N., Oppenheimer, J., & Kurki, A. (2004). Modeling other-regarding preferences and an experimental test. Public Choice, 119(1), 91–117.   
Hamann, K., Bender, J., & Tomasello, M. (2014). Meritocratic sharing is based on collaboration in 3-year-olds. Developmental Psychology, 50(1), 121 (ISO 690).   
Jackson, J. M., & Harkins, S. G. (1985). Equity in effort: An explanation of the social loafing effect. Journal of Personality and Social Psychology, 49(5), 1199.   
Jara-Ettinger, J., Gweon, H., Schulz, L. E., & Tenenbaum, J. B. (2016). The naïve utility calculus: Computational principles underlying commonsense psychology. Trends in Cognitive Sciences, 20(8), 589–604.   
Kanngiesser, P., & Warneken, F. (2012). Young children consider merit when sharing resources with others. PLoS One, 7(8), Article e43979. management or self-deception? Journal of Experimental Social Psychology, 55, 53–62.   
Nowak, M. A. (2006). Five rules for the evolution of cooperation. Science, 314(5805), 1560–1563.   
Peirce, J. W. (2007). PsychoPy – Psychophysics software in Python. Journal of Neuroscience Methods, 162(1–2), 8–13.   
Sebanz, N., Bekkering, H., & Knoblich, G. (2006). Joint action: Bodies and minds moving together. Trends in Cognitive Sciences, 10(2), 70–76. distributing joint actions. Acta Psychologica, 210, Article 103158. is enhanced by the perception of a partner’s effort. Cognition, 174, 37–42. distribution of effort in joint action. Evolution and Human Behavior, 44(4), 339–348.   
Tomasello, M., Melis, A. P., Tennie, C., Wyman, E., & Herrmann, E. (2012). Two key steps in the evolution of human cooperation: The interdependence hypothesis. Current Anthropology, 53(6), 673–692. Maximizing coefficiency in coordination. Psychological Science, 30(6), 930–941.  

</div>

---

Title: Taking Apart What Brings Us Together: The Role of Action Prediction, Perspective-Taking, and Theory of Mind in Joint Action
Authors: Lucia Maria Sacheli, Elisa Arcangeli, Desiré Carioti, Stephen A. Butterfill and  Manuela Berlingeri
Year: 2022
Journal: Quarterly Journal of Experimental Psychology
Type: Publication

## Abstract

The ability to act together with others to achieve common goals is crucial in life, yet there is no full consensus on the underlying cognitive skills. While influential theoretical accounts suggest that interaction requires sophisticated insights into others’ minds, alternative views propose that high-level social skills might not be necessary because interactions are grounded on sensorimotor predictive mechanisms. At present, empirical evidence is insufficient to decide between the two. This study addressed this issue and explored the association between performance at joint action tasks and cognitive abilities in three domains—action prediction, perspective-taking, and theory of mind—in healthy adults (N = 58). We found that, while perspective-taking played a role in reading the behaviour of others independently of the social context, action prediction abilities specifically influenced the agents’ performance in an interactive task but not in a control (social but non-interactive) task. In our study, performance at a theory of mind test did not play any role, as confirmed by Bayesian analyses. The results suggest that, in adults, sensorimotor predictive mechanisms might play a significant and specific role in supporting interpersonal coordination during motor interactions. We discuss the implications of our findings for the contrasting theoretical views described earlier and propose a way they might be partly reconciled.




---

Title: Tool Use and Causal Cognition
Authors: Teresa McCormack, Christoph Hoerl and Stephen A. Butterfill (eds)
Year: 2012
Type: Publication

<h3>Description</h3>
<p>A collection of essays by philosophers and cognitive scientists on tool use and causal cognition.</p>
<h3>Contents</h3>
<ol>
  <li>Teresa McCormack, Christoph Hoerl, & Stephen A. Butterfill: Tool Use and Causal Cognition: An Introduction</li>
  <li>Jim Woodward: A Philosopher Looks at Tool Use and Causal Understanding</li>
  <li>Melissa L. Greif & Amy Needham: The Development of Tool Use Early in Life</li>
  <li>Daniel Povinelli & Derek C. Penn: Through a Floppy Tool Darkly: Toward a Conceptual Overthrow of Animal Alchemy</li>
  <li>Amanda Seed, Daniel Hanus, & Josep Call: Causal Knowledge in Corvids, Primates and Children: More Than Meets the Eye?</li>
  <li>Brian J. Edwards, Benjamin M. Rottman, & Laurie R. Santos: The Evolutionary Origins of Causal Cognition: Learning and Using Causal Structures</li>
  <li>Teresa McCormack & Christoph Hoerl: Tool Use, Planning, and Future Thinking in Children and Animals</li>
  <li>Christopher Peacocke: Representing Causality</li>
  <li>John Campbell: Why Do Language and Tool Use Both Count as Manifestations of Intelligence?</li>
  <li>Georg Goldenberg: Effects of brain damage on human tool use</li>
  <li>Lucilla Cardinali, Claudio Brozzoli, Francesca Frassinetti, Alice C. Roy, Alessandro Farn&egrave;: Human tool-use: a causal role in plasticity of bodily and spatial representations</li>
  <li>Charles Spence: Tool-use and the representation of peripersonal space in humans</li>
</ol>

---

Title: Tracking and Representing Others’ Mental States
Authors: Stephen A. Butterfill
Year: 2017
Type: Publication

## Abstract

Few things matter more than the mental states of those nearby. Their ignorance defines
limits on cooperation and presents opportunities to exploit in competition. (If she’s seen
where you stashed those mealworms she’ll pilfer them when you’re gone, leaving you without
breakfast. And you won’t get that grape if he hears you sneaking past.) What others feel,
see and know can also provide information about events otherwise beyond your ken. It’s no
surprise, then, that abilities to track others’ mental states are widespread. Many animals
including scrub jays (Clayton, Dally and Emery 2007), ravens (Bugnyar, Reber and Buckner
2016), goats (Kaminski, Call and Tomasello 2006), dogs (Kaminski et al. 2009), ringtailed
lemurs (Sandel, MacLean and Hare 2011), monkeys (Burkart and Heschl 2007; Hattori,
Kuroshima and Fujita 2009) and chimpanzees (Melis, Call and Tomasello 2006; Karg et al.
2015) reliably vary their actions in ways that are appropriate given facts about another’s
mental states. What underpins such abilities to track others’ mental states?




---

Title: Two Kinds of Purposive Action
Authors: Stephen A. Butterfill
Year: 2001
Journal: European Journal of Philosophy
Type: Publication

## Abstract

It is normally assumed that there is only one kind of purposive action. This article argues that there are two kinds of purposive action, which require different models of explanation. One kind of action is done without awareness of reasons; another kind of action is done because the agent is aware of reasons for that action. The argument starts by noting that philosophers disagree about what explains action. Some claim that actions are explained by impersonal facts, such as facts about how things should be or have been historically (e.g. Millikan, Stout). Others claim that actions are explained by mental states, such as beliefs and desires (e.g. Davidson, Velleman). These philosophers are usually regarded as offering conflicting accounts of one thing. However, they are best understood as giving accounts of different models of action-explanation. Neither model fits every case, so there are at least two kinds of purposive action.




---

Title: Do Humans Have Two Systems to Track Beliefs and Belief-like States?
Authors: Ian A. Apperly and Stephen A. Butterfill
Year: 2009
Journal: Psychological Review
Type: Publication

## Abstract

The lack of consensus on how to characterize humans' capacity for belief reasoning has been brought into sharp focus by recent research. Children fail critical tests of belief reasoning before 3 to 4 years of age (H. Wellman, D. Cross, & J. Watson, 2001; H. Wimmer & J. Perner, 1983), yet infants apparently pass false-belief tasks at 13 or 15 months (K. H. Onishi & R. Baillargeon, 2005; L. Surian, S. Caldi, & D. Sperber, 2007). Nonhuman animals also fail critical tests of belief reasoning but can show very complex social behavior (e.g., J. Call & M. Tomasello, 2005). Fluent social interaction in adult humans implies efficient processing of beliefs, yet direct tests suggest that belief reasoning is cognitively demanding, even for adults (e.g., I. A. Apperly, D. Samson, & G. W. Humphreys, 2009). The authors interpret these findings by drawing an analogy with the domain of number cognition, where similarly contrasting results have been observed. They propose that the success of infants and nonhuman animals on some belief reasoning tasks may be best explained by a cognitively efficient but inflexible capacity for tracking belief-like states. In humans, this capacity persists in parallel with a later-developing, more flexible but more cognitively demanding theory-of-mind abilities.




---

Title: Is Goal Ascription Possible in Minimal Mindreading?
Authors: Stephen A. Butterfill and Ian A. Apperly
Year: 2016
Journal: Psychological Review
Type: Publication

## Abstract

In this response to the commentary by Michael and Christensen, 
we first explain how minimal mindreading is compatible with the 
development of increasingly sophisticated mindreading behaviours 
that involve both executive functions and general knowledge, and then 
sketch one approach to a minimal account of goal ascription.




---

Title: A Minimal Architecture for Joint Action
Authors: Cordula Vesper, Stephen A. Butterfill, Guenther Knoblich and Natalie Sebanz
Year: 2010
Journal: Neural Networks
Type: Publication

## Abstract

What kinds of processes and representations make joint action possible? In this paper, we suggest a minimal architecture for joint action that focuses on representations, action monitoring and action prediction processes, as well as ways of simplifying coordination. The architecture spells out minimal requirements for an individual agent to engage in a joint action. We discuss existing evidence in support of the architecture as well as open questions that remain to be empirically addressed. In addition, we suggest possible interfaces between the minimal architecture and other approaches to joint action. The minimal architecture has implications for theorising about the emergence of joint action, for human-machine interaction, and for understanding how coordination can be facilitated by exploiting relations between multiple agents' actions and between actions and the environment.





---

Title: What Does Knowledge Explain? Commentary on Jennifer Nagel
Authors: Stephen A. Butterfill
Year: 2013
Type: Publication

## Abstract

Knowledge is a mental state: Nagel may be right about this  but wrong to suppose that knowledge is prior to belief in the sense that being able to recognize belief somehow depends on having a concept of knowledge.  This commentary identifies objections  to Nagel's arguments for priority.  Some of these objections arise from Nagel's selective use of developmental evidence on mindreading: additional findings reveal a more complex (and more interesting) picture of how abilities to recognize and track knowledge and belief develop.  If Nagel's arguments for priority fail, why hold that knowledge is a mental state?  An alternative approach might draw on arguments that intention is a mental state.  Knowledge and intention play complementary and interlocking roles in planning and practical reasoning.  Perhaps it is these roles, not claims about priority, which complicate attempts to reduce either knowledge or intention to belief or desire or some combination of these.


<p>Nagel's paper is on PhilPapers: <a href="http://philpapers.org/archive/NAGKAA-3.1.pdf">philpapers.org/archive/NAGKAA-3.1.pdf</a></p>


---

Title: Mindreading by body: incorporating mediolateral balance and mouse-tracking measures to examine the motor basis of adults’ false-belief tracking
Authors: Zani, Giovanni and Butterfill, Stephen A. and Low, Jason
Year: 2023
Journal: Royal Society Open Science
Type: Publication

# Abstract

The role played by motor representations in tracking others belief-based actions remains unclear. In experiment 1, the dynamics of adults’ anticipatory mediolateral motor activity (leftwards–rightwards leaning on a balance board) as well as hand trajectories were measured as they attempted to help an agent who had a true or false belief about an object’s location. Participants’ leaning was influenced by the agent’s belief about the target’s location when the agent was free to act but not when she was motorically constrained. However, the hand trajectories participants produced to provide a response were not modulated by the other person’s beliefs. Therefore, we designed a simplified second experiment in which participants were instructed to click as fast as possible on the location of a target object. In experiment 2, mouse-movements deviated from an ideal direct path to the object location, with trajectories that were influenced by the location in which the agent falsely believed the object to be located. These experiments highlight that information about an agent’s falsebelief can be mapped onto the motor system of a passive observer, and that there are situations in which the motor system plays an important role in accurate belief-tracking.  


<div class="fulltext">

# 1. Introduction  

When we observe another person performing an action, our motor system becomes active as if we are executing that action (e.g. [1,2]). This mechanism allows us to track others’ goals—the outcomes to which their actions are directed—and to predict their movements. Although actions can be coded at a low muscle-specific level which strictly reflect how those actions are carried out kinematically (e.g. [1,3]), our motor system can also—when actions are directed to a goal—compute the best way (based on the context) of doing something now to achieve something later (e.g. [4]). In this way, contextual information that is actual [5,6] or non-actual [7,8], perceived or imagined, can refine or drastically change how means-to-an-end actions are actively planned and performed, as well as how they are coded in the motor system of a passive observer. However, it is still unclear whether and to what extent an observer’s motor system can also accommodate information about others’ beliefs to generate fast and accurate behavioural expectations.  

When we reach to grasp an object, we use a set of necessary bodily displacements, such as arm extension and hand aperture, but the way we move is also influenced by situational constraints, such as the location of (e.g. [9,10]), or how familiar we are with, that particular object (e.g. [11]). For instance, when we see that the handle of our cup is not facing us but the opposite direction, we reach for it with an unconventional movement to achieve a more comfortable posture later [6]. And the kind of information that the motor system accommodates is not limited to what we can visually access. When our goal is to grasp an object, our kinematics will be modulated when we hear a sound that is incongruent with the sound of the contact target (e.g. aluminium-sound when reaching for a paper object; [12,13]) or even when we smell a fruit that has a different size of the one we are reaching for (e.g. smelling a strawberry when reaching for an apple; [14]) (for a review of the multisensory aspects associated with action execution see [15]).  

Adults can also automatically track the goal an observed action is directed towards regardless of the specific effector used [16,17] or the perceptual availability of the movements [4]. For example, adults watching someone wearing a miniaturized soccer shoe kicking a ball with the index finger show motor facilitation in their own index finger, but also in their leg [16]. That is, while the observer’s motor system resonates with the low-level movements involved in the action (i.e. kicking the ball with the finger), it also codes for aspects of that action that are symbolic although not perceptually available in the actual environment (i.e. a soccer kick typically requires a leg movement) [18,19].  

Overall, non-actual environments evoked during motor-imagery, such as the ones that are triggered by a sound, a smell or a symbolic value, can inform the motor system. Although motor imagery is the internal rehearsal of movements without any overt movement, it is well established [20] that it is characterized by a similar neural activation that occurs when preparing [21] and executing [22,23] an action. Also, similar to how performing an action depends on contextual limitations, the efforts taken to think about an action also increase as a function of imagined movement constraints. For example, it takes more time to walk, but also to think about walking, on a narrower beam compared to a larger beam [7]. In other words, regardless of how things actually are (that is, regardless of the fact that in reality the thinker is not actually executing nor observing any action), the thinker’s motor system becomes active as if it is performing that action within the limitations of the non-actual environment. Then, it is possible to conjecture that non-actual environments specified by an agent’s belief-like state could also modulate the observer’s motorically grounded expectations [19]. For example, consider a situation in which an agent has last registered the targeted object where it is not anymore while a passive observer knows the object’s current location. In this case, the agent will plan and execute actions based on her non-actual environment, and she will reach-to-grasp the object in the wrong location. Accordingly, the observer’s motor system needs to process information about the agent’s belief-like state (incompatible with the current reality) to motorically code that the best way (from the agent’s point of view) to do something now is actually to go to the wrong location.  

There is some initial support for the conjecture that belief-like states can be processed by an observer’s motor system. In their adaptation of the ball detection task [24], van der Wel and colleagues [25] showed that analysing participants’ hand movements can be helpful to investigate how conflicts between one’s own and others’ beliefs are resolved automatically and online. Here, participants moved their mouse to click the location of a target ball with hand trajectories that were attracted towards the alternative empty location when the agent had a false belief about the whereabouts of the ball, regardless of the fact that the agent’s belief was irrelevant for the task. Recently, Zani et al. [26], used a Wii balance board (WBB) to study adults’ mediolateral leaning during the observation of live actions performed by an agent who had a false belief about the location of an object. They found that participants’ early motor activity foreshadowed the agent’s action, which was based on the non-actual environment as specified by her false belief. Indeed, before the agent displayed any overt cues to suggest which box she would have moved towards and regardless of the fact that participants were not instructed to track the agent’s beliefs, they spontaneously leaned in anticipation towards the box that was empty but that the agent believed to contain the object.  

Considering that motor processes occur spontaneously and have a minimal impact on cognitive resources [27,28], Zani and colleagues’ [26] findings raise the possibility that it is useful for social cognition that motor representations of an upcoming action can consider others’ belief-like states to generate accurate behavioural expectations. There are, however, limitations to Zani et al.’s study. First, the live non-computer-based setting of their task set-up meant that they could not rule out the possibility that there may have been variability in the agent’s behaviour across participants. Consequently, for our current research, we created a computer-based application of Zani et al.’s [26] real-time interaction task to ensure consistency in presentation of the agent’s actions across participants. Second, the use of a balance board for answering questions about the motor-generated behavioural expectations underpinning belief tracking remains preliminary, and we note that even van der Wel and colleagues’ [25] mouse-tracking approach to study belief tracking is still not common in the theory-of-mind field. Given concerns that implicit or spontaneous measures for studying belief tracking may be fragile and difficult to replicate [29,30], we sought to determine if there is coherence between adults’ anticipatory mediolateral leaning and hand movements as they attempted to help an agent who had a false or a true belief about an object’s location. With respect to the different indicators of early action understanding, our prediction was that spontaneous leaning and mouse cursor trajectories would cohere in response patterning, with both metrics foreshadowing prediction of the agent’s action rather than the observer’s action.  

We were also motivated to uncover new information about the extent to which motor-related information is mapped onto belief tracking. There is evidence suggesting that, in scenarios not involving beliefs, the ability to generate motor representations of an action is impaired by bodily constraining the observer [31] or even the agent [32]. For instance, Liepelt and colleagues [32] instructed participants to lift their index or middle finger in response to a number stimulus presented between the index and middle finger of a photograph of an agent’s static hand. Participants’ reaction times were slower when the agent’s index and middle fingers were tied compared to when the agent’s fingers were free, and compared to when the constrained fingers were those not involved in the participant’s action (thumb and ring finger). In other words, although participants’ ability to move was not directly manipulated, the functioning of their own motor system was significantly disrupted during the observation of an irrelevant agent being unable to move. In stressing such findings, we do not claim that belief tracking relies exclusively on motor-related information. There may be multiple routes to belief tracking. Nonetheless, if the onlooker’s motor system is sometimes necessary for tracking others’ beliefs, we predicted that even the bodily constraining of an agent should disrupt observers’ ability—as detected in participants’ body posture and mouse cursor trajectories—to motorically represent belief-based actions.  

# 2. Experiment 1  

## 2.1. Method  

### 2.1.1. Participants  

Fifty-nine right-handed adults were recruited for this experiment in exchange for course credit. Two participants were excluded owing to technical problems. The final sample size was of 57 participants $(M=19.4$ years, range $=18{-}31$ years, 33 females and 24 males)  

### 2.1.2. Design and stimuli  

Participants were tested individually in a single experimental session lasting approximately 1 h. They were asked to stand on a WBB with the right hand holding a mouse and the left-hand comfortably resting on the table. As per instructions, they watched video clips presented on a monitor in front of them and unlocked one of two boxes by clicking on it every time that the agent asked for help. The helping component was inspired by Buttelmann et al.’s real-time false-belief helping task [33]. The original authors were interested in how infants and young children help an agent who is unsuccessfully trying to open either a box in which she falsely believes the object is located or a box which she truly believes is empty. Buttelmann and colleagues reason that infants and young children in the false belief condition help the agent in opening the box containing the object because they understand that she wants to retrieve the object but has a false belief about its location. In the true belief condition they help the agent with the empty box she is directly struggling with because they understand that the agent is not trying to retrieve the object. Our overarching prediction focused on the different indicators of early behavioural expectation. To this end, and differently from Buttelmann and colleagues, we adopted a combination of body-posture and mouse-tracking techniques to study early implicit belief-tracking and motor processes in the adult observer. Nonetheless, since the task by Buttelmann and colleagues is a variation of the classic false belief change-of-location scenario [34] and is rich in bodily kinematics produced by the agent, its procedure is well suited to study how the motor system resolves social situations involving beliefs [26]. Further, although we did not attempt to make any predictions about adults’ final helping choice, it is worth noting that our computerized task retained aspects of the Buttelmann et al.’s real-time task that were instrumental to facilitate meaningful comparisons between participants’ hand trajectories directed towards one box or the other. Accordingly, having the agent trying to open the empty box when she knew the object’s true location allowed the analysis of how participants reaching to open the box she was directly struggling with were influenced by her true belief of the object being located inside the other box. On the contrary, if the agent with a true belief had tried to open the box containing the object, this would have probably resulted in participants helping the other agent with trajectories that were not attracted towards the irrelevant opposite box.  

Four video clips were adopted as experimental stimuli (see figure 1 for a schematic of their time sequence). Each participant watched each experimental stimulus 18 times, for a total of 72 trials. The order of the videos and the initial location of the chocolate was randomized across participants:  

(i) true belief untied (TBU): after the agent placed a chocolate bar in one of the two boxes, the experimenter (watched by the agent) moved the chocolate bar from that box to the other box. Then the agent left the room. While the agent was outside the room, the experimenter locked the boxes with a black pin. Note that the locking mechanism was seen from the participant’s point of view but not by the agent. Then the agent came back into the room and, after $1200\mathrm{ms,}$ she reached for the empty box. After unsuccessfully trying to open the lid, the agent assumed a neutral position and the sentence prompt ‘help me’ appeared on the screen;  

(ii) false belief untied (FBU): after placing a chocolate bar in one of the two boxes, the agent left the room. While the agent was outside, the experimenter moved the chocolate bar from one box to the other and he locked the boxes with a black pin. Note that the locking mechanism was seen from the participant’s point of view but not by the agent. Then the agent came back into the room and, after $1200\mathrm{ms},$ she reached for the empty box. After unsuccessfully trying to open the lid, the agent assumed a neutral position and the prompt ‘help me’ appears on the screen;  

(iii) true belief tied (TBT): after the agent placed a chocolate bar in one of the two boxes, the experimenter (watched by the agent) moved the chocolate bar from that box to the other. Then the agent left the room. While the agent was outside the room, the experimenter locked the boxes with a black pin. The locking mechanism was seen from the participant’s point of view but not by the agent. When the agent came back into the room it was clearly shown that her ability to move was impaired by bandages blocking her arms and legs (the agent’s tunic was warn as movement-restricting bandages). After $1200~\mathrm{ms}_{,}$ , the agent leaned towards the empty box. Then the agent assumed a neutral position and the promt ‘help me’ appeared on the screen; and  

(iv) false belief tied (FBT): after placing a chocolate bar in one of the two boxes, the agent left the room. While the agent was outside, the experimenter moved the chocolate bar from one box to the other and he locked the boxes with a black pin. The locking mechanism was seen from the participant’s point of view but not by the agent. Then the agent came back into the room and it was clearly shown that her ability to move was impaired by bandages blocking her arms and legs. After $1200\mathrm{ms}.$ , the agent leaned towards the empty box. Then the agent assumed a neutral position and the prompt ‘help me’ appeared on the screen.  

Participants’ leaning on the WBB was recorded during a time window with a fixed duration of 1200 ms starting when the agent came back into the room and ending before the agent leaned towards one of the boxes. The mouse tracker time window had a maximum duration of $3000\mathrm{ms}$ and started when the prompt ‘help me’ appeared on screen and ended when the participant clicked on one of the two alternatives (figure 1). Participants were instructed to start moving the mouse as soon as possible and, if they took $400~\mathrm{ms}$ or longer to move their mouse a message appeared on screen prompting a faster response in the following trials (i.e. ‘please start moving earlier $\mathrm{on,}$ even if you are not fully certain of a response yet’). If they took more than $3000\mathrm{ms}$ to click, a warning message appeared on screen (i.e. ’time out!’).  

![](/public/img/articles/zani2023_mindreading/91333d991754afadb02952c41ab2cc82c7484be037fc9afa7590534e14ca0584.jpg)  
Figure 1. Experiment 1: times of Interest. The balance time window had a fixed duration of 1200 ms starting when the agent came back into the room $(a)$ and ending before the agent leaned towards one box $(b)$ . The mouse tracker time window had a maximum duration of 3000 ms and started when the prompt ‘help me’ appeared on screen $(c)$ and ended when the participant clicked on one of the two alternatives $(d)$ . The face of the confederate agent is blurred only for the purposes of publication.  

### 2.1.3. Apparatus and measures  

The WBB (Nintendo, Kyoto, Japan) is a force platform included in the popular game Nintendo WiiFit. The WBB has been proven to be a reliable tool measuring temporally and spatially sensible information about the body’s centre of pressure (COP) [35]. We used the WBB to measure participants’ anticipatory mediolateral shifts in balance posture exhibiting a lean towards the rightside box or towards the left-side box during the time of interest by calculating the average participants’ COP displacement from the COP position at the beginning of the time of interest. The WBB was connected to a computer via Bluetooth and custom software (provided by Nathan van der Stoep at https://www.multisensoryspacelab.com/) was used to calibrate participants’ baseline COP and to record their shifts in COP during the time of interest. The WBB data was post-processed by resampling at a stable $50\mathrm{Hz}$ and processed through an eight order Butterworth filter with a low-pass set at ${\boldsymbol{12}}\mathrm{Hz,}$ as suggested by Clark et al. [35].  

Table 1. Experiment 1: descriptive statistics of the proportions of final helping behaviour with now-full box as outcome by condition (TBU, true belief untied; FBU, false belief untied; TBT, true belief tied; FBT, false belief tied).   


<html><body><table><tr><td>mean</td><td>median</td><td>s.d.</td></tr><tr><td>TBU 0.63</td><td>0.83</td><td>0.40</td></tr><tr><td>FBU 0.97</td><td>1.00</td><td>0.06</td></tr><tr><td>TBT 0.63</td><td>0.78</td><td>0.38</td></tr><tr><td>FBT 0.80</td><td>0.94</td><td>0.31</td></tr></table></body></html>  

Freeman and Ambady’s Mouse Tracker software [36] was used to record participant’s final helping behaviour as a binary outcome (i.e. participants either clicked on the now-full box or the now-empty box), and to analyse the mouse cursor trajectories. Typically, in a mouse-tracker experiment, participants begin a trial by clicking a start box located in the bottom centre of the screen and then they move the mouse cursor to one of two alternatives in the top corners of the screen. The resulting trajectory is recorded at a high temporal resolution of $60{-}75\mathrm{Hz}$ [36] and provides information about the attraction that the unchosen alternative has on the participant. Such mouse trajectory attraction is commonly operationalized in terms of area under the curve (AUC; the geometrical area between the ideal trajectory and the participant’s trajectory). The AUC is calculated by summing any curvature heading towards the unchosen alternative (computed as positive AUC) and any curvature heading away from the unchosen alternative (computed as negative AUC) [37,38]. For example, when participants are asked to categorize a face as belonging to a male or female, the AUC of their mouse trajectories is greater when they are shown a picture of a male with feminine features (e.g. long hair) compared to when they are presented with a picture of a male with typical male features [39]. The responses were recorded with a Logitech G502 mouse (set at 1000 dpi and $125\mathrm{{Hz})}$ . The two clickable response boxes were over-imposed on the unlocking mechanisms, which were 56 pixels in height and width and were located approximately on the midline of the screen (i.e. 600 pixels upwards and 1690 pixels sideway).  

## 2.2. Results  

### 2.2.1. Helping behaviour analysis  

Because the final helping behaviour had a binary outcome (i.e. participants had to help the agent by opening either the now-full box or the now-empty box) that was recorded in multiple trials, we calculated the final helping behaviour proportions. The final helping behaviour proportion was defined as the number of choices to help with the now-full box in a specific condition (e.g. TBU) divided by the total number of the trials in that condition. As the proportions were not normally distributed, we performed all the analysis with non-parametric tests (Wilcoxon signed-rank tests).  

The results showed that participants chose to help with the now-full box significantly more in the FBU condition compared to the TBU condition $(Z=-5.012\$ , $p<0.001;$ ), more in the FBT condition compared to the TBT condition $(Z=-3.104\$ , $p=0.002,$ ), and more in the FBU condition compared to the FBT condition $\left(Z=-4.336\right)$ , $p<0.001,$ ). No difference in helping behaviour was detected between TBU and TBT conditions $\left(Z=-0.016\right.$ , $p=0.987)$ (table 1).  

### 2.2.2. Anticipatory leaning analysis  

We analysed participants’ mediolateral leaning on the WBB $(n=46/57)$ . Given the multi-trial nature of experiment 1, some of the participants found it difficult to remain still and relaxed for the whole duration of the experiment. For this reason, we visually inspected the raw WBB data to check for participants’ ability to consistently hold a relaxed and stable body posture. In line with the approach used by Zwaan et al. [40], we made sure to analyse mediolateral leaning of participants who were able to keep an adequate neutral body posture throughout the duration of the experiment. Participants (11) with a COP exceeding $\pm4\textrm c m$ before or during the critical time-window were excluded (see figure 2 for an example of the distribution of body displacement in one included participant versus one excluded participant). Mann–Whitney $U\cdot$ -tests were conducted to determine whether there was a difference in the average leaning between conditions.  

![](/public/img/articles/zani2023_mindreading/0e372eb2c8511f9caf408e28e18d8ad848123012c830ba69fdf5a539f223d8e5.jpg)  
Figure 2. Experiment 1: example of displacement from body midline of one included participant compared to one excluded participant. Positive values reflect rightward body shifts; negative values reflect leftward body shifts. The continuous line in the box represents the median, length of the box represents the interquartile range (IQR) and the whiskers extend to the highest and lowest observations. Points outside the box are outliers (quartile $\pm1.5$ times the IQR).  

![](/public/img/articles/zani2023_mindreading/b7c8779e13bf3d42eb38cb4a593ab553fae67c45bcb50dd7e68a8d592e1c1737.jpg)  
Figure 3. Experiment 1: displacement from body midline. Displacement from body midline (0) between groups (TBU, true belief untied; FBU, false belief untied; TBT, true belief tied; FBT, false belief tied). Positive values reflect a leaning towards the now-full box; negative values reflect a leaning towards the now-empty box. The dotted line in the box represents the mean, continuous line represents the median, length of the box represents the interquartile range and the whiskers extend to the highest and lowest observations.  

In line with Zani et al. [26], results revealed a significant difference between TBU and FBU conditions (Mann–Whitney $U=748,$ $p=0.015_{\cdot}$ ; figure 3), with participants in the FBU condition leaning towards the now-empty box $(M=-0.007$ , $\mathrm{Mdn}=-0.002$ , s.d. $=0.03$ , confidence interval $\mathrm{(CI)}=-0.015$ , 0.003) and participants in the TBU condition leaning towards the now-full box $\begin{array}{r}{(M=0.007,}\end{array}$ , $\mathrm{Mdn}=0.004$ , s.d. $=0.026,$ $\mathrm{CI}=-0.001$ , 0.014). Instead, when the agent was constrained, anticipatory leaning in true versus false belief conditions was not significantly different: TBT-FBT (Mann–Whitney $U=1053.$ , $p=0.969)$ with participants’ body posture almost overlapping across tied conditions (TBT: $M=0.002$ , $\mathrm{Mdn}=-0.003,$ , $\it{s.d.}=0.04_{\it{\/}}$ , $\mathrm{CI}=\mathrm{\Omega}-0.01$ , 0.014; FBT: $M=-0.003_{,}$ , $\mathrm{Mdn}=-0.002$ , $\mathbf{s.d.}=0.031$ , $\mathrm{CI}=-0.012$ , 0.006). Nonsignificant differences emerged from the remaining Mann–Whitney $U$ tests conducted between TBU-TBT (Mann–Whitney $U=846$ , $p=0.098)$ and FBU-FBT (Mann–Whitney $U=968_{\cdot}$ , $p=0.482)$ .  

Table 2. Experiment 1: mean areas under the curve (AUC) by chosen box in each condition (neTBU, now-empty box in true belief untied; nfTBU, now-full box in true belief untied; neFBU, now-empty box in true belief untied; nfFBU, now-full box in false belief untied; neTBT, now-empty box in true belief tied; nfTBT, now-full box in true belief tied; neFBT, now-empty box in false belief tied; nfFBT, now-full box in false belief tied).   


<html><body><table><tr><td>count</td><td>mean AUC</td><td>s.d.</td></tr><tr><td>neTBU 348</td><td>-0.066</td><td>0.343</td></tr><tr><td>nfTBU 606</td><td>-0.019</td><td>0.356</td></tr><tr><td>neFBU 161</td><td>-0.011</td><td>0.257</td></tr><tr><td>nfFBU 785</td><td>-0.001</td><td>0.167</td></tr><tr><td>neTBT 359</td><td>-0.007</td><td>0.274</td></tr><tr><td>nfTBT 596</td><td>-0.005</td><td>0.154</td></tr><tr><td>neFBT 190</td><td>-0.019</td><td>0.254</td></tr><tr><td>nfFBT 768</td><td>-0.010</td><td>0.227</td></tr></table></body></html>  

### 2.2.3. Mouse-tracking analysis  

In the following data analysis, we explored the amount of attraction exerted by the non-chosen alternative on the trajectories of the mouse cursor, as expressed by the AUC of each trajectory.  

Before performing formal analysis, we excluded from the dataset all trials $(4.45\%)$ in which the initiation time $({\mathrm{IT}};{}$ amount of time that the mouse cursor takes to reach a distance of 30 pixels from the centre of the starting location) was more than $400\mathrm{ms}$ . Having an $\mathrm{IT}$ set at $400\mathrm{ms}$ is not necessary when running a Mouse Tracker experiment, and some researchers avoid using it altogether (e.g. [41,42]); nonetheless, it has been described as the optimal cut-off to be adopted when measuring online processes in Mouse Tracker experiments (e.g. [43,44]). Since all participants had an IT below $400\mathrm{ms}$ in more than $75\%$ of the trials across and within conditions, they were all included in the final analysis.  

After checking the raw data for an IT of $400\mathrm{ms}$ or longer, as per standard practice in mouse-tracker experiments (e.g. [36,45,46]), we remapped all trajectories to one side of the screen and, because raw trajectories vary in duration (and thus they contain a different number of data points), we normalized them into 101 time steps using the linear interpolation provided in the Mouse Tracker Analyser software [43]. Combined, these two transformations facilitate meaningful comparisons. Lastly, we excluded trials in which the AUC was deviating more than 2 s.d. from the average.  

Several participants did not choose to click the now-full box and the now-empty box at least once per condition (e.g. multiple participants never clicked the now-empty box in the FBU condition). For this reason, similar to the approach adopted by Kieslich & Hibig [42], we analysed Mouse Tracker data in a linear-mixed model using participants as random intercept and final choice (now-empty; now-full), condition (true belief; false belief), constraint (untied; tied) and their interaction as predictors. Table 2 provides the descriptive statistics about the number of times (i.e. ‘count’) that participants chose to help by clicking on one box (e.g. now-empty; ne-) or the other (e.g. now-full; nf-) in each condition.  

No significant main effects nor interactions emerged. No main effect of choice $(F_{1,335}=0.534_{.}$ , $p=$ 0.465), condition $(F_{1,335}=0.800_{\cdot}$ , $p=0.372)$ nor constraint $(F_{1,335}=0.074,~p=0.786)_{,}$ ; no interaction between condition and choice $(F_{1,335}=1.046_{\cdot}$ , $p=0.307)$ , between condition and constraint $(F_{1,335}=$ 2.181, $p=0.141)$ , between choice and constraint $(F_{1,335}=0.104\$ , $p=0.747)$ nor between condition, choice and constrain $(F_{1,335}=1.140$ , $p=0.286,$ ).  

In general, unlike van der Wel et al. [25], participants’ trajectories were not attracted towards the unchosen alternative, as indicated by negative AUC values.  

## 2.3. Discussion  

Considering that there is no normatively correct helping response to Buttelmann’s helping task [47], we did not make any specific prediction on participants’ final helping behaviour. Nonetheless, adults showed a pattern of explicit behaviour that could be interpreted as similar to the results found by the original authors. In fact, although participants in experiment 1 chose to help by clicking the now-full box more than the now-empty box in all the conditions, they did so more in FBU compared to the  

TBU as well as more in the FBT compared to the TBT. One possibility, as per Buttelmann and colleagues’ explanation [33], is that participants helped in retrieving the object more in the false belief conditions because they understood that the agent was trying to retrieve the chocolate where she last saw it, so they helped her in getting the chocolate. And they opened the empty box more in the true belief condition because they reasoned that since the agent knew where the object was she must have had another reason to try to open the empty box. Alternatively, it might be that secretly hiding the chocolate in the false belief condition made it more salient so to generate the expectation that the agent was going to look for it [48].  

The analysis of adults’ mediolateral balance shifts, in line with the results obtained by Zani et al. [26], confirmed spontaneous motor anticipation of belief-based actions in FBU and TBU conditions. In the FBU condition, adults leaned towards the empty box, i.e. the box in which the agent believed the object to be located; in the TBU condition, they leaned towards the full box i.e. the box in which the agent knew the object was located. The fact that the mediolateral difference between true belief condition and false belief condition disappears when manipulating the agent’s ability to move (i.e. ${\mathrm{TBT}}={\mathrm{FBT}} $ ) is suggestive of an attenuation of participants’ ability to motorically represent the goal of the observed action. However, the lack of a significant effect within conditions (i.e. TBU $=$ TBT; FBU $=$ FBT) also indicates that the effect of constraint on the ability to generate motor predictions about observed belief-based actions is not conclusive. One potential explanation for why anticipatory mediolateral leaning was not completely obliterated by motor restrictions is that constraining the agent might not be as effective in disrupting motor processes in the observer as directly interfering with participants’ ability to move [31], or as disrupting their motor-related cortical areas [49]. However, impairing an agent’s ability to move has been shown to be effective in disrupting motor preparation [32] in the observer. Alternatively, it may be that the motor system might not be necessary for fast action prediction, as indicated by evidence showing that participants born without upper limbs are able to generate behavioural expectations [50]. Another possibility is that the motion of a constrained agent who consistently leans towards one box before asking for help triggers motor representations in the observer. In fact, although such motion occurred after the WBB time window, the participants’ motor system might have used this information to generate expectations about which location the constrained agent was going to lean towards in the upcoming trials. Overall, more research is needed to clarify the boundaries and limits of spontaneous action prediction.  

Finally, in contrast with the effect observed by van der Wel and colleagues [25], participants’ mouse cursor trajectories did not reveal conflicts between one’s own and the agent’s beliefs. One possible explanation is that mouse trajectories, similar to other implicit measures for studying belief tracking may be unstable and difficult to replicate [51]. Alternatively, the lack of attraction towards the box in which the agent believed the chocolate to be located might have originated from confounds that were introduced in the design phase. In our attempt to maintain as much as possible some of the ecological validity of the original Buttelmann et al.’s helping task [33] as well as of Zani et al.’s task [26], we asked participants to click on response boxes that were over-imposed (i.e. camouflaged) onto the unlocking mechanism. The fact that the response boxes were not in the top right and top left corners, as it is commonly done in mouse tracker experiments (e.g. [25,52]), but on the midline of the screen, might have forced participants in experiment 1 to exert an early correction towards the chosen alternative. This could have ultimately resulted in trajectories not having the time and space to be pulled towards the opposite location. In addition, it may be that participants were not as much motivated in following the sequence of events as in van der Wel et al. [25], or that they did not visually perceive the agent at the crucial response time. Participants may have decided how they would respond to the upcoming request for help well before it appeared; for instance, perhaps seeing the object’s final location triggered a decision about where to help and ignored any events occurring after this. In the same vein, they may have learned that if the chocolate was initially located in one box, they were going to have to click the other box because the location was always swapped. In this case, participant could have lost any motivation to spectate the scene, even before the belief induction phase.  

# 3. Experiment 2  

We originally adapted Buttelmann et al.’s real-time interaction task [33] for experiment 1 because of its potential for documenting spontaneous motor processing of others’ belief-based actions. Our computer-based task was successful in eliciting participant’s anticipation of the actions of an agent who was free to move. However, bodily constraining the agent was only partially effective in disrupting participants’ motor representations, and the mouse-cursor trajectories they produced were not influenced by the agent’s beliefs. Experiment 2 was conceived to overcome the design limitations of experiment 1 while maintaining the aim of improving our understanding of the functional relationship between motor processes and belief-tracking.  

Considering the design limitations of using a computerized version of the helping task to study fast mindreading and motor processes, participants in experiment 2 were not given the possibility to help the agent with either the now-empty box or the now-full box. Instead, they were instructed to click on the final location of the chocolate. In particular, removing the helping component conferred three advantages. First, not having the agent leaning towards one box before asking for help removed the motoric confound of a constrained agent who retains some degree of freedom to move. Second, asking participants to indicate the location of the chocolate allowed using response boxes with the standard size and location found in the literature (e.g. [25,52]), as opposed to the more ecologically valid (but small and awkward in location) camouflaged response boxes adopted in experiment 1. Third, by having correct–incorrect responses (as per van der Wel et al. [25]), we were able to discard the wrong responses so to isolate the effect of the agent’s irrelevant beliefs and her ability to move on mouse cursor trajectories landing on the actual location of the chocolate. In addition, a go/ no-go manipulation was also introduced in experiment 2. We exploited the fact that when go/no-go stimuli are presented in a fixed location, participants’ visual attention is selectively deployed in anticipation of the forthcoming stimuli [53]. To this end, we ensured that participants paid attention throughout all the duration of the trials and that they visually perceived the agent by instructing them to provide a response at the end of the sequence of events only if the agent was present on the scene.  

Overall, experiment 2 was designed to test if adults’ automatic belief tracking abilities (as revealed by their mouse cursor trajectories) are modulated when the agent is physically constrained as opposed to when she is able to move. It is worth noting that the data collection was performed in New Zealand during a period in which COVID-19 rules were temporarily lifted. We were required to design experiment 2 as a computerbased task that could be run on multiple (i.e. 14) computers at the same time to allow fast data collection. Although there are disadvantages to group testing compared to individual testing, such as an increased difficulty in the control of the testing environment [54], an experimenter was always present to monitor that the session was proceeding appropriately (no intervention was ever required) and we used no-go trials to ensure that participants looked at their screen and were focused on their task.’  

## 3.1. Method  

### 3.1.1. Participants  

$\mathbf{G}^{*}$ Power 3.1 indicated that a sample size of 35 would be needed to reach the desired power of 0.80 for the style of data characteristics used by van der Wel et al. [25] (input: $f\left(U\right)=0.33.$ , error probability $=0.05\AA.$ ; number of groups $=1$ , number of measurements $=4.$ ). Fifty-five right-handed adults were recruited for this experiment in exchange for course credit. Eight participants were excluded because they did not pay attention, as indicated by more than $25\%$ of commission errors (i.e. execution of go responses in no-go trials). The final sample of 47 participants $\left(M=19.4\right.$ years, range $=17-31$ years, 40 females and seven males) was more than sufficient to reach the desired power of 0.80.  

### 3.1.2. Design and stimuli  

Participants were tested in groups of 14 in a single experimental session lasting $20\mathrm{min}$ . Each participant was assigned to a computer with a blank screen and a start button already set up to initialize the experiment after receiving the instructions. The instructions were provided simultaneously to all participants as follows.  

While a video still representing the agent standing between two boxes and holding a chocolate bar was projected on a big screen, the experimenter read out loud the attached caption. ‘This is a computer-task that takes about $10{-}15\operatorname*{min}$ . For every trial you will see a scene showing two boxes and a person inside a room, and also there is a single chocolate bar being moved from one box to another box. You have to observe what happens. After you hear a beep sound, the person can either come back to the room or not. If the person comes back into the room, you have to click on a button as quickly as possible to indicate whether the chocolate bar is in the right box or the left box. If the person does not come back into the room, you don’t have to click on the button and the scene will end on its own. Let me show you what a trial looks like. After signing the consent form, put your headphones on and click OK to start the computer-task.’ At this point, a true belief example trial was played for everyone to see, then participants could begin the experiment.  

![](/public/img/articles/zani2023_mindreading/072b6088dbd336e4ad89d5054085c226bcc3f7ea75456cba82c3bc06b5c78d19.jpg)  
Figure 4. Experiment 2: times of events. Schematic of the relevant events occurring in the true belief untied (TBU), false belief untied (FBU), true belief tied (TBT), and false belief tied (FBT) conditions. After $12000\mathrm{ms}$ the agent came back into the room and participants had to click on the top right or top left corner of the screen to indicate the location of the chocolate. The face of the confederate agent is blurred only for the purposes of publication.  

Four video clips were adopted as experimental stimuli (see figure 4 for a schematic of the crucial events as they occurred in each condition). The videos were presented in eight blocks of four videos each, for a total of 32 trials. In addition, one no-go trial for each block was added to ensure that participants were motivated to watch the videos and were visually processing the agent in the go trials. The order of the videos and the location of the chocolate was randomized across participants. If participants took $400~\mathrm{ms}$ or longer to move their mouse, after their choice, a message appeared on screen prompting a faster response in the following trials (i.e. ‘please start moving earlier on, even if you are not fully certain of a response yet’) and, if they took more than 3000 ms to click, a warning message appeared on screen (i.e. ‘time out!’). Further, if participants clicked on the wrong location (i.e. the empty box), the message ‘wrong location’ appeared on screen, and if they clicked when they were not supposed to (i.e. in the no-go trials) they were shown the message ‘click only if the woman is in the room’.  

### 3.1.3. Apparatus and measures  

The experimental room was $880\mathrm{cm}$ wide, $1500\mathrm{cm}$ long and $250\mathrm{cm}$ tall. The curtains were always drawn and a standard light attached to the ceiling at the centre of the room was turned on and was not reflecting on any computer screen. Seven participants sat at individual desks facing the left long side of the room and the remaining seven participants sat facing the right side of the room. The distance between the two rows of participants was $400\mathrm{cm}$ back-to-back while the distance between participants in the same row was of $150\mathrm{cm}$ head-to-head. An experimenter sat between the two rows to monitor the session. Participants’ responses were recorded with the commercial mice Dell MS116 $'1000\mathrm{Hz},$ set on the standard medium speed of Windows 10). The mouse-tracking software response boxes were located in the top corners of the screen and were 150 pixels in height and 300 pixels in width. The audio level was set on level 8 of Windows 10 on all computers.  

## 3.2. Results  

### 3.2.1. Mouse-tracking analysis  

Before performing formal analysis, we excluded from the dataset all trials $(12.04\%)$ in which the IT was longer than $400\mathrm{ms}$ . Furthermore, similar to Wirth et al. [55], all trials $(3.27\%)$ in which participants reached and clicked the wrong box (i.e. the now-empty box) were counted as errors and discarded. Participants (eight) with more than $25\%$ of commission errors (i.e. execution of go responses in no-go trials) were excluded from all data analysis.  

All participants included in the final data analysis (47/55) had an IT below $400\mathrm{ms}$ in more than $75\%$ of the trials across and within conditions, they had an aggregate of $10.63\%$ of commission errors and they showed a good understanding of the instructions by committing less than $5\%$ of wrong box errors.  

After checking the raw data for an IT of $400\mathrm{ms}$ or more, $\mathrm{go/no{-}g o}$ performance and errors, as per standard practice in mouse-tracker experiments (e.g. [36,45,46]), we remapped all trajectories to one side of the screen and we normalized them into 101 time steps using the linear interpolation provided in the Mouse Tracker Analyser software [43]. Finally, we excluded trials in which the AUC was deviating more than 2 s.d. from the average of all trials of that condition.  

A linear-mixed model with an unstructured within-subject error covariance using participants as random intercept and including belief (true belief, false belief) and constraint (untied, tied) as fixed factors showed a significant effect on AUC of belief $(F_{1,46}=8.270_{.}$ , $p=0.006)$ . Participants clicked the box containing the chocolate with hand trajectories that were more similar to the ideal straight line connecting the starting location to the target box in the true belief condition compared to the false belief condition. This is indicated by AUCs being closer to zero in TBU and TBT compared to the more negative AUCs of FBU and FBT conditions (figure 5). Recall that an AUC equals to zero when the trajectory does not curve towards to, nor away from the unchosen alternative (i.e. ideal trajectory);  

![](/public/img/articles/zani2023_mindreading/1b0eb745b87ad7d97f36178d4a19017d6862ad59997bcd88b5c25758a7c307e7.jpg)  
Figure 5. Experiment 2: comparison between true belief (TB) and false belief (FB) trajectories. Visual representation of averaged mouse cursor trajectories in the TB and FB conditions (with the factor constraint collapsed). The straight black line represents the ideal path connecting the starting location with the full box. Participants’ trajectories in the FB condition were more attracted towards the box containing the object (or more repulsed by the box in which the agent falsely believed the object was located.  

Table 3. Experiment 2: mean areas under the curve (AUC) of participants’ mouse tracker trajectories in true belief untied (TBU), true belief tied (TBT), false belief untied (FBU), and false belief tied (FBT) conditions. The more AUC is negative, the more the trajectory is attracted towards the chosen alternative.   


<html><body><table><tr><td>mean AUC s.d.</td></tr><tr><td></td></tr><tr><td>TBU -0.031 0.139 47</td></tr><tr><td>TBT -0.036 0.197 47</td></tr><tr><td>FBU -0.070 0.149 47</td></tr></table></body></html>  

it is positive when it is attracted towards the unchosen alternative, and it is negative when it is repulsed away from the unchosen alternative. There was no significant effect of constraint $(F_{1,46}=$ 0.307, $p=0.582^{\cdot}$ nor interaction between belief and constraint $(F_{1,46}=0.067_{.}$ , $p=0.797)$ ) (see descriptive statistics in table 3).  

## 3.3. Discussion  

As of today, the only published study using mouse-tracker technology to investigate mindreading processes indicates that adults click the location of a ball with hand trajectories that are influenced by where an agent believes the ball to be [25]. Since experiment 1 did not detect any effect of the agent’s belief on the mouse cursor trajectories of participants who clicked to help, modifications to the experimental design were implemented in experiment 2.  

In experiment 2, to ensure that participants paid attention to the scene and that they visually perceived the agent during the crucial time window, we implemented a go/no-go manipulation requiring participants to click the location of the chocolate when the agent came back into the room and to withhold their response when the agent did not come back into the room. Similar to van der Wel et al., we predicted that mouse cursor trajectories would have been more attracted towards the empty box when the agent falsely believed the chocolate to be stored in the empty box compared to when the agent knew that the chocolate was in the full box. In addition, we expected that impairing the agent’s ability to move would have also impaired participants’ fast belief tracking abilities. However, constraining the agent did not influence movement parameters, and the main effect of belief had a puzzling opposite direction to what we expected, with participants’ trajectories generally (i.e. regardless of the constraint) being pulled in the opposite direction of the empty box when the agent falsely believed that the chocolate was in the empty box. One possible explanation is that participants’ hand movements were generally reaching the target by following the shortest path and that the main effect of belief was the result of some noise in the data. Alternatively, it might be that participants in the false belief condition had to counterbalance their tendency to move towards the empty box to avoid an incorrect response, paradoxically resulting in them having trajectories more attracted towards the full box. In the true belief condition, the instruction of clicking the box containing the chocolate combined with the agent’s true belief did not generate the same conflict, and trajectories were closer to be ideal. Indeed, it has been suggested that sometimes the suppression of a pattern of motor activity is a mechanism that comes into place to prevent the urge to provide a non-required response [56] and that the more motor processes for an action are active, the more those processes are subsequently inhibited [57]. In experiment 2, participants were instructed to watch the unfolding of the events and to click the location of the chocolate, so it is possible to conjecture that a quick and prepotent response to move the mouse cursor towards the (belief-congruent) empty box was prepared, and adjustments took place to prevent a wrong behaviour.  

# 4. General discussion  

Reasoning and deliberating about others’ actions is an ordinary ability that we all have first hand experience with. However, how humans sustain fluid social interactions in real-time by accurately anticipating what others are going to do is far from clear. Here, we tested adult participants to investigate the possibility that, since motor processes can spontaneously guide how the outcomes of an action are predicted (e.g. [17]), it is conceivable—where that kind of goal ascription occurs in false-belief tasks—for motor representations to account for someone’s belief-like state [19]. The idea here was that, by using the efficiency of the motor system, mindreading could be achieved with a minimal cognitive cost by feeding belief-related information into motor representations and without reasoning about beliefs as such. Two experiments extended on the initial evidence showing that an agent’s belief-like state can modulate motor representations in the observer [26], and measured whether motor processes contribute to the use of information about beliefs when observers spontaneously anticipate another’s actions.  

In support of a tight relationship between belief-tracking and motor processes, our anticipatory leaning results indicate a reliable influence of the agent’s belief on mediolateral balance in the untied condition but not in the tied condition. In experiment 1, participants spontaneously shifted their balance towards the empty box in the false belief condition and towards the full box in the true belief condition when the agent was free to move. Crucially, such belief-congruent modulation of the motor representations of a goal-directed action was attenuated when the agent was motorically constrained, as indicated by lack of anticipatory leaning. That is, WBB results suggest that the agent’s inability to move prevented adult observers to generate motor representations of an action, and information about beliefs-like states lacked a framework (at least a motoric one) to express itself. Experiment 1 also revealed a pattern of adults’ explicit helping behaviour that is consistent with Buttelmann et al.’s [33] original findings with young children. Participants chose to help with the full box more in the false belief condition compared to the true belief condition when the agent was free to move. Interestingly, the same difference between false and true belief conditions emerged when the agent was constrained. Then, if we accept Buttelmann et al.’s interpretation that this pattern of results is suggestive of participants holding the agent’s belief into consideration when providing explicit responses, the WBB and the explicit behaviour results combined are in line with the conjecture that impairing an observer’s ability to motorically represent the outcome to which a belief-based action is directed towards would negatively impact spontaneous mindreading while sparing flexible reasoning about others’ beliefs.  

In terms of mouse cursor trajectories, we did not detect any evidence of online conflicts between participants’ and agent’s beliefs in experiment 1, and experiment 2 had puzzling results. In experiment 1, regardless of the condition, hand movement parameters revealed that choice selection was performed with confidence by reaching the target alongside an ideal straight trajectory connecting the starting location with the chosen box. In experiment 2, contrary to our predictions and differently from van der Wel et al. [25], mouse trajectories landing on the location of the object were not curved towards but away from the location in which the agent falsely believed contained the object. There are two possible explanations. One possibility is that hand movement parameters, contrary to how participants’ body posture is influenced by the agent’s beliefs, were not influenced by the agent’s beliefs. This could be interpreted as an indication that belief-tracking is not cognitively efficient [58], or even that it does not exist at all (e.g. [29,30]), especially if we consider a process to be cognitively efficient only when it is automatic, stimulus-driven and completely independent from cognitive resources. Also, while there is evidence that tracking another person’s belief can be done rapidly and involuntarily (e.g. [25,59]) under cognitive load [60], other authors find that secondary tasks [58] and emotional states [61] can cause a cognitive turbulence that affects even the simplest forms of implicit mindreading. It might be more appropriate to think of efficient, minimal, mindreading as spontaneous rather than fully fledged automatic: its functioning might be largely characterized by fast and unconscious processing of the scene.  

There is a second possibility of explaining the mouse cursor trajectories. In experiment 2, we facilitated spontaneous processing of the agent’s belief-like state by asking participants to click on the location of the object only if the agent came back into the room at the end of the sequence of events. That is, using a go/no-go manipulation we ensured that participants deployed attentional resources to the belief induction phase as well as to whether the agent was free to move or constrained. While constraining the agent had no effect on the way participants moved the mouse cursor to the target object, a puzzling effect emerged when considering how participants processed the other person’s beliefs. Different from our prediction, the mouse cursor trajectories were not more attracted but more repulsed by the location where the agent falsely believed the object to be located. One possibility— though not a conclusive one—is that motor representations for the other person’s expected action (i.e. that she will go to the box she believes contains the object) were not more active but inhibited. An observed action usually has a facilitatory rather than inhibitory effect on the motor representations of that action. Nonetheless, a few studies using electroencephalography (EEG; e.g. [57]), transcranial magnetic stimulation (TMS; [62,63]) or a combination of EEG and TMS (e.g. [64]) have suggested that it is possible for a post-stimulus rebound effect to reflect inhibition following the activation of the motor system. Think about a funambulist who is trying to keep an appropriate balance on a rope. Just when he is about to fall on his right, he counters the not-anymore required (if not dangerous) rightward movement by moving leftwards. However, while inhibiting the rightwards movement using a counter movement to his left, he can overdo it, ending up rebounding on the left side of the rope. This rebound reflects inhibition of a previously activated—and ‘now’ unnecessary— representation of an action and may be related to the previous activation of the motor system. When the observed action is relevant to the observer, such as when participants are anticipating what the agent will do, the motor system becomes more activated for a movement that reflects the likely outcome of the observed action (as we found in experiment 1’s anticipatory leaning towards the empty box). Subsequently, such as when the agent’s goal is irrelevant to participants that are instructed to click on the location where they know the object is (i.e. experiment 2), it becomes more inhibited. Regardless, the mouse-tracking results were unlike those obtained by van de Wel et al. [25] in a conceptually similar task: participants’ trajectories were not attracted towards the box in which an agent who was free to move believed the object to be located. Since the mouse tracker did not produce the predicted belief congruent compatibility effect in terms of curvature attraction towards the box in which the agent—truly or falsely—believed the object to be located, a post-stimulus rebound interpretation remains a possibility that needs further research and we urge caution in the interpretation of the mouse tracking results.  

In conclusion, our results suggest that information about beliefs can be efficiently processed by the motor system to generate accurate behavioural expectations [26]. However, our claim is not that belieftracking relies exclusively on motor processes. On the contrary, the evidence points in the direction of multiple routes available to mindreading [65] and the data we were able to gather in terms of whether or not motor disruptions negatively impact mindreading is preliminary and leaves the door open to alternative interpretations regarding how exactly belief-related information feeds into motor representations. On the one hand, we found some indications that motor processes and representations in the observer can carry information about beliefs during action observation, and that the way anticipatory leaning is sensitive to belief-based actions can be modulated by disrupting the agent’s possibility to act. On the other hand, the use of the WBB for answering questions about belief-based action understanding is still novel, and the converging evidence we sought by measuring belief-congruent effects on participants’ mouse cursor trajectories warrant further research.  

Ethics. The School of Psychology Human Ethics Committee under delegated authority from Central Human Ethics Committee of Victoria University of Wellington provided ethics approval for the study, and informed consent was obtained from all individual participants included in the study. The confederate agent depicted in figures 1 and 4 gave written consent to be depicted in the current research article.   
Data accessibility. The Wii Balance software adopted in experiment 1 is freely available upon request at https://www. multisensoryspacelab.com/ and the Mouse Tracker software adopted in experiments 1 and 2 is also freely available at http://www.mousetracker.org/.   
Authors’ contributions. G.Z.: conceptualization, data curation, formal analysis, methodology, writing—original draft; S.A.B.: conceptualization, funding acquisition, supervision, writing—review and editing; J.L.: conceptualization, funding acquisition, supervision, writing—review and editing.   
All authors gave final approval for publication and agreed to be held accountable for the work performed therein. Conflict of interest declaration. We declare we have no competing interests.   
Funding. This research was funded by the Royal Society of New Zealand Marsden Fund (17-VUW-074, contract VUW1706).  

Acknowledgements. We thank Katheryn Edwards for her research assistance.  

# References  

1. Fadiga L, Fogassi L, Pavesi G, Rizzolatti G. 1995 Motor facilitation during action observation: a magnetic stimulation study. J. Neurophysiol. 73, 2608–2611. (doi:10.1152/jn.1995.73.6.2608)   
2. Gallese V, Lakoff G. 2005 The brain’s concepts: the role of the sensory-motor system in conceptual knowledge. Cogn. Neuropsychol. 22, 455–479. (doi:10.1080/02643290442000310)   
3. Cavallo A, Becchio C, Sartori L, Bucchioni G, Castiello U. 2012 Grasping with tools: corticospinal excitability reflects observed hand movements. Cereb. Cortex 22, 710–716. (doi:10. 1093/cercor/bhr157)   
4. Jeannerod M. 2006 Motor cognition: what actions tell the self. New York, NY: Oxford University Press.   
5. Rosenbaum DA, Chapman KM, Weigelt M, Weiss DJ, van der Wel R. 2012 Cognition, action, and object manipulation. Psychol. Bull. 138, 924–946. (doi:10.1037/a0027839)   
6. Zhang W, Rosenbaum DA. 2008 Planning for manual positioning: the end-state comfort effect for manual abduction–adduction. Exp. Brain Res. 184, 383–389. (doi:10.1007/s00221-007-1106-x)   
7. Decety J, Jeannerod M, Prablanc C. 1989 The timing of mentally represented actions. Behav. Brain Res. 34, 35–42. (doi:10.1016/S0166- 4328(89)80088-9)   
8. Decety J, Lindgren M. 1991 Sensation of effort and duration of mentally executed actions. 1997 An analysis of spatiotemporal variability during prehension movements: effects of object size and distance. Exp. Brain Res. 117, 457–464. (doi:10.1007/s002210050241)   
11. Gentilucci M. 2002 Object motor representation and reaching–grasping control. Neuropsychologia 40, 1139–1153. (doi:10.1016/ S0028-3932(01)00233-0)   
12. Castiello U, Giordano BL, Begliomini C, Ansuini C, Grassi M. 2010 When ears drive hands: the influence of contact sound on reaching to grasp. PLoS ONE 5, e12240. (doi:10.1371/journal.pone. 0012240)   
13. Zahariev MA, MacKenzie CL. 2007 Grasping at ‘thin air’: multimodal contact cues for reaching and grasping. Exp. Brain Res. 180, 69–84. (doi:10.1007/s00221-006-0845-4)   
14. Castiello U, Zucco GM, Parma $\lor,$ Ansuini C, Tirindelli R. 2006 Cross-modal interactions between olfaction and vision when grasping. Chem. Senses 31, 665–671. (doi:10.1093/ chemse/bjl007)   
15. Betti S, Castiello U, Begliomini C. 2021 Reachto-grasp: a multisensory experience. Front. Psychol. 12, 614471. (doi:10.3389/fpsyg.2021. 614471)   
16. Betti S, Castiello U, Sartori L. 2015 Kick with the finger: symbolic actions shape motor cortex excitability. Eur. J. Neurosci. 42, 2860–2866. (doi:10.1111/ejn.13067)   
17. Rizzolatti G, Sinigaglia C. 2010 The functional role of the parieto-frontal mirror circuit: interpretations and misinterpretations. Nat. Rev. Neurosci. 11, 264–274. (doi:10.1038/nrn2805)   
18. Cattaneo L, Caruana F, Jezzini A, Rizzolatti G. 2009 Representation of goal and movements without overt motor behavior in the human motor cortex: a transcranial magnetic stimulation study. J. Neurosci. 29, 11 134–11 138. (doi:10. 1523/JNEUROSCI.2605-09.2009)   
19. Butterfill SA, Apperly IA. 2016 Is goal ascription possible in minimal mindreading? Psychol. Rev. 123, 228–233. (doi:10.1037/rev0000022)   
20. Mellet E, Petit L, Mazoyer B, Denis M, Tzourio N. 1998 Reopening the mental imagery debate: lessons from functional anatomy. NeuroImage 8, 129–139. (doi:10.1006/nimg.1998.0355)   
21. Jeannerod M. 1994 The representing brain: neural correlates of motor intention and imagery. Behav. Brain Sci. 17, 187–202. (doi:10. 1017/S0140525X00034026)   
22. Lotze M, Montoya P, Erb M, Hülsmann E, Flor H, Klose U, Birbaumer N, Grodd W, 1999 Activation of cortical and cerebellar motor areas during executed and imagined hand movements: an fMRI study. J. Cogn. Neurosci. 11, 491–501. (doi:10.1162/089892999563553)   
23. Porro CA, Francescato MP, Cettolo $\lor,$ Diamond ME, Baraldi P, Zuiani C, Bazzocchi M, Di Prampero PE, 1996 Primary motor and sensory cortex activation during motor performance and motor imagery: a functional magnetic 07688.1996)   
24. Kovacs AM, Teglas E, Endress AD. 2010 The social sense: susceptibility to others’ beliefs in human infants and adults. Science 330, 1830–1834. (doi:10.1126/science.1190792)   
25. van der Wel RPRD, Sebanz N, Knoblich G. 2014 Do people automatically track others’ beliefs? Evidence from a continuous measure. Cognition 130, 128–133. (doi:10.1016/j.cognition.2013. 10.004)   
26. Zani G, Butterfill SA, Low J. 2020 Mindreading in the balance: adults’ mediolateral leaning and anticipatory looking foretell others’ action preparation in a false-belief interactive task. R. Soc. Open Sci. 7, 191167. (doi:10.1098/rsos. 191167)   
27. Iacoboni M, Woods RP, Brass M, Bekkering H, Mazziotta JC, Rizzolatti G. 1999 Cortical mechanisms of human imitation. Science 286, 2526–2528. (doi:10.1126/science.286.5449.2526)   
28. Rizzolatti G, Craighero L. 2004 The mirrorneuron system. Annu. Rev. Neurosci. 27, 169–192. (doi:10.1146/annurev.neuro.27. 070203.144230)   
29. Kulke L, Johannsen J, Rakoczy H. 2019 Why can some implicit theory of mind tasks be replicated and others cannot? A test of mentalizing versus submentalizing accounts. PLoS ONE 14, e0213772. (doi:10.1371/journal. pone.0213772)   
30. Kulke L, Reiß M, Krist H, Rakoczy H. 2018 How robust are anticipatory looking measures of theory of mind? Replication attempts across the life span. Cogn. Dev. 46, 97–111. (doi:10.1016/ j.cogdev.2017.09.001)   
31. Ambrosini E, Sinigaglia C, Costantini M. 2012 Tie my hands, tie my eyes. J. Exp. Psychol. Hum. Percept. Perform. 38, 263–266. (doi:10.1037/ a0026570)   
32. Liepelt R, Ullsperger M, Obst K, Spengler S, von Cramon DY, Brass M. 2009 Contextual movement constraints of others modulate motor preparation in the observer. Neuropsychologia 47, 268–275. (doi:10.1016/j. neuropsychologia.2008.07.008)   
33. Buttelmann D, Carpenter M, Tomasello M. 2009 Eighteen-month-old infants show false belief understanding in an active helping paradigm. Cognition 112, 337–342. (doi:10.1016/j. cognition.2009.05.006)   
34. Wimmer H, Perner J. 1983 Beliefs about beliefs: representation and constraining function of wrong beliefs in young children’s understanding of deception. Cognition 13, 103–128. (doi:10. 1016/0010-0277(83)90004-5)   
35. Clark RA, Bryant AL, Pua Y, McCrory P, Bennell K, Hunt M. 2010 Validity and reliability of the Nintendo Wii balance board for assessment of standing balance. Gait Posture 31, 307–310. (doi:10.1016/j.gaitpost.2009.11.012)   
36. Freeman JB, Ambady N. 2010 MouseTracker: software for studying real-time mental processing using a computer mouse-tracking method. Behav. Res. Methods 42, 226–241. (doi:10.3758/BRM.42.1.226)   
37. Freeman JB, Dale R. 2013 Assessing bimodality to detect the presence of a dual cognitive yN, 2008 Will a category cue attract you? Motor output reveals dynamic competition across person construal. J. Exp. Psychol.: Gen. 137, 673–690. (doi:10.1037/a0013875)   
40. Zwaan RA, van der Stoep N, Guadalupe T, Bouwmeester S. 2012 Language comprehension in the balance: the robustness of the actioncompatibility effect (ACE). PLoS ONE 7, e31204. (doi:10.1371/journal.pone.0031204)   
41. Koop GJ, Johnson JG. 2013 The response dynamics of preferential choice. Cognit. Psychol. 67, 151–185. (doi:10.1016/j.cogpsych.2013.09. 001)   
42. Kieslich PJ, Hilbig BE. 2014 Cognitive conflict in social dilemmas: an analysis of response dynamics. Judgm. Decis. Mak. 9, 13. (doi:10. 1017/S1930297500006392)   
43. Freeman JB, Ambady N. 2009 Motions of the hand expose the partial and parallel activation of stereotypes. Psychol. Sci. 20, 1183–1188. (doi:10.1111/j.1467-9280.2009.02422.x)   
44. Hehman E, Stolier RM, Freeman JB. 2015 Advanced mouse-tracking analytic techniques for enhancing psychological science. Group Process. Intergroup Relat. 18, 384–401. (doi:10. 1177/1368430214538325) 45. Spivey MJ, Grosjean M, Knoblich G. 2005 Continuous attraction toward phonological competitors. Proc. Natl Acad. Sci. USA 102, 10 393–10 398. (doi:10.1073/pnas.0503903102)   
46. Koop GJ, Johnson JG. 2011 Response dynamics: a new window on the decision process. Judgm. Decis. Mak. 6, 9. (doi:10.1017/ S1930297500004186)   
47. Fizke E, Butterfill S, van de Loo L, Reindl E, Rakoczy H. 2017 Are there signature limits in early theory of mind? J. Exp. Child Psychol. 162, 209–224. (doi:10.1016/j.jecp.2017.05.005) 48. Allen JWP. 2015 How to help: can more active behavioral measures help transcend the infant false-belief debate? New Ideas Psychol. 39, 63–72. (doi:10.1016/j.newideapsych.2015.07. 008) 49. Costantini M, Ambrosini E, Cardellicchio P, Sinigaglia C. 2014 How your hand drives my eyes. Soc. Cogn. Affect. Neurosci. 9, 705–711. (doi:10.1093/scan/nst037)   
50. Vannuscorps G, Caramazza A. 2016 Typical action perception and interpretation without motor simulation. Proc. Natl Acad. Sci. USA 113, 86–91. (doi:10.1073/pnas.1516978112)   
51. Poulin-Dubois D et al. 2018 Do infants understand false beliefs? We don’t know yet— a commentary on Baillargeon, Buttelmann and Southgate’s commentary. Cogn. Dev. 48, 302–315. (doi:10.1016/j.cogdev.2018.09.005)   
52. Freeman JB. 2018 Doing psychological science by hand. Curr. Dir. Psychol. Sci. 27, 315–323. (doi:10.1177/0963721417746793) 53. Hong X, Wang Y, Sun J, Li C, Tong S. 2017 Segregating top-down selective attention from response inhibition in a spatial cueing go/no-go task: an ERP and source localization study. Sci. Rep. 7, 9662. (doi:10.1038/s41598-017-08807-z)   
54. Echemendia RJ, Iverson $\mathsf{G L},$ McCrea M, Macciocchi SN, Gioia GA, Putukian M, Comper P. 2013 Advances in neuropsychological assessment of sport-related concussion. Br. J. Sports Med. 47, 294–298. (doi:10.1136/ bjsports-2013-092186)   
55. Wirth R, Foerster A, Kunde W, Pfister R. 2020 Design choices: empirical recommendations for designing two-dimensional finger-tracking experiments. Behav. Res. Methods 52, 2394–2416. (doi:10.3758/s13428-020-01409-0)   
56. Naish KR, Houston-Price C, Bremner AJ, Holmes NP. 2014 Effects of action observation on corticospinal excitability: muscle specificity, direction, and timing of the mirror response. Neuropsychologia 64, 331–348. (doi:10.1016/j. neuropsychologia.2014.09.034)   
57. Schuch S, Bayliss AP, Klein C, Tipper SP. 2010 Attention modulates motor system activation during action observation: evidence for inhibitory rebound. Exp. Brain Res. 205, 235–249. (doi:10.1007/s00221-010- 2358-4)   
58. Schneider D, Lam R, Bayliss AP, Dux PE. 2012 Cognitive load disrupts implicit theory-of-mind processing. Psychol. Sci. 23, 842–847. (doi:10. 1177/0956797612439070)   
59. Samson D, Apperly IA, Braithwaite JJ, Andrews BJ, Bodley Scott SE. 2010 Seeing it their way: evidence for rapid and involuntary computation of what other people see. J. Exp. Psychol.: Hum. Percept. Perform. 36, 1255–1266. (doi:10.1037/a0018729)   
60. Qureshi AW, Apperly IA, Samson D. 2010 Executive function is necessary for perspective selection, not level-1 visual perspective calculation: evidence from a dual-task study of adults. Cognition 117, 230–236. (doi:10.1016/j. cognition.2010.08.003)   
61. Bukowski H, Samson D. 2016 Can emotions influence level-1 visual perspective taking? Cogn. Neurosci. 7, 182–191. (doi:10.1080/ 17588928.2015.1043879)   
62. Villiger M, Chandrasekharan S, Welsh TN. 2011 Activity of human motor system during action observation is modulated by object presence. Exp. Brain Res. 209, 85–93. (doi:10.1007/ s00221-010-2522-x)   
63. Betti S, Castiello U, Guerra S, Sartori L. 2017 Overt orienting of spatial attention and corticospinal excitability during action observation are unrelated. PLoS ONE 12, e0173114. (doi:10.1371/journal.pone.0173114)   
64. Hummel F, Andres F, Altenmüller E, Dichgans J, Gerloff C. 2002 Inhibitory control of acquired motor programmes in the human brain. Brain 125, 404–420. (doi:10.1093/brain/awf030)   
65. Samson D, Apperly IA. 2010 There is more to mind reading than having theory of mind concepts: new directions in theory of mind research. Infant Child Dev. 19, 443–454. (doi:10. 1002/icd.678)

</div>

---

Title: How to Construct a Minimal Theory of Mind
Authors: Stephen A. Butterfill
Year: 2011
Type: Talk



---

Title: Talking About and Seeing Blue
Authors: Stephen A. Butterfill
Year: 2011
Event: Colour and Sensory Knowledge, IUC Philosophy of Science Conference
Type: Talk

## Abstract

Categorical perception is a pervasive and useful feature of human experience much neglected by philosophers despite illuminating psychological research on this topic.  The findings of this research on categorical perception are relevant to the truth of basic claims about which properties humans can perceptually experience and they bear on the validity of arguments about the nature of perception.  Focusing on the case of colour, this talk reviews some of the key evidence for categorical perception and extracts a characterisation.  Together with findings about the development of categorical perception of colour and its complex relations to the use of verbal labels for colour categories, this provides a basis for rejecting what Frank Jackson calls a "subject-determining platitude", namely that "'red' denotes the property of an object putatively presented in visual experience" (Jackson 1996: 200).  Categorical perception of colour differs from other forms of perception with respect to phenomenology and epistemology.  Seeing blue or red, unlike seeing the particular colours of things, does not involve the presentation in visual experience of a property.



---

Title: Intention and Motor Representation in Action Explanation
Authors: Stephen A. Butterfill
Year: 2012
Type: Talk



---

Title: Mindreading and Joint Action
Authors: Stephen A. Butterfill
Year: 2011
Event: Das Gehirn - ein Beziehungsorgan
Type: Talk

## Abstract

In this talk I present some research on minimal theory of mind, on joint action and on relations between the two.



---

Title: How to Construct Cooperative Agents
Authors: Stephen A. Butterfill
Year: 2013
Event: Cooperation: Why, How and With Whom?
Type: Talk



---

Title: Intention and Motor Representation in Joint Action
Authors: Stephen A. Butterfill
Year: 2012
Event: Pre-Reflective and Reflective Processing in Social Interaction
Type: Talk

## Abstract

On the assumption that social motor representation plays a role in explaining how effective joint action is possible, is there also a role for motor representation in explaining what joint action is? Philosophers tend to assume that motor representation is only an enabling condition for joint action and of no direct interest to narrowly philosophical theories of joint action and shared intention. In this talk I shall argue that social motor representation and shared intention have distinctive roles in explaining the purposiveness of joint action. This gives rise to a challenge. On the one hand, effective joint action--imagine two people erecting a tent in a gale together--sometimes requires both shared intentions and social motor representations plus a certain kind of harmony between the two. On the other hand, recognizing their distinctive roles precludes the existence of direct inferential links between shared intentions and social motor representations. The challenge is to explain how these two kinds of representation could sometimes harmoniously contribute to effective joint action despite the lack of inferential integration.



---

Title: Intention and Motor Representation in Joint Action
Authors: Stephen A. Butterfill
Year: 2012
Type: Talk



---

Title: Interacting Mindreaders
Authors: Stephen A. Butterfill
Year: 2012
Type: Talk



---

Title: Joint Action and the Emergence of Mindreading
Authors: Stephen A. Butterfill
Year: 2013
Event: Origins of Social Cognition Lecture Series
Type: Talk



---

Title: Intention and Motor Representation in Explaining Action
Authors: Stephen A. Butterfill
Year: 2012
Event: Reconceptions of Action
Type: Talk



---

Title: Joint Action: Conceptual Tools for Scientific Research
Authors: Stephen A. Butterfill
Year: 2011
Type: Talk



---

Title: Minimal Theory of Mind: How to Measure Mental States
Authors: Stephen A. Butterfill
Year: 2013
Type: Talk



---

Title: Motor Representation and Shared Intention
Authors: Stephen A. Butterfill
Year: 2012
Event: Collective Intentionality VII
Type: Talk

## Abstract

On the assumption that motor representation plays a role in explaining how effective joint action is possible, do we also need motor representation to explain what joint action is? Philosophers tend to assume that motor representation is only an enabling condition for joint action and of no direct interest to narrowly philosophical theories of joint action and shared intention. In this talk I shall argue that social motor representation and shared intention have distinctive roles in explaining the purposiveness of joint action. This gives rise to a challenge. On the one hand, effective joint action--imagine two people erecting a tent in a gale together--sometimes requires both shared intentions and social motor representations plus a certain kind of harmony between the two. On the other hand, recognizing their distinctive roles precludes the existence of direct inferential links between shared intentions and social motor representations. The challenge is to explain how these two kinds of representation could sometimes harmoniously contribute to effective joint action despite the lack of inferential integration.



---

Title: Joint Action and Knowing Others' Minds
Authors: Stephen A. Butterfill
Year: 2011
Event: Mindreading
Type: Talk



---

Title: Joint Action and the Emergence of Mindreading
Authors: Stephen A. Butterfill
Year: 2011
Event: Developmental Aspects of Joint Intentions and Actions
Type: Talk

## Abstract

<p>How can we explain the emergence, in evolution or development, of sophisticated forms of theory of mind cognition?  One conjecture is that their emergence somehow involves joint action (Knoblich & Sebanz, 2006; Hughes & Leekam, 2004; Moll & Tomasello, 2007).  This raises two questions.  First, what forms of theory of mind cognition are required for joint action?  Second, how might abilities to engage in joint action be involved in the emergence of full-blown theory of mind cognition?  This talk will attempt to answer both questions.</p><p>On the first question, it is often held that all joint action involves shared intention.  This is problematic for the conjecture that abilities to engage in joint action partially explain the emergence of theory of mind cognition if, as I argue, shared intention presupposes theory of mind cognition at close to the limits of what humans are capable of.  The problem can be avoided by rejecting the assumption that all joint action involves shared intention.  I shall briefly defend an account of joint action without shared intention.  On this account, joint action presupposes only minimal theory of mind cognition.</p><p>On the second question, I shall explain how abilities to engage in joint action provide a route to knowledge of others' goals distinct from ordinary third-person interpretation.  This allows us to explain how humans are able to break into the Gricean circle and understand communicative intention.  Because communicative intention is a foundation of communication by language, and because communication by language in turn plays a role in the emergence of full-blown theory of mind cognition (Astington & Baird, 2005), this may amount to one (indirect) way in which the combination of joint action with minimal theory of mind cognition partially explains the emergence of full-blown theory of mind cognition.</p>



---

Title: The Problem of Other Minds
Authors: Stephen A. Butterfill
Year: 2011
Event: The British Science Festival
Type: Talk



---

Title: Shared Agency and Motor Representation
Authors: Stephen A. Butterfill
Year: 2012
Type: Talk

## Abstract

Shared agency is paradigmatically involved when two or more people paint a house together, tidy the toys away together, or lift a two-handled basket together.  To characterise shared agency, some philosophers have appealed to a special kind of intention or structure of intention, knowledge or commitment often called `shared intention'.  In this paper we argue that there are forms of shared agency characterising which requires appeal to  motor representation.  Shared agency is not only a matter of what we intend: sometimes it  constitutively involves interlocking structures of motor representation.  This may have consequences for some metaphysical, normative and phenomenological questions about shared agency.



---

Title: Shared Agency with Parallel Planning
Authors: Stephen A. Butterfill
Year: 2013
Event: Collective Intentionality
Type: Talk



---

Title: Minimal Theory of Mind and Joint Action
Authors: Stephen A. Butterfill
Year: 2011
Type: Talk



---

Title: Which Joint Actions Ground Social Cognition
Authors: Stephen A. Butterfill
Year: 2011
Event: Rational Agency
Type: Talk

## Abstract

<p>Several researchers have conjectured that joint action partially explains how sophisticated* forms of cognition emerge in development or evolution (for example, Knoblich & Sebanz 2006; Moll & Tomasello 2007).  If any such conjecture is correct, what could joint action be? </p><p>The leading approach to characterising joint action focuses on shared intention (Bratman 1993, 2009).  A shared intention is something that stands to a joint action roughly as an ordinary intention stands to an individual action.  Given some widely held claims about rationality and knowledge, shared intention requires knowledge of intentions about intentions (Butterfill forthcoming).  So shared intention already presupposes sophisticated* (social) cognition.  If the conjectures about evolution and development are true, not all significant cases of joint action can involve shared intention: if they did, abilities to engage in joint action would presuppose sophisticated* forms of cognition and so could not explain how they are acquired in evolution or development.</p><p>An alternative approach to joint action starts from the claim, motivated by semantic considerations, that a joint action is an action with two or more agents (Ludwig 2007).  An immediate objection to this claim is that, given any of several widely held views about action, events standardly offered as paradigm joint actions turn out not to be joint actions at all.  This objection can be overcome by refining the claim that a joint action is an action with two or more agents.  This alternative approach is necessary for characterising the joint actions that could explain how sophisticated* forms of cognition emerge in development or evolution.</p><p>* - yes, I do realise that the term 'sophisticated' isn't very scientific; the talk will be more specific.</p>



---

Title: Collective Agency and Knowledge of Others’ Minds
Authors: Stephen A. Butterfill
Year: 2013
Event: Aristotelian and Contemporary Perspectives on the Mind
Type: Talk

## Abstract

When friends walk together, they typically exercise collective agency.  By contrast, two strangers walking side by side exercise parallel but merely individual agency.  This and other contrasts invite the question, What distinguishes collective agency from parallel but merely individual agency?  To answer this question, philosophers standardly appeal to a special kind of intention or structure of intention, knowledge or commitment often called 'collective intention'.  The idea is that exercises of collective agency stand to collective intention much as exercises of ordinary, individual agency stand to ordinary, individual intention.  In this talk I shall use this parallel between individual and collective intention to argue that some forms of collective agency are grounded in representations and processes more primitive than those associated with collective intention.  Collective agency is not always a matter of what we intend: sometimes it  constitutively involves certain structures of motor representation.  One consequence is concerns a role for collective agency in explaining knowledge of others' minds.  Reflection on what is involved in sharing a smile suggests that there is a route to knowledge of others' mental states that is neither straightforwardly perceptual nor inferential but hinges on interaction.



---

Title: Collective Intentionality and Social Intelligence
Authors: Stephen A. Butterfill
Year: 2013
Type: Talk



---

Title: Monitoring and Controlling the Mental States of Others
Authors: Stephen A. Butterfill and Ian A. Apperly
Year: 2013
Event: All Souls Metacognition Seminars
Type: Talk

## Abstract

The success of infants and nonhuman animals on some belief reasoning tasks may be best explained by a cognitively efficient but inflexible capacity for tracking belief-like states. In humans, this capacity persists in parallel with a later-developing, more flexible but more cognitively demanding theory-of-mind abilities. The later-developing ability clearly involves meta-cognition, both because it involves thinking about thoughts as such, and because it involves at least some conscious, controlled processes. In contrast the early-developing capacity may not be conscious or controlled, and may not involve thinking about thoughts as such. We will consider how these characteristics may explain the efficiency of the early-developing capacity, and whether this means the capacity is meta-cognitive in any meaningful sense.



---

Title: Motor Representation in Joint Action
Authors: Stephen A. Butterfill
Year: 2013
Event: Vision, Action and Concepts
Type: Talk

## Abstract

What do recent findings about mechanisms for interpersonal coordination reveal about the nature of joint action?  Joint action paradigmatically occurs when two or more people paint a house together, tidy the toys away together, or lift a two-handled basket.  Standard accounts of joint action invoke a special kind of intention or structure of intention, knowledge or commitment often called 'shared intention'.  Arguably, our having a shared intention requires that our plans interlock, which in turn requires that we represent each others' plans.  So, on the standard view, joint action involves representing not only what is to be done but also another's plans for doing it.  In this talk I shall explain how recent findings on mechanisms for interpersonal coordination motivate an alternative view, one that appeals to abilities to act instead of abilities to reflect on others' plans.  Rather than representing each other's plans, it is sometimes sufficient for joint action that we plan each other's actions.  (This may initially appear incoherent; I shall show that it isn't.)  Perhaps, then, there are forms of joint action characterising which requires appeal to motor representation.  Joint action is not only a matter of what we intend: sometimes it constitutively involves certain structures of motor representation.



---

Title: Not Just Wide but Shared: Joint Action Is a Core Form of Social Intelligence
Authors: Stephen A. Butterfill
Year: 2013
Event: Wide Cognition and Social Intelligence
Type: Talk



---

Title: Perceiving Anger and Sharing Smiles: The Roles of Perception and Social Interaction in Acquiring Knowledge of Others’ Mental States
Authors: Stephen A. Butterfill
Year: 2013
Event: Emotion and Social Cognition
Type: Talk

## Abstract

How could we come to know that another is angry about an obstacle she has encountered, or that she is happy about an outcome?  Some such knowledge is uncontroversially acquired by inference.  However, some philosophers have recently defended the hypothesis that knowledge of others' anger or joy might be acquired by perceiving it (e.g. Smith, 2010; McNeill, 2012a,b).  In the first part of this talk I offer a challenge to the view that humans can perceive anger or joy in the same sense that they can perceive shapes or textures.  The challenge is to specify a model of anger and other mental states which captures how these mental states appear to the perceivers.  This is a hard challenge to meet because available models arguably render mental states imperceptible.  In the second part of the talk I propose an alternative way in which knowledge of others' mental states could be acquired, one that hinges on interaction rather than perception or inference.  Reflection on what is involved in sharing a smile suggests that one route to knowledge of others' mental states might involve interacting with them.



---

Title: Planning for Collective Agency
Authors: Stephen A. Butterfill
Year: 2013
Event: Collective Agency and Cooperation in Natural and Artificial Systems
Type: Talk



---

Title: Planning for Collective Agency
Authors: Stephen A. Butterfill
Year: 2013
Type: Talk

## Abstract

What does exercising collective agency require when our acting collectively is intentional?  On the leading, best developed account, Michael Bratman's, intentional collective agency requires shared intention and shared intention is explained in terms of interconnected planning.  For our plans to be interconnected is for them to concern not just facts about our environment and goals but also facts about each others' plans.  In this talk I shall argue that interconnected planning is neither sufficient nor necessary for intentional collective agency.  I shall also defend the possibility that parallel planning might underpin intentional collective agency.  What matters is not whether our plans are interconnected in the sense that they include facts about each others' plans: in some or all cases, what matters for intentional collective agency is rather that we each individually, in parallel plan all of our actions and so conceive of our own and each other's actions as parts of a single plan.  This may have consequences for understanding the roles of motor cognition in collective agency, as well as for modelling and simulating collective agency.



---

Title: Two Systems and Two Theories of Mind
Authors: Ian Apperly and Stephen A. Butterfill
Year: 2013
Event: Theory of Mind, Simulation and Meta-Cognition: Laureate's Colloquium with Josef Perner
Type: Talk

## Abstract

We argue that mindreading involves not only multiple systems but also multiple models (or theories) of the mind.  The argument turns on three questions.  First, how could mindreading be both flexible and efficient?  We suggest that, in a sense it can't.  Instead mindreading involves two or more systems; some trade efficiency for flexibility and others make the converse trade-off.  But how could mindreading--which paradigmatically involves constructing reason-giving, causal explanations for actions by appeal to mental states with arbitrarily nestable contents and uncodifiably complex functional roles--ever be efficient?  One possibility is that mindreading sometimes involves unsophistcated but useful models of the mind.  If this is right, we face a third question.  How can hypotheses about which model of the mind a mindreader is using be tested?   Unsophisticated models have signature limits, and these limits may make it possible to identify the operation of a given model across contexts and across types of subject.



---

Title: Varieties of Joint Action
Authors: Stephen A. Butterfill
Year: 2013
Event: Varieties of Shared Intentionality
Type: Talk



---

Title: Joint Action
Authors: Stephen A. Butterfill
Year: 2014
Type: Talk



---

Title: Joint Action without Mindreading
Authors: Stephen A. Butterfill
Year: 2014
Type: Talk

## Abstract

Joint action is a familiar feature of everyday life.  Paradigmatic joint actions include things like painting a house together, walking together and playing a piano duet.  On leading accounts of joint action, engaging in joint action presupposes mindreading abilities.  But are there forms of joint action engaging in which would not require mindreading?  In this talk I aim to identify interagential structures of motor representation that play a role in coordinating some joint actions, and to argue that this role is parallel to one played by shared intention.  The parallel indicates that we can give a theoretically coherent and empirically motivated account of a form of joint action that does not require mindreading.  This  removes an obstacle to holding that abilities to engage in joint action partly explain the emergence, in evolution or development, of mindreading.



---

Title: Minimal Models of the Physical and of the Mental: Processes, Representations and  Signature Limits
Authors: Stephen A. Butterfill
Year: 2014
Event: Minimal Mindreading
Type: Talk

## Abstract

This talk introduces a series of hypotheses and claims about the systems and models involved in mindreading (or ‘theory of mind’), explains how they generate predictions by drawing a parallel with cognition of physical properties like momentum, and highlights some recent evidence indicating that some of the hypotheses may be correct.



---

Title: Naturalising Joint Actions
Authors: Stephen A. Butterfill
Year: 2014
Event: Naturalising Action
Type: Talk

## Abstract

Joint action is a familiar feature of everyday life. Paradigmatic cases include moving objects together, walking together and playing piano duets. Many joint actions comprise two or more actions involving multiple agents which are purposive in this sense:  among all of their actual and possible outcomes, there is one or more to which the actions are collectively directed. One challenge for an account of joint action is to provide a framework for explaining in virtue of what actions involving multiple agents are collectively  directed to outcomes. A familiar way to meet this challenge is by appeal to one or another notion of shared intention. In this paper we show that more is needed to fully meet the challenge. In some cases, actions involving multiple agents are collectively directed to an outcome not in virtue of any kind of shared intention but in virtue of a certain interagential structure of motor representations. Further, some joint actions are collectively directed to outcomes partly in virtue of this interagential structure of motor representations. This suggests that the building blocks needed for constructing an account of joint action may include not only shared intention but also a certain interagential structure of motor representations.  We conclude by discussing some consequences for accounts of shared intention.



---

Title: Shared Agency Involves Changing Perspective
Authors: Stephen A. Butterfill
Year: 2014
Type: Talk



---

Title: Acting Together & Acting as One
Authors: Stephen A. Butterfill
Year: 2015
Event: Desire and Action
Type: Talk



---

Title: Only Phenomenal Expectations Connect Core Knowledge of Objects to Thought
Authors: Stephen A. Butterfill
Year: 2015
Event: The Nature and Origins of Human Cognition
Type: Talk

## Abstract

Infants have core knowledge of objects, causes, numbers, actions and much else besides (Spelke, 2003; Carey, 2009).  But what is core knowledge?  There are challenges which apply to the leading theoretical accounts (compare Butterfill, 2007; Keren and Schul, 2009; Adolphs, 2010).  A way of responding to these challenges exists for the case of core knowledge of objects, however: several researchers have conjectured that infants’ core knowledge consists in a system of object indexes (Leslie et al. 1998; Scholl and Leslie 1999; Carey and Xu 2001; Scholl 2007). One consequence of this conjecture is the existence of an interface problem.  The representations and processes which comprise the workings of object indexes have only limited influences on thought and action.  How then could core knowledge play a role in explaining the emergence, in development, of knowledge concerning physical objects and their interactions?  One possibility hinges on the notion of a phenomenal expectation, which is approximately a sensation in Reid’s sense (Reid, 1785a,b). You have a phenomenal expectation concerning an object’s movements where these are unperceived in the most straightforward sense (because they are occluded, for example) and yet your overall experience is not neutral concerning the object’s movements either.  Perhaps the transition from core knowledge to knowledge proper has such a protracted developmental course because only phenomenal expectations connect core knowledge of objects to thoughts about objects.



---

Title: Acting Together: Motor Representation and Cooperation
Authors: Stephen A. Butterfill
Year: 2015
Event: Kolloquium des Instituts für Philosophie II
Type: Talk



---

Title: Commentary on Wolfgang Prinz and Michael Graziano
Authors: Stephen A. Butterfill
Year: 2015
Event: Modelling Self on Other
Type: Talk



---

Title: Acting Together and Acting As One
Authors: Stephen A. Butterfill
Year: 2015
Event: Empathy, Group Membership and We-Intentionality
Type: Talk



---

Title: How Do Mindreaders Model Minds?
Authors: Stephen A. Butterfill
Year: 2015
Event: Mindreading, an invited symposium at the European Soceity for Philosophy and Psychology (ESPP)
Type: Talk

## Abstract

"What it is to be a mindreader?
Mindreading involves identifying mental states; this requires having some model of the mental, much as identifying physical states requires having some model of the physical.  
And philosophical failures to characterise minds reveal that there are multiple models of the mental, much as 
the history of science reveals that there are multiple models of the physical.  
To say that someone is a mindreader therefore leaves open the question of which model of the mental she is using.  
Just as humans use multiple models of the physical (an expert physicist will probably leave quantum mechanics behind when putting up a garden fence in favour of a model she can more efficiently deploy), so it is likely that they use multiple models of the mental.  
This may matter for understanding why mindreading is sometimes but not always automatic—some models are relatively easy to acquire or apply but are limited in accuracy, others are harder to acquire and use but also more accurate.  
But how can we test hypotheses about which model is used in a particular task?  As in the physical case, different conjectures about models of the mental can be distinguished because different models have different signature limits.
In particular, one class of models, minimal models of the mental, have signature limits involving identity.  
Recent scientific discoveries indicate that these limits can be used to confirm conjectures about how infant and adult mindreaders model minds.



---

Title: Systems, Models and Signature Limits
Authors: Stephen A. Butterfill
Year: 2015
Event: Signature limits in implicit theory of mind: Evidence for two systems of mindreading?  Workshop at the Society for Research in Child Development
Type: Talk

## Abstract

"Two puzzles about mindreading, and in particular the nature of belief ascription, require resolution.  Can infants ascribe false beliefs in their first or second year of life?  Some measures indicate that they can, others that they cannot.  Is belief ascription automatic?  Some findings suggest that it is, others that it is not.  Reflection on these puzzling patterns of findings suggests that we should step back to ask, What it is to ascribe beliefs?  More generally, What it is to be a mindreader?  

Mindreading involves representing mental states; this requires having some model of the mental, much as representing physical states requires having some model of the physical.  The history of science reveals that there are multiple models of the physical.  Some models are relatively easy to acquire or apply but are limited in accuracy, others are harder to acquire and use but also more accurate.  The first part of this talk will show that there are also multiple models of the mental.  To say that someone represents beliefs or other mental states leaves open the question of which model of the mental she is using.  

Just as humans use multiple models of the physical (an expert physicist will probably leave quantum mechanics behind when putting up a garden fence in favour of a model she can more efficiently deploy), so it is likely that they use multiple models of the mental.  But how can we distinguish among hypotheses about which model is used in a particular task?  In the physical case, such hypotheses can be distinguished by identifying signature limits.  To illustrate, impetus mechanics makes incorrect predictions about certain trajectories.  If a certain group of individuals use impetus mechanics on a particular task, they should make incorrect predictions about these trajectories.  Testing whether they make such predictions can therefore yield evidence about which model of the physical they are using.  The second part of this talk will show that certain models of the mental have signature limits.  In particular, simpler models of the mental are limited in making incorrect predictions when beliefs essentially involve identity.  Other talks in this symposium provide evidence that, in certain cases, mindreading exhibits this signature limit.

A conjecture about how mindreaders variously model minds does not completely solve the puzzles about the automaticity and development of mindreading.  The third part of this talk concerns systems; that is, the different ways in which a model of the mind can be implemented cognitively in an actual mindreader.  It is a familiar idea that different models of the physical are implemented in different cognitive systems; representing physical states can involve core systems or modules, for example.  Representing mental states may similarly involve multiple systems.  Conjectures about multiple systems are linked to conjectures about the models they implement.  If mindreading involves multiple systems which implement multiple models of the mind, we can discover this thanks to relations between systems and models and their signature limits.



---

Title: Introduction to the Workshop on Practical Reasoning and Motor Representation
Authors: Stephen A. Butterfill and Corrado Sinigaglia
Year: 2015
Event: Practical Reasoning and Motor Representation
Type: Talk



---

Title: Purposive Action from Motor Representation to Intention
Authors: Stephen A. Butterfill
Year: 2015
Event: How much mind do we need for responsibility?
Type: Talk



---

Title: How to Distinguish Two (Or More) Systems for Social Cognition
Authors: Stephen A. Butterfill
Year: 2016
Event: The Nature and Origins of Human Cognition
Type: Talk

## Abstract

Suppose you observe two exercises of competence in social cognition and want to know 
whether the systems underpinning the exercises are the same or distinct.  How can you tell?  An immediate obstacle is theoretical: there are many attempts to characterise ‘system’, each only slightly different from the next, and no obvious principle for deciding between competing characterisations.  You therefore cannot rely on any one theory.  Despite this obstacle, it seems to be possible to formulate hypotheses about the distinctness (or identity) of systems which generate testable predictions.  But how?  This talk aims to extract a recipe for distinguishing (or identifying) systems from research on understanding speech, action, emotion and belief.



---

Title: Core Knowledge, Phenomenal Expectations and Thought
Authors: Stephen A. Butterfill
Year: 2016
Event: New Directions in Philosophical Psychlogy
Type: Talk

## Abstract

How is core knowledge linked to full-blown thought and intentional action?  Infants in the first months of life have core knowledge of objects, causes, numbers, actions and much else besides (Spelke, 2003; Carey, 2009).  But what is core knowledge?  There are challenges which apply to the leading theoretical accounts (compare Butterfill, 2007; Keren and Schul, 2009; Adolphs, 2010).  One way of responding to these challenges exists for the case of core knowledge of objects, however: several researchers have conjectured that infants’ core knowledge consists in a system of object indexes (Leslie et al. 1998; Scholl and Leslie 1999; Carey and Xu 2001; Scholl 2007). Accepting this conjecture does enable us to answer challenges to the theoretical coherence of postulating core knowledge, but it also means we are confronted with a further challenge about the interface between core knowledge and thought.  The representations and processes which comprise the workings of object indexes have only limited influences on thought and action.  How then could core knowledge play a role in explaining the emergence, in development, of full-blown thought about, and intentional action on, physical objects?  I propose that one possibility hinges on the notion of a phenomenal expectation, which is approximately a sensation in Reid’s sense (Reid, 1785a,b). In general, an aspect of the overall phenomenal character of an experience is a phenomenal expectation just if its subject routinely and unthinkingly takes it to be informative about things that are only distantly related (if at all) to what experiences associated with this aspect of phenomenal character intentionally relate the subject to.  Phenomenal expectations can provide a low-cost, efficient link between core knowledge and full-blown thought and intentional action.  Perhaps the transition from core knowledge to knowledge proper has such a protracted developmental course because only phenomenal expectations connect core knowledge of objects to thoughts about objects.



---

Title: Perceiving Mental States
Authors: Stephen A. Butterfill
Year: 2015
Type: Talk

## Abstract

How could we come to know that another is angry about an insult or happy about an outcome?  Some philosophers have defended the hypothesis that knowledge of others' anger or joy is sometimes perceptual (e.g. Smith, 2010, 2015; McNeill, 2012a,b).  In this talk I consider two challenges to this hypothesis.  The first challenge is to identify evidence in favour of it, or at least to explain what evidence could bear on the hypothesis.  Perhaps this challenge can be met by considering categorical perception of expressions of emotion, for which there is some evidence. The second challenge is to specify a model of anger and other mental states which captures how these mental states appear to the perceivers.  This is a hard challenge to meet because available models arguably render mental states imperceptible.  In the last part of the talk I propose an alternative way in which knowledge of others' mental states could be acquired, one that hinges on interaction rather than perception.  Reflection on what is involved in sharing a smile suggests that one route to knowledge of others’ mental states might involve interacting with them.



---

